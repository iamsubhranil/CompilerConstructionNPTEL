1
00:00:00,000 --> 00:00:15,439
Okay, so let us start now the session. So one thing is that last session all of you

2
00:00:15,439 --> 00:00:20,039
look very sleepy, so look like you are tired of static analysis, right? All of you become

3
00:00:20,039 --> 00:00:27,560
very static. So I need to get some dynamism in you. So we will get to, we will look at

4
00:00:27,559 --> 00:00:33,280
something called dynamic analysis. So not much but at least I will give you introduction

5
00:00:33,280 --> 00:00:42,200
what does it mean, what to do with it.

6
00:00:42,200 --> 00:00:51,560
So the analogy was that remember we said that, so we said that there are two ways of, even

7
00:00:51,560 --> 00:00:57,280
as a human there are multiple ways of inspecting a program and figuring out what is going on.

8
00:00:58,000 --> 00:01:05,120
So what were the different ways we said we could really find, maybe let us say find a

9
00:01:05,120 --> 00:01:11,920
bug in a program. One is we can actually stare at the code and then say okay what is going

10
00:01:11,920 --> 00:01:16,680
on with it. That was static analysis because you are just looking at the program text and

11
00:01:16,680 --> 00:01:20,799
try to figure out what is going on. It was a very similar case with our analysis that

12
00:01:20,799 --> 00:01:26,159
we were doing till now. We were just analyzing the program text which was maybe compiled

13
00:01:26,159 --> 00:01:29,840
down to bit code or whatever it is and then it was, we analyzed the bit code. But whatever

14
00:01:29,840 --> 00:01:35,000
it is, it is the form of the program text, right? We were not doing anything with the,

15
00:01:35,000 --> 00:01:40,239
we were not trying to understand the executions of the program. So the other way of analyzing

16
00:01:40,239 --> 00:01:46,039
a program is to simply run the program a lot of inputs, collect what happens on those different

17
00:01:46,039 --> 00:01:50,039
inputs and they say oh looks like the program is doing this, right?

18
00:01:50,039 --> 00:01:54,239
Like for example, let us say you want to figure out what a certain program is doing. What

19
00:01:54,239 --> 00:01:59,919
you can do is you can essentially stare at the text and say oh two integers plus a plus

20
00:01:59,919 --> 00:02:05,119
b okay it is adding two numbers. The other option is just run the program on different

21
00:02:05,119 --> 00:02:11,240
inputs. You give 1 and 2, it gives 3. You give 4 and 5, it gives 9, right? And then

22
00:02:11,240 --> 00:02:15,159
say oh I tested it on quite some few programs. Every time it gives the addition of two numbers.

23
00:02:15,159 --> 00:02:21,379
So must be the program which adds two numbers. What is the problem in each of these two cases?

24
00:02:21,379 --> 00:02:29,259
So let us say static analysis and dynamic analysis. So what is the pros and the cons

25
00:02:29,259 --> 00:02:47,939
do you think? Static analysis will be? Ensure the correctness. Excellent, excellent. That

26
00:02:47,939 --> 00:02:52,500
is the main important point, right? For a static analysis we are trying to analyze all

27
00:02:52,500 --> 00:02:59,340
possible executions and then say what might have happened, what might happen, right? However,

28
00:02:59,340 --> 00:03:05,060
in dynamic analysis we simply run the program on few inputs and that is all I get to see.

29
00:03:05,060 --> 00:03:08,419
So let us say even this addition of two numbers maybe if the program was something like this

30
00:03:08,419 --> 00:03:21,379
where it says if a is greater than b then return like a plus b else return a minus b. So let us

31
00:03:21,379 --> 00:03:28,299
say all the inputs you sampled with one of them were a greater than b. So you never even handle

32
00:03:28,299 --> 00:03:31,699
the other side. You never even went to the other side. So you never got an output where you got

33
00:03:31,699 --> 00:03:35,899
the other result. So you never got to know that the program has a different behavior because you

34
00:03:35,900 --> 00:03:41,539
never run the program on an input which could have exhibited that other behavior. However,

35
00:03:41,539 --> 00:03:46,580
in a static analysis you would have done some sort of like MFP analysis where this would be

36
00:03:46,580 --> 00:03:50,860
one basic log, this would be one basic log and you will take a join of these two basic logs.

37
00:03:50,860 --> 00:03:56,900
So no matter what you would have anyway seen tried to capture the different behaviors. Very

38
00:03:56,900 --> 00:04:00,460
good. So if static analysis is so good why should you even have dynamic analysis?

39
00:04:00,460 --> 00:04:13,100
But I still have to do an analysis. So what do we do in that case? You are on the exactly

40
00:04:13,100 --> 00:04:19,900
the right path. No, but I can still take anything and do some sort of static analysis on it.

41
00:04:19,900 --> 00:04:30,379
Debugging I can do static analysis also. I can try to see what are the different like for the

42
00:04:30,379 --> 00:04:33,819
buffer overflow example. We were trying to do debugging in static analysis. We were trying

43
00:04:33,819 --> 00:04:38,300
to find out the range sets of the index and whichever if the index can overflow then I

44
00:04:38,300 --> 00:04:52,899
would say that well looks like there could be a bug. No, but that you can do in static analysis

45
00:04:52,899 --> 00:05:01,979
also. So static analysis will tell you the you can do a pointer analysis as a static analysis

46
00:05:01,979 --> 00:05:10,339
and it will tell you the what are the locations it can point to. What is that bit of uncertainty?

47
00:05:10,339 --> 00:05:17,379
Why is that there is a certain bit of uncertainty? So what it is summarizing things for all inputs.

48
00:05:17,379 --> 00:05:24,819
That is what we want. I want to know the summary overall inputs. That is anyway what I want to

49
00:05:24,819 --> 00:05:41,500
capture. Those things I can always discount in static analysis also. I can say don't even look

50
00:05:41,500 --> 00:05:46,420
at paths which are going here or coming from here. I can do the discounting. So it's a matter of

51
00:05:46,420 --> 00:05:53,620
modeling the program properly, modeling those constructs properly. Just think about what all

52
00:05:53,620 --> 00:05:59,900
we learned last time. So we are doing an MFP analysis. So what cannot be nice in that setting?

53
00:05:59,899 --> 00:06:21,099
So we are doing this. We did this data analysis. So what was the property of the MFP analysis?

54
00:06:21,100 --> 00:06:30,140
So what is the ultimate thing? The ultimate thing is I want the MOP solution no matter I do

55
00:06:30,140 --> 00:06:34,540
a static analysis or dynamic analysis. In dynamic analysis also if I am able to capture all paths

56
00:06:34,540 --> 00:06:41,140
and I can summarize the results across all paths, I will be most happy. That is like awesome life.

57
00:06:42,260 --> 00:06:49,180
So problem is your inputs can be, number of inputs can be infinite. It may not even be bounded.

58
00:06:49,300 --> 00:06:55,740
That is what is happening in dynamic analysis. Some parts are not sampled. Some parts are

59
00:06:55,740 --> 00:07:00,340
sampled because that input is seen. Some parts are not sampled because input is not seen. And

60
00:07:00,340 --> 00:07:06,780
as I do a meet of all paths only on the paths which are sampled. So that is the idea. The idea

61
00:07:06,780 --> 00:07:12,980
is that instead of looking at all executions, I do a few executions and I take a meet over,

62
00:07:12,980 --> 00:07:21,660
meet or join over whatever results I have seen there. So the problem is that there are certain

63
00:07:21,660 --> 00:07:26,980
paths which are missed out. I have not seen them in execution of those paths. So it is not really

64
00:07:26,980 --> 00:07:34,020
the MOP solution. So if I do this meets of join path like this, then let us say I have,

65
00:07:34,180 --> 00:07:49,459
this is my solution dynamic. This is my solution static and this is my solution actual. Can

66
00:07:49,459 --> 00:08:02,699
I give, can you give me a relation among them? So what is happening in static analysis? So what

67
00:08:02,699 --> 00:08:07,819
happened with the MOP solution? We end up computing the MOP solution. So the MOP solution

68
00:08:07,819 --> 00:08:20,180
and MOP solution, how are they related? So it is an, so the MOP is over approximated as the MOP

69
00:08:20,180 --> 00:08:31,980
solution. So essentially then what is it? So S star is over approximated by S static, solution

70
00:08:31,980 --> 00:08:41,139
static. What happened in case of dynamic analysis? Some paths are missed out. This S static is this

71
00:08:41,139 --> 00:08:46,460
optimal solution is actually the MOP solution, is the solution I would have liked to have. But

72
00:08:46,460 --> 00:08:52,460
I did not get all the paths. I just got a few sample paths and I took a meet over those sample

73
00:08:52,460 --> 00:09:00,539
paths, meet or join over those sample paths. So then what is the solution then? So it is smaller

74
00:09:00,539 --> 00:09:14,939
than this. So this is exactly the crux of the situation. So I would have liked to reach a star,

75
00:09:14,939 --> 00:09:22,779
but either I have to go the static way and reach an over approximation or I have to reach,

76
00:09:22,779 --> 00:09:36,980
go the dynamic way and get an under approximation. So if I was doing, so like if you try to use those

77
00:09:36,980 --> 00:09:42,899
results in a compiler that can be dangerous because I can miss out on definitions if I am

78
00:09:42,899 --> 00:09:50,419
reaching definition in a dynamic way. So I might think oh this does not reach and I can do an

79
00:09:50,419 --> 00:10:03,500
optimization which can really spoil things. So dynamic analysis generally, I will come to that

80
00:10:03,500 --> 00:10:09,740
okay because I agree this is a compiler school so I should always connect to compilers. But dynamic

81
00:10:09,740 --> 00:10:15,219
analysis has already many other applications other than compilers like for instance in program

82
00:10:15,220 --> 00:10:21,620
debugging like somebody also already said. The good part about that is that if you see a fact

83
00:10:21,620 --> 00:10:27,940
in a dynamic analysis that fact is surely there because I saw an execution that is why I included

84
00:10:27,940 --> 00:10:33,940
that factor. If I say some dynamic some reaching definition is there in this set I do not know

85
00:10:33,940 --> 00:10:37,580
what all reaching definition I missed. If I missed anything or not that I don't know,

86
00:10:37,580 --> 00:10:46,060
but whatever I included surely that is there. But in case of static analysis it can happen

87
00:10:46,060 --> 00:10:52,940
that it came due to some over approximation. Not in the reaching definition case because here

88
00:10:52,940 --> 00:11:00,259
the solutions converge to the A star but in other analysis like constant propagation for instance.

89
00:11:00,259 --> 00:11:08,299
So constant propagation if I do the dynamic way if it says that somewhere a value 5 is seen you

90
00:11:08,299 --> 00:11:15,860
are sure that that value 5 is seen there. It may be that some other value 8 is also possible that

91
00:11:15,860 --> 00:11:20,179
is a different matter but that value 5 must have been there at least through some execution.

92
00:11:23,059 --> 00:11:28,980
So essentially one is the curse of over approximation the other is that of under

93
00:11:28,980 --> 00:11:34,500
approximation. So none of them is bad or good it is very difficult to make a pick.

94
00:11:34,500 --> 00:11:40,500
So it is always good to know both and depending on the situation you use whatever you want to use.

95
00:11:40,500 --> 00:11:47,740
Sir in the case of dynamic analysis if you look at it out of the context of the compiler,

96
00:11:47,740 --> 00:11:53,940
so wouldn't it be used for it and through an invariant property or something like that?

97
00:11:53,940 --> 00:11:57,340
But an invariant will be has to hold across all program executions.

98
00:11:57,340 --> 00:12:07,420
No it is possible and it is done. So one way it is done is program invariant an interesting

99
00:12:07,420 --> 00:12:12,460
property of program invariant is let me just include the whole class. So there is this notion

100
00:12:12,460 --> 00:12:17,620
of program invariant. So these are actually the tools that you use to prove the correctness of

101
00:12:17,620 --> 00:12:23,100
programs. So for example a program invariant there simply you can just simply think them of

102
00:12:23,100 --> 00:12:27,139
some predicates. You can just say that the program invariant at a certain point is i is

103
00:12:27,139 --> 00:12:34,899
greater than 0 which means that no matter what path I come to this place the value of i will

104
00:12:34,899 --> 00:12:38,740
always be greater than 0. So that is an invariant at the program point. Why is it interesting?

105
00:12:38,740 --> 00:12:45,220
Because let us say I am doing a division of I am doing a divided by b. I am computing some x

106
00:12:45,220 --> 00:12:53,860
equals a divided by b and I can prove that at all through all paths I can prove that b is greater

107
00:12:53,860 --> 00:13:02,779
than 25. Let us say I can find this invariant. Why is it interesting? So I have this statement

108
00:13:02,779 --> 00:13:14,660
which is x is equal to a divided by b. Why is it interesting? Yes I cannot do a divide by 0 because

109
00:13:14,659 --> 00:13:19,659
I know b is always greater than 25. So I can prove I can give you with guarantee that there

110
00:13:19,659 --> 00:13:28,740
is no way that this guy can produce a divide by 0 error. Now the problem is that there are

111
00:13:28,740 --> 00:13:35,339
certain invariants I mean most often invariants have to be guessed they cannot be computed like

112
00:13:35,339 --> 00:13:40,939
especially loop invariants. So they you basically can guess an invariant and you can check if that

113
00:13:40,940 --> 00:13:47,380
is invariant or not. But that guessing has to be done like through a clever guy. Some guy has to

114
00:13:47,380 --> 00:13:52,020
come and scratch his head and look at the code and say oh looks like this is invariant. And then

115
00:13:52,020 --> 00:13:55,860
it can be checked it is invariant or not and you can throw it away even if it is not invariant.

116
00:13:55,860 --> 00:14:01,220
I am not getting into details but a dynamic analysis is good way of guessing that invariant.

117
00:14:02,380 --> 00:14:06,020
So if you sample a few program paths all of them you observe that b is greater than 25.

118
00:14:06,059 --> 00:14:11,659
Propose that invariant, propose it okay let the invariant b is greater than 25. Then you can

119
00:14:11,659 --> 00:14:18,059
anyway formally check you can actually statically check if it is correct or not. So there are many

120
00:14:18,059 --> 00:14:26,179
situations where such analysis becomes really interesting because of that. So the main difference

121
00:14:26,179 --> 00:14:34,860
again just to summarize is that whenever I get a behavior in static analysis because it is an

122
00:14:34,860 --> 00:14:45,100
over approximation I get something called false positives which means that it may say that a

123
00:14:45,100 --> 00:14:49,419
certain faulty behavior is possible though that behavior is not possible because it did an

124
00:14:49,419 --> 00:14:59,259
over approximation. However in case of dynamic analysis I can essentially miss behaviors right

125
00:14:59,259 --> 00:15:04,700
because this guy is only sampling on a few paths and it may not see the faulty behavior which it

126
00:15:04,700 --> 00:15:14,020
would have seen if it had been able to see all paths. Fine okay good so now the question is how

127
00:15:14,020 --> 00:15:20,180
do we do dynamic analysis? How can we go about doing dynamic analysis? So let us say the dynamic

128
00:15:20,180 --> 00:15:24,540
analysis I want to do or let me just answer one question there somebody asked me I will forget

129
00:15:24,540 --> 00:15:33,020
about it. So why do you think it will be interesting for a compiler to do any form of dynamic analysis?

130
00:15:33,019 --> 00:15:45,419
Because the facts I produce from this I may not be able to use because they may not be safe. So

131
00:15:45,419 --> 00:15:53,699
if I directly use them in an optimization I can produce wrong results. So what can we do? So why

132
00:15:53,699 --> 00:15:59,379
can a compiler be interested in some sort of dynamic analysis? So can you give me some interest

133
00:15:59,379 --> 00:16:04,539
in dynamic analysis? Something that you can do by just executing the program multiple times.

134
00:16:04,539 --> 00:16:12,059
Oh my god it is so long I mean slowly much simpler things.

135
00:16:34,539 --> 00:16:46,500
No but then I might have missed even for that particular platform I might have missed some

136
00:16:46,500 --> 00:16:52,500
inputs so that I be greater than 25 may not even hold for even for that execution even for that

137
00:16:52,500 --> 00:17:03,779
environment. But even those inputs you may not be able to sample the complete all of them right even

138
00:17:03,779 --> 00:17:26,819
that set might be very large if not unbounded. So conditional jumps are nothing but what is

139
00:17:26,819 --> 00:17:41,939
used to implement your if statements they are very common things. No but you have already done

140
00:17:41,939 --> 00:17:46,899
the analysis and then you have already compiled the code right so the code is already compiled.

141
00:17:46,899 --> 00:17:53,779
Now even if you see that jump there is not much you can do you have already spoiled whatever had

142
00:17:53,779 --> 00:17:59,899
to be spoiled right so the dinner is over then you realize that so that is not going to help me now.

143
00:17:59,899 --> 00:18:15,460
Yeah that is okay. The input from a user is a different channel altogether of course we can

144
00:18:15,460 --> 00:18:19,500
take annotation from user which can help us but here we are saying we just sample from program

145
00:18:19,500 --> 00:18:25,180
executions what can we do with that. So one very interesting very important dynamic analysis is

146
00:18:25,180 --> 00:18:34,460
referred to as profiling program profiling rather control flow profiling. So control

147
00:18:34,460 --> 00:18:40,140
flow profiling is actually used to let us say count how many times a program statement is

148
00:18:40,140 --> 00:18:48,779
executed right I just count how many times a program statement is executed that is it big

149
00:18:48,779 --> 00:18:55,019
deal why should I be interested in doing that that is maybe similar to what Ujjal wanted to say

150
00:18:55,019 --> 00:19:02,299
probably. So once I know that histogram if I know that how many times a instruction is executed what

151
00:19:02,299 --> 00:19:09,019
can I do with it. No it is executable time does not mean that the state change will be the same

152
00:19:09,019 --> 00:19:19,259
no cache is like if it was making the same transition even if it is the i plus plus like

153
00:19:19,259 --> 00:19:25,660
if the value of i is 2 it becomes 3 but if the value of i is 45 it becomes 46 so caching 2 to 3

154
00:19:25,660 --> 00:19:33,500
is not going to help me much. It caches the instruction but instruction caching doesn't

155
00:19:33,500 --> 00:19:38,299
work like that right so there is a prefetcher and so you can do some sort of prefetching

156
00:19:38,379 --> 00:19:48,779
additional but that is one way but how will it is a compiler manage memory maybe but more simply I mean

157
00:19:54,539 --> 00:20:00,139
that is a good point right I can find out how many times a function is executed if I see a

158
00:20:00,139 --> 00:20:05,339
function is executed a lot of times I can inline that function so what is inlining a function

159
00:20:05,419 --> 00:20:08,619
basically copying its whole code inside it what does it save

160
00:20:10,699 --> 00:20:15,500
yeah so it's a lot of code to actually make a function call you have to push the parameter

161
00:20:15,500 --> 00:20:20,939
onto the stack push the return address make the jump right even coming back you have to destroy

162
00:20:20,939 --> 00:20:24,699
the frame so there is so much to do right so you can save all that if you inline the code

163
00:20:25,419 --> 00:20:29,099
but you would not like to do it for the whole program because then the code becomes too much

164
00:20:29,099 --> 00:20:34,379
and the same function may be used a lot of times and duplication of code a lot of problems so maybe

165
00:20:34,380 --> 00:20:38,460
for a few functions which you know are small and use a lot often I can do this business

166
00:20:39,580 --> 00:20:46,540
the other thing is let's say for example I have I know that I have an if-then-else statement and

167
00:20:46,540 --> 00:20:52,220
I know that this statement is executed more often than this statement like sorry the if branch is

168
00:20:52,220 --> 00:20:58,700
the then branch is executed more often than the edge branch let's say you know that so then there

169
00:20:58,700 --> 00:21:05,019
are certain optimizations you can do to sort of speed speed up executions along this path

170
00:21:06,380 --> 00:21:12,220
right try to always do things along this path it might happen that you miss out something here

171
00:21:12,220 --> 00:21:16,940
right so maybe the cost of this path increases actually right the other path maybe the cost

172
00:21:16,940 --> 00:21:22,620
increases which as I said yesterday is not allowed by our traditional optimization our

173
00:21:22,620 --> 00:21:27,740
traditional optimization will not allow that if the execution cost of any path increases it will

174
00:21:27,740 --> 00:21:32,859
say I cannot do that optimization right but there are these special optimizations referred

175
00:21:32,859 --> 00:21:38,620
to as pgo's or profile guided optimizations which can do that which are allowed to do that

176
00:21:38,620 --> 00:21:43,420
which can say that okay if I have a heavily heavily executed path I can push more code there

177
00:21:43,420 --> 00:21:51,339
I can sorry I can reduce code there or make that path lighter right even if I do not like for

178
00:21:51,339 --> 00:21:58,939
example what can you do let's say for example I have this particular program and I know that

179
00:21:58,939 --> 00:22:10,220
this particular path maybe let's use a blue let's say this blue path is very heavily executed and

180
00:22:11,019 --> 00:22:15,740
let me just try to say what statements are there

181
00:22:21,819 --> 00:22:22,459
you

182
00:22:22,460 --> 00:22:51,460
Let us say x and z are already initialized. Let us say I have this computation.

183
00:22:51,460 --> 00:23:10,700
Let us say I have this computation. So, what can I do here? Can I do something if I know

184
00:23:10,700 --> 00:23:24,019
that this blue path is heavily executed? How? Now, I mean, I am specifically giving you

185
00:23:24,019 --> 00:23:44,539
an example. So, on this example, what can you do? I cannot remove z. Yeah. I can do

186
00:23:44,539 --> 00:23:52,539
what? No. So, essentially the thing is that this particular maybe this is not a good example.

187
00:23:52,539 --> 00:24:05,779
I can actually do a traditional optimization here. No, I want a specific answer and I will

188
00:24:05,779 --> 00:24:29,460
have that answer. I do not want any other answer. Okay. Let us say this. Let us say

189
00:24:29,460 --> 00:24:44,460
this is the example. So, what can I do? Where do I pre-compute it? No, but I still have

190
00:24:44,460 --> 00:24:49,460
to compute it. How does it help me? There is no redundancy, right? A plus B is not computed

191
00:24:49,460 --> 00:24:52,460
multiple times. It is still, even if you computed it temporarily, you still have to do that

192
00:24:52,460 --> 00:24:58,460
computation. No, but you do not know. Let us say this is the whole program. Let us say

193
00:24:58,460 --> 00:25:20,460
this is the whole program. Okay, I give a more. I will keep on changing it till I get

194
00:25:20,460 --> 00:25:39,460
the answer I want. What about this particular case? Yeah, so I can. So, let us think of

195
00:25:39,460 --> 00:25:45,620
constant propagation. So, this will not allow constant propagation. Why not? Because I am

196
00:25:45,620 --> 00:25:49,779
getting different values of x along different paths. So, I will get a not constant and I

197
00:25:49,779 --> 00:25:55,579
will get a non-constant here and I cannot do constant propagation. But now, if you

198
00:25:55,579 --> 00:26:03,180
allow me to do constant propagation, modular profile information, then if I know that this

199
00:26:03,180 --> 00:26:11,139
path is heavily executed, then I can actually could put constant propagate it 5 here.

200
00:26:11,140 --> 00:26:28,620
Yeah, it is unsafe. No, but that does not help. Not constant, constant are at analysis

201
00:26:28,620 --> 00:26:34,100
time. At runtime, these entities do not exist. At runtime, these are actual program states

202
00:26:34,100 --> 00:26:38,500
where these guys have values and you are running only one execution then. Something becomes

203
00:26:38,500 --> 00:26:42,660
non-constant because there can be coming through different executions. It may be a

204
00:26:42,660 --> 00:26:46,819
program input, but when you are executing the program, you know the inputs. They are

205
00:26:46,819 --> 00:26:51,220
already values and you can actually know which path you are taking. So, actually taking exactly

206
00:26:51,220 --> 00:27:01,220
one program path. Yes, so essentially what you can do is, so these are referred to this

207
00:27:01,220 --> 00:27:11,140
class of, you can do something called speculation. So, you speculate that because this guy is

208
00:27:11,140 --> 00:27:18,380
5, now it is constant propagate z and this whole thing you can say output as 5. What

209
00:27:18,380 --> 00:27:26,660
you can do is, you can put a check here. Did I end up taking the same path? If your check

210
00:27:26,660 --> 00:27:32,860
fails, so this is like putting an extra information, extra code here, a check code here. If that

211
00:27:32,860 --> 00:27:41,580
check code fails, it will return control back to the whole, back to the entry point and

212
00:27:41,580 --> 00:27:47,540
re-execute the whole thing with the actual values, the actual code.

213
00:27:47,540 --> 00:27:53,620
Yes, that is why the new path will become, the other path will become slow because it

214
00:27:53,619 --> 00:28:01,259
has to restart from a separate execution and do it and come back. But if it does not happen

215
00:28:01,259 --> 00:28:09,899
a lot often, then I am good. So, maybe instead of 50, it is let us say these many times.

216
00:28:09,899 --> 00:28:14,379
You see through profile information that is there is a lot of times and this only happens

217
00:28:14,379 --> 00:28:23,099
5 times. Do it. I mean 1 in a whatever number of zeros times, you will fail and you have

218
00:28:23,099 --> 00:28:27,219
to re-execute. You have to incur more cost than you would have got by not doing this

219
00:28:27,219 --> 00:28:34,179
optimization. But then it is okay if it happens very few times. And this is a very, so these

220
00:28:34,179 --> 00:28:39,819
are very aggressive class of optimizations, but they are used a lot in like both architectures

221
00:28:39,819 --> 00:28:44,859
and compilers. So, even there are things like value speculation where you just speculate

222
00:28:44,859 --> 00:28:48,179
the value of a variable. You say looks like the variable is going to have this value.

223
00:28:49,180 --> 00:28:55,340
value and see. So, there are a lot of very interesting things happen with such profile

224
00:28:55,340 --> 00:29:00,060
information. So, let us try to build a dynamic analysis, think of a dynamic analysis which

225
00:29:00,060 --> 00:29:06,220
will do profiling. So, I want to do the simplest kind of profiling which is I want to find

226
00:29:06,220 --> 00:29:14,259
out a histogram of basic blocks. I want to find out how many times is a basic block traversed

227
00:29:14,259 --> 00:29:19,700
in a given execution. So, now over multiple execution I can sort of accumulate that values

228
00:29:19,700 --> 00:29:24,940
and then I have a nice profile across multiple iterations that what is the probability how

229
00:29:24,940 --> 00:29:32,140
many times a basic block will be executed. So, I want for every basic block I want to

230
00:29:32,140 --> 00:29:37,779
count how many times was that basic block hit in a given execution. How can I build

231
00:29:37,779 --> 00:29:43,519
that as a dynamic analysis? So, this is control flow profiling because we are trying to understand

232
00:29:43,519 --> 00:29:47,359
something about the control flow. So, how can I build that analysis?

233
00:29:47,359 --> 00:30:08,879
Very good as simple as that and how do I maintain the tracker? But how will you dump that? No,

234
00:30:09,880 --> 00:30:15,260
I mean you are right completely right, but I just wanted to like ask you I mean more

235
00:30:15,260 --> 00:30:18,600
details about the implementation. How will you actually do this implementation if you

236
00:30:18,600 --> 00:30:26,120
had to? What will you how will you maintain that information? So, there is a variable

237
00:30:26,120 --> 00:30:29,240
corresponding to each basic block. How will you maintain that which variable is corresponding

238
00:30:29,240 --> 00:30:32,400
to which basic block? What is the frequency of each basic block? How will you maintain

239
00:30:32,400 --> 00:30:38,120
that information? Vector of very good very good vector of basic blocks.

240
00:30:38,120 --> 00:30:51,200
Excellent exactly that nothing more than that right. So, you give each basic block an identifier

241
00:30:51,200 --> 00:30:57,000
right. For each basic block you give let us say this is my basic block 1, this is 2, this

242
00:30:57,000 --> 00:31:04,599
is 3, this is 4, this is 5, this is 6, this is 7. Then you take an array of 7 size 7,

243
00:31:04,599 --> 00:31:15,759
7 integers and whenever a basic block is hit you just have an instruction which is count

244
00:31:15,759 --> 00:31:25,799
basic block number or basic block id plus plus right. So, every basic block knows what

245
00:31:25,799 --> 00:31:32,559
is the counter it has. So, the first one will be count 1 plus plus, this guy will be count

246
00:31:32,559 --> 00:31:38,559
2 plus plus, count 3 plus plus, this will be put in at as an instruction right inside

247
00:31:38,559 --> 00:31:44,000
the code the LLVM code. So, you will use LLVM or any other compiler to insert this instruction

248
00:31:44,000 --> 00:31:49,960
in the code. Whenever that code will get executed it will increment that counter. At the end

249
00:31:49,960 --> 00:31:56,480
of the day you dump this array it will contain the histogram of all basic blocks the count

250
00:31:56,480 --> 00:32:13,200
of all basic blocks right. Works for us any questions on this?

251
00:32:13,920 --> 00:32:25,000
to our actual assignment which was that we wanted to figure out if there is a buffer

252
00:32:25,000 --> 00:32:36,400
overflow in our arrays. So, I want to write a dynamic analysis which will trigger an error

253
00:32:36,400 --> 00:32:44,200
whenever there is a buffer overflow on my stack. Do you understand what is a buffer overflow?

254
00:32:44,200 --> 00:32:53,680
Before that who did you guys look at that program tell me what happened in that program what was

255
00:32:53,680 --> 00:32:59,880
why you are behaving so weird that motivation dot C could you run it? It showed weird results

256
00:32:59,880 --> 00:33:03,720
for your machine also. Oh thank God. Did you study the code and try to figure out what was

257
00:33:03,720 --> 00:33:20,200
going wrong there? Why does it change the value of C?

258
00:33:33,720 --> 00:33:47,000
Excellent. So, I think the class almost got the idea right. So, it was exactly that business what

259
00:33:47,000 --> 00:33:51,920
you said. So, essentially what was happening is there was this variable this array sitting here

260
00:33:51,920 --> 00:34:01,720
and the before the array the variable C was stored right and essentially what this guy did

261
00:34:01,720 --> 00:34:08,559
was whenever it had to it ended up the computation was such that it ended up computing array minus

262
00:34:08,559 --> 00:34:15,880
1. So, whenever it so C there is no check on the bounds of an array it does not check if you are

263
00:34:15,880 --> 00:34:22,679
crossing the bound of an array. So, it simply takes the base address and adds the index to it

264
00:34:22,679 --> 00:34:31,360
whatever is the index value multiplied with the size of the base type right that is exactly the

265
00:34:31,360 --> 00:34:36,920
computation that C does and dereferences this value. So, in this case it looked at the base

266
00:34:36,920 --> 00:34:48,240
address was array it did a minus 1 it reached C and it overrode that value and as you said in GCC

267
00:34:48,240 --> 00:34:54,920
it ends up putting I here in Clang it ends up putting C here or the other way around whichever

268
00:34:54,920 --> 00:35:10,480
is the yes yes. So, because in Clang C gets stored here in GCC I get stored here. So,

269
00:35:10,480 --> 00:35:19,800
the memory layout which means that which variable will come where depends on the compiler. The

270
00:35:19,800 --> 00:35:25,400
compiler does not guarantee that I will store things in a certain way it is completely up to

271
00:35:25,400 --> 00:35:35,440
the compiler to swap things around as it wants right. So, the example showed you two things one

272
00:35:35,440 --> 00:35:43,600
is that buffer overflow is dangerous and these errors are extremely difficult to catch because

273
00:35:43,599 --> 00:35:49,880
the bug was not in array the bug was in the error was in the value of C which has nothing

274
00:35:49,880 --> 00:35:56,440
to do with array at all. The array initialization what happened never got even used anywhere and

275
00:35:56,440 --> 00:36:03,279
whatever was used to compute the final value was C and you see a wrong value in C and you try to

276
00:36:03,279 --> 00:36:09,360
debug the call chain of the dependencies of C and you will not find anything there because nothing

277
00:36:09,360 --> 00:36:17,280
is happening anywhere right. So, buffer flow flows are very difficult to debug because it is

278
00:36:17,280 --> 00:36:22,640
interference between like different memory addresses it is not that that something wrong

279
00:36:22,640 --> 00:36:28,559
is happening to that variable that I can easily detect that is one thing. Second thing is that

280
00:36:28,559 --> 00:36:36,840
do not trust the memory layout of a compiler it is not that a compiler will layout memory in a

281
00:36:36,840 --> 00:36:43,079
certain order never trust that never write your code assuming that right. So, in certain cases

282
00:36:43,079 --> 00:36:49,720
for like very seasoned programmers often use such assumptions but then they know what can happen

283
00:36:49,720 --> 00:36:56,280
where but otherwise do not make such assumptions because a compiler is free to put allocate memory

284
00:36:56,280 --> 00:37:01,640
any way it wants. In fact, there are memory optimizations which actually say key how should

285
00:37:01,640 --> 00:37:05,800
I allocate memory which will give me the best performance right. So, the compiler the language

286
00:37:05,800 --> 00:37:12,840
gives the compiler full freedom to allocate memory in any way it wants right. So, the memory layout

287
00:37:12,840 --> 00:37:18,120
is completely up to the compiler do not trust that and it differs so that is why it was differing

288
00:37:18,120 --> 00:37:22,840
across compilers GCC and Clang were both showing different results and it is none of their faults

289
00:37:22,840 --> 00:37:27,880
it is the fault was with the programmer the programmer gave wrong answer did the wrong

290
00:37:27,880 --> 00:37:36,039
computation. So, now what I want to do is I want to detect such overflows buffer overflows and

291
00:37:36,039 --> 00:37:49,400
let us say I assume that it is an overflow by only one more word not more than one word. So,

292
00:37:49,400 --> 00:37:56,240
overflow can only happen for I will I can end up accessing a minus 1 but I will not access a minus

293
00:37:56,239 --> 00:38:02,799
2 like I cannot make that bigger blender like a small off by 1 errors are very common errors

294
00:38:03,519 --> 00:38:07,599
right lot of times I mean instead of less than you put a less than equal to right such things

295
00:38:07,599 --> 00:38:13,199
often happen right I mean so these off by 1 errors are very common. So, let us say if I do

296
00:38:13,839 --> 00:38:19,119
create a problem I will create a problem by only one word but I will not create a problem of more

297
00:38:19,119 --> 00:38:25,759
than one word. So, let us just simplify our case by taking this assumption. So, under this assumption

298
00:38:26,239 --> 00:38:38,000
how can I write a dynamic analysis which can detect memory overflows buffer overflows any ideas.

299
00:38:56,239 --> 00:39:19,039
How would I know what are valid addresses that like keeping track of water value addresses needs

300
00:39:19,679 --> 00:39:26,800
almost as much space as you are already using you see what I am saying right for so you have

301
00:39:26,800 --> 00:39:30,559
to keep some sort of shadow memory. So, for every memory here you have to remember that is it valid

302
00:39:30,559 --> 00:39:40,880
or not valid excellent idea excellent idea because I have this assumption that I will probably at

303
00:39:40,880 --> 00:39:46,719
most overflow by one word what I can do is instead of laying out things one after the other whenever

304
00:39:46,719 --> 00:39:52,719
I am laying out one word instead of laying out one word I will put a buffer here and put a buffer

305
00:39:52,719 --> 00:39:57,679
here. Buffer means another extra word here and an extra word here.

306
00:40:02,480 --> 00:40:06,480
Oh yeah you have to do it you are doing extra computation but this is not that much as

307
00:40:07,039 --> 00:40:14,000
like putting a like completely duplicating your full memory you have to use extra memory because

308
00:40:14,000 --> 00:40:18,639
you are doing extra computation right even here we had this extra memory right we had to maintain

309
00:40:18,639 --> 00:40:28,559
this table. Do you see this so we put a buffer a word before and after every so before the array

310
00:40:28,559 --> 00:40:34,960
also we will put one array one word before the array and one word after the array maybe we can

311
00:40:34,960 --> 00:40:39,840
just do it for arrays just to save memory let us say other variables I do not care overflows can

312
00:40:39,840 --> 00:40:43,840
only happen on arrays I will just do it for arrays so before every array access I put a

313
00:40:45,120 --> 00:40:50,079
word after every array access also I put a word. Now what

314
00:40:56,000 --> 00:40:57,680
I want to get a runtime error when I hit that.

315
00:40:57,679 --> 00:41:15,919
Which part the hash part but so you have to save very good idea so you have to save

316
00:41:15,919 --> 00:41:26,319
save something in this hash part. Excellent I can put some weird bit pattern let us say 1 1 0 0 1

317
00:41:26,320 --> 00:41:32,480
1 0 0 1 1 0 0 1 1 0 0 some weird thing I write there so all these guys I write the same business

318
00:41:36,320 --> 00:41:44,720
right I write the same bit string in all these locations right so there is a 1 by

319
00:41:44,720 --> 00:41:49,600
2 to the power 32 chance that I will hit that accidentally but I will take the chance

320
00:41:49,599 --> 00:42:02,960
it is a large chance but still I will take it right so I will find so I will store all of them

321
00:42:02,960 --> 00:42:12,719
with this and then how do I what extra code do I add tricatch to give me more simpler answer

322
00:42:12,719 --> 00:42:17,119
so because I will go to instrument it you have tricatch I need to put it in LNB bytecode right.

323
00:42:20,559 --> 00:42:23,039
So whatever you tell you have to implement it in LNB bytecode.

324
00:42:26,880 --> 00:42:30,319
Which value where so what exactly how will I exactly implement this

325
00:42:35,360 --> 00:42:39,519
but A of I may not be the right thing because A of I you will not get A of I in LNB

326
00:42:40,799 --> 00:42:44,960
and moreover there can be other problems there can be a P is equal to A plus I

327
00:42:44,960 --> 00:42:53,840
and you say star P star P is equal to 5 then what it may not look so neat.

328
00:42:53,840 --> 00:43:01,519
Before any dereference we will check the.

329
00:43:01,519 --> 00:43:10,800
Yes before every dereference you check so every time you get a dereference says some star P so

330
00:43:10,800 --> 00:43:19,680
you check if star P is equal to equal to that special address that special character the special

331
00:43:20,800 --> 00:43:23,920
the bit string that I put then flag error.

332
00:43:28,320 --> 00:43:31,200
Else you do the star P and continue whatever you are doing.

333
00:43:36,160 --> 00:43:39,600
Does it make sense completely clear.

334
00:43:40,800 --> 00:43:54,000
You should not write those programs you should not write those programs

335
00:43:55,920 --> 00:43:59,760
which uses A minus 1 to get updated please do not write those programs.

336
00:43:59,760 --> 00:44:03,440
I mean other variable which is stored at A plus 1.

337
00:44:07,120 --> 00:44:11,120
No first of all how do you know what variable gets stored at A minus 1.

338
00:44:11,760 --> 00:44:15,200
As I said it is completely up to the compiler to place anything at A minus 1.

339
00:44:15,200 --> 00:44:19,120
A minus 1 is an address that you should not use you are not allowed to use that.

340
00:44:20,640 --> 00:44:25,040
That is the first thing second thing is even even programmatically it is a bad practice

341
00:44:25,599 --> 00:44:32,960
to like so the memories each memory symbol that use every variable that use is supposed to be

342
00:44:34,079 --> 00:44:35,759
not dependent on anything else.

343
00:44:37,440 --> 00:44:43,039
Like address wise like x y z are three different variables you should not like if there is an

344
00:44:43,039 --> 00:44:54,079
array of 10 bytes and then there is a integer C. So I should never use like some location some

345
00:44:54,079 --> 00:44:58,000
operation on A to update C. I should not do that right.

346
00:44:58,000 --> 00:45:03,279
I have C why not use C you want to set C is one set say C is one.

347
00:45:03,279 --> 00:45:06,079
Why do you want to say A minus 1 as one right.

348
00:45:06,079 --> 00:45:21,840
So no no so this is only for the analysis in your actual code when you actually run the code or

349
00:45:21,840 --> 00:45:26,400
when you actually deploy the code it will not have this instrumentation because this is expensive

350
00:45:26,400 --> 00:45:33,200
right before every access every memory access I am doing a if check I am putting a check.

351
00:45:33,200 --> 00:45:37,440
So that is lot of code I would not ship that product with so much code.

352
00:45:37,440 --> 00:45:42,160
It is only to do the analysis it is only to do the analysis I use this extra

353
00:45:42,160 --> 00:45:50,000
space and this extra instructions to say that let us try to let us see if I can trigger that fault.

354
00:45:52,400 --> 00:46:08,079
Yes yes exactly so these problems can be on the stack this can be on the heap solution is are

355
00:46:08,079 --> 00:46:12,800
similar right if you have it on the heap what do you do whenever you do a malloc instead of

356
00:46:12,800 --> 00:46:18,320
using the systems malloc you use your own version of malloc you have your version of malloc which

357
00:46:18,320 --> 00:46:25,200
puts this extra code extra locations before and after the malloc block right and your own free

358
00:46:26,000 --> 00:46:30,960
which will instead of saying whenever it says free a particular address it will say free minus

359
00:46:30,960 --> 00:46:36,080
my address like whatever some are supposed to be so the user wanted this much buffer but you give

360
00:46:36,080 --> 00:46:42,160
it this much buffer this extra thing is yours and when the and but to the user you will return this

361
00:46:42,159 --> 00:46:49,119
address user will not even know that there is nothing there right and whenever the user says

362
00:46:49,119 --> 00:46:55,759
free of this you will go and say free of this so you will have your modified versions of the

363
00:46:55,759 --> 00:47:02,399
malloc and free calls and then you will you will for every memory access you will

364
00:47:04,079 --> 00:47:10,480
you will check it if it is it could be a error in this location it is one of these locations that

365
00:47:10,480 --> 00:47:21,679
can be faulty and if yes you trigger fault so all these memory checkers like address

366
00:47:21,679 --> 00:47:29,199
sanitizer or well grind mostly the technique is this they have more sophisticated algorithms

367
00:47:29,199 --> 00:47:34,480
they are which are much faster give you more information but the high level idea is sort of this

368
00:47:41,119 --> 00:47:51,039
right so now can we get our hands dirty can we try building such an analyzer in LLVM so what does

369
00:47:51,039 --> 00:47:56,320
it take now let us come to what theory again now let us come to how do we build it in LLVM let us

370
00:47:56,320 --> 00:48:05,599
say I want to do it on the stack right so what do I need to do let us plan it I want to only do it

371
00:48:05,599 --> 00:48:13,920
on the stack I do not want to do it on heap so how will I do that in in LLVM bit code LLVM IR

372
00:48:17,519 --> 00:48:24,000
yes so I have to do what insert aloka instructions so like I have to look at the aloka instructions

373
00:48:24,000 --> 00:48:29,839
there and after each aloka instruction or before each aloka instruction I add my own aloka

374
00:48:29,840 --> 00:48:37,120
instruction right so this will give me extra space to for this extra variables that is one

375
00:48:37,120 --> 00:48:50,960
phase this is insert aloka then not store instruction so the dereference is done with

376
00:48:50,960 --> 00:48:57,680
something called this GEP instruction gate element pointer instruction right so there is this gate

377
00:48:57,679 --> 00:49:05,519
element pointer instruction you have to catch all such GEP instructions right for every such

378
00:49:05,519 --> 00:49:12,079
instruction you have to check if this is equal to that pattern whatever pattern you have set here

379
00:49:12,079 --> 00:49:16,159
so there is aloka instruction and you also have to maybe that is what you are saying store a

380
00:49:16,159 --> 00:49:19,599
special pattern into this aloka instructions in these locations

381
00:49:28,239 --> 00:49:34,480
yeah you can sure sure sure but my implementation I did a shortcut so I am telling you what I did

382
00:49:34,480 --> 00:49:39,679
I did not want you to see that so yeah you are right so maybe I can do it only for arrays I can

383
00:49:39,679 --> 00:49:43,359
just do it before and after an array but that requires me to find the type of the array and I

384
00:49:43,359 --> 00:49:49,519
should do that yeah that's true but I just essentially did it for every aloka instruction

385
00:49:49,519 --> 00:49:55,119
just find if it's aloka put another aloka in between but you're right I mean we can maybe

386
00:49:55,119 --> 00:49:59,839
we get only do it for arrays it saves a space and whenever I have a GEP instruction you

387
00:50:01,759 --> 00:50:09,199
look at this and you make the check you check if the address at that location held at that location

388
00:50:09,199 --> 00:50:14,400
has is that special bit pattern that you stored here that you put in the store instruction

389
00:50:15,759 --> 00:50:20,239
if it is then trigger the error if not you are good

390
00:50:20,239 --> 00:50:26,879
yes yes

391
00:50:29,839 --> 00:50:35,679
so now you have the tool you will run that pass that will do all the instrumentation required

392
00:50:35,679 --> 00:50:38,639
you run the program on it it will trigger the fault if there is any

393
00:50:39,599 --> 00:50:46,319
and then I'll show you the code how we can get it done and then maybe you can

394
00:50:46,720 --> 00:50:52,320
um so we'll see how can we use the rest of the time so then we can spend a little time in you

395
00:50:52,320 --> 00:50:56,800
like tinkering around with that code and try to see if you can do something

