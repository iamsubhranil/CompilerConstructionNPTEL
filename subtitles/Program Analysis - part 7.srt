1
00:00:00,000 --> 00:00:14,419
So, now we will start with, so now essentially we know some structure to the space of solutions

2
00:00:14,419 --> 00:00:19,260
that are algorithm traverses right. How what all does it touch, what how does it move we

3
00:00:19,260 --> 00:00:25,060
know something, but we still do not know that why does it why should it terminate or why

4
00:00:25,059 --> 00:00:29,939
should it why should it compute the solution that we are looking to get those things we

5
00:00:29,939 --> 00:00:34,219
have not we do not know yet right. So, let us try to now argue mathematically and see

6
00:00:34,219 --> 00:00:38,460
why does it really work because now I can because now I have figured out what is exactly

7
00:00:38,460 --> 00:00:42,140
happening on this lattice on this mathematical structure I do not really need to worry too

8
00:00:42,140 --> 00:00:45,820
much about the implementation or the algorithm that we used right.

9
00:00:45,820 --> 00:00:53,460
So, let us see so there is this big big big big theorem known as a Naster-Tasca theorem

10
00:00:53,619 --> 00:00:59,899
which essentially gives some very interesting results for such computations. So, it says

11
00:00:59,899 --> 00:01:09,200
that let D the set D with the less than equal to operator be a complete lattice and let

12
00:01:09,200 --> 00:01:17,859
f going from D to D be a monotonic function on this set D with on this particular lattice

13
00:01:17,859 --> 00:01:29,500
and let P be the set of all fixed points of f then first thing is the set of fixed points

14
00:01:29,500 --> 00:01:37,299
is non-empty which means that f under this condition which surely have at least one fixed

15
00:01:37,299 --> 00:01:46,060
point. So, this tells me something about the existence of a fixed point right.

16
00:01:46,060 --> 00:01:55,259
So, if you have a complete lattice if you have a monotonic function then my there will

17
00:01:55,259 --> 00:02:05,299
be at least one fixed point in this lattice second is P with less than equal to forms

18
00:02:05,299 --> 00:02:14,419
a complete lattice sorry this the second very interesting point is that ok. So, it

19
00:02:14,419 --> 00:02:21,300
first says that there surely exists a fixed point second thing, but it may have more than

20
00:02:21,300 --> 00:02:28,500
one fixed point right. So, then it says that it also tells us something about the structure

21
00:02:28,500 --> 00:02:35,219
of this set of fixed points. So, P is the set of fixed points it also tells us that

22
00:02:35,219 --> 00:02:44,500
the set of fixed points P forms a complete lattice under the same ordering relation really

23
00:02:44,500 --> 00:02:51,219
interesting result do you understand what is going on. So, I have this big set in that

24
00:02:51,219 --> 00:02:55,639
set it says that ok there is going to be a set of fixed points and this set is going

25
00:02:55,639 --> 00:02:59,719
to be non-empty this set P is going to be not. So, this big set is a set D and this

26
00:02:59,719 --> 00:03:06,519
small set P is going to be non-empty not just that this set P itself is going to be a complete

27
00:03:06,519 --> 00:03:11,159
lattice under the same ordering relation. So, we have a mini lattice inside this bigger

28
00:03:11,159 --> 00:03:19,399
lattice the third thing is that the least fixed point of f coincides with the greatest

29
00:03:19,400 --> 00:03:25,640
lower bound of the set of post fixed points and the greatest fixed points of f coincides

30
00:03:25,640 --> 00:03:33,319
with the lub of the prefix points of f. So, it means that now let us say my. So, the

31
00:03:33,319 --> 00:03:43,360
diagram would look something like this. So, these are my post fixed points and these are

32
00:03:43,360 --> 00:04:00,040
my prefix points. So, it says that if I take my prefix points and if I. So, if I. So, these

33
00:04:00,040 --> 00:04:07,760
are my these are my prefix points right where x is less than equal to f of x. So, when I

34
00:04:07,799 --> 00:04:17,360
apply f I go up the lattice right and for these if I take a join. So, I find their join for this

35
00:04:17,360 --> 00:04:30,039
subset let us say I find the point right then if I take the join of only the fixed points I would

36
00:04:30,040 --> 00:04:41,240
end up getting the same point. Do you understand what is going on? So, it says that you look at

37
00:04:41,240 --> 00:04:49,520
all the prefix points this is my set of all prefix points if you take their join it essentially will

38
00:04:49,519 --> 00:04:59,919
be it will coincide with taking the join of only the fixed points. Similarly, is the case

39
00:04:59,919 --> 00:05:13,039
by duality similarly is the case for the meet with the post fixed points. So, now let us go

40
00:05:13,040 --> 00:05:22,400
back to computing least fixed points. So, first is that. So, essentially what has this mainly

41
00:05:22,400 --> 00:05:27,000
established for us it has first. So, these two things are really interesting first it actually

42
00:05:27,000 --> 00:05:35,000
told us that like if I am able to get my data flow facts to work with the complete lattice then I am

43
00:05:35,000 --> 00:05:39,960
sure I will be able to and an order preserving function and my transfer function is an order

44
00:05:39,959 --> 00:05:45,359
preserving function in that case I am surely going to get one solution to my set of equations

45
00:05:45,359 --> 00:05:49,879
there are at least going to be at least one solution to this set it will not be the case

46
00:05:49,879 --> 00:05:57,359
of no solutions. Remember what would be same what was a lattice and what was a complete lattice.

47
00:05:57,359 --> 00:06:09,879
Right. So, even for any subset of elements either finite or infinite has a LUB and a GLB if that

48
00:06:09,879 --> 00:06:17,480
condition is satisfied then it is a complete lattice. So, because my set D may not be a

49
00:06:17,480 --> 00:06:24,000
finite lattice I may sometimes have to even talk about taking meets or joins over infinite subsets.

50
00:06:24,000 --> 00:06:34,279
So, now let us start looking at I will again introduce some definition. So,

51
00:06:34,279 --> 00:06:43,000
a chain is going to be totally ordered that is by definition. Now there is a notion of a finite

52
00:06:43,000 --> 00:06:49,079
chain what is a finite chain if the set of elements in that chain are finite then I would

53
00:06:49,079 --> 00:06:55,039
refer to as a finite chain. Now there is a notion of something called an ascending chain. So,

54
00:06:55,039 --> 00:06:59,599
what is an ascending chain? So, till here when we were talking about chains we were talking about

55
00:06:59,600 --> 00:07:11,920
a set. Here we are seeing a sequence of elements. So, a sequence of elements forms an ascending

56
00:07:11,920 --> 00:07:22,120
chain if I can put those elements in a total ordered form. So, a 1 is less than a 2 then less

57
00:07:22,120 --> 00:07:35,120
than a 3 a n then this sequence not the set this sequence a 1 a 2 a 3 a 4 sequence means the order

58
00:07:35,120 --> 00:07:44,600
is important in this listing. So, this sequence is referred to as an ascending chain. Similarly,

59
00:07:44,600 --> 00:07:48,920
I can define a descending chain what is a descending chain it should be able to put it

60
00:07:48,920 --> 00:07:56,319
the opposite order and then there is this big definition of something known as if something

61
00:07:56,319 --> 00:08:04,400
ascending chain or descending chain eventually stabilizes. So, we say a chain eventually

62
00:08:04,400 --> 00:08:17,120
stabilizes. So, I say an ascending chain let us say a 1 a 2 a n eventually stabilizes if

63
00:08:17,120 --> 00:08:32,080
there exists some k such that. So, this may even not be finite. So, this may go on forever.

64
00:08:34,000 --> 00:08:40,240
I can have infinite infinite sequence, but I say that this set will the sequence would

65
00:08:40,240 --> 00:08:50,680
eventually stabilize if there exists some k such that a 1 is less than equal to a 2 is less than

66
00:08:50,679 --> 00:09:04,159
or equal to a 3 is less than or equal to a 4 goes on till a k and all values after k are the same.

67
00:09:09,959 --> 00:09:16,519
So, it says that it keeps on increasing, but there is some point after which it will just stay there.

68
00:09:16,519 --> 00:09:38,159
Right any questions on this? So, now think about the case that if I had this data flow again

69
00:09:38,159 --> 00:09:45,879
remember that algorithm and forget that we had this we had this flag which will mark the end

70
00:09:45,879 --> 00:09:51,720
of termination and we simply collect the sets the values that I get at each program point.

71
00:09:51,720 --> 00:09:56,799
I just sample I just collect keep on collecting the values of this program point they will form

72
00:09:56,799 --> 00:10:07,799
a first they will form an ascending chain because every time the value will be something more than

73
00:10:07,799 --> 00:10:16,279
what I got previously and after some point when they will keep on seeing the same value again and

74
00:10:16,279 --> 00:10:23,079
again and again and again. So, that computation produces a chain an ascending chain which

75
00:10:23,079 --> 00:10:33,959
eventually stabilizes. So, now this condition is referred to as ACC or ascending chain condition.

76
00:10:33,960 --> 00:10:42,960
So, ascending chain condition says that if you have a lattice such that all ascending

77
00:10:42,960 --> 00:10:51,040
chains eventually stabilize. So, it means that if you have some lattice no matter which ascending

78
00:10:51,039 --> 00:11:06,000
chain I pick up that is surely going to stabilize. So, what does this tell us? So, if I have a lattice

79
00:11:06,000 --> 00:11:14,919
if my lattice D on which I am going to compute my data flow solution if that D is a lattice

80
00:11:14,919 --> 00:11:23,879
which eventually stabilizes what can I say about the computation? The computation will terminate

81
00:11:23,879 --> 00:11:29,799
because whenever I see so that flap that I was there was to check about this eventual

82
00:11:29,799 --> 00:11:34,919
stabilization. So, if it ever sees that I get two things in the sequence which are the same the loop

83
00:11:34,919 --> 00:11:47,159
will break and will come out. So, now there is this something known as the clean iteration.

84
00:11:47,159 --> 00:11:52,439
So, essentially the algorithm that we now essentially have to compute the least fixed

85
00:11:52,439 --> 00:12:01,519
point is that you start with the bottom element. So, once so I start with the bottom elements then

86
00:12:01,519 --> 00:12:12,399
I keep on applying F to it while A is not equal to F I keep on going and I keep on reassigning

87
00:12:12,399 --> 00:12:24,120
like F A into A. So, this will always so if my F is a monotonic function then the sequence of

88
00:12:24,120 --> 00:12:33,960
A's that I will get here will always form an ascending chain and if that ascending chain

89
00:12:33,960 --> 00:12:43,639
eventually stabilizes and if the lattice on which my if this values A are picked up from a set D

90
00:12:43,639 --> 00:12:54,840
under some operation such that D satisfies the ACC condition then this loop will sometime on

91
00:12:54,840 --> 00:13:01,439
the other break because it whenever it eventually stabilizes will have A is equal to F A and I

92
00:13:01,439 --> 00:13:09,840
will be able to compute the least fixed point. So, clean iteration says that if you start with

93
00:13:09,840 --> 00:13:16,720
your bottom element and keep on applying a monotonic function you will always hit the

94
00:13:16,720 --> 00:13:34,759
least fixed point. Sorry come again no need not be no need not be why is monotonicity important

95
00:13:34,759 --> 00:13:39,560
otherwise I will not have an ascending chain. So, ascending chain condition says that given

96
00:13:39,559 --> 00:13:48,799
an ascending chain so essentially let us go back maybe we. So, essentially what was the thing that

97
00:13:48,799 --> 00:13:55,279
this notion of an ascending chain was a definition right this was a definition we said that a sequence

98
00:13:55,279 --> 00:14:04,039
of values from D such that the values can be arranged in this form is referred to as an ascending

99
00:14:04,039 --> 00:14:20,559
chain this was just a definition any change the values are in total order yes a chain is a set

100
00:14:20,559 --> 00:14:35,159
and ascending chain is a sequence they are not actually the same thing yes yes yes yes so we

101
00:14:35,159 --> 00:14:39,159
have broken down the definition into multiple definition so that you can follow a logistic

102
00:14:39,159 --> 00:14:48,079
logical order that is all. So, there is a set and I sort that set that sorted set is the ascending

103
00:14:48,080 --> 00:14:53,560
chain right so if I sort it in the increasing order that is an ascending chain if I sort it

104
00:14:53,560 --> 00:15:00,360
the decreasing order that becomes a descending chain for the same chain right and then I would

105
00:15:00,360 --> 00:15:06,720
I will pick an ascending chain and I will ask if that ascending chain eventually stabilizes if

106
00:15:06,720 --> 00:15:13,920
the ascending chain eventually stabilizes then I would say so that means that there is some finite

107
00:15:13,919 --> 00:15:20,159
constant k like so after a finite number of like visiting a finite number of elements even in that

108
00:15:20,159 --> 00:15:34,799
infinite sequence I will be able to get values which start repeating that is one way of saying

109
00:15:34,799 --> 00:15:41,639
this actually right the height remains finite so in that case there is no other way to go no other

110
00:15:41,639 --> 00:15:46,480
place to go so it has to this thing but right this particular definition does not even assume

111
00:15:46,480 --> 00:15:51,759
that this particular definition does not assume anything at all this guy this guy just says so

112
00:15:51,759 --> 00:15:56,039
this is still a definition right these guys are why it happens in the R lattice is a different

113
00:15:56,039 --> 00:16:01,960
matter but right now this is just a definition right so I am just trying to define what does

114
00:16:01,960 --> 00:16:09,399
eventual stabilization mean right so it I will say that an ascending chain eventually stabilizes

115
00:16:09,399 --> 00:16:17,079
if after a after visiting of a finite number of elements in that sequence rest of the elements

116
00:16:17,079 --> 00:16:23,759
are just repetitions that is what I if that happens then I will say that this particular

117
00:16:23,759 --> 00:16:28,240
ascending chain eventually stabilizes I am just defining it why it happens for all actors is a

118
00:16:28,240 --> 00:16:35,600
different matter but right now we are just defining it and then we define the notion of ascending

119
00:16:35,600 --> 00:16:42,399
chain condition this is also a definition right so I am saying that if there is a lattice such

120
00:16:42,399 --> 00:16:46,840
that all ascending chains no matter which ascending chain I pick from the lattice if

121
00:16:46,840 --> 00:16:53,879
that surely stabilizes then I would say that the lattice satisfies the ascending chain condition

122
00:16:53,879 --> 00:16:59,960
again a definition there is again I am not really relating it to what happens to our lattice these

123
00:16:59,960 --> 00:17:16,799
are simply definitions right now okay so right if 3 gives 2 f 4 is 3 no so just the function is

124
00:17:16,799 --> 00:17:23,720
not enough you have to define the function on what lattice what is the lattice lattice is the

125
00:17:23,720 --> 00:17:39,279
set of integers on less than equal to okay okay no no you have to say it for all elements in I

126
00:17:39,279 --> 00:17:56,519
okay okay okay so so like people said right like plus with 2 that is going to be a monotonic

127
00:17:56,519 --> 00:18:03,000
function maybe I am missing a lot of things you start with so let us draw the lattice so we have

128
00:18:03,000 --> 00:18:17,359
2 then we have 3 and then you have 4 okay now what and how do they move a 3 is 2 and f 4 is

129
00:18:17,359 --> 00:18:27,599
like this okay so now on this function this is not that this does not form an no so essentially

130
00:18:27,599 --> 00:18:36,319
there is an ascending chain which is 2 3 4 is an ascending chain okay so now what for all points

131
00:18:36,319 --> 00:18:43,039
that is the important part no so what does it mean it should be that if 2 is less than 3 it

132
00:18:43,039 --> 00:18:51,519
implies that f 2 should be less than equal to f 3 right so is that happening for your f 2 is

133
00:18:51,519 --> 00:19:02,639
not even defined so the f 2 is 3 no your f 2 is it is 1 no you wanted it to be 1 so does it satisfy

134
00:19:02,639 --> 00:19:11,680
this you check so if 2 is less than 3 f 2 is less than f 3 okay you are getting one point lesser

135
00:19:11,680 --> 00:19:25,880
so you are doing a minus 1 basically how fine yes no but remember where did I start start off

136
00:19:25,880 --> 00:19:36,320
with you start with bottom element that is important so very good point really good point

137
00:19:36,320 --> 00:19:40,680
took me some time to understand what you are saying so yes if you start with arbitrary points

138
00:19:40,680 --> 00:19:47,960
it does not guarantee anything at all think about your case like data flow analysis I set

139
00:19:47,960 --> 00:19:52,440
this sets to arbitrary values and I start my computation do you think you will reach the final

140
00:19:52,440 --> 00:20:01,039
solution right so the initialization is as important right that is why we every algorithm

141
00:20:01,039 --> 00:20:04,720
we mentioned initialization initialization in fact yesterday for a long time we did not even

142
00:20:04,720 --> 00:20:13,440
say how to initialize yeah no he is saying it is there okay he is saying it is a set of everything

143
00:20:13,440 --> 00:20:24,279
right so if you start with arbitrary points I do not know what happens nobody knows what happens

144
00:20:24,279 --> 00:20:30,960
it only says that if you start with the bottom element I can tell you it will lead each the least

145
00:20:30,960 --> 00:20:42,400
fixed point okay so when is it guaranteed to terminate so if I have a if I have a lattice

146
00:20:42,400 --> 00:20:54,640
which satisfies the ACC condition that particular with a monotonic function then that should surely

147
00:20:54,640 --> 00:21:04,120
terminate right because and then the question is that where does it terminate so that will

148
00:21:04,120 --> 00:21:14,240
always terminate at the LFP the least fixed point so in general so essentially this is the

149
00:21:14,240 --> 00:21:22,120
like this is the final result that on a complete lattice which satisfies ACC with monotonic

150
00:21:22,119 --> 00:21:28,959
cancer functions the LFP or the MFP whichever we were looking at the bottom semi-lattice or

151
00:21:28,959 --> 00:21:33,799
the upper semi-lattice the maximum fixed point or the least fixed point whatever you want essentially

152
00:21:33,799 --> 00:21:40,839
it this exists and is computable because I just gave you an algorithm to compute it the clean

153
00:21:40,839 --> 00:21:51,879
iteration right so that is why this whole business works I am don't get confused with MFP I

154
00:21:51,880 --> 00:21:57,240
should not have written MFP I mean we are working with joins and so we are we will talk

155
00:21:57,240 --> 00:22:04,600
about least fixed points not about maximum fixed points so in general the whole structure looks

156
00:22:04,600 --> 00:22:13,120
like something like this so essentially it says that if I start with my bottom element and I keep

157
00:22:13,120 --> 00:22:21,280
on applying my function on that bottom element I will keep on getting values which are greater

158
00:22:21,279 --> 00:22:33,759
than that right so this is the place where I am in the prefix point region right every time I

159
00:22:33,759 --> 00:22:41,519
get values which will be larger and larger to this thing just consider this set that I got by

160
00:22:41,519 --> 00:22:49,319
applying this again and again and again so if I take a join of those guys just by the definition

161
00:22:49,319 --> 00:22:59,119
of taking a join this is going to be greater than this this is going to be less than or equal to

162
00:22:59,119 --> 00:23:10,159
the least fixed point of F right so that is how the computation looks like right and then you

163
00:23:10,159 --> 00:23:15,359
will have a lot of fixed point setting here I don't know what happens to those but you could

164
00:23:15,359 --> 00:23:20,359
have done the computation in the other way with a different function so I should not have put F

165
00:23:20,359 --> 00:23:27,919
here this is some other function G right so you could have done a computation starting from the

166
00:23:27,919 --> 00:23:35,199
other direction you could have started from top and you could have just applied G multiple times

167
00:23:35,199 --> 00:23:44,519
on top kept on climbing down and if you take a meet of those guys then that will be lesser

168
00:23:44,519 --> 00:23:50,639
than this and then you would reach the GFP and that would have been the way to reach the greatest

169
00:23:50,639 --> 00:24:01,519
fixed point right so it says if you start from the top and applying a function of a certain kind you

170
00:24:01,519 --> 00:24:06,720
will be able to keep on you will be able to hit the least fixed point you can do the same business

171
00:24:06,720 --> 00:24:13,440
in the opposite direction to reach the greatest fixed point understand that once you hit a fixed

172
00:24:13,440 --> 00:24:18,480
point or hit a fixed point you cannot move across fixed points there is no way to write I mean like

173
00:24:18,480 --> 00:24:26,000
you apply it again you will still remain there but the cool part is that this particular guys

174
00:24:26,000 --> 00:24:32,640
the least fixed point the the least fixed point the greatest fixed point and the set of fixed

175
00:24:32,640 --> 00:24:58,920
points in between they themselves form a complete lattice which one yeah so you can view it anyway

176
00:24:59,000 --> 00:25:05,039
you want you can you can view it anyway you want so you can view it as starting from the bottom

177
00:25:05,039 --> 00:25:14,039
and applying the like growing like keep on applying it keep on applying F to it till you

178
00:25:14,039 --> 00:25:19,360
reach the lowest fixed point or you can think it the other way around you can flip the lattices

179
00:25:19,360 --> 00:25:26,519
around and you can start from the top and apply some function G till you hit the greatest fixed

180
00:25:26,519 --> 00:25:36,759
point whatever we drew was this particular thing so we started with bottom and we kept on getting

181
00:25:36,759 --> 00:25:48,240
larger and larger sets by our ordering iteration till we hit the best solution yeah

182
00:25:48,240 --> 00:26:07,400
yeah from the top but maybe from with a different function how but why would you not want the other

183
00:26:07,400 --> 00:26:11,519
fixed point that is the first question what why are you why should you be interested in the other

184
00:26:11,519 --> 00:26:20,759
fixed points no but why do you want that lattice it just shows that it just tells you that those

185
00:26:20,759 --> 00:26:26,920
lattices those points do form a mini lattice but why would you be interested in hitting that mini

186
00:26:26,920 --> 00:26:35,440
lattice so at least in our data flow scenario we do not have any interest in finding those mini lattices

187
00:26:41,519 --> 00:26:47,879
no that is not done empirically that is not done empirically that is not done for example that is

188
00:26:47,879 --> 00:26:54,559
done mathematically so there is a mathematical proof that this will happen so I do not want to

189
00:26:54,559 --> 00:26:59,799
do the proof here but there is a very interesting proof in fact you go back and look at this

190
00:26:59,799 --> 00:27:05,200
particular proof it essentially says that we can actually prove that if there are two fixed points

191
00:27:05,200 --> 00:27:11,799
they will always have this ordering and you can always find the top element there but in our

192
00:27:11,799 --> 00:27:17,039
scenario we are not interested in getting the other fixed points for us it does not really matter

193
00:27:17,039 --> 00:27:24,279
right and all it matters for us is only this part right going all the way from the bottom till the

194
00:27:24,279 --> 00:27:29,759
till we reach the LFP we don't even care anything else so for us even a similarity structure is good

195
00:27:29,759 --> 00:27:35,160
enough what happens the other direction what happens for the meets I am not even interested

196
00:27:35,160 --> 00:27:41,320
about that because we are never applying meet anywhere we are only applying joints right so

197
00:27:41,320 --> 00:27:51,360
whatever structure is there for meets I am not even using it so it does not matter right yeah

198
00:27:51,360 --> 00:27:57,360
so this is much more interesting with the proofs but like you spend two classes doing the Naster

199
00:27:57,360 --> 00:28:02,400
Rasky theorem and then because more interesting but I'll keep it in interest of time but I will

200
00:28:02,400 --> 00:28:09,440
really ask you to go and see that why this really works at least the first couple of points are not

201
00:28:09,440 --> 00:28:22,160
difficult to show they are not so difficult proofs now the question is about precision so again

202
00:28:22,160 --> 00:28:29,040
remember that what did we really want to compute what we really wanted to compute was the MOP

203
00:28:29,039 --> 00:28:34,359
solution the meet over all path solution or the join over all path solution if you will right so

204
00:28:34,359 --> 00:28:42,480
essentially what we do we would have wanted is that we we try to find out all paths from the program

205
00:28:42,480 --> 00:28:48,680
so how will this MOP solution look like essentially what we're trying to how will you now you know the

206
00:28:48,680 --> 00:28:52,079
lattice and the structure and all that so mathematically can you write down what does

207
00:28:52,079 --> 00:29:05,159
the MOP solution look like how would the so let us say I have some graph

208
00:29:22,079 --> 00:29:37,240
I don't know why you always end up making the same graph okay let me not okay so let's say this is

209
00:29:37,240 --> 00:29:44,000
a this is B this is C and I want to compute the MOP solution here the meet over all path

210
00:29:44,000 --> 00:29:50,079
solution here for the join over all path solution here so how do I how will I apply this solution

211
00:29:50,079 --> 00:29:53,960
so let's say this guy has a transfer function which is f1 this guy has a transfer function

212
00:29:53,960 --> 00:29:59,439
which is f2 this guy has a transfer function which is f3 how do I compute this particular

213
00:29:59,439 --> 00:30:12,519
answer how what is my MOP is going to be at this particular point so let's say I start with something

214
00:30:12,519 --> 00:30:20,639
let's say I start with some value here it's some initialization of this guy which could be some

215
00:30:20,639 --> 00:30:29,240
value let's say alpha so the entry point to this entry block let's say the dataflow fact is alpha

216
00:30:29,240 --> 00:30:33,839
I know that so I have set it to that and I want to find out the meet over all path solution at

217
00:30:33,839 --> 00:30:52,720
this particular point how do I how do I do this what is the function going to be very good very

218
00:30:52,720 --> 00:31:01,319
good very good so I will first apply alpha on f1 then I will start going around this path right

219
00:31:01,319 --> 00:31:13,919
now so I will apply f1 alpha on f1 then I will apply f2 on f1 then join of right then join of

220
00:31:13,919 --> 00:31:27,480
f3 of f1 of alpha this is what we want to compute what do we actually compute the MFP solution or

221
00:31:27,599 --> 00:31:35,480
LFP solution whatever we want what are actually we computing actually that is why I drew the

222
00:31:35,480 --> 00:31:43,039
other diagram again it is not interesting so I have to extend this so let me just change this

223
00:31:43,039 --> 00:31:56,879
so I want a I want b c I want b

224
00:31:56,880 --> 00:32:25,720
e f g and I start with the alpha now you have to write more so this is what I was trying to avoid

225
00:32:25,839 --> 00:32:40,920
so then then what is my MFP solution MOP solution now though you guys tell me now this is f a f

226
00:32:40,920 --> 00:32:56,600
b f c f d fe f f bad but let us say at the beginning of this beginning of g so this is

227
00:32:56,600 --> 00:33:01,640
the program point where I am interested to find the MOP solution so what is my MOP solution here

228
00:33:01,640 --> 00:33:19,440
yeah so long chain of f a then f b then f d then fe of alpha join of

229
00:33:19,440 --> 00:33:47,080
yeah f f so if f a f c f d let's say ff of alpha then something then other two parts

230
00:33:49,680 --> 00:34:00,920
what about the MFP path MFP solution what does the MFP solution look like fe applied to

231
00:34:00,920 --> 00:34:29,800
so that will be f d of join of which two things f b f a of of alpha join f c

232
00:34:30,960 --> 00:34:42,119
f a of alpha join same for the other direction can you see the difference between these two

233
00:34:42,119 --> 00:35:00,280
equations not completely but somewhat yes yes yes we are applying less functions

234
00:35:01,920 --> 00:35:11,039
so we wanted to compute the MOP but somebody told us don't do MOP do MFP and we are we since

235
00:35:11,039 --> 00:35:21,440
yesterday I am teaching you MFP now why should this why should it work to compute the MFP when

236
00:35:21,440 --> 00:35:26,240
we wanted the MOP solution so essentially we want the MOP right all of you agree what we want why is

237
00:35:26,359 --> 00:35:33,839
it the MOP want because any of these paths is a possible execution path right and whatever

238
00:35:33,839 --> 00:35:39,679
property we are we get should we should be something that should be possible in some

239
00:35:39,679 --> 00:35:47,439
execution right so I am taking a meet over all possible executions that are possible

240
00:35:48,400 --> 00:35:58,079
right but we are computing something which looks very different why what is going on

241
00:35:58,079 --> 00:36:15,360
very good very good so can you see when will these two be equal yes yes if the join is

242
00:36:15,599 --> 00:36:23,840
distributed over your function f then both of them will they not look the same right so if

243
00:36:23,840 --> 00:36:38,360
you have distributed frameworks then MOP solution and MFP solution coincide was reaching so which

244
00:36:38,360 --> 00:36:43,400
of them is more efficient MFP is much more efficient because see how less we are times

245
00:36:43,440 --> 00:36:50,440
we are applying the function but the theory says that if my framework is distributive if my

246
00:36:50,440 --> 00:36:57,880
function distributes over my joint operator then I have my MOP solution and my MFP solution will

247
00:36:57,880 --> 00:37:07,320
coincide awesome news question is for reaching definitions is it the case can you look at the

248
00:37:07,400 --> 00:37:14,559
transfer function and tell me is that transfer function distributive over join you know the

249
00:37:14,559 --> 00:37:20,480
lattice you know the transfer function can you can you quickly try out and see if it really looks

250
00:37:20,480 --> 00:37:36,440
to be the case how do you do that hey this side decide new that we are doing no we have two elements

251
00:37:36,440 --> 00:37:43,599
we are computing the join of it that is all forget the control flow graph now right now just

252
00:37:43,599 --> 00:37:49,360
talk about the distinct you know the lattice you know you have the subset lattice of definitions

253
00:37:49,360 --> 00:37:57,400
and you have the transfer function which is in minus skill union gen now for this particular

254
00:37:57,400 --> 00:38:02,960
function on that lattice tell me what happens now there is no predecessor successor nothing is there

255
00:38:02,960 --> 00:38:10,880
so is this function if the form of this function distributive over this lattice is the question

256
00:38:10,880 --> 00:38:22,199
how will you do it so what is the stupidity how do I distribute it so what are you trying to prove

257
00:38:22,199 --> 00:38:42,799
what is the theory we are trying to prove yes yes so if I have if I take FA union join FB this

258
00:38:42,800 --> 00:38:56,519
is going to be the same as right so is it hard to show just write your in and out equations put

259
00:38:56,519 --> 00:39:03,760
it in this form and see what you get okay so so I will give it for homework this is not this is

260
00:39:03,760 --> 00:39:10,039
actually trivial there is not much truth I mean just a matter of like doing it like properly now

261
00:39:10,039 --> 00:39:15,719
let us look at this particular equation let us look at the MOP solution can you tell me something

262
00:39:15,719 --> 00:39:22,480
about the relation between these two forms between the MOP and MFP solutions what are we doing a see

263
00:39:22,480 --> 00:39:29,279
that your F's are monotonic functions right so can you use that information to say something about

264
00:39:29,279 --> 00:39:37,400
this among these two guys which of them will be higher so is there a relation between these two

265
00:39:37,559 --> 00:39:46,960
guys so I get some values of this is what if this is a distributive framework instead let us say I

266
00:39:46,960 --> 00:40:01,760
compute alpha as FA union FB and I compute beta as F of A union B sorry A join B right if you join

267
00:40:01,760 --> 00:40:11,280
FB or A join B right so now the question is that can I can I tell something about alpha and beta

268
00:40:11,280 --> 00:40:29,360
some relation between alpha and beta so what do you know you know that A join B is bigger

269
00:40:29,360 --> 00:40:43,200
than both A and B right by the definition of join okay what else do you know you know that

270
00:40:43,200 --> 00:40:55,680
because it is a monotonic function you know that A is less than FA B is less than FB and her very

271
00:40:55,679 --> 00:41:03,039
good okay so which is less than equal to which one so like you are right maybe that you are

272
00:41:03,039 --> 00:41:12,759
just reasoning in slightly different order I guess so this is going to be the case right right

273
00:41:12,759 --> 00:41:23,519
so if this is the case if this is the case then can you establish a relation between MOP and

274
00:41:23,519 --> 00:41:38,559
FNFP so what is the relationship between MOP and FNFP which one is which one the upper one

275
00:41:38,559 --> 00:41:43,199
looks like MOP right the lower one looks like MFP where we first you take the join and then

276
00:41:43,199 --> 00:41:53,119
apply the function right so in that case your MOP solution less than equal to the MFP solution

277
00:41:53,119 --> 00:42:03,920
so when what does less than equal to mean if this solution is this solution then what do we say this

278
00:42:03,920 --> 00:42:14,639
over approximates right so essentially what is going on right now okay so then essentially

279
00:42:14,639 --> 00:42:35,279
what is going on is the MFP solution over approximates the MOP solution so I have left

280
00:42:35,279 --> 00:42:39,719
a lot of exercise for you these are like sort of simple discrete math assignments there is nothing

281
00:42:39,719 --> 00:42:45,319
more to it right so try these out at home like you will really be convinced you will be able

282
00:42:45,319 --> 00:42:49,079
to convince yourself that what is going on they are just a matter of putting things together

283
00:42:49,079 --> 00:42:55,919
there is nothing more to it so then essentially what you can say is the MFP solution will always

284
00:42:55,919 --> 00:43:07,919
over approximate the MOP solution what does it mean what does that really mean guys what happened

285
00:43:07,920 --> 00:43:17,800
you guys did not have coffee that tea was not good is it yes so it will always compute a safe

286
00:43:17,800 --> 00:43:24,639
solution so it may be the case that you do not get the best solution but you will surely get the

287
00:43:24,639 --> 00:43:30,039
safe solution you will surely get a safe solution so now let us summarize this whole business that

288
00:43:30,039 --> 00:43:40,880
we so essentially the idea is that but why not compute MOP right for even analysis like

289
00:43:40,880 --> 00:43:52,000
constant propagation computing the MOP solution is undecidable forget even high complexity right

290
00:43:52,000 --> 00:43:58,159
so there is even no not even a hope of computing the MOP solution right so the only way to get

291
00:43:58,159 --> 00:44:03,599
a solution is to get the MFP solution so now the whole business looks like this key if it is a

292
00:44:03,599 --> 00:44:13,399
monotone framework what does a monotone framework mean that you have you you satisfy ACC on a on a

293
00:44:13,400 --> 00:44:31,240
monotonic function right so if you have a monotone framework in that case your MFP solution over

294
00:44:31,240 --> 00:44:38,519
approximates your MOP solution this is the first learning the second learning is that if you have

295
00:44:38,519 --> 00:44:45,079
a better structure if you have a distributive framework what is the distributive framework

296
00:44:45,079 --> 00:44:52,360
when your function is distributive the function distributes over joins in that case your MOP

297
00:44:52,360 --> 00:45:01,840
solution is equal to the MFP solution now let us go back to our analysis so people should wake up

298
00:45:01,840 --> 00:45:10,400
now people have slept with the the mathematical part of it okay let us go back to our analysis

299
00:45:10,400 --> 00:45:17,960
in our analysis let us look at reaching definitions reaching definitions was it distributive has

300
00:45:17,960 --> 00:45:25,600
somebody able to prove that so take my word for it till you prove it to yourself like to me if

301
00:45:25,600 --> 00:45:31,079
you are not like if it does not turn out to be the case but assuming that reaching definitions

302
00:45:31,360 --> 00:45:39,159
it is a distributive framework because of that I actually even if I compute my MFP solution I

303
00:45:39,159 --> 00:45:44,079
actually end up getting the MOP solution I still get the optimal solution still get the best

304
00:45:44,079 --> 00:45:58,679
solution what about constant propagation is it distributive why is no why no why no give me an

305
00:45:58,679 --> 00:46:02,399
example where it is not distributive so when it is not distributed things are easy now give

306
00:46:02,399 --> 00:46:10,440
me a counter example you are done give me a counter example which shows it is not distributive

307
00:46:10,440 --> 00:46:19,559
hey we saw it saw an example yesterday remember the example can you reproduce that example

308
00:46:19,559 --> 00:46:35,599
right right so let us do that so it was x equals 2 y equals 3 it was x equals 3 y equals 2 and

309
00:46:35,599 --> 00:46:43,039
we want to get a solution here so if I try to get the if I take that if I take the apply the

310
00:46:43,039 --> 00:46:48,360
functions and then take a meet so what happens if we and there we have z equals x plus y

311
00:46:48,360 --> 00:46:59,840
so if I apply the functions then what happens then I get so I get here 2 comma 3 and here I

312
00:46:59,840 --> 00:47:05,599
end up getting 3 comma 2 but I am applying I am getting the MOP solution so I am not allowed

313
00:47:05,599 --> 00:47:09,960
to merge them yet so I will merge them here wherever I decide the solution right so now

314
00:47:09,960 --> 00:47:25,760
I will get it and I will get 2 comma 3 comma 5 where did I go really far okay so what do we

315
00:47:25,760 --> 00:47:32,400
get with the MOP solution so what is the MOP solution then then I take a merge so I apply

316
00:47:32,400 --> 00:47:45,440
the function still further that becomes 2 3 and 5 join 2 3 2 and 5 that is my MOP solution

317
00:47:45,440 --> 00:48:00,639
and that will be what that will be not constant top not constant and 5 that is my MOP solution

318
00:48:00,759 --> 00:48:06,879
what is my MOP solution or where I do the other way round the other side of distributivity what

319
00:48:06,879 --> 00:48:14,159
will I do there first I will take the join as soon as I take a join between 2 and 3 and join

320
00:48:14,159 --> 00:48:24,759
of 3 comma 2 and then I apply my f right which is my z equals x plus y right so this immediately

321
00:48:24,759 --> 00:48:30,519
becomes not constant not constant apply f on it which again gives me not constant not constant

322
00:48:31,079 --> 00:48:39,199
so that it is constant propagation is not distributive because constant propagation is

323
00:48:39,199 --> 00:48:46,719
not distributive so I cannot and getting the MOP solution is undecidable so there is no other

324
00:48:46,719 --> 00:48:54,119
option I compute the MFP solution which is still an over approximation of my MOP solution so the

325
00:48:54,119 --> 00:48:58,880
constant propagation we do not get the best solution we get something which is over approximation

326
00:48:58,880 --> 00:49:18,800
of that yeah no these are completely different things altogether separability and

327
00:49:18,800 --> 00:49:29,200
distributivity are different thing altogether they do not so distributivity is on the structure

328
00:49:29,200 --> 00:49:35,560
of the function f right now the structure the function f could be could be non separable where

329
00:49:35,560 --> 00:49:39,000
it is using things from other things that is a different matter but they are they are different

330
00:49:39,000 --> 00:49:42,440
aspects I do not have readymade examples but you should be able to construct cases where

331
00:49:42,440 --> 00:49:58,400
both the things can so it is safe for monotonic frameworks but for distributive frameworks it is

332
00:49:58,400 --> 00:50:07,159
right so final summary is this so if I have a monotone framework consisting of a complete

333
00:50:07,639 --> 00:50:14,679
that satisfies ACC and a set of monotone functions that contain an identity element and is closed

334
00:50:14,679 --> 00:50:21,000
under function composition then I will essentially be able to if I compute the MFP solution I will

335
00:50:21,000 --> 00:50:30,159
be able to get a safe solution and if I have a distributive framework with the correct spelling

336
00:50:30,159 --> 00:50:37,559
and a monotone framework sorry and the functions are also distributive in that case I get solutions

337
00:50:37,559 --> 00:50:52,839
we I will be able to get the optimal solution the MFP solution so our reaching definitions

338
00:50:52,839 --> 00:51:00,139
the lattice was a complete lattice it satisfies ACC so every finite lattice is always a complete

339
00:51:00,139 --> 00:51:09,059
lattice right because because there are no infinite sets anyway so you do that extra

340
00:51:09,059 --> 00:51:16,539
condition is not does not really matter right so the transfer functions are both monotonic

341
00:51:16,539 --> 00:51:20,980
and distributive so it will always end up computing the MFP solution so essentially

342
00:51:20,980 --> 00:51:27,019
what we have now what with after all this big business what did we get we got a nice unified

343
00:51:27,019 --> 00:51:36,900
framework a unified mathematically sound framework and what it gives is it gives me a nice checklist

344
00:51:36,900 --> 00:51:41,860
right even if you want don't want to do all the proofs and assume the people who did it before

345
00:51:41,860 --> 00:51:48,019
you were smart enough to have done the smooth proof properly you can just trust them and use

346
00:51:48,019 --> 00:51:53,659
but you still get a nice checklist which says that now you do not have to do the termination

347
00:51:53,659 --> 00:51:58,940
proofs the soundness proofs for every analysis that you design separately you would not have

348
00:51:58,940 --> 00:52:03,219
to argue about that remember how did we start doing the analysis that termination proof for

349
00:52:03,219 --> 00:52:09,539
the reaching definition case we said oh there is a set of definitions but this set of definition

350
00:52:09,539 --> 00:52:14,420
only increase I can see this transfer function is doing that then it but it is I see the total

351
00:52:14,420 --> 00:52:20,179
number of definition is bounded so I was analyzing on the on that particular analysis think about a

352
00:52:20,179 --> 00:52:26,139
more complicated analysis doing that might be harder instead I can simply use my checklist I

353
00:52:26,139 --> 00:52:33,219
can simply say okay does my does is it a complete lattice does it satisfy ACC is it a monotone

354
00:52:33,219 --> 00:52:38,659
framework is a distributive framework so these are small questions to answer on a given given

355
00:52:38,659 --> 00:52:44,379
analysis right and once you've answered that you exactly know what your framework is supposed to

356
00:52:44,380 --> 00:52:49,820
do it is it immediately guarantees that your framework would terminate the analysis would

357
00:52:49,820 --> 00:52:54,380
terminate and it guarantees the sort of solution you will get it will get a sound solution or you

358
00:52:54,380 --> 00:53:00,059
get exact solution whatever you get so you do not have to do all the proofs already so

359
00:53:00,059 --> 00:53:03,900
Nostra taskie cleaning they have been able to solve they have been kind enough to do all the

360
00:53:03,900 --> 00:53:09,960
proof for us right now we can simply trust them and we can just check that our analysis that we

361
00:53:09,960 --> 00:53:14,960
have designed satisfies those conditions or not right if those satisfy the conditions and those

362
00:53:14,960 --> 00:53:19,240
questions are similar to what I asked you right is constant propagation transfer function monotonic

363
00:53:19,240 --> 00:53:23,840
is it distributive and it's a matter of and it as I said this is a discrete math question right

364
00:53:23,840 --> 00:53:31,240
sit back and see what what happens once you have that you are you can actually say that fine my

365
00:53:31,240 --> 00:53:37,639
analysis is going to have these properties right so you do not have to right so this is the whole

366
00:53:37,639 --> 00:53:44,599
thing about the idea of striving for this unified framework that we sort of started yesterday maybe

367
00:53:44,599 --> 00:53:50,559
almost day before yesterday right so this is this whole business about dataflow analysis which

368
00:53:50,559 --> 00:53:55,159
establishes this very nice sound mathematical framework in which you can build your analysis

369
00:53:55,159 --> 00:54:04,900
and you get guarantees that how your analysis would work so how much time do we have we have

370
00:54:04,900 --> 00:54:12,420
some time so let me just think what to do okay I just give you bits and spurts of few things I

371
00:54:12,420 --> 00:54:18,300
don't know how much after lunch if you have get I'll have time to do that if that we'll see how

372
00:54:18,300 --> 00:54:26,820
it goes okay so one thing I wanted to talk about is there is a more generic framework to

373
00:54:26,820 --> 00:54:41,740
analysis something known as abstract interpretation so it sort of subsumes dataflow analysis right so

374
00:54:41,740 --> 00:54:48,539
essentially it again is a big theory of over abstractions so essentially it says that how

375
00:54:48,539 --> 00:54:55,980
can I build simpler analysis which can scale well but still give me certain guarantees right

376
00:54:56,139 --> 00:55:02,539
and the interval analysis that I talked about yesterday I did not tell you I cheated a bit

377
00:55:02,539 --> 00:55:08,820
and that is actually taught more in terms of the abstract interpretation then in the data

378
00:55:08,820 --> 00:55:13,820
analysis framework so data analysis is more in the compiler domain so for optimizations and all

379
00:55:13,820 --> 00:55:17,500
people end up using data analysis but abstract interpretation is a more general theory which is

380
00:55:17,500 --> 00:55:24,380
used even in the verification community this is one thing second thing I wanted to talk about is

381
00:55:24,539 --> 00:55:36,019
so I just want to tell you that something like this exists and and you can ask Google God to

382
00:55:36,019 --> 00:55:43,460
tell you about more about this right so search for it and try to do things okay so the other

383
00:55:43,460 --> 00:55:50,300
thing I want to talk about is there is this notion of so whenever we are doing an analysis

384
00:55:50,300 --> 00:55:56,780
we are essentially saying that a program is extremely complex right if we try to model

385
00:55:56,780 --> 00:56:01,420
everything in the program it becomes very difficult to model it so essentially that is

386
00:56:01,420 --> 00:56:05,660
why we have to do these abstractions so what is an abstraction abstraction is basically throwing

387
00:56:05,660 --> 00:56:09,260
away details about the program throwing throwing away details which you think are not useful

388
00:56:09,260 --> 00:56:14,220
right yesterday you guys did an abstraction where we were building this buffer overflow analysis

389
00:56:14,220 --> 00:56:20,019
right what was abstraction the abstraction was that we will only look at integer variables

390
00:56:20,019 --> 00:56:25,539
because those are the variables which occur as indices to arrays can create a buffer overflow

391
00:56:25,539 --> 00:56:35,500
second is we said that we will only look at operations of the kind V1 is equal to V2 plus

392
00:56:35,500 --> 00:56:42,219
minus some constant C because that is the that is what generally happens with array indices

393
00:56:42,219 --> 00:56:47,380
generally array indices don't show any other nobody multiplies things that I mean not that

394
00:56:47,380 --> 00:56:53,380
you cannot do it but generally you don't do it right so essentially what we did was

395
00:56:53,380 --> 00:57:00,780
we essentially said that every operation which looks like this we will retain in our model

396
00:57:00,780 --> 00:57:06,340
and every other analysis we will assume that that variable becomes what those statements

397
00:57:06,340 --> 00:57:09,500
are there I have to do something with those statements right what if they end up coming

398
00:57:09,500 --> 00:57:14,260
here so what do I do I have to do something about it I still have to say what values they

399
00:57:14,260 --> 00:57:26,260
can get so what is the worst I can assume the top right the minus infinity to infinity

400
00:57:26,260 --> 00:57:30,180
so I assume every other operation pushes the values to minus infinity to infinity or in

401
00:57:30,180 --> 00:57:34,920
other words we this is a non-deterministic assignment so it is star means it can just

402
00:57:34,920 --> 00:57:41,340
assign it to any value by the way what does the lattice for the interval analysis look

403
00:57:41,340 --> 00:57:49,180
like what will the lattice look like and what is the ordering relation so I am sorry

404
00:57:49,180 --> 00:57:58,820
what is the set and the ordering relation so what is the bottom element think about

405
00:57:58,820 --> 00:58:11,300
it what do you want no so how did we initialize the sets you saw the code yesterday right

406
00:58:11,300 --> 00:58:23,539
so actually in this case so every such range like let us say 2 to 5 essentially represents

407
00:58:23,539 --> 00:58:31,620
a set of elements right 2 3 4 5 so what should be the corresponding set for the bottom element

408
00:58:32,619 --> 00:58:44,779
0 elements right unfortunately in this range business I cannot write it I can write it

409
00:58:44,779 --> 00:58:53,099
but it is very bad I mean I can write minus 5 and like the other side minus 5 and minus

410
00:58:53,099 --> 00:59:01,179
6 negative range which says that of course but this is like very clumsy and not nice

411
00:59:01,539 --> 00:59:12,699
no no but you do not 0 to 0 1 to 1 is singleton elements right singleton sets yeah those are

412
00:59:12,699 --> 00:59:18,819
constant values the singleton sets but bottom element what do we do so we define a bottom

413
00:59:18,819 --> 00:59:25,819
we add an dummy bottom which is basically means that there are zero elements what is

414
00:59:25,820 --> 00:59:39,820
the first level then after that singleton sets like 0 to 0 1 to 1 2 to 2 so on 4 to 4 then what

415
00:59:39,820 --> 00:59:55,500
next level yes so 0 to 1 1 to 2 then 0 to 2 so on and so how do you take the meat remember

416
00:59:55,500 --> 01:00:01,219
meat operation now mean of the 2 and the mean of the left hand sides and the max of the right

417
01:00:01,219 --> 01:00:07,579
hand ends that is exactly what is happening see that is how not meat in this case join so the

418
01:00:07,579 --> 01:00:12,539
join is happening this way and what is going to be the top element minus infinity to infinity

419
01:00:12,539 --> 01:00:21,980
that is also sort of dummy but we put it right so this is the lattice and what is the ordering

420
01:00:21,980 --> 01:00:31,579
relation how do I define the ordering relation how do I say something is less than something

421
01:00:31,579 --> 01:00:44,500
length of the interval no length of the interval will not work right no that is also not required

422
01:00:44,500 --> 01:01:06,179
what about these two guys say 2 to 20 and let us say 12 to 15 right so the range of values contained

423
01:01:06,179 --> 01:01:12,980
within one of them should be completely subsumed by the second the right hand side right so like

424
01:01:12,980 --> 01:01:22,300
in this case this is less than equal to 2 to 20 right because the right hand end is past this

425
01:01:22,300 --> 01:01:33,099
and the left hand end is before this that is the ordering relation okay so like now back to

426
01:01:33,099 --> 01:01:38,820
abstractions so essentially the abstraction we did was we said that any so if I have an expression

427
01:01:38,980 --> 01:01:45,539
I have a statement which assigns to something like this I will simply retain it everything

428
01:01:45,539 --> 01:01:51,460
else I'll say it's it can be just anything at all right so I can do abstraction on the data flow

429
01:01:51,460 --> 01:01:58,380
I can see that certain statements can do weird things can just do anything they want similarly

430
01:01:58,380 --> 01:02:05,580
I can do abstraction on the control flow you can say that rather than actually looking at

431
01:02:05,579 --> 01:02:10,340
the control flow graph and saying that the control can be only be transferred in this manner

432
01:02:10,340 --> 01:02:17,380
which requires such a sophisticated analysis can't we not say okay any control can go to anywhere

433
01:02:17,380 --> 01:02:24,860
that's an abstraction then I don't need the control flow graph at all so I can throw up

434
01:02:24,860 --> 01:02:28,980
in a control flow graph I can say I don't care about what the control flow graph is I take a

435
01:02:28,980 --> 01:02:36,099
bag of my statements s1 s2 s3 s4 and I say any statement can just go anywhere and loop itself

436
01:02:36,099 --> 01:02:41,740
and go like this and loop itself it can so it's a complete graph on all these guys with even

437
01:02:41,740 --> 01:02:47,099
self loops so if I do that so essentially what I've done is I've thrown away my control flow

438
01:02:47,099 --> 01:02:52,099
graph I said I don't care about my control flow graph give me a solution on this particular thing

439
01:02:52,099 --> 01:02:57,500
this is so people define these two types of analysis and these are this is a very important

440
01:02:57,500 --> 01:03:05,860
distinction one is called a flow sensitive analysis where I care about how control can

441
01:03:05,860 --> 01:03:17,739
flow the other is flow insensitive analysis where I do not care about how control flows I assume

442
01:03:17,739 --> 01:03:22,619
that control flow control can flow in any way any these statements can be arranged in any order

443
01:03:22,619 --> 01:03:36,339
for a flow sensitive analysis we compute data flow facts at each program point but a flow

444
01:03:36,339 --> 01:03:44,380
insensitive analysis anything can just flow anywhere right so in flow insensitive analysis

445
01:03:44,380 --> 01:04:01,019
we create one summary solution for whole function right so now if you think about the landmark

446
01:04:01,019 --> 01:04:14,980
of program analysis so we have so we talk about these multiple types of sensitivities we talk

447
01:04:14,980 --> 01:04:25,820
about like like do you want to model function calls so correspondingly we have context sensitive

448
01:04:25,820 --> 01:04:41,220
or context insensitive analysis if you want to model control flow behavior you have flow

449
01:04:41,220 --> 01:04:55,780
sensitive and flow insensitive analysis what we have covered so far is only this flow sensitive

450
01:04:55,780 --> 01:05:03,180
analysis we have not even modeled function calls right so we currently only have solutions

451
01:05:03,180 --> 01:05:09,820
for every function separately so in the future lectures if the instructor is talking about

452
01:05:09,820 --> 01:05:16,260
these things you should be aware of what they are even if you do not know how they are computed

453
01:05:16,260 --> 01:05:23,340
so there are algorithms to actually induce like flow sensitivity how would you make a function

454
01:05:23,340 --> 01:05:33,100
flow sensitive how will you how will it know where to so let us see an example how what is

455
01:05:33,100 --> 01:05:37,260
flow sensitive analysis and what is flow insensitive analysis just to make sure that you are ready for

456
01:05:37,260 --> 01:05:43,700
the next sessions so essentially it means that let us say I have function foo and I have a

457
01:05:43,700 --> 01:05:51,380
function bar which is called from here somewhere in the function let us say this is foo 1 similarly

458
01:05:51,380 --> 01:06:04,360
I have another function foo 2 which also has a call to bar now let us say I want to do an inter

459
01:06:04,360 --> 01:06:13,380
procedural analysis as opposed to the intra procedural analysis we are doing till now so

460
01:06:13,380 --> 01:06:21,059
we only assume our whole universe is one function and that is all I care about right so now if you

461
01:06:21,059 --> 01:06:30,579
want to analyze this function so let us say this guy takes a parameter a so x takes some parameter

462
01:06:30,579 --> 01:06:39,139
y now there are two ways of doing this analysis right one is the context sensitive way of doing

463
01:06:39,139 --> 01:06:47,860
this analysis is to analyze each call to bar separately right separately figuring figure out

464
01:06:47,860 --> 01:06:54,460
that what will happen with bar when it is invoked here and what will happen with bar if it is invoked

465
01:06:54,460 --> 01:07:04,500
here right so for each of these calls so these are called call sites for each of these call sites

466
01:07:04,500 --> 01:07:13,740
you will have a different solution for the things in bar the other option not just that even the

467
01:07:13,739 --> 01:07:18,979
effect that bar has like let us say the value it returns that will be that will depend on that

468
01:07:18,979 --> 01:07:31,579
bar was called here not here right similarly the other option is that you do an analysis assuming

469
01:07:31,579 --> 01:07:37,619
that bar could have been called anywhere so it is similar to doing this MOP and MFP sort of business

470
01:07:38,339 --> 01:07:45,099
one option is that you first merge the behaviors of this function like wherever it is called you

471
01:07:45,099 --> 01:07:53,099
merge those values that can occur and then analyze this function the other is first analyze this

472
01:07:53,099 --> 01:07:58,539
function separately and then apply the respective function the rest of the function on that those

473
01:07:58,539 --> 01:08:03,900
particular pieces right so these are this is a difference as you can understand context

474
01:08:03,900 --> 01:08:09,740
sensitive analysis is more expensive than context insensitive analysis but again it can give you

475
01:08:09,740 --> 01:08:19,980
much better accuracy right so next you may be exposed to this context sensitivity context

476
01:08:19,980 --> 01:08:24,699
I am not sure exactly what is the thing but you should know these terms you should know what is

477
01:08:24,699 --> 01:08:29,760
context sensitivity what is context sensitivity what is flow sensitive analysis what is flow

478
01:08:29,760 --> 01:08:38,840
insensitive analysis any questions on the topics let me see if the next session we can do a very

479
01:08:38,840 --> 01:08:49,840
quickly do a flow insensitive analysis just to tell you how it works why is context sensitive

480
01:08:49,840 --> 01:08:54,000
more expensive because whatever we are doing right now what what we are doing is that every

481
01:08:54,000 --> 01:09:00,039
program point we are maintaining what happens at that program point and how that particular

482
01:09:00,039 --> 01:09:05,640
value propagates further in a context insensitive analysis we don't even have the control flow

483
01:09:05,640 --> 01:09:12,039
graph so there is no notion of a program point anymore and because I don't even know so program

484
01:09:12,039 --> 01:09:15,319
points are defined only on the control flow graph right so if you do not know an ordering

485
01:09:15,319 --> 01:09:20,640
of the statements the behavior the program point does not mean anything at all so now what I do

486
01:09:20,640 --> 01:09:28,200
is we compute one summary structure one summary solution which is true at every program point

487
01:09:28,200 --> 01:09:40,760
right so let's take a very very simple very this example so let's say I have x equals 1 y equals

488
01:09:41,280 --> 01:09:50,640
2 x equals 5 right so let's say this is my program so I am doing an exact analysis which

489
01:09:50,640 --> 01:09:57,079
is trying to track the value of each variable let's try to do a flow sensitive analysis of this

490
01:09:57,079 --> 01:10:02,560
so when will I will do a flow sensitive analysis what is the value I'll get here I'll say that

491
01:10:02,560 --> 01:10:10,440
both x and y are not initialized what will happen here I will say that x is initialized to a valued

492
01:10:10,439 --> 01:10:18,960
1 here I will say that x is initialized is assigned a value 1 y is assigned a value 2

493
01:10:18,960 --> 01:10:29,479
and here I will say x is assigned a value 1 sorry x is assigned a value 5 and y is assigned a value

494
01:10:29,479 --> 01:10:47,279
2 agreed okay now tell me can I somehow summarize these solutions which will be true irrespective

495
01:10:47,279 --> 01:10:53,759
of which order I run these statements and where I ask this question I want a summary

496
01:10:53,760 --> 01:11:08,760
solution for this whole thing I can do what no it's not about constant so I can simply say either

497
01:11:08,760 --> 01:11:19,039
I can say x is not constant I can say that x can point to a set of values 1 and 5 and y to a set

498
01:11:19,039 --> 01:11:37,439
of values 2 okay so what information have we lost here what about we have lost something

499
01:11:37,439 --> 01:11:48,560
about program point but maybe I should complicate this example let's I also have z is equal to

500
01:11:48,560 --> 01:11:57,360
x plus y so let's put this other thing so then essentially why what I have here is that x is

501
01:11:57,360 --> 01:12:12,560
5 y is 2 and z is 7 right now if I do the flow insensitive part what will happen to z it can

502
01:12:12,560 --> 01:12:16,640
take any value of x because I do not care about which order the statements are being

503
01:12:16,640 --> 01:12:30,760
done and so by values of z can be either 2 plus 1 3 or it can be 2 plus 5 7 no not defined if you

504
01:12:30,760 --> 01:12:42,640
are if you are doing a propagation oh I see I see huh so either you do that you can say not defined

505
01:12:42,640 --> 01:12:48,039
garbage values it is possible to have a garbage values otherwise the problem is that garbage will

506
01:12:48,039 --> 01:12:53,400
go and sit everywhere otherwise so almost so instead of that let's try to keep an initialization

507
01:12:53,400 --> 01:12:59,760
that values will always get initialized okay I am doing a little clumsy analysis but let's say

508
01:12:59,760 --> 01:13:04,360
we take an initialization which is x equal to 0 equal to z equal to 0 these are global variables

509
01:13:04,359 --> 01:13:15,839
so then we will of course I will get a 0 at all these places also right taken point taken right

510
01:13:15,839 --> 01:13:23,159
so now essentially what I ended up having is I have a bad value of z which was not even possible

511
01:13:23,159 --> 01:13:31,679
in a flow sensitive analysis right but think about the complexity it's a very simple analysis

512
01:13:31,680 --> 01:13:40,560
right so every time so I did not have to take maintain meets like sorry maintain the ins and

513
01:13:40,560 --> 01:13:45,320
the outs at every program point take a meet and do something I don't even have to bother doing that

514
01:13:45,320 --> 01:13:53,200
I can simply just every time I maintain my set and update it depending on what happens but you

515
01:13:53,200 --> 01:13:56,760
have to be very clever about doing the summarization the only thing you can you cannot do a kill

516
01:13:56,760 --> 01:14:02,119
basically now anymore right so because the kill because you could do the kill because you knew

517
01:14:02,119 --> 01:14:06,840
that something happens after something only then that killed as possible so now the kills will not

518
01:14:06,840 --> 01:14:11,239
be available so you have to do what are called weak updates you can only append something to

519
01:14:11,239 --> 01:14:17,159
the sets you cannot remove anything from the sets anymore right so this is what a flow insensitive

520
01:14:17,159 --> 01:14:23,400
analysis looks like right so it is much simpler simpler in the sense in even in terms of space

521
01:14:23,399 --> 01:14:29,679
you can understand what was the space taken by the flow sensitive analysis it was a size of the

522
01:14:29,679 --> 01:14:40,199
solution set times the number of basic blocks what is the size of the solution set here just

523
01:14:40,199 --> 01:14:49,119
the size of one solution right very cheap the memory footprint is very small right in fact

524
01:14:49,159 --> 01:14:55,199
there are certain analysis like pointer analysis which are generally implemented as flow insensitive

525
01:14:55,199 --> 01:15:03,039
analysis because the sort of accuracy we get is okay with like so essentially pointer analysis

526
01:15:03,039 --> 01:15:09,359
is used to drive other optimizations right so why can pointer analysis create a problem what

527
01:15:09,359 --> 01:15:14,920
is a what is a problem with if you get pointers how you are seeing so can you give me an example

528
01:15:14,920 --> 01:15:20,000
where it can create a problem which let's say reaching definitions or let's say liveness analysis

529
01:15:20,000 --> 01:15:30,399
maybe that is easier so what what can be the problem with liveness analysis right so I let's

530
01:15:30,399 --> 01:15:39,239
say I want to try to I want to figure out if some variable Y is live here or not right now let's

531
01:15:39,239 --> 01:15:47,599
say I do not find any use of Y anywhere down the line but I see one basic block which uses star of

532
01:15:47,599 --> 01:15:59,399
Q what is the start of Q nobody knows what if this star of Q was Q was nothing but ampersand

533
01:15:59,399 --> 01:16:12,599
Y it is actually using Y but in disguise as a pointer dereference right so all your analysis

534
01:16:12,599 --> 01:16:18,039
that we have been doing you first will have to do a pointer analysis to figure out which

535
01:16:18,039 --> 01:16:24,759
location a variable can point to and then modify your analysis accordingly to take care of such

536
01:16:24,760 --> 01:16:32,720
scenarios right so pointer analysis is typically implemented as a flow insensitive analysis because

537
01:16:32,720 --> 01:16:39,440
the accuracy you get with like the sophisticated flow insensitive analysis is good enough to drive

538
01:16:39,440 --> 01:16:44,760
these other optimizations they do not do they do not hurt it too much so it is not too bad so I

539
01:16:44,760 --> 01:16:49,960
will come back I will again see the mood of the class if I find it is interesting I will do a

540
01:16:49,960 --> 01:16:56,560
flow insensitive points to analysis will be very interesting maybe I will drive it more

541
01:16:56,560 --> 01:17:02,760
to examples and not do too much of heavy theory right and if I see that the mood is not good

542
01:17:02,760 --> 01:17:05,800
then we will move to something called dynamic analysis.

