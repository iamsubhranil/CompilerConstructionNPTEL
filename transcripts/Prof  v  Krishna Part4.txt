 So, if you look at this code here, once you draw this CFG, you will find that here is one basic block. From this basic block, you have one edge to this basic block. You have another kind of couple of basic blocks here from which there is an edge to the block here, but that part is unreachable. So that part goes away. And then you have, so I just, and then I do not need the label here. Basically, now I can, I will basic block here and edge to the next basic block. This guy has only one successor, the bottom guy has only one predecessor. I can straighten the, do straightening. So this label is gone. I do not need. Similarly, now here is a basic block which has, now initially this basic block had two parents, two predecessors. Now it has only one predecessor. So because you did one optimization, it enabled one more. So now this basic block, so I have one basic block all the way here, then this, then this. Now if you look at it, if you do some simple constant propagation, we have not learned how to do it, but that is fine. So here it is y equal to 2 and y equal to b plus 1. You have already done reaching definitions, right? The reaching definitions will tell you that this definition reaches nowhere, right? So y equal to 2, this guy will, is gone. Then y equal to b plus 1, constant propagation will make it y equal to 2. Now this b equal to 1 reaches nowhere, then x plus plus remains. Now you have this if else, is y greater than 3? No, so you know that the then part is gone. So this is constant propagation if you do, that goes out. And now I have this if, before I do, see here I have y greater than 3, the else part is y is less than 3. So that means this inner if is always false. So I can not only remove that part, but I can also remove this inner, okay? And if you are dealing with CFG, you will find that this particular block now has only one parent. So you will merge those two, now I will have this if x greater than 5, y equal to y minus 3. And now comes something trickier. Now I have a while loop, while y is less than 100. Your constant propagation will tell you that y is, value of y can be either 2 or minus 1. So constant propagation, normally we keep only one constant. But let us say you do something smart, we do not know what that smart thing is. Then you can say this condition is true for the first time, right? So we will come to that. So we have this while loop here, we will first convert it to a do while loop, right? Do while y is 100. And we know the condition is true for the first time, so we can, we do not need an if condition on the top. If we did not know, then we would be forced to keep a condition that looks like this. If y is less than 100, right? But in our case we know it, so we skip that. And now I have z equal to 4 and z equal to 5. This definition reaches nowhere. So this definition goes. Then I have z equal to 5, this is loop invariant. I will move it outside, right? And now I have z equal to 5 which reaches here. It is a constant. So I remove that and da-da. I have y equal to y minus 3, what is the value of y here? 2. So 2 minus 3 is minus 1. This also goes and I can do couple of more things. So this kind of, right. So now if we look at this code, right? Using the techniques we have studied so far, this is what you can do. And some of you said look, I am smart. I can see that this is actually doing just a simple addition. Sum equal to sum. So what I am adding? y, y plus 1, y plus 2, y plus 3 up till 100 from some initial value of y, right? And then you applied your favorite mathematical formula and computed this whole part. If y equal to 2, what will be the answer? Else, what will be the answer? That can also be done, right? So some of you said look, I will replace the whole do-y loop and the print to something like this. If y equal to 2, sum equal to something else, sum equal to something else, right? Both are same, is it? You get the same answer? Yes. Really? Sir, if we plug in y and sum, then it is 2 to the power minus. So there is something interesting that many of you have missed. The initial value of sum is not given. Yes, sorry? Yes, so we do not know. Sum equal to sum constant value. Sum plus sum constant value, yes. Both are fixed. Both are the same. Same for y equal to 2 or minus 2. And they would not be same, but the formula is same. How can it be same? Sir, for y we are starting from 2, next step. See here, let us say y is minus 1. 0, 1, they cancel out, 2 to 99 and the other way is 2 to 99, right? Good. So now the moral of the story is that either way you have only a single number, sum equal to sum plus sum constant. What is the, anyone bother to calculate it? Huh? 4949. 4949, is it? All of you are in the, I have not calculated it. If you say it, I will just take it. Okay, wow. So this whole thing is gone. The print sum will go and I will replace it with sum and now can we remove this as well? Okay, a couple of things I have. See here is z equal to 5, right? If this is my whole code, I can remove z equal to 5 and I can probably also remove, I can remove, I can remove y equal to minus, I can remove y equal to 2, I am not using it. This goes, wait slowly, one at a time. So, right? Okay, I have, if x greater than 5, nothing, right? Now can I eliminate this if condition? Because the condition has no side effects, I can eliminate that as well. So once I eliminate that, I do not need x plus plus. So please do not tell me in the morning all the code I wrote is only two lines of code. No, some plus equal to. No, fine, you, whether you keep it some plus here or here, that is right. So of these, the last optimization is something that not many compilers do, where we took the while loop and try to compute. to, if it is such a simple math, it can be done, but otherwise it is harder. The other thing which is hard is y's value is it minus 1 or 2, right? And then you merge both of them into a single, you say hey, both of them will have compute the same value. That is a bit of math and a compiler may not normally do. No, it is not always you can identify that. And then compute the closed form expression. That is what you guys did, right? You took the do while loop, you took the, computed the closed form expression. From that you said hey, I can actually reduce the closed form expression to a single number. That is what was that. I think researchers understand and the developers know about these techniques, but as I said, unless the pattern is something obviously simple, it is not easy to come up with closed form expressions in arbitrary code. You know, but I can have arbitrary code in between, right? That makes it hard. See, if the code is simple, it can be done and I am pretty sure we can find prior work on that. Okay. Yes, that can also be done. What is your name? Atharva is saying if all my, if I have a piece of code in which some variables, values are already there or some variables are assigned some constants and I am doing some evaluation on that. Why cannot the compiler partially evaluate that part and plug in that code? That also happens. Those who are interested read about partial evaluation. Okay. People do a lot of work on that. But anyway, moral of the story was the code that, the optimizations that we did yesterday can be very effective, right? I mean, do you see any link between this and this, right? And Ujwal, to be able to say that this and this are equivalent is pretty hard, right? We are talking something else in the morning. Okay. Any questions on this so far? Okay. Then, what I will do? I will close this and, okay. So, now we will start a new topic which is not actually new. I am told you have already been, I mean, the, Professor Shubhujit from Kanpur has already covered quite a bit of data flow analysis. I however need a few concepts to be on top of your mind or in your cache. So, what I have done? I put in some introductory material which we will call as recap, okay, which will go over quickly then before we go into our material, okay. We want to do some optimization. These optimizations need to understand how the data is flowing in the program and we want to do data flow analysis to do this, to understand about the program. So, data flow analysis we do so that we can provide information about how a program manipulates the data in the program, okay. So, it basically studies the behavior of the function. You can use the data flow analysis to build the control flow information. If you find that y is always 2, then you could say, hey, because y is always 2, the y greater than 3, that condition is false. So, your data flow information can help refine and build control flow information, okay. You can use data flow analysis to understand the program. For instance, you can use it to say, hey, here is a piece of code that sorts an array, ascending order, right. It is pretty involved but can be done in theory, right. You can use data flow analysis to generate the model of the original program and verify that the model is correct, okay. The key point about data flow analysis as you guys know is that it should give information that the program does not misrepresent what the procedure does. When it says it may do something, that means the rest of it is not possible. The opposite of may is must not, right. So, the data flow analysis says that something is impossible, that should be the case that it is never possible, okay. Data flow analysis is also done for program validation to validate that the program does what it says, okay. There are different types of analysis, intra-procedural and inter-procedural analysis. We will study, we will start with intra-procedural analysis, then we will touch upon inter-procedural analysis, okay. You have already seen iterative data flow analysis where you build a collection of data flow equations, right. So, what is a data flow equation? It tells which data may flow into which variable or which expression or different program abstractions and once you have these equations, they are solved iteratively. What we do is we invariably start from a conservative set of initial values and continuously improve the precision. The dominator computation yesterday, for instance, was one such example where we initially said for each variable, the dominators are the set of the all, sorry, for each statement, set of dominators are all the statements and kept on refining them, right, okay. So one disadvantage of such a scheme is that initially we may be handling too large a data. So what sometimes people do, they start from an aggressive set of initial values, very small, kind of which is very aggressive and then continuously improve the precision, kind of improve the precision, kind of I will make it bigger, bigger, bigger. So both are possible depending on the program, problem you are solving you can choose. So the advantage is the data sets are small to start with. The choice mostly depends on the problem at hand, okay. For instance, by the way, you remember the reaching definition example, right. So in this code, can you tell does the definition of I at line 4 reach the users in 7 and 8? Does it reach yes or no? Yes it may reach. But if I say, must it reach? I do not know, right. But reaching definitions, when we say mostly we talk about may and may information. So using may information we say that this I in both the statements it reaches, right. And what about does the value of J at line 7 is computed here? Does it reach the line 10? Does it reach the use in line 10? Does the value, does the definition J gets here at line 7, does it reach? It may reach. Why it may not reach? Sorry? If n is negative, if n is negative, you are saying this may not even execute. Then some other definition may reach. Am I asking is this the only definition that may reach? No. I am saying, is it guaranteed that this definition will reach? No, why not? Correct. Okay, so? So, will the definition of this J, whatever the I that may get, I may change or not I do not know at this time. I am getting there is some definition here. Will it reach here? Is it guaranteed to reach that point? Assuming the while loop is, I enter the while loop. Still no guarantee, why not? What happens in the G function? So what may happen? It can be infinite loop, right? If it is an infinite loop, it may not reach. So, yeah, so there can be, you can even terminate in G. And if you want to be paranoid like that, you can even have an exception inside that, which will jump out, right? So what we are saying, it may reach, right? Make sense? Anyone who still does not see that this J, there is a chance that this, after you execute this J, I may not get this definition here, because the loop may not terminate. So most of the time, when we do such analysis, we assume that all loops terminate, all branches are taken, we are, when you say it is precise, it is module of those things. Okay. So you have already done reaching definition. Good. So data flow equations behavior, so when we specify data flow equations, so for example, in the previous line, we kind of say, here is a definition, here is a definition, this definition is created in this block, and the definition is flowing through me, right? So before the block, what definitions were reaching? After the block, what definitions are carried forward, right? So we call these equations as transfer equations or transfer equations or flow equations, right? So in the forward analysis, you know that given for a block S, how do I compute the out? The out depends on its ins and what is happening inside, right? So if I see whatever is happening inside is, I know is a constant, then it is a function of ins, and this F encapsulates whatever is happening in the block. In backward analysis, I compute my in based on outs of my outs, right? And the rules have an interesting property that they change the values only in one direction, something like if I initially have all zeros, then from zeros it will only go to ones, it will never go from one to zero, right? So basically what we are saying, the information is going only in one progressing one direction, we call it kind of intuitively that is what and we call it as monotone, what is a monotone, we have been informed, right? So this ensures that iterations, the process will terminate. By the way, you studied about reaching definitions, right? What is the use of reaching definition? We can remove dead code, right? We can remove dead code, what else can we do? You can do many things. Can you use reaching definitions to find errors in the program? Such as? If there is no definition is reaching a use, then Java will say uninitialized variable, right? And because of what you have studied in the properties of lattices and fixed points, we know that this iterative solution will produce an acceptable solution, right? And brief summarization of the monotones, we say a function is a monotone if x is less than y, then fx is less than fy. And the flow function has to model the effect of the programming language, I mean what the statement does. And we want the flow functions to be monotones because we want the process to terminate, good. And we say for a function f, it has reached a fixed point if f of z is equal to z, okay? So that is a fixed point of a function. And in our case, when we have a series of data flow equations, we compute the fixed point and we call it the solution, right? That means we cannot define it any further, okay, good. And our goal is to compute data flow equations by doing the meet over all paths. This is covered, right? MOP solutions, good. So we start with some prescribed information at the entry or sometimes exit and then keep on doing either forward or backward analysis. And we repeatedly apply this till we reach a fixed point, okay. This is the kind of a skeleton of a forward analysis, okay? So let us, maybe you have been shown a similar algorithm using different thing. We will go over it and derive constant propagation from this, okay? So let us pay attention here. So we have a set of nodes where for our convenience, we can assume every statement is a different node. And statement, do not keep very complicated statements. We will keep every statement as, let us say our three address code statements, simple statements, okay? We have a set of nodes, entry node, okay? And the transfer, the flow function for each of these things, which is like it takes a node and it takes some input and gives you some other output. L is my lattice, lattice of values. And so let us see what we do. Initially for each block, so I have a work list. I want to process all the blocks in my input. So I have a work list where I initialize it to N minus entry. So I initialize the entry, I initialize that. And I initialize the in of entry to be some unit value, okay? And I initialize the in of every other basic block as some top value, top value in my lattice, okay? Then what I do? I take one element from the work list. Which element doesn't matter? I pick one element from the work list and then what I do for that element, for that element, I look at all its predecessors. From the predecessors, what am I getting? My predecessors out is my in, right? So what I will do, I want the out of that predecessor. How do I get the out of that predecessor? See I have a block like this. I want to take a meet of the out of this and out of this, right? This out and this out, I want to take a meet of, correct? And this out I can compute. If I know this in, then I can take the in if I call this as P, right? So whatever is the in of that P, I can use the transfer function of this guy and take the input and compute the out. Similarly, I can take this guy's transfer function, compute this guy. So now once I have these two, I can take a meet of these two to give me the in for this block B. That's what I am doing here. So I am taking a meet of all my predecessors outs and computing my in. Then I will check if my in is different from what was there before. If it is different, then I am setting my in as the new value and then what I am saying, hey, something has changed. I have two options. Like in the previous case, I will say reanalyze the whole world or say don't reanalyze the whole world but analyze only what may get affected because of me. What may get affected because of my in? Only my successors, not others. So what I will do, if the value is, if my in has changed, then I will set my in to the new value and add to the work list all my successors. All are on the same page. And then we keep on repeating till the work list is empty. And do we have a conviction that this loop will terminate? Why? And now I am adding to the work list. I may randomly add to the work list, right? What is the guarantee that I will terminate? Anyone? Yes, I am removing one element at a time to the work list and then adding, in the worst case, all my successors. There may be a loop. So I keep on adding my successors. So may be, will I be in an infinite loop? Right? So what I am doing, I am adding my successors. If I am in a loop, you add me, I add you. Why? I mean, it is a set, work list is a set. Yes, so there are no repeated elements. That is right. So I have added all my successors. Let us say I have only one successor. That is you. And we are in a loop and so you will add your successors. That is me. So you add me, I add you. Then there is a change. Okay, good. That is the key point. I am adding only when there is a change. Okay. Why do you say so? So Rishabh is saying after certain time, there will not be any change. What gives you that confidence? Right. So you are right. So you are doing a meet. So in a lattice, if you keep doing meet, you will finally reach the bottom. Once you reach the bottom, there will not be any more change. It is a lattice. We do not know what the elements are. Null set, empty set, we do not know. We are talking in terms of a lattice. I initialize to top. I keep taking meet, keep taking meet. Either there is no change or I mean there is no, finally I have to stop somewhere because the lattice height is finite. So if I keep on taking meet, finally I will terminate. Right. Yes, no, no, no. What is bothering? Okay, okay. Anyone still bothering? Okay. Yes, we are definitely assuming there have to be monotonic. If it is not monotonic, then we are not sure. So F is monotonic and it is working on a lattice. That gives us, okay. Fine. We will use this iterative data flow analysis to derive an algorithm to do constant propagation. Okay. We already have seen how we are using the constant propagation. So what is the idea of constant propagation? So we will take whatever values that are constants on all possible executions, on all possible executions and then we will propagate those. If I have an expression which is guaranteed, variable which is guaranteed to be constant in all possible executions, then I will replace those occurrences of the variable with a constant, right. I will replace it in all, as far as I can push, okay. But this is conservative. It can discover only a subset of all possible constants. We cannot discover all possible constants, right. Why do I say I cannot discover all possible constants? Why do I say I cannot discover all possible constants? Example, what is the example? Okay. Yeah. See what you are seeing is the ordering. What if I do the other way around? See I mean what if I will first do the other optimization then do constant propagation. But here is an example, right. I mean very simple example. If i is greater than 10, x equal to 3, else x equal to 5, right. This code was written long back. So if you do not like 2018 and make it 2000, you will recollect the y2k problem. Right. If it is greater than 2000, do something else, do something else. If you look at this code and want to optimize now, the code is still there but now you know that this year is always going to be greater than 2000. But the compiler would not know and cannot say that this is a constant. It is a constant. So the programmer knows, programmer with his intelligence or her intelligence now know that it is a constant. But we cannot detect all the constants. Similarly, there may be a loop that the programmer knows that it will be executed or it will never be executed. But compiler cannot figure out some of those. So we are, we discover only a subset of the constants. And a constant lattice, constant propagation lattice is this lattice where you have all the constant literals in the middle and you have top on the top and meet of any one of them is bottom. Right. So what is the, what do these values top and bottom mean? For us, bottom means constant value cannot be guaranteed. Right. So if a value of Xi compute to be a bottom, it means it is not a constant. If it is top, it means it may be a constant but not yet determined. So these are the initial values. And for all X, X meet top is X and X meet bottom is bottom. And if it is two constants, I am doing C1 meet C1 is C1 and C1 meet C2 is bottom. Does that make sense? And so we will be using a pair of techniques from a pretty old paper and this technique is called the Kildall's algorithm. And if you are interested, you can also look at the refluis paper of the old time. So we are talking about simple constants. So we are talking about constant that can be proved to be constant provided you do not assume which way the branch is taken. You will assume that both branches are taken and only one value is maintained per variable along each path. So I cannot say X is either minus 1 or 2. In the previous loop, we said no, no, Y will be minus 1 or 2. No. So here we are talking about simple constants where, do you want to watch? Go ahead. We will maintain only one value. We will not maintain multiple values, simple constants. The Kildall's algorithm starts with an entry node. The processing starts with an entry node. We will process each node and produce a constant information. That is, I will process a statement and say I had a set of constants. Now I have another set of constants. And we will pass this information to all its successors. And at a merge point, let us say I have a set of constants coming from left side, another set coming from right side. And what will I do? I will take a pairwise meet. And when I am processing a node, if its constant value has changed, but the constants it carries has changed, then I will say my constants have changed. New successors, make sure you are added to the work list. For simplicity, we will assume we have one basic block per statement. And for each statement, we will have a transfer function. We will see what the transfer function will look like. The important thing is the data set of dataflow values. What am I tracking? I want to know whether a variable is a constant or not. Correct? So for each block, I will track for each variable v1, v2 up to vn, I will track whether it is a what is its constant value or rather what is its value. What value can a variable take? Either one of the constant literals, top or bottom. A variable may contain only these three types of values, either a constant literal, top or bottom. Now, if I call it as this map as m that takes a variable v and gives me its value, then each variable, each statement when I process it, it takes one m as input and gives me an m prime as output. That is, it has, it takes as input a set of values for variables and gives out another set of values for the variables. So now let us look at how the functions look like. Again, as we said, we will start with an entry node. Which statements in the program can change my variable to value map m? Only assignment statements, nothing else, right? Jumps do not change nothing, right? Only assignment statements. So now let us understand how does it, how do these things change for assignment statements? Okay. Let us say I have a statement S and I want to compute the flow function Fs, right? And we say it is an assignment statement. So what is the structure of an assignment statement? It can be, sorry, S can be of one of the following, right? S can be a copy, right? Or what expressions I can have? Either a unary expression or a binary expression. That is it. My three address code does not have anything more than that. So x equal to y of z or x equal to of y, right? Now if this is my statement, so my flow function of Fs takes some m as an argument. What is m? m is the mapping flow of variables to values. In the out for S, which variables value may change? My statement is of the form x equal to blah. Which variables value may change? X. For rest of the variables, the value will not change. Does that make sense? Okay. So, for the Fs of m, right, how do I define this function? It returns an m prime such that m prime of a variable v is equal to mv, the old, this mv, if v is not equal to x, right? If v is not equal to x, if v is not equal to x, then m prime v is same as mv. If I write, if I let me, okay, here it is, I am writing v there, so I will just change it to v so that we talk about the same thing. Okay? So, this is v, m prime of v prime is equal to m of v prime if v is not equal to v prime. Okay? So, if you are not, if you are writing to v, then the map of all other variables, there is no change. If v prime is equal to v, right? So what will happen to m prime of v? What will happen to m prime of v? Let us compute. What will happen to m prime of v? There are three conditions. If v is equal to y is the statement you are processing, what will be m prime of v? Perfect. m prime of v is equal to m of y. What were it was? Right? Fine? Okay. If it is y of z, then what? What can this of be? Plus minus star, something like that, right? Okay? So, v equal to y of z, then what? Right. So, you are saying m prime of v equal to m of y of m of z. So, let us say m of y was 2 and m of z was 3, then you will say, and this is, op is plus, then you will do 2 plus 3 and mark it as 5. But what if this is 2 and this is bottom? If what does it mean? One of them is not a constant, the other one is a constant. Then what? Then? Not a constant. Not a constant. So, if both of them, if this is a constant, c1 and this is a constant c2, then I will do c1 of c2. If one of them is bottom, then? Then the value is bottom. This is this or bottom. When is it bottom? If either one of them is bottom. Okay? And similarly, if it is v equal to op y, what will it be? What will be m prime of v? If y is constant, if y is constant, then? Then op c1. If m of y is equal to c1 else bottom. If it is bottom, this is bottom. Make sense? Yeah. Yeah. This one, right? Yeah. What it says is, if it is bottom, then? This one, right? Yeah. What it says is, you are processing a statement which says v equal to blah. Correct? Before processing this statement, you had values for all the variables including v. After processing this statement, which one of the old values have changed, may have changed? Only those which, only that of v. For the rest which is not v, let us say you have v1, v2, v3. You are writing v1 equal to blah. Does it have, because of this statement, does the value of v2 and v3 change? No. What we are saying, except for the current variable which is being written to, for rest all the variables, the value is same as previous value. Right? Okay. So, we know that the value of y and z will be either constant or bottom, not top, because there must be some initialization. Right. So, in the context of Java, right, where you are guaranteed that there are no uninitialized variables, you can be guaranteed that this will never happen. However, it may so happen that during the analysis, the way you choose the, the order in which you choose, it may so happen that I am doing top of top, because you have picked a basic block. See, we are saying pick any block, we are not saying in any order, right. You have picked a basic block whose predecessors have not yet been processed. So, you may get a top. So, in that case, you just leave it as top. You do not make it a bottom, you just keep it as top. So, that is why we still kept this rule that if neither of them is bottom, we will keep it as top. We will let it, after some time, the top will become one of the more complex. Yeah. So, now what you are saying is, why do not I take into consideration some properties of mathematics and make it more precise, right. You can. So, you are saying, what is your name again? Badri. Badri. So, what Badri is saying is, if I, let us say I am doing an op, where I am doing something multiplied by 0, I can as well, even if the other number is bottom, I can as well make it a 0. Yes, you can. What else can you do like that? X minus x. X minus x. Both x's are bottoms, but you can say, in general, bottom minus bottom is not 0, right. But x minus x is, so you can take some of those mathematical or x divided by x, right. Some of those you can. What would x divided by x? X divided by x is not guaranteed to be 1, right, because you do not know if x is 0. But yeah, so you can, I mean, you can then find out if x is 0 or not. You can take into those mathematical properties. In, for a simpler scenario, we are saying, let us not worry about that, okay. And at a merge point, so now if I have, from this side I am getting 1M1, from this side I am getting M2. What is M1? It is a map from every variable to its value. What is M2? It is a map from every variable to their value in that path. Now I want to compute a merged M. How do I compute this? For each variable V, MV equal to M1V meet M2V, perfect. Okay, questions? Okay, there it will be in terms of sets. There it has to be in terms of sets. So you, let us say, see, I do not know what I will, were you taught using bit vectors or? Bit vectors. Okay, and did you, what did you initialize the values of each nodes? You started with empty sets, okay. In your case, then the meet was the union operator. The meet was the union operator. And when you keep meeting, finally you will reach, what is the worst you can assume? Every variable, every definition reaches every point. So your bottom is the set of all variables. Your top is the set of no variables. So it is empty set, right? Okay, in the mop type of solutions, meet over all paths, that is what we try to do. There is also something called job type of solutions, join over all paths. So, okay, what you keep your top and bottom is not so important. Some people keep lattice like this, some people keep it this way. But as long as you are proceeding in one direction, you are in good position, you are in good shape, okay. It is just people's, what you are used to. So I am used to this thing where my top is on the top and bottom is on the bottom. There are some people who like it the other way around. There are some school of thoughts, okay. So we understand the transfer functions and we understand what we do at a meet, right? Any questions on this? No? Okay, if not, we will take an example. So for this example, okay, we will do, what will you do? Do constant propagation. What are my variables? X, Y and Z. And now we said we will start with the entry. So the entry point, every variable has, is mapped to top, top, okay. So what is the transfer function for this statement? It changes the value of X to the constant literal 10. Y and Z, it does not change. This statement changes the value of Y to 1. This one? Z to 5. This one will take the value of Y and the transfer function is like this. The transfer function for that would be this. Both are constants. If M Y, sorry, if M Y and M Z, this is C 1 and M Z equal to C 2. Both are constants. So the transfer function can be some code like this for this. And transfer function for this would be if X is constant, then new value of X is C 1 minus 1, else bottom. Similarly here, transfer function for this. No that is meet here. Transfer function for print, nothing. It is not an assignment statement. We are only looking at assignment statements. So here we will just treat it as an identity function. It just takes an M and passes the same M down. So now let us do constant propagation. So I will start from here. I will start M. Let me do one thing. So what is my M? So my M is X equal to top, Y equal to top, Z equal to top. That is what I started with. I do not know at this time. And after processing the first statement, what will it be? It will be 10, right? After processing the second statement, what will it be? What would X? 10. See it takes an M. It took an M of X equal to 10 and Y equal to top and changed it to Y equal to 1. And then third one? Z 5. Now I have if condition. So if you see it in the CFG style, I will take this M that I have, this X equal to 10, Z equal to 5 and pass it to both the branches. So let me do that. Now let me, which one should I handle now? Which one should I process? The then part or the else part? Does not matter. So let us say I process the then part first. So after processing Y equal to Y by X, what will happen? Y is? So it will take the old value of Y and old value of X and get me 0, right? Integer division. And then I have X equal to X minus 1. What will it be? X equal to 9. And then I will just see if I can. And then Z equal to Z plus 1. It will become 6. And now I am doing Z equal to, in the else part, see. So at the end of the con, end of the then part of the con, I have X equal to 9, Y equal to 0, Z equal to 6. If you follow the algorithm, right, if you are careful, in my work list initially I had only the entry, which is at the top. Then I added X equal to 10. As I process this, the X equal to 10, the m value has changed. So I added its successor. Because I changed Y equal to something, next again the m value, what is the m value here at this time, before print? No, initially it is initialized to top, top, top, right. So technically after I process Z equal to Z plus 1, I will add to my work list its successor. Who is its successor? Print, right, or rather the join point you can say. So now if you say this print, which is the basic block, which has two predecessors. One predecessor is this Y equal to 0, the other predecessor is Z equal to Z plus 1. Now let us say I decide to process print. Then what will be the value of my m here? So I am taking a meat of top, top, top and X equal to 9, Y equal to 0, Z equal to 6. And it will be 906. No problem, we are not done yet. Now what is there in my work list? So the out of this will be, if I add, since its m has changed, I can process this guy and its out will be same X equal to 9, Y equal to 0, Z equal to 6. And now there is nothing more to add. The print has no successors, it will not add nothing. But what is there in my work list is Z equal to Z plus Y. Let me process that. I will do X equal to 10, Y equal to 1, Z equal to 5. What will be the out? Z will be equal to 6. And then I am saying Y equal to 0. So what will be the out? X equal to 10, Y equal to 0. Now what is the successor of this Y equal to 0? Print. Now for print, so the Y equal to 0's out has changed. I will add its successor now. I will add its successor. Now what is its successor? The print. So for processing print, I will take the meat of its predecessors. So I will take a meat of Y, X equal to 10, X equal to 9. It will be bottom. How do I write bottom? I will just write B. I do not have latex fonts here. I could search and put it. I am just writing B, B for bottom. Then meat of Y equal to 0, Y equal to 0, Y equal to 0, Z equal to 6, Z equal to 6. And then what will be the out of this? Out of the print? X equal to B. Nothing has changed. So I will stop here. And now what have I done? I have identified the constants. I have not done the constant replacement yet. I have not done the constant replacement yet. Now what I will do? I will go over this code. On the right hand side, wherever there is an expression, I will take the constants from that map and replace. So this will become Y equal to 0. This will become X equal to 9. This will become Z equal to 6. This will become Z equal to 6. This is already Y equal to 0. And this will become print X plus, not B plus, not bottom plus, X plus 0 plus 6. But 0 plus 6 I can simplify to 6. So it will be print X plus 6. And now you can invoke your reaching definitions and find where does this X equal to 10 reach? Nowhere. Remove. Y equal to 1 reaches? Nowhere. Z equal to 5 reaches? Nowhere. Oh sorry, sorry, sorry, sorry, sorry. X reaches. So I have to keep the X. My bad, my bad. This X reaches. Y and Z go away. This Y, poof, this X remains. Does it? Yeah, this is X equal to 9. This is X equal to 9. Why do I need this X equal to 10? Oh this will go down here. That's why. There is a reaching definition. This definition does reach. This X is equal to 9. This may also reach. This guy poof, this guy poof, this guy poof. So the else part is gone. So we did first pass, we propagated the constants. Second pass we replaced them and threw away unnecessary definition. Right? All on the same page? Any questions? Now? Okay. If you look at. If you look at. Yeah, here the lattice is a skewed lattice. I mean it's a kind of a flat, flat like this. As in? No, no, no, no, no, we don't have to reach the top, do we? In reaching definitions do we always reach a place where set of all definitions? No. We stop somewhere in between. Similarly when we did these dominators, we didn't say everybody is my dominator. You may. Okay. So what you are saying is when you take a meet, there you don't always go to the bottom. Here the moment you take a meet with anything other than you, you quickly fall onto the bottom. Yes. This is a, that way it is skewed. It's kind of very, the height is only bottom top. Okay. Okay. Okay.