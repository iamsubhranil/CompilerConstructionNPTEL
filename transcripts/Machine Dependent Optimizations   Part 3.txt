 Okay, so what we saw in the morning was a simple code generation scheme and as I said in the morning what we are going to now see is a more sophisticated code generation scheme that is by constructing the directed acyclic graph for a basic bra and then from that trying to generate code. Okay, so the reason why the simple code generator was not efficient is that it has no big picture, right. It has no idea of how, what are the variables which are going to be used in subsequent statements, right and other things. Okay, and even simple optimizations like common sub-expression elimination which sometimes is required in the generated code, it does not have any knowledge of that to do that. That is because it is considering one intermediate statement at a point in time. Okay, and the order of evaluation of expression again may change the cost and it does not really take that also into account. So, let us see how we can form code generation by constructing a directed acyclic graph. Okay, so if you look at a basic block, the basic block has a sequence of statements and these sequence of statements for these sequence of statements again we are talking about statements which are three address formats, right. We look at all of them and then we generate or we construct a DAG for that directed acyclic graph and in this DAG the reads represent okay unique identifiers that means that variables are constant in your program. Okay, and the interior nodes are operations like for example, plus or minus or whatever it is. Okay, and you have to now have a sequence by which you have to go through this so that you will be able to generate code for this in an efficient way. Okay, so the order in which they have to be visited is basically the sequence number or the ID that we are going to give and if you visit them in that order or in that reverse order so to say then you will be able to generate efficient code for that. So let me explain this by means of an example, right. So here is a piece of three address code, right, which is computing something, right. So if you look at it, it is basically calculating A of I, B of I, right and then that product, okay and then with that product it is basically adding that, okay adding that. Okay, so it is basically accumulating A of I into B of I across all of them some kind of a vector product is what it is kind of computing, incrementing I and then iterating, right. So if you look at it, this is a basic block because there is no control transfer instruction till the last instruction and there is no instruction to which control can jump into also, right. So that is why it is called a single entry single exit. If it enters here, it can only exit here, it cannot exit anywhere else, correct. This is the property of a basic block, single entry and single entry, okay. So how many of you follow this three address code? Yeah, afternoon, it is because of afternoon or we are all following it, right, okay. Okay, so now if I look at the right hand side that is where I have the DAG for that, it is also easy to understand, right. For example, here I am doing some indexing operation, okay for A, some indexing operation for B. Here I am multiplying 4 and I, of course I use I naught for some reason, let me explain that little later. Then the same 4 I is used in indexing operation of both of this, correct. And then you can see that on this side I am adding I with 1 and then I am checking for less than or equal to, that is possibly this statement. And of course here I am multiplying A of I and B of I and I am adding it with product, okay. And I keep doing this. As far as this basic block is concerned, this is what is happening. As it is you can see in this three address code that 4 I is calculated twice, right. You could avoid that by doing common sub expression elimination or by constructing this DAG itself you can actually identify the common sub expression and you can eliminate that also, right. You will see how to construct the DAG, but I am just giving you this example and then giving you the picture how the DAG will look like, right. Now once you have this as I mentioned earlier, all the leaf nodes are either variables, variables meaning typically these are program variables A, B and 4. Here in this example you can think that variables which start with the name T are temporaries created by your intermediate code. They are not program variables in the sense that, I mean in the sense that after this basic block or after this region of code if those variable values are not saved anywhere it is okay. But variable values like A, B or in this case I etcetera, A and B are non-scalar variables arrays, okay. So, they have multiple values whereas variable like I or product, right. They are scalar variables, right. Their values need to be saved because they are program variables. Others are temporaries generated by your intermediate code. Now in this what we can see is that each leaf node is either a variable or a constant, okay. And each internal node is some kind of an operation multiplication, addition or indexing less than or equal to and so on, right. So, this is what we mean by a DAG and if you go back to the previous thing that is exactly what we have said, right. Leafs are labeled by unique identifiers, variables are constants and interior nodes are labeled by an operator, some kind of an operation that we perform. And we are going to give a sequence ID for each one of these nodes and that tells us in what order we want to compute them, okay. So, first let us see how to construct the DAG. Then we will go about how to give the sequence ID for them. So, again you process the tree address code one by one. Take each piece of each tree address code, right. And then you add certain nodes or edges in the So, let us take the statement of the form x is equal to y of z, right. It is basically performing an operation on y and z. So, you find out if node y is not defined in the graph, okay. That means that, right, it is not already been used. y is a program variable or y could either be a program variable or could be a temporary, okay. Now, if y is not defined in the DAG and you are seeing it for the first time, then it has to be a program variable because if it is a temporary, it must have been defined before that, correct. If you are going to use a temporary which is a part of this expression, the temporary should have had some value defined to it without which you cannot use it in some other expression. If it is a program variable, yes, program variable would have been defined elsewhere in some other basic block, okay. And it would have a value which you are going to use it, okay. So, if node y is not defined in the DAG, right, then it must be a program variable. So, you create a leaf node with the label y. If similarly for node z, if it is not defined in the DAG, you create another leaf node and name it as z. And now you have, so basically otherwise you have some other node which is named y, which has been computed as a part of any of the previous statements. So, whichever node you have as y and whichever node you have as z, connect them and then call that as x. And the connecting node from which you draw edges to y and z, okay, is basically what is called x and that has the operation op, okay. So, here you are also going to check if there is a node with the same operation and the left child which is node y and the right child which is node z. That means that this expression is also already computed and there is already a temporary for this, in which case you can call that node itself also as x, okay. That is really what it is saying, okay. So, again let me go through this. If there is a node with operator op and left and right children as node y and z, then call this node y, sorry, call this node also as n because that already computes y op z. It is already existing in the graph, you can reuse it, okay. I will show you the example of this when we come to that 4 i statement. If it is not, then you create a node as n and then put a left child of this as node y and right child of this as node z. Again the left and right are important because not all operations are commutative. You have to be careful about that, right. So, you have to do that and you in this particular case, in the else case you actually create a new node, okay. Now, delete x from the list of attached identifiers and append x to the, so for the new node you basically call this as x because x may be redefined, okay or it may be the case x is defined for the first time, x could be a temporary and it could be defined for the first time. Node n is the one which is going to be called as x, okay. So, you give the name x to that node and if there is any other identifier which also has x you delete it, okay and maybe they can be renamed as x naught or x 1 or something like that, okay. If you have a statement of the form x is equal to y which is a copy statement, then identify if there is a node y, right. If there is a node y then you can attach x to it. If there is no node y, you create a node, leaf node with label y, add x to it. That is essentially what you try to do. In other words, every time you encounter an operation, right, you find out whether its left and right children already exist. If it exists and you also see whether the operation exists. If that operation with the left and right child already exists that means that you have already computed the value. So, you can actually go and call that also as x. Otherwise, you create that operation, connect the left and right child to it. If the nodes y and node z do not exist, create them. These are, you know, variables which are going to be started. So, that is essentially what we do. Let us just go through that example step by step and then try to understand how this works, okay. So, let us take the first statement 4 i, right. So, here one of the operand is i, the other one is 4, right. We are starting with an empty graph. So, neither of them is available. So, we can start off with the leaf nodes 4 and i and star is the operation that you perform, correct. So, you put a node with star and then left child and right child are 4 and i and this is going to be called t 1. So, attach the name t 1 to this node, right. The next step is t 2 equal to a of t 1, right. So, here the operation is the indexing operation which we show it like this, correct. And one operand for this is a which is a variable name and a does not exist in this graph originally. Therefore, we create a leaf node for a and attach it to the left child, attach it as a left child and the right child is t 1. t 1 already exists in the graph. So, you connect it to t 1, correct. Now, the next statement is 4 i, right. 4 and i already exist in the graph, constant 4 and constant i already exist. In fact, there is a node with star and left child as 4 and right child as i. That means what? This value has already been computed. You have seen another statement which is exactly of this form, right. So, there is no need to create another node t 3 for that. You can call this itself as t 3. That is why you are attaching t 3 to the same node. Now, by doing this what have I achieved? We have achieved common sub-expression elimination. You are going to compute this only once, correct. Now, let us go to the next one. Next statement is b is equal to t 3. That means that it is an indexing operation. Question, yeah. Question or? Okay. Okay. Right. The next one is b is equal to t 3, right. So, b does not exist. So, we create b as a leaf node. We put an indexing node and then connect t 3 to this, okay. This is called t 4, right. t 3 can also exist here. I do not know why it was got removed, but t 3 will also exist here because if there is a future reference for t 3, right, that is same as 4 i. This value has to be taken. So, t 3 is not removed from here. Do not take it that way. t 1 comma t 3 is here. t 4 is created which is the indexing operation. Then the next step is t 2 star t 4. Create a new node, put star for that and call that as t 5. The next step is one more addition, okay. t 6 equal to product plus t 5. Product does not exist. So, you create a leaf node for that and this is the right child. Create a new node, call that as t 6. Then one more step, right. So, here, so this is an equal thing. Remember, this is, if you see in that algorithm, we have a separate set of statement to be executed when you have a equal to b kind of an operation. So, in this case, what you need to do is whatever is the node t 6, attach the label product to that, right, prod to that and wherever prod was there, you renumber them as prod 0, prod 1, prod 2 and so on. This is an earlier value of prod. This is a new value of prod. That is really what it is, okay. So, originally, if you see the previous slide, this was prod and this was t 6. Now, when you process this statement, prod equal to t 6, right, this label prod is attached to t 6 and the earlier statement prod is deleted or it has been renumbered. You can consider that as being renumbered and that is renumbered to t prod 0. See, subsequently, if you do one more, let us say a plus prod or something like that, this will become prod 1 and the new one will become prod because that is the value of prod that you have to use subsequently in the basic block, correct. See, remember that this value of prod is the one that you have to use in the any statement subsequently. That is the reason why we rename this as prod and then renumber this to prod 0 or whatever. Is that okay? Is that clear? Okay. So, again, a similar thing is going to happen here when you say t 7 is equal to i plus 1 and i is equal to t 7. Essentially, what is happening is i is going to become i plus 1, right. So, when you process the next statement, i is already there, okay, you create a constant 1 and you have to use and then put plus there, call that as t 7. Then the next statement is i is equal to t 7. So, you attach the label i also to this and then renumber this to i naught, got it? Okay. Then the last statement is less than or equal to go to, right. For that, this constant 20 is needed which is another internal node. I think that number is not being put in here, but that is 20, right. And then this is basically what it is. So, if you look at this, this is the sequence of intermediate statements, okay, the DAG for this sequence of intermediate statements. This already has removed constant sub-expression. Now, if you can come up a very efficient way of implementing this DAG or generating code for this DAG, that is what I mean by implementing. If you can come up with an efficient way of generating code for this DAG, that would essentially mean we are able to generate code being able to look this far down in the code, what is being used and what is not being used, right. Remember earlier when we said we did not have a big picture, we were saying that we were not even seeing the next statement in the intermediate code. Now, we are able to see a sequence of statements at the level of a basic block and then able to generate code for that, right. That is a slightly better situation, isn't it? Okay. Now that you have this DAG, how do you generate code for this? In what order do we generate code for this? That is the next question, right. Okay. So, before we go that, let us just say that if you look at this DAG, it also represents data dependence, right. For example, it says to compute T6, you need T5. To compute T5, you need A of 4i or T2. To compute this, you need T4 and to compute that you need the address of B plus 4i. To compute this, you need i and 1, all of these things. So, that the data dependence information is already stored and when you generate code, right, you have to generate code bottom up, right. Because you cannot generate code for this unless you have generated code for these two. You cannot generate code for this unless you have generated code for this. So, in the instruction sequence also, the code generated, right, you need to have the code for this, the code for this and then only the code for that, right. That is what that makes sense, right. So, code generation is always bottom up, okay. So, as we mentioned, this represents data dependences. It is useful for eliminating common sub-expression, okay. It is going to be useful in identifying the expression evaluation of code generation order, okay, that we said earlier also. So, if you want to do instruction reordering, again, dependence is an important information that you need to know. And if you use this DAG, later on, we will not exactly this DAG, but we will use some form of a DAG to show how to do instruction reordering, right. That also we will talk about it or instruction scheduling to exploit parallelism, okay. Now, let us just look at how do we go about generating code for the DAG, how do we order them and how do we list them, okay. The first step is to list them and give a number for that and then traverse them in some reverse order of numbering to generate the code. So, the algorithm proceeds in the following way. You first select an unlisted node n in your DAG, okay, all of whose parents have already been listed. That means that whenever you want to visit a node, you have to make sure that their parents have already been visited, all their parents have been visited. Remember this is a DAG, so your node may have multiple parents, parents meaning nodes which are above that. If you want to look at the graph, again look at it here, right. So, if you want to visit, let us say this node, you have to make sure that its parent has already been visited, okay. So, this visiting you are going to do top down, code generation you are going to do bottom up, right. So, if you want to visit this node, you have to ensure that its parent has already been visited. Similarly, for this node, similarly for this node. In order for you to visit this, both these nodes must have been visited already and must have been labeled already. That is the condition, right, alright. So, first select an unlisted node n, all of whose parents have been listed. If the node itself is the root, that means that it did not have any parents, that also can be selected in that step, right. Call that node as n and list that node. So, basically the unlisted node n, all of whose parents have been listed is going to be listed first, right. And then you take that node and then take the leftmost child of that node, right, that is m, okay. Leftmost child of m that has no unlisted parents. Again, among the left, among the children, you choose the one which is leftmost and all of whose parents have already been listed, right. Now, and is not a leaf node and it is that itself is not a leaf node, then you do the following thing. You then list m, that left node, because all his parents have been listed. So, you can now list the node and then depth first. You go on that node and go further down. That is really what you do. If you do not have any nodes, okay, which satisfy this condition, maybe there are children, but their parents have not been listed, their other parent has not been listed, then what you do is you go breath first, right. So, in this step, you go to the next sibling in this while loop. Here you go depth first. We will again see an example and then see how the traversal takes place, okay. So, I am going to take this particular graph, okay, which is little bit more of a DAG than the one that we saw earlier, right, all right. Okay, so we start with node 1, okay. Node 1 has no parents, that means it can be listed, right. Then what is the next step? Then you have to go to each children, leftmost child, all of whose parents have been listed. So, which one is that? 2, right. Can 2 be listed? Yes, 2 has only one parent, which has already been listed. So, 2 can be listed. Then what you do? Just tell me the node number, there are several pluses and minuses in the thing. Then you try 6, but can 6 be listed? Leftmost child, all of whose parents have been listed. That is not the case because 5 was not listed, right. So, then you go breath first, right. Then you go to the next child of this one. In fact, sorry, if you look at 2, 2 has this as the leftmost child, this as the rightmost child or the right child if you want to call it, but this also has one of its parent not listed, correct. When you were in 2, 3 was not listed. So, you have found that none of these nodes can be listed next. So, you go breath first. Correct, at that point in time you go breath first and then you go to the node 3. Node 3 can be listed because its parent has already been listed, right. Now, next is you look at the children of 3, 4. 4 can be listed because both 2 and 3 have been listed, right. Then you go depth first, right. 6 can be listed, right. 9 and 10 you do not list them because they are leaf nodes, right. If they are leaf nodes, you do not list them now, right. Leave that, right. Then you go up, go up. Sorry, I am sorry, I am going. I went in the opposite direction, sorry, right. Then of course, you have finished the left child of 4. You have to go to the right child that is 8, right. Then its left child, 8 can be listed because 8 has only one parent that has already been listed, right. Then you go to 8. After 8 is done, 11 and 12 need not have to be listed because they are leaf nodes. Now, this is your listing order, okay. Now, if you see this, you will see that if I am going to generate code for 1 after generating code for 2 and 3, then these dependencies are satisfied, right. Similarly, if I am going to generate code for 2 after generating code for 4 and 6, that is correct because it depends on 4 and 6. But even to generate 4, I need code for 5 that is below, correct. So, in some sense, if you look at this listing order, it essentially satisfy all my dependencies, correct. It satisfies everything, right. Any questions? One step backward. No, no. What is your question? What is the? What was the problem with that one, I said? It is the same thing. Just follow the same algorithm. Only thing is I chose to do the diagram, I mean, chose to do this example rather than that example, okay. That are, that have, that are root, is it? That did not have any parent. Does not matter, you can start off with anything, okay. If you have multiple options, which one to choose, right, that is the first node. That is your question, sorry, I did not understand that. So, for example, if I have one more node, which did not have any parent, right, I can choose either one of them, right. Obviously, one of them may be more efficient than the other one. I will tell you later on what is that efficient means, but I am not guaranteeing that you will generate optimal code, right. You will generate more efficient code, more efficient than the simple method, but there is no guarantee that this will be the best one, okay. Let us say, remember, we said that there are several possible orders in which you can do that and that ordering essentially changes certain things, okay. We will, we are going to talk about it very, very soon. So, wait on that, okay, right. So, if I had multiple options, I would have chosen one of them and that may, may not necessarily be the best one. That, that is really what it is, okay. Now, having done this, okay, we basically have this evaluation order in the following way, right. I am also including all the leaf nodes in this evaluation, right. So, in order for me to evaluate 8, I need 11 and 12. So, start with 11, then 12, then 8, okay. Then we have 6 and in order for me to evaluate 6, I need 9 and 10, okay. Then 6, in order for me to evaluate 5, I need 7, okay. 5, 4, in order for me to evaluate 3, well, I have already evaluated 12, so I do not need to worry about it. So, 3, 2 and 2, okay. Question? Go ahead. No question? Okay, right. So, essentially we have listed all the internal nodes in this order and when you generate code, you have to go in the reverse order. But before you generate code for 8, you have to make sure that the leaf nodes are also covered. The reason that we do the leaf nodes in the end is also the following. For example, I have 11 and 12 here in order for me to calculate 8 or in order for me to generate code for 8. Now, later on you will see schemes in which you will say that the left node, this is specifically for CISC code generation, the left node is first moved to a register, the right node can be in memory, then this operation is register memory operation result going into register, right. So, that way what I will do is that I will do a move operation for this. I do not need to generate any code for 12, I can generate code for 8 or I can generate a move operation for this, a move operation for this and an operation with two registers for this, either one of them I can do. So, the correct order is to traverse the nodes top down using that algorithm and then when you want to generate code, you go bottom up, first generating code for all the leaf nodes and then for the other nodes and so on, right. So, what we have seen so far is code generation, DAC construction and code generation. Now, this part we saw as was pointed out depending on which root node I choose, my ordering might change, okay and this may necessarily generate different sets of code, right. We will talk about the notion of optimal code generation and then say that when my DAC is a tree, right, how this optimal, how this code generation schemes turns out to be an optimal code generation scheme, that is really what we are going to see. For that we are going to first talk about this algorithm called Seti-Wulman algorithm, this was developed way back in the 70s. So, first we will talk about that. Then of course, we will talk about dynamic programming approach and then we will also talk about tree pattern matching and then conclude this with people optimization. Any questions so far? DAC construction is clear? So, given a basic block, you first construct the DAC and if that DAC happens to be a tree, then you can use any one of these two algorithms to generate efficient code for that. That is an optimal code generator, okay. We will see what optimality is that, right, what is optimality, right. So, again when you talk about code generation, the order of evaluation of expression really matters and that essentially influences the quality of the code generated. Now, I will actually go more into this problem when we talk about the Seti-Wulman algorithm and then talk in the context of using the number of registers, stores and other things. So, the problem is how do we determine the optimal code generation order for a basic block specified in the DAC representation. If it is in the DAC, this problem is NP-HOT, okay. But if this happens to be a tree, then we can actually do it in polynomial time, right. So, when we say optimal, what we really mean is that it is optimal in terms of the code length, number of instructions that are generated, okay. And it is also optimal in terms of the number of registers that were used because often times what you are given is that you are given a basic block and you have a machine architecture which says that you have this many free registers available for you which can be used for generating code for this, right. And if the number of registers available is fewer than what this thing minimally requires, then you will generate code which will involve spills, spill loads and stores and that will again add to additional code and that is why your code may not be optimal. So, we really have to see how do we do this efficiently and if this happens to be a tree, we can actually generate this efficiently, right. So, if the DAG is a tree, then either we can use the Seti-Wulman algorithm or we can use dynamic programming and we can solve that problem, okay. So, again let us take another example here, right. Here we have a piece of four instructions, okay. Now, what we will do is that we will try to generate code for this, right, without really thinking too much about it, right. By that what I mean is that we will use the DAG. This is also a DAG, but it is a tree, right. It is a directed acyclic graph, right and it specifies all the dependencies, okay. Internal nodes are operations and leaf nodes are, okay, variables. Now, if you are given this graph and you want to generate code for this, okay, and you are going to generate code for a Sysc machine, right and this supports only one memory operand in an arithmetic instruction. That means that the other operand has to be in register, okay. So, the left operand is same register as the destination, okay. That is really what it says, okay. Also, I will say that in this particular code, ABCD are the program variables, ABCDE are the program variables, T1, T2, T3, T4 are temporaries and at the end of the basic block only T4 is live. That means that I do not really need to worry about the values of T1, T2, T3 after this basic block. That means that I do not have to save these values in some memory locations, right, okay. So, what you are going to do is that since you are going to generate code for each basic block, at the end of each basic block, we have to make sure that any variable which is live outside that basic block, their value is stored in a memory location, okay. We will see that, right. So, first thing is that let us try to generate code for this. I am going to just use some arbitrary order, right, arbitrary bottom-up order just to show that one order is better than the other order. That is really what I wanted to do, okay. So, let us take, I like the left-hand side better. So, let us start with the left-hand side. This is the bottom-most node. I need to generate code for this, correct. I can generate code saying that A is moved into a register, B is added to it. Remember here R0 which is my left operand is also the destination operand, okay, same as the destination. So, this generates code for A plus B, right. Now, next I go and generate code for, I cannot generate code for any of these things, right, because in order for me to generate code for this, I must have generated code for this. In order for me to generate code for this, I must have generated code for that. So, let me go and generate code for T2. Again T2, I do a similar thing, right. Here I move C to R1 and then do the addition. Remember when I did this, I kept the added value T1 in R0 register, right. Why? Because this is going to be used somewhere else in the calculation. So, keeping that in R0 register is useful for me because the next operation I am going to perform on that, I can make use of this register value, right. So, if it is possible, keep it in the register. So, that is why I gave a new register for this, right. Now, after this, if I want to do this subtract operation, right, what should I do? This is in R1, this I can reuse, but this R1 is in a register, but this is the right operand, okay. So, let us assume that only the right operand in this instruction can be a memory instruction. Left operand has to be a register instruction, right. Then what happens, sorry, right. Let us assume that we have only two registers, R0 is in this, R1 is in this. Now, you say that you want to load this in one more register, you do not have a register. This being in a register is not very useful because this is right operand. So, we ended up doing the wrong way, correct. You understand that, right. So, the machine architecture says that you need a register for the, yeah, you need a register for the left operand, the right operand can only be in memory. Right operand can also be in register, that is not a problem, but the left operand cannot be in a memory, that is the problem, right. If your architecture specifies that your left operand cannot be in memory, then you have ended up in the wrong side, correct. So, now, what you have to do is you either have to spill this to memory, right, and then load this in that particular register and then perform this operation, right, or you spill this in memory, take that register, load it, perform this operation, reload it and then perform that or you can use it even from the memory because left, sorry, you cannot use it from the memory. This has to be a register, right. Left operand has to be a register. So, you have to reload it. So, let us see what is the cost that we are going to pay for that. So, I am going to save T 1, back into the memory location, that means that R naught is being put back into location T 1, right. That is the spill that we are talking about. Now, R naught is available. I load E into R naught. I perform this operation, but again look at it. I have my register available, but this is in memory. I have to reload it again in register, right. So, I load T 1 again into R 1 register and then perform my operation and because at the end of it, I have to save the value of T 4 which is live out of this basic block. I do a store file, correct. So, if you look at the sequence of instruction, this is something which is unexpected, right. Store of R 1 to T 1 is unexpected and similarly, this load of T 1 to R 1 is also unexpected, right. We could have avoided these things or we could have possibly avoided this how we did some other order of evaluation of expression. This is what we mean by order of evaluation of expression. I could have computed the left hand side first and then the right hand side or the right hand side first and then the left hand side. I could have even done something worse. I could have computed this first, this, this and then found out that something else is not possible. Go do spill. I could have gone all these way. If the DAG is big enough, there are many such possibilities. Correct, we cannot obviously explore all of them in order to generate the efficient code. So, when we say efficient code, we want to make sure that the number of instructions, right, that you have generated is fewer in number, right. And you are given some number of registers. In this case, we assume that we had only two registers, right. If you had three registers, there would not have been a problem, right. This could have been in R naught, this could have been in R, sorry, this could have been in R 1. This we could have loaded it into R 2 and then computed the whole thing peacefully, right. Because you had only two registers, these spills and stores are required, sorry, spills and saves are required, right, spills are stored, correct. Okay, so this particular order of evaluation of T 1, T 3, sorry, T 1, T 2, T 3, T 4, right, incurs ten instructions and one spill and a corresponding save, right, or a corresponding load so to say. Now, let us look at the same thing, but in this order, right. Here my order of evaluation is T 2 first, T 3 next, T 1 later and then T 4, right. So, what happens is if I want to do T 2 first, I will load C into R naught, I will add R naught to and then I have to calculate T 3 for which I will load E into a register. I already have a register, I have two registers, only R naught has been used. I can now use R 1, right. So, I can load E into R 1 and I can now do this operation subtract, the result will be in R 1. Now, I can release R naught and I can use R naught to load A and I can compute this. Then of course, I can compute the remaining things, right. So, if I have started off somehow from here and gone all the way up, I would have done it using two registers and with no spill loads and stores, correct. Whereas, if I did the other way around, I would have incurred more instructions, right. Yes, okay. So, the question is given a tree like this, how do I find out in what order I have to traverse and how do I make sure that that order results in the minimal number of instructions and spills? That is the question, right. Question? Could be happy, no? Okay. Is it afternoon or is it things are so simple or things are too bad? One of the three, multiple choice question. Yes, yes. Afternoon, sleepy situation, no? Yes, yes. More than the temporary variables, you definitely need to distinguish between what is live out outside of the basic block, right. For example, here look at T 3, right. If I know that T 3 is not going to be used anywhere else, right, I have calculated T 3. Let us look at it. So, this is the calculation for T 3, right. At the end of this calculation, T 3 is in R 1, okay. But T 3 is not in memory. T 3 is in R 1. Now, after this, similarly if I look at T 1, T 1 when it was subsequently, I am computing T 1 which is in R 0, right. But when I calculate T 4, I overwrite into that R 0. That means that the value of T 1 is gone, right. Value of T 1 is no longer needed, right. Similarly, the value of T 3 is no longer needed, right, outside of this basic block. So, I am not trying to save these values from these registers into some memory location, right. So, if it is not live out, you do not have to save them, okay. And that is the essential difference that you have to make in code generation. Only the variables which are live out of the basic block need to be saved into their memory locations. So, for example, here we store R 0 into T 4 because after this basic block, we will take some other basic block. There we may to reuse R 0. And that should not lose the value of T 4, right. So, you need to save that value. That is the distinction you have to make. Which one? T 4. You have to find the location for T 4 and then store it, okay. This is temporary. This could be in the local variable stack frame possibly, right. Yeah. This kind of, okay, height is one possible thing, but I could have both the left child and right child or left sub tree and right sub tree of the same height, okay. There is something more that is needed which we are going to talk about it next. But yes, that is really what we need to find out. Yes. Height may be something, okay. Again, it is here. Okay. So, let us come to this Saiti-Wulman algorithm, right. So, again as I mentioned earlier, we talk about this optimal code generation for trees using this algorithm and said to be optimal in the sense that it produces the shortest instruction sequence, okay, over all instruction sequences that you evaluate it. That means that you cannot do it with fewer instructions than what is generated by the Saiti-Wulman algorithm, okay. And it takes into account the register requirement, right, and generates the code with this register requirement. Now, if the tag representing the data flow graph is a basic block tree, of course, this is what I said. If it is a tree, then we can use the Saiti-Wulman algorithm, okay. How does the Saiti-Wulman algorithm work? Again, it works in two phases. In the first phase, we are going to label and in the second phase, we are going to do code generation, okay. So, labeling is also going to be done bottom up, okay. Sorry, labeling is going to be done bottom up according to the number of registers required to generate the code. Label essentially represents if a node has a label k, it means that the minimum number of registers required to generate code for that node without any spill is k. That is what it means. So, we have to somehow identify this number and put it, right. Code generation is top down. Remember, see what is going to happen is that labeling is bottom up, code generation is top down, okay. It is not that the root node's code is going to be generated first, but the procedure is a depth first procedure going top down, right. So, one of the important things that is being followed in this code generation is what is going to be called as contiguous evaluation. By contiguous evaluation, what we mean is that, right, you want to complete code generation of a sub-tree in full before you move to the other sibling. That means that let us say when you are working on the left child or left sub-tree of a node, if you have done some part of code generation, you do not stop it half way through and then jump to the other sub-tree. You complete this entire sub-tree before you move to that other one. The reason for doing that is that if you leave some part of this sub-tree computed and then you want to jump, then whatever registers that you have used, either you have to save them in memory and give those registers for the computation of the other sub-tree, right, or you have to incur more spills, right. That is the reason. So, if you complete that entire sub-tree first and then go to the other sub-tree, then it is guaranteed that that code necessarily results in minimum instruction sequence, okay. So, we are going to do this for a machine model where these computations are carried out in registers and the instructions are of the form either having two register operands or one register operand and a memory operand. The left operand has to be a register, cannot be a memory. Right operand can be a memory, okay. So, same as what we have seen earlier, okay. Now, the labeling algorithm is a very simple algorithm, okay. You look at that node. If the node is a leaf node and it is a left node, right, because the left has to be in register, correct. Leaf node is typically a variable or a value, right. So, if it has to go into a register, you have to move that value to a register. So, it requires some cost. So, if the node is a leaf node and it is a left node, then it incurs a cost of one to move that value into a register. Whereas, if it is a right node, it can be in memory. I do not have to move it because my operands allow my right operand to be in memory, right. So, I will node, I will label those nodes, right nodes as value 0, okay. This is for the leaf node, right. Then for any other node, which has let us say two children, okay. If both children have the same label, let us look at this case. If both, sorry, if both do not have the same label value, then whichever one is maximum, that will be the label value. If they have the same label value, then it is either one of them plus one, right. So, this is exactly what you are going to do. Again, I will show you the example and tell you why this makes sense. Again, remember the label of a node represents what? Minimum number of registers required to compute that node without any spill. That is also important, right. Minimum number of registers required to compute without any spill, okay. Now, let us see how this makes sense, right. Yeah, go ahead. Is, well, here what we are going to assume is that if it is a left node and it is a constant, it has to be moved to a register, right. If it is a right node, it can be, it need not have to be, okay. Again, as I mentioned to you, this scheme that we are going to discuss in the example that we are going to see is for CISC code generation because we are going to assume this model, right. If this model changes, then the algorithm also has to be adapted accordingly, okay. Now, let us look at this algorithm and then see when it is applied to this DAG, what happens, right. So, this is a leaf node and it is a left child. So, what should be the label value for this? 1. What about here? 0. 0. 1. 1. 0. So, we can easily label all the leaf nodes without a problem. Take all the leaf nodes. If it is a left child, 1, right child, 0, right. Now, if I look at this particular subtree, how many registers do I need to evaluate that? Only 1. And if I apply my algorithm, my algorithm says that the left child and right child do not have same value, then it is a maximum of the 2, which means 1, okay, correct. So, if I consider this particular 1, right, these two have different values, maximum of this is 1. Now, if you ask me why is that that computing T1 requires only 1 register even though computing one of its child also requires 1 register. The other can be in memory, right. That is the reason. Now, what about T3? T3 requires 2 by our algorithm. That is true. You people remember the algorithm and you have applied it correctly. That is good. But why does it require 2? Both are not leaf. Both will be in the register. So, E has to be in the register. So, that requires 1 register, correct. But this can be in memory. To calculate T3, you need at least 1 register, correct. To calculate T2, you need at least 1 register. Without that, you cannot calculate, right. Therefore, even if you say that you do not need any register for doing this, you need to do this first before you can do this thing. So, essentially the minimum register that is required to do this would be the maximum of this plus 1. Sorry, not the maximum. These are equal. Sorry. So, any one of them plus 1, correct. So, if I have 2 registers, right, then I can use one register to calculate this and another register to load this and then compute this value. I am going to extend this little later, but let us go with this example for the time being. Now, what about here? Again, we can say T1 requires 1 register. What about T4? 2. Why 2? Maximum of that. Algorithm says maximum of that. So, say T and Wolman are correct. They are intelligent. They said that correctly, but why are they intelligent? For computing, correct. But for calculating T3, I need 2 registers. For calculating T1, I need 1 register. Should not it be totally 3? Even though I might require 2 registers for this, after calculating the result, I can keep the value in one register and then reuse the other registers for the other calculation. So, essentially after computing this value, there is only one register that I need for storing this, correct. And if these 2 are different, the maximum is at least going to be one more than the other, right. Therefore, if I take one out of this, the remaining should be enough for computing this one. So, the requirement for this is specified by the requirement of the one which has more registers, which requires more registers, right. That is the reason for this. So, does that mean that the order of evaluation does not matter? Say that it is only the maximum subtree that I have to, the one which requires the maximum register. It matters because if I do end up generating code for this first and want to keep this in the register, then I would require 2 more registers for doing this, correct. That is a bad decision. Whereas, if I have done this first, I could have done it with 2 registers and then given up all, but one register and then use those registers for calculating this subtree. That means that whenever you have a subtree, sorry, whenever you have a node with left subtree and right subtree having different register requirement, you must first compute the one with the higher requirement. First satisfy them and then generate code for that. Then after that, go ahead and generate code for the other one. And when you do that, what really happens is that you can release all but one register and that should be sufficient for generating code for the other side. So, even if I say this requires m registers, right, and this requires m minus 3 registers, right, I can use all these m registers to calculate this and then I can release m minus 1 registers, right, except for one register which holds the result value and then use those m minus 1 registers. I only require m minus 3 here. Even better that, right. I can compute this without any problem and then I can go ahead and complete, right. That is why in the Sethi-Wulman algorithm, when you do the labeling, right, if you have different values, different label values for the left and right side, right side, then you take the maximum of the two and label it as the root node value. And in those cases, you have to calculate the one which has higher register requirement first and then the other. And again, when you calculate the generate code for this subtree first, remember you have to complete this entire subtree before you go here. Because if you do some part of the subtree and then say, okay, stop, I will go to the other side, then you are gone. Why? Because you have partial results evaluated and those needs to be kept and you cannot release your m minus 1 registers, right. That is the reason why you have to complete code generation for this before you move to the other side, right. Is that clear? Any questions? Okay. So, let us see how this happens. Okay. So, we have this. So, the code generation algorithm is that, okay. So, once you have labeled all of these nodes, the minimum number of registers that you require to generate code for this is given by the label of the root node, okay. So, if you have that many number of registers, then you can generate code for this without any spill, okay. And you can actually generate the optimal code. And to generate the optimal code, what you need to do is that you need to start off with the root, okay. There is an algorithm which actually goes step by step, which we will also describe little later on, right. And essentially that algorithm, the way by which it calculates is that it will see whether the left child or the right child, which has more register requirement. It will try to generate code for that side first and then go to the other side. And then once it goes to a particular side, it goes depth first, right. That is really what it does. Again, it applies the same algorithm. Between left child and right child, whichever one which has more number of requires, whichever one which requires more number of registers, that is done first, okay. So, let us see what happens here. This is the detail of that particular algorithm. We will look at it carefully, right, okay. Now, this uses two data structures, one called R stack, which is the register stack and the other called T stack, which is the temporary stack, right. Supposing, let us say you are given R register and you want to generate code for this using R registers, right. It may be possible that, I mean, it may be the case that the root of this tree has a label less than R, in which case you should be able to generate less than or equal to R, in which case you should be able to generate code without any spill. Or it may be the case that it is greater than R. If it is greater than R, right, then obviously there will be some spills and some temporaries which are needed. So, this T stack is the temporaries that we are going to talk about, okay. So, this uses a recursive procedure called gen code, which generates code for node n. And when it generates code for node n and this R stack, which is actually a stack, stack means what? Lost in first out data structure, okay. So, you should be able to do push and pop. The top of the stack always holds the value computed of the left side. So, look at the last statement, right. So, in doing this code generation, we are always ensured that the left child is calculated on the top of the stack, on the register on the top of the stack. That is really what we are trying to ensure, okay. I will go through that code generation in detail and you will understand what is really happening, okay. And not only the left child holds the left child values being held in the top of the R stack, the rest of the R stack remains in the same state as the one before the call. That is also very important, okay. It also uses a particular operation on the stack, which is an unusual operation, which is called the swap operation, which is typically what is not defined in the stack, right. Stack you only have push and pop, but swap essentially swaps the top two values of the stack. So, that is an additional operation which is needed and that is needed to ensure that this previous condition that we talked about. We will see what that is, okay. And again this is needed to prove the optimality case, that is really what it is. We are not going to go into the proof, but it is needed for that. The code generation algorithm proceeds in the following way. It has five cases to consider and let us look at each one of those cases and then see what is the code generated, right. This is case one. In case one, the node is a leaf node and is the left most child or the left child, let us say because we have only two children, we only talk about left child, right. That means that it is a case like this, where there is a root node or there is a parent node and then there is possibly a right tree or it could also be a leaf node. We do not know, but this could potentially be a sub tree, right. That is the case, how do we generate code for this, right. Let us say that given the R stack in the current form, after generating code for this, we have to ensure that the R stack is in the same form and the top of the stack has the value of the left most child, right. So, in this case what we do is that we take the top of the stack, whatever is that, whatever is the register and we load the value of n into that register. Since this is a left child, remember the left child cannot be a memory operand, it has to be a register operand. So, I load this n into that register, which register, the top of the stack and when I do that, I am automatically guaranteeing that the top of the stack contains the result of the left sub tree, correct, right. So, in case one, we generate the code which is load n, which is this particular node, right into the top of the stack, right. So, by that what we are doing is that we are ensuring that the top of the stack, whichever whatever is the register there, that contains the result of the left sub tree, correct and the rest of the stack is not disturbed. It is as it is, as it was what it was before, okay. That is good, right. Now, if that is not the case, right, it could be the right child, okay. If it is the right child, okay. If it is the right child, its label has to be equal to 0, right. That means it is the right child. If its label is not 0, then it could be an internal node, right. If it is a leaf node only, its value would be 0, right. So, in this case, what I do is that, so in the first case, the node itself is the leaf node. In the second case that I am talking about, the node is not the leaf node or the right node. If it is the right node, you do not need to generate any code for that, okay, because it could be a memory operand. It could be the variable itself, right. So, in this case, the node is this, okay. N is an internal node. It has a left child and a right child. The right child is a leaf node, okay. The right child has a label n equal to 0, right. So, this is the node for which we want to generate code in this case, right. Earlier, I was thinking about this. If it is actually right child, you do not generate any code for that. It is a node whose right child is a leaf node and the left child can be a sub-tree, right. In which case, what you need to do is that recursively, you need to generate code for n 1 and then generate code for this. This operand can be in the memory and when you generate code for this n 1 sub-tree, that is going to be in the, the result of that is going to be in the top of the stack or the register which is on the top of the stack. So, the operation here is that operation, top of the stack register n 2, which is label n, correct. Let us go through that again, okay. So, the situation is it is an internal node. Its right child is a leaf node with label 0, correct. So, I need to generate code for the left sub-tree and when I generate the code for the left sub-tree, this generate code routine is going to generate code using the registers which is given in the label value, correct. And the result of this sub-tree is going to be in the register which is the top of the stack. These are known properties. So, first I generate code for the left sub-tree. The top of the stack contains the result of this sub-tree. So, I perform operation using the register which is the top of the stack and its right operand is n, okay, which could be a memory operand. We do not care about it, right. So, in this case, this sequence of instruction would generate the optimal code for this case. Not only it will generate the optimal code for this case, it will generate the optimal code saying that the top, the I mean when you do this, this has the result values available in the top of the stack. Similarly, this has the result value available in the top of the stack and nothing else has been altered, right. The nothing else has been altered. You are not going to see it unfortunately in the code generation algorithm. You are only going to see it in the proof and we are not going to go into the proof anyway. So, let us not worry about it, right. But it is required for proving the optimality, okay. Now, the third case is one where the left child and the right child are not leaf nodes, right. So, here I have a node n, right, which has a left subtree and a right subtree, right. And let us assume that the left subtree requires fewer registers than the right subtree. And I know that the left subtree also requires fewer than R registers, correct. It requires fewer than R registers. The right child or the right subtree requires more than what the left subtree requires. But I do not know whether it is less than or equal to R. It could be greater than R also, right. So, in this case what I am going to do, right, remember that the top of the stack register should always calculate the left side result, okay. But because this is higher, we have to calculate the right subtree first. Whichever one which has greater requirement is what we need to calculate first, right. But if I generate code for this and then generate code for this, I may not necessarily keep the registers in the correct way. So, what I do here first is that I do a swap of the top two registers, right. So, let us say if R1 has been in the top and R2 is the second top, then it changes as R2 and R1. I now use R2 to generate code for this, okay. And then after that I push back my R1 and generate code for this one. That way I will ensure that the rest of my stack is maintained as it is and the top of the stack has the, right, result of the left subtree. That is the reason why we do this. So, remember here I have done the swap. I generate the code for N2. So, N2 is going to be generated and the result will be in the second register which we will call it as R2 for the time being, okay, right. So, after I have generated code for N2 in R2 register, I pop the stack. When I pop the stack what happens? R2 is ejected, right. And then I hold it in a temporary location called R, right. I remember this which register was the previous top of the stack register, happened to be R2, right. Let us remember that for the time being until we finish this code generation, right. Then I generate code for N1, all right. Then see what happens. When I generate code for N1, what was the top of the stack at that point in time? R2 was popped out, R1, right. Remember R1 was on the top, R2 was next. We swapped it. We generated code with R2. We popped R2. So, what is remaining? R1. R1 is on the top of the stack. So, you are going to generate code for N1 with R1 on the top of the stack. So, since the generate code procedure, let us assume that, right, inductively is going to generate code for this left subtree correctly, then it will have the result value in R1, right. Then after that, this is what we are going to do, right. This node has operation to be performed. So, that is the operation to be performed. If it is an add or subtract, you put that operation. Then top of R stack, which is R1, correct and R. What is R? R2, right. Remember you evaluated this subtree in R2, correct. And then you remember that somehow you evaluated this subtree in R1. Now, you are saying that you are doing op R1 and R2, okay. Now, you push R2 again, push R stack, R2 and then again you swap. So, R2 and R1 will go back in the same order and the top of the stack still will contain R1 and that contains the left subtree value or the subtree value, correct. That is really how we go by this. Any questions? Slightly complicated, but if you go through this step by step, you can understand how it works, right. Question? Yeah. Okay. So, one condition, again we are not going to go why this condition is required, right. That goes into the proof of the optimality. The condition is that whenever you evaluate the left side, left subtree, that left subtree result has to be in the top of the stack. That is the condition. So, in order to do that, you are essentially doing all these juggleries. Otherwise, you are fine. You are generating code for N2, okay. And then you will generate code for N1. Then you will generate this operation. As far as code generation part is concerned, what you are going to see in the generated code, right, you are only going to see this part of the code, right. See the print statement is what is going to go in the generated code. These are all what we call as bookkeeping activities of the code generator, right. So, what happens is that you have the left subtree and you have the right subtree and then you are trying to generate code for this, right. And we know that this has a value 5, this has a value 3, right. Then our intuition says that which is basically the depth of the tree intuition. It is not just the depth, but it is the label value which could be caused by the depth also, right. So, we say that we have to generate code for this part first. When I generate code for this part, the result let us say is in some register R2, correct, right. And out of these five registers except R2, all other registers are free for me to use, right. Now, I can come back and generate code for this, right. And I generate code for this and the result is in R1, right. And then as far as generating code for this node is concerned, it is basically operation R1. Comma R2, correct. It is also correct. So, the code that I am going to generate as a part of my code generation is the code which is generated for this, okay. Let us call this code CR, right hand side. The code which is generated for this, let us call this code CL and the code which is generated for this node, correct. In other words, because it is a recursive call and it goes like this, the way that it is going to look like in the order. So, what I am going to do is that I am going to do, let me write it here, okay. First, I am going to generate the code for the right sub tree. So, that is code CR. Then I am going to generate the code for the left sub tree which is code CL. Then I am going to generate the code for the node which is code N. This is the order in which the code is going to appear in the program or in the compiled code, let us say. For the program, this is the code that is generated. The rest of the statements that you see, save this popped stack in some register, etc. are all maintenance code of the code generator, okay. The condition that we require is that you have the top of the stack, okay, and the top of the stack is R1, then R1 must compute the left sub tree, okay. In order for you to do that, originally you had R1 and R2 like this. When you generate code, if you have generated code for this using R1, correct, then what would have happened is this will have R1 instead of R2, correct. Then your top of the stack condition would not be satisfied, right. That is the reason why we do not do that. That is why what we do is that we swap these two values and then temporarily make R2 as the top of the stack, generate code for this. The result value will be in R2. Then after that, you remember R2 and pop it out. Then R1 becomes the top of the stack, correct. Generate code for the left side which will actually produce a result in R1. Then after that, push R2, swap again so that you will have R1, R2 in the reverse direction, right. So, all of these juggleries that you do, that is only in your data structure or stack and other things. That has nothing to do with the code that you generate. The code that you generate is only these three parts. Of course, these are all recursive parts. So, it will further go down into each one of its left sub tree and right sub tree and so on, correct. So, that is really what happens, okay. Let me just take two more minutes and then complete the rest of the discussion, okay, right. This is one case. We have more cases to cover, right. So, this is the fourth case and let us see what happens here, right. Here the right sub tree requires fewer registers and the left sub tree requires more registers. Again, we do not know whether it is greater than R or less than R, but it is greater than the right sub tree. So, in this case, we have to generate the code for the left sub tree first and then the right sub tree. Because you are going to generate code for the left sub tree, right, it is actually easy. You generate code for N1 with the top of the stack, okay. Then you pop the stack, right. That means that R1 comes out and you hold it in a temporary register. Again, this is your bookkeeping code, not a part of the generated code. Then you generate code for N2. Now R2 is the top of the stack. You generate the result in R2, right. And then now this is the code that you generate for N, which is basically operation, right, or top of the stack, okay. So, that is how this code is generated, right. And then you push R stack back into it so that now R2 is on the top of the stack. Again, all of this is again going to go into the proof of why this is optimal, okay, which we are not going to see in detail, okay. Let us just quickly go to the last case. And so far what we have seen is that we have seen the cases where one side is at least less than R, right. Let us see what happens in the last case where actually both sides can be greater than or equal to R. When it is greater than or equal to R, obviously there is going to be some spill that is going to be happening, right. So, in this case what we will do is that we will first compute the right side first, generate code for that. Then we will pop the top of the stack, okay. And then do this following operation where we will actually store that particular register value in some temporary location. Remember both of them are greater than R. So, they are going to involve spills. You have at most R registers here. I mean you have R registers available to you, but this computation itself requires more than R registers. So, if I reserve one more register for this, for the result value, then this will only have R minus 1 registers available, but it requires more than R registers. So, I will have more spills. So, what I am going to do is this. I first compute this value or generate code for this part. And then the result I am going to save it in some temporary location T1. That way I can release all the R registers for computing the left side. Use all of those R registers to do the code generation for the left subtree, right. And then see remember right hand side can be in memory, left hand side has to be in a register. So, computing this first, I can store the value into a temporary location and then use the temporary location as a part of operand for this operation, correct. So, that is really what we do. So, after you generate code for N1, generate code for N1 will have the value in the top of the stack register, correct. So, that register along with this temporary on which you will perform the operation. Again if you want to see an example, let me see if I get this correct, okay. So, here is the case where we have, right. Let us say this is 5 and this is 7, okay. I am specifically taking the example of the left side having more, requiring more registers than the right side, okay. And I want to generate code for this, right. Let us assume that in my architecture I have only 4 registers available. So, both of them are greater than or equal to 4, right. In this case what do I say? I first say generate code for, sorry, generate code for right side, okay. And let us say that I have registers R1, R2, R3, R4 in the top of my stack like this, okay. R1 is on the top. So, the result value is going to be on the top of the stack. Then I generate code which says store R1 in a temporary location T, correct. Then I can also release R1. Now, using those 4 registers I will generate code for the left-hand side, right. Again the result will be on the top of the stack. So, I perform whatever is this op, okay, op top of the stack which is R1, right and T. Why? Because my right operand can be in a memory, right. If it says my left operand can be in a memory then I could have done it in either order, right. It only says the right operand can be in the memory, left has to be in a register. So, it is preferable that I generate code for the left-hand side with the result value in the top of the stack so that that same register can be used in the operation. Otherwise, what would have happened if this is in memory, if I have calculated this first, sorry, if I have calculated this first, if I have done the following thing, let us see, code CL, correct. And then let us say store result R1 into some temporary location, let us call it as TL, right. Then let us say code CR, right. R will be in a register but that is not useful for me, correct. Then I have to do one more load of this TL to some register R2 and then I have to do this operation, right. R1, R2 or whatever, correct. So, this generates this extra code which is not really good, is not it? So, that is the reason why you do not do this and you do this. Even though the right side requires fewer registers than the left side. So, typically in this code generation, right, you follow that algorithm and if the, if one of the sub trees require fewer than the available number of registers, then you go to the sub tree which has the maximum requirement. You finish that computation first, leave the result in the register and then release all but that register for the computation of the other side. The computation of the other side requires fewer registers, therefore it could be computed without any spill, right. So, that is the algorithm that we follow, okay. Let us see, we are about to finish, okay. So, this is the last phase, okay. So, if you actually follow that algorithm, right, I have not gone through this step by step, you will actually end up in this evaluation order. You can verify that, right and this evaluation order is the optimal order. You cannot have any other order which will generate fewer than eight instructions, right. In this case, we have assumed two registers. If you have had only one register, what would have happened, right? If you had only one register, you would have generated code for this, spilled the value in memory, generated, means moved this into the register, computed this, spilled this in memory, do this, it will be in register, this will be in memory, generate code for this, right. Can you all do a homework, try to see whether applying that algorithm works correctly on this or not, right. I will make all my slides available. It is also going to be available from the NPTEL webpage, okay. We will make all of those things available to you, but you can try to work this example out and then see whether it meets it. So, I am going to stop with this slide. The next step is dynamic programming. How many of you know about dynamic programming? Okay. Those of you who do not know have a quick, right, review of that. What is dynamic programming? Not now, but tomorrow, right. So, we will see dynamic programming tree pattern matching and then move on to register allocation.