 So, I think we can start. So, just to recap what we did just before the lunch. The fundamental idea of PIC was to essentially ensure that the relocations which would otherwise appear on tech section are moved into the data section right and GOT holds the address and essentially what you do is you get the address of GOT using the relative addressing. This is what we saw. Now assignment. What you should do is you have already written this shared library which had this code right. So, let us write a client code for it and let us print the address of GBL variable which is defined in the shared library and address of another global variable which is defined in the program and see if you see something unexpected. So, before we actually get to that can someone first tell me what is the expected thing. So for example, where is var stored? Var in this myprog.c where is it stored? Data section or BSS right. So, the address will be according to the memory map which we saw right. Where is GBL stored? Where is GBL stored? GBL is defined by the shared library. So, where is GBL stored? Will it be in the data section of myprog.c of myprog.c or should it be somewhere in the memory mapped region of libmy.so right. So wherever shared library is loaded somewhere within that is what we expect. Now try to run this code and see what happens. So we expect address of var to be in the data section and address of GBL somewhere far away from it right. Why 8 bytes different? I mean are you observing difference of 8 bytes. So someone is observing the difference between address of GBL and address of var is 8 bytes. Is that logical? Is anyone observing GBL is in the somewhere far region which might be in the memory mapped region? Can you look at the process map and see where is the memory mapped region where libmy.so is loaded. So let us look at this I have the code. So I have this code which is doing the same thing. I am printing the address of this. Now I will add a scan of here so we can examine the process. I run this program and I actually see very small difference between the two. Now if I examine the process map I do see that libmy.so was loaded but it was at some address f c something something. And I do see there is some data section here which is read write. So var is somewhere close to that and for some reason GBL is also very close to that. So what really happened? So somehow GBL variable which was actually supposed to be in the shared library is also loaded in the data section. Does everyone at least confirm that this is what we are observing? Now any theories of why this happened? Shouldn't we be seeing some address close to this region where the library was loaded? Ideally that is where it should be. The reason this happens is because the a.out which is produced is executable. It is not relocatable. Now what happens is when this code is linked into a.out there is no idea to the linker and compiler where GBL is going to come from. And they cannot change the text section of this with additional relocation because it is supposed to be the finalized thing. So how will the address of GBL be obtained? Is everyone clear about the problem which I am trying to describe? So a.out which is produced which contains the code of main is already finalized. It shouldn't be having any additional relocations to be processed. But GBL itself is not known because GBL will come from some library. So what compilers and linkers do is they do something called as a copy relocation. So if you look at a.out you will see a relocation called as R386 copy from GBL. So what this relocation is going to do is whenever the shared library is loaded and wherever that address of the GBL in the shared library is it is going to copy content of that into the data section of the executable. And that's how it will work and all the subsequent references of GBL will actually be from the data section. So although data was owned by the shared library it actually got copied into the data section of the executable. And that's why you observe that GBL is actually close to your normal variables. Is it clear? Now we saw how to do data references. We saw how shared libraries compiled with position independent code to refer to data. But what about functions? So let's say this is my shared library code and foo is calling bar. Now again just like the problem we had with data we have the same problem. That means address of bar may be different when the bar is actually loaded in context of some process. So do we need to do anything for function calls also? Any idea? Remember the calls were already relative. So when foo called bar the call instruction didn't take the absolute address of bar. It took the relative address of the bar. So by that logic we shouldn't need to do anything for the functions. But we need to do something. And symbol resolution is a problem. So your assignment is to tell me what happens in this case. So let's say I have a shared library which has bar which is defined and I have myproc.c which also defines bar. If this was normal code what will happen? If this was myproc.c and main.c what will happen? Why will there be error? So function with the same signature. In terms of linker why it's an error? What we saw yesterday? Correct. So function definitions were treated as strong symbol. Whatever we learned yesterday. Now what is the expected output in this case? Linker should raise error. At what point will it raise error? At what point will it raise error? Will it be at creation time creating executable or will it be at load time? Can you try and tell me when does the error come? Try the exact same case and tell me what is the error you get at whatever time? What is the error you got? Try with m32. Sorry? No error. So some people are saying they are not getting any error. So what is the actual output? How did 10 come? Anyone got the error? So there is some warning but not an error. So the resolution rules for dynamic shared libraries are slightly more interesting than what we learned yesterday. So what we had learned yesterday was if there are two strong symbols there is a problem. But that is not true when it comes to shared libraries. In shared libraries the functions or anything can be overridden by other things. So for example if you write a function called malloc in your program and call malloc it is not the lipsys malloc which will get called. It will be your malloc which will get called. So there is some preference to the client code to override something which was defined in the shared library. Does that make sense? There is slightly more convoluted things where if there was a libmy.so and libmy1.so and they had conflicting definition, client did not do anything. So let us say bar was actually defined in some other SO file. Then it will depend on the order in which things get loaded and the later one gets the preference. So it is kind of hard to figure out exactly which one got used. Now if you make bar static from libmy.so then this will not happen because when you say something is static it cannot be overridden by someone else. So this principle applies to only things which are visible outside the shared library. Whatever is not visible outside shared library cannot be overridden by others. But whatever is visible outside a shared library can be overridden by other. For that matter even if you define a gbl variable it will get overridden with the one which you have in the program. Does that make sense? Now function calls for this reason, now imagine what happens. So if you had foo calling bar and you are compiling a dso can you really replace this call with the relative address of bar which was defined in the SO. Did everyone get my question? So the question is now that you know these rules when you are trying to generate libmy.so can this function call actually call this bar function using the relative address of the bar. So will the call instruction generated for this statement will be called of something to find the address of this bar. So if you look at this so let us look at the shared library code. So I have this code let me try to compile it. For now I will just remove fpick so it looks simpler. Now if I look at obj dump and if I go to foo it is not generating actually call to bar using the relative address. It is generating a relocation for it and why was that done is because I do not know that this is the exact bar which will get called because it might get overridden. Now if I do this static let me make this function static. Now if I look at the dump I actually see call to the bar. Does that make sense? So when it was not static what happened is there was a possibility that someone could overwrite this definition of bar. That is why compiler could not generate code which will directly call this bar. So it has to generate a relocation and as soon as I make it static then it starts using relative addressing and directly calls bar. Now since there was a relocation generated we have the same problem which we had with data because the text section will get changed based on address of bar which might have overridden it. So we have to do something with function calls just like we were doing for data. All calls to functions which might be overridden which means any function which might be exported out of the shared library. But if you make something static in the shared library and you call that function that means you are saying it is bound statically. So static you can think of it as bound statically so I always know it is always going to call this instance and not any other instance. When it was not static then there is a possibility that someone can override its definition in which case I do not know address of that. That is why I had to generate relocation just like we do for data. So we have to do something for this. So what can we do? Same thing right. Just like for every address we stored its address in got we will do the same thing for every function you create an entry in got and you use that. So call will actually be load the address of function from got and go to that address. So we can do the same thing. Now unfortunately this is not efficient for functions because unlike variables remember typically when you are writing any shared library for example is there any variable which you do use from libc or you use only functions from libc. So libc has bunch of things how many times you had to use a variable which was defined in libc. How many times you had to do extern int of some variable which you are using and that variable was defined in libc. Almost never right. The purpose of libraries is to provide interfaces which mostly will be through functions and not data right. Now what is the problem with got? Remember every reference which needs to happen to that variable goes via additional indirection because we have to first get the address of got then look at the address of that variable and get it. So every time if you do this there is considerable overhead added for every reference right which may not be the best thing for functions because functions are very common in dso's which will be cross referenced in the client code and you don't want every call to go via this indirection. Does that make sense? So we do something more for this. And one other thing is this thing that library may actually define thousands of functions but only some of them are used right and if you put their addresses in got you have to do something which will populate that address at load time. So once the loader is loading the program it has to resolve all the references and resolve all the relocations and if there are thousand functions in the library it has to patch at least thousand relocations even though when most of the common times you are using just printf and scanf right. So there is lot of work which is happening at load time which could be useless. Is this clear to everyone? So there are two problems. One is there could be too many functions right and second is we have to resolve all the functions which may not be the best thing because not all of them will get used. So we have to do something lazily. We don't want to do something prematurely when the application starts. That is the idea which we are trying to go against. So that is where something called as PLT comes in. Processor linkage table. So this is again one more level of indirection. So what happens is whenever you want to call a function you don't simply call the function directly. You call something in the PLT. So you can think that every function has a PLT entry just like every variable had a GOT entry. Every function has a PLT entry and PLT entry is not data. PLT entry is actually code. Executable code. So PLT does not hold data. PLT holds code. And what is going to happen is when you go to the PLT it will actually get the address from the GOT. So for every function you do two things. You create a PLT entry and you also create a GOT entry. Now when you are doing the call you call the PLT entry into the function of that function. The PLT entry of that function is going to look up the address from GOT. And then it is going to call the resolver which will try to actually resolve the function call. And that is the special entry called PLT L0. So PLT L0 is actually some code from dynamic linker which is going to do the symbol resolution. Now what happens is this. When you call the function first time you will first call the PLT of that. That will essentially try to get the GOT and this address which is stored here is actually address of the next instruction. So what will happen is when you get this address and you call that address you will actually come to the next instruction only. And this will call the resolver which is PLT 0 and something will happen. But is this clear up to this stage? So what is happening is first time we are calling PLT of that function that calls the that gets the address from the GOT. But GOT actually holds the address of the next instruction only. So GOT will come back to the next instruction and call the resolver. Is this clear? Now some magic happens after the first call. So what resolver is going to do is resolver is going to change the address in the GOT to actually point to the function. So GOT will be modified after the first call to that function. And GOT now will start having the actual address of the function. Now let us imagine what happens for the second call. So when you do the second call we come to here and when we get the address from GOT we actually get the address of the function and we start executing the function. So what happened is first time when the function was called we did not know the address. So we called the resolver. After resolver is done figuring out the address of the function it over wrote the address in the GOT and said now this is the address of the function. So next time when you call the same function again you actually have the address of the function in GOT. Is this clear? This is kind of bit complicated. But the fundamental principles you have to remember is we do not want to populate GOT the application start time because that involves lot of overhead. So what we do is we say that GOT holds initially address of a resolver function which is going to find out where the address of the function is. And once resolver is done it is going to update that address and say now here is the actual function. So every subsequent call is actually going to happen faster. It still is going through PLT but it does not do any other things. So what did we achieve with this is essentially we do not have to populate GOT completely. So we are populating GOT lazily. And then after the first call overhead is paid all the subsequent calls are faster because they directly get the address of the function. So after resolver after resolver it will come to if you overwrite the address and then comes to function. Correct. Correct. So what resolver is doing is it is trying to figure out what is the address of the function and once it is done figuring out the address it will overwrite the GOT and then start executing that address. Is this clear? So this allows us to get position independent function calls also. So no matter where a function is loaded it can be called and PLT again you can see PLT is the executable code and GOT is the data. So PLT can still be shared across processes because it just bunch of code. What is the things which are changing are still in the GOT only. We are not changing anything in the PLT. So the code section is completely shared including the code which is present in the PLT only GOT is modified. Any questions on this? Sorry. Resolvers job is essentially to figure out which symbol to pick up. So for example if there are multiple foos which one to pick up according to the rules for dynamic shared libraries. So it is part of the linker code which figures out when there are two symbols what to do. So what are the pros and cons of PIC? So one is obviously pro is you are able to get shared libraries by which you can share the text section. You do not have to kind of duplicate the text section. The cons is obviously you have some runtime overhead because you have GOTs and other things. Everything goes through at least one level of indirection. Every reference at least goes through one GOT reference and in case of function after first call one PLT reference. So there are some overheads and every variable and every function which is defined actually needs to have a GOT entry. So GOT can actually be very large. So that will take some space in your program when it is running. Does that make sense? That is why when you are writing shared libraries it is very important for you to know which things are actually needed to be exposed outside shared library and which things are needed just for the internal thing. So for example printf might be using bunch of utility routines for doing its own operation but those can be marked static and as soon as they are marked static they do not need a PLT entry or a GOT entry. That is why it is very important to tag your functions to respect the visibility because it enables compiler to do more optimizations and linker to do more optimizations like this. Is it clear? Now whatever we saw so far was what happened in Linux x86. Now obviously when you are designing new architectures you want to see what are the common things which happened in the old architecture and improve hardware support for some of the things. So one of the things which x86-64 architecture adds is it adds relative data addressing. So this trick which we were doing that we had to call to a dummy instruction and get from the stack is no longer needed on x86-64 because x86-64 allows you to do current instruction plus minus something to access the data. So x86-64 supports PC relative addressing and some of the support for PIC gets simplified because of that. So it requires essentially fewer instructions because you don't have to do that dummy call. One other thing which x86-64 enforces at least GCC is it forces you to create shared libraries using FPIC only. So you cannot create a shared library without FPIC. Remember before we got into FPIC we were trying to create shared library which had relocations on the text section. So x86-64 Linux implementation does not allow you to do that. So you have to compile your shared libraries using FPIC. How many of you have heard of a term called as code models? Anyone? So code model is essentially set of things. Correct. Somewhat yeah. So essentially what happens is whenever compiler is generating code it assumes some code model. Now what happens is typically you can think of code model as something which describes how far addresses you can access from instructions. Now by default x86-64 supports PC relative addressing and the way things are supported is the displacement can be 32 bits. So you should be able to reference anything from current instruction which lies above 2 GB or below 2 GB. Now what happens if you have data which does not fit in 2 GB? Then you cannot use PC relative addressing. Let us try that. Let us say I have Let us say I have ARR which is of 1 GB and I am trying to access it now in the program. It worked. And it printed something. I mean it should have printed. So it printed some garbage stuff. Now let me try to increase this to 2 GB. It still worked. Let me make it 3 GB. Still worked. This is 7 GB. Okay. So GCC is actually realizing it is absolute address. Let us try. I think I will need to try it. But essentially what I was expecting sorry for going on detour. But essentially what happens is since it supports PC relative addressing what happens is you can refer to the data from the code section which falls within the 2 GB range. Now for some reason GCC is realizing it is going far away and it is actually using absolute address. I do not know how to force it to use relative address. But since you were using relative address and if your data does not fit then what will actually happen is it will not be able to figure out it will not be able to reference that data using the PC relative addressing. And that is supposed to be the default code model where you always use data which will fit within the 2 GB range. But if that does not happen then compiler and linker cannot figure out how to do this. And that is where you need to actually change the code model to use large addresses where it can actually be more than 2 GB. And then it will actually use slightly slower code to reference data than using relative addressing. Now one of the things which we said was one of the advantages of one of the problems with static libraries was that if there is a bug in static library once it is fixed you have to tell all of your customers to recompile and relink their application. How does DSO solve this? So we said that DSO is going to solve this problem. But so far whatever we have seen does not solve that problem because what we so far learned is just how to load DSO that does not say how to actually distribute a bug fixed DSO. And how does it ensure that client does not have to change? Correct. So that would do it. The problem which happens is there are cases where so when you fix something so let us say you have mylib.so. So what will happen is mylib.so someone has mylib.so then how do you know whether it is fixed or not? So you want to version your SO saying this is version 1, this is version 2, this is version 3 and you can tell your customer please use version 3 to get this bug fixed. So you need something to say that this is the version of mySO. So what happens is each DSO has something called as a SO name and a real name. So SO name is what is actually used by the linker. So whenever I say libmy.so this is SO name. So whenever linker wants to load a library it will look at the SO name. But the physical name of the file which is stored in the file system may not be actually that. It could actually be libmy.so.something. So typically you will always see every SO file has dot some numbers. So those are the actual names of those files but that is not the SO name which is actually used by the linker for loading. And what typically you do is you create a symbolic link between the SO name file to the real file. So what allows this you to do is programs the client code whenever it needs to say that I want this library they always refer to the SO name. They do not refer to the actual file name. And you as an author of the library can ship a new version and client can create a SIM link to that and it will start working. Does that make sense? So just to show you so if you look at ldd a dot out which we were seeing. So this libvdso.so this you can think of it as the SO name. The dot one is actually the so if you look at the actual file the actual file name is this. But what loader when it needs to load it only uses the SO name which is up to this point. So if I get a new version with dot two I will simply put it and the same code without any changes will start using that file. Does that make sense? So if you look at redelf it actually shows what all libraries you need. So if I do redelf dash da dot out it shows all the libraries which are needed by this program. So if I do redelf dash da dot out it shows bunch of things and some of the entries you can see are something called as needed. So needed are the set of shared libraries which are needed for this program to start. So these are the ones which will actually be loaded by the loader as part of the application startup type. So when the application starts the loader is going to look at what all is marked as needed in this executable and it is going to load all those shared libraries. Does that make sense? Now we had seen something like what happens in the loader earlier. There was start which called libc start and ultimately called main. Now that we have shared libraries also learned how does the thing happens. So what needs to happen is the loader will look at all the segments which were marked as pt load. Pt load were the segments which were present in the executable which needed to be mapped into the memory map which was code segment data segment and so on. So loader looks at all the segments which were pt load and loads them. There is a field in the elf called as interrupt. You can see that here. So if I print the program headers for a file I see something like this interrupt which the program interpreter ld linux x86 64 something something. So this is actually the dynamic linker. So this SO file actually has code for dynamic linker. So what this is saying to the loader is once you are starting to execute this program please call this guy to do the further processing. So what loader will simply do is once it starts executing the binary it will call and once it is done mapping the pt load segments it will call this guy ld linux or whatever we saw in the 64 bit variant and this is the dynamic linker. Dynamic linker is going to look at all the things which were marked as dded which I showed you in the previous slide from the executable and start loading all those libraries. And then kernel will essentially get the exec system call and will start transferring control to the actual program execution. Does that make sense? So what happened is essentially when the program starts running in the kernel, kernel is first going to look at there is something called as interrupt specified so I will call that guy. That guy which is the dynamic linker is going to call is going to look at whatever was marked as needed in the executable and load all those shared libraries. And then all the segments will be loaded from the program and then the program execution start will be starting from underscore start function. No then you get that error that could not load shared library. So what will happen is so it you have to realize at what point that event happened. So let's say dynamic linker is looking at the needed list. So when it looks at the first needed entry so let's say that was a.so it loaded that. Now before it went to further you deleted b.so which was also needed. So when linker actually goes to needed and b.so is not present it is going to cry out. Once it is start loading and if it has loaded and then you delete then it also doesn't matter. So the timing has to be precise where linker is not fully done loading yet and you deleted something. I don't know what will happen. Correct the entire.so will be loaded. If it was already in physical memory you still need to load it by load in this context mean you have to set up the virtual addresses where it will be loaded to point to that. You have to create physically more space into the RAM. It just means that you have to create mapping that these virtual addresses hold this portion of the.so physically it may be backed in this same copy which was already present. I will come to that. But that is a good point. So now does everyone at least understood whatever we have covered so far. Now obviously you don't want to pay application start. So for example if you are using printf or if you are using some shared library function only for very small amount of time. Do you really want to pay for the entire load for the entire duration. So what happens is when you have loaded the d.so that was loaded by the loader or dynamic linker and that remains loaded for the entire duration of the program. So that no matter how frequently you use it versus don't use it. Once you have said I need this it will get loaded and it will remain for lifetime of the application. Now that obviously may not be the best case specially for very large application you may do some processing in chunks. Like for example if you look at game itself or any other such large application it may require some functionality for some specific duration within the application. Once you are done using that functionality you may say I don't want this functionality now because you are done with whatever needed to be done. So that's where applications can actually call dynamic linker. So far we saw loader calling dynamic linker at the application start time but there are ways in which application can call dynamic linker. And what is the interface obviously. So there is a function called as dlopen. How many of you had heard of this function. So there is a function called dlopen which you can call from your C program. It takes a file name as the argument which is the file name of the .so which you want to load. And it takes a flag which says at what point the resolution should happen. So whether do you want to do as soon as the file is opened do you want to do symbol resolution or you want to do symbol resolution lazily as things are being used from that library. So for example if you say rtld now so what will dynamic linker do it will go and resolve all the symbols. No matter whether you use them don't use them at this point everything will be resolved and all the subsequent references will be fast because you don't have to re resolve them. If you say rtld lazy then linker will simply map it into your virtual address space will not do any resolution. And once you call something then it will say oh I don't know its address so let me resolve first and then come back. It's a file it's not file path it's the library name. So you have to say where to locate so as a programmer at build time you have to tell where to look for shared libraries. Whether those shared libraries are loaded by the loader or by loaded by your application. LD library path again as usual keeps working. Now once you have loaded it how will you call a function because you can't say now refer to variable gbl because it was never referenced in your program. So there is another API called dl sim which is from this dso which was opened give me address of this symbol. And you get the handle and then you use that address. Once you are done you can do dl close which will close the. You can think of it like this that it gives you a handle to a symbol which you requested and then you can use that. I have an example which shows how to use this. And then there is dl error which will say whether anything happened I mean anything went wrong in the whole process. Now you can see that you have control over when to open the shared library and when to close it and you can do this as often as you want and for as shorter or as longer duration of the time during your application. No loader will not do. I will come to that. But essentially when you are saying so the entries which are used via dl open will not have dt needed in the else. So remember we saw something like there is something called as needed. This word generated by compiler or during the assembly process. So this says I need lib dot so. What loader is going to do is it is going to load all the shared libraries which had this flag. Any library which is only dl opened and not statically linked at build time by statically link I mean was linked at the time of creation of executable will not have this flag. What you are so think of it this way that wl path etc which you are giving is only to say that this is where shared libraries live. It does not say all the shared libraries are needed depending on the references which you are doing the shared libraries will be marked as needed. So this is the sample code. So I have I am doing dl open of some library and I am saying lazily if there is any error I check it. Otherwise I say give me handle of a function called as of a symbol called advec and I store it in advec and advec has this prototype and I simply call it as a function and I get now advec is not real lib vector dot so will not be loaded until the application actually starts execute. Correct and we can we can see that. So let us see that. So let us say I take this code. Now for simplicity I will say this is. Is everyone clear what happened here now if we do ldd ldd does not say I need lib my dot so and you can actually see it in action. So let us try to debug this code. So I will put a break point on main. So now the program has started but it has not yet done dl open. Now let us switch back to this. So we have this is the memory map of a dot out. my dot so here. Let me execute this. Let me re-examine the map. You can see lib my dot so now. So it was actually loaded when it was needed. And if you do the same thing with the earlier examples we were trying where it was kind of linked at compile time that this is needed. Then you need and you will see at the program startup itself it is already loaded. So those are calls to the dynamic linker which is part of OS in some sense. Yes so internally it will do some system calls to get to that. It is not a libc feature. So that kind of concludes most of the things which I had with respect to the surrounding environment. So just to kind of recap what we saw so far was how function calls were done. And if you look at function calls who played major roles in getting function calls working. Which component compiler. So most of the magic for function call was done by compilers. Then we went into details of object files. The creation of object file was essentially job of assembler. Then we looked at linker which was its own thing and it had its own quirky rules of how to do things. Then we looked in the morning we started off with libraries where we saw how to create libraries and what are the additional features of linkers. Then we went into virtual memory and processes and how when something is running on the system what is the view of that to the actual processor and the resources. Then we looked into the dynamic linking including position independent code and this. So that kind of covers most of the things which I wanted to talk about. The remaining session is all about how various language features are implemented. What all happens when you do something in your C language or C++ language. What all happens across the stack to make it work. Now I don't have any slides for these. I was bit lazy to actually prepare them. But I wanted this to be more interactive. That's why I have not kind of put fixed slides.