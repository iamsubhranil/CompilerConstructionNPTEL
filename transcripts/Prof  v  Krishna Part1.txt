 My name is Krishna and this is the second year I am coming here for the ACM summer school. Last year we had a great time. I hope I will have something similar here. So, we will be talking about introduction to, we will be talking about optimizations and high level optimizations and I was seeing what Malay was covering. They are pretty kind of advanced stuff and I am happy to see lot of you are nodding and so that means you guys are all in great shape. I will start with a bit of high level overview that I am sure you have already done it. So you can think of the whole compiler business as there are some, what is a compiler? What is a compiler? What you are saying is a word. What I have asked is a noun. You are saying what does a compiler do? What is a compiler? So you can rephrase it. Translate. You give me another word. So what does it translate? It is a tool, right? It is a translator. It translates what? To? Machine level language. It has to be always machine level language. It should always lower the level of abstraction. If I take a, just to make it maybe slightly kind of those who are sleeping. Let us say I will take my input is an assembly code and I want to generate Java code or C code. Would that be a compiler? Yes sir, yes, no. Okay, good. You have heard of this thing called interpreter? What is the interpreter? It interprets the single line of code. It executes line by? Aha. So now I, so let us take our traditional understanding of a compiler, right? It takes source code and outputs, machine coded. How is the machine code executed? Line by line. But you do not call that interpreter, right? Do you? Why do you call one guy interpreter, one guy the compiled code is executed but like say list code or say python code you call it interpreted. Why? What is the difference? Yeah, let us do one thing. There are multiple people who are very anxious. Let us just raise hands. Interpreter has to generate something called a byte code. An interpreter generates byte code, is it? What is your name? Rishabh. So Rishabh, where did you hear this word byte code? In what context? Sorry? Correct. So in what context did you hear the word byte code? So it is some low. But the, by the way, the interpreter does not generate or does not have to generate a byte code, okay? Byte code is some IR. So for instance, you hear this code typically in the context of languages like Java, right? So when you do Java C, it takes Java code and generates the byte code. And then the byte code is interpreted. Why do not we call it executed? Why do you call it interpreted? What is the difference? Yeah. If we need an, let us call it instead of abstraction, let us call it if we need a software tool in between to execute, then we call it interpreted, right? So that is the whole idea. So there is not much difference between interpretation and execution. We say execution and the hardware executes it. When a software instead executes the same code, okay, or evaluates the same code, we call it interpretation, right? Okay. So when we take a, when we say a compiler, a compiler takes some source code and outputs some other code. But typically most of the compilers we deal with, they deal with some source code of high level language and generate machine code. Yeah. Aha. Good. So the question is when there is already a compiler, why think about interpretation? There are things an interpreter can do that a compiler cannot. Can you guess what? See, I like these questions, you know, because for every question I will answer by another question. But yeah, it is a very good question, right? What is your name? Fahad. Fahad. Yeah. So the question is if there is a compiler, why think about interpreters? Or if there is an interpreter, why think of compilers? And I said because an interpreter can do things that a compiler cannot. Debugging simpler. Yeah. Aha. How? Because executing line by line, I mean, the interpreter stops. So you know that that line or the line before it has finished. Whereas the interpreter is ready to go to place back what exactly went wrong. Not entirely right. So if you are running, we are using a debugger. Inside BDD is a... You need some way to stop the execution or pause the execution, right? So there is something more fundamental about an interpreter. So a compiler does not have something that an interpreter has. Both of them need the program, right? But besides that, the compiler has, does not have something that the interpreter has. User input. User input. So given a program, the compiler generates an executable without knowing what the input can be, the user input. An interpreter has that. As a result, it can do more things. So there are advantages of having an interpreter. Okay? And as a matter of fact, when you design a language, invariably the first thing you have, you design keeping an interpreter in mind. Because every language construct needs a semantics. And that semantics is given... I mean, think of the... You design an interpreter at some level. And then you say, hey, no, I would like to have an A.out for this. You say, I will generate a compiler. But there are languages which... I mean, there are languages who say, like, we want only an interpreter because we get more advantages of it. Right? Any questions? Now, I will ask a question. I gave you an advantage of an interpreter. Then why not only keep an interpreter? No, no. Interpreter need not actually generate an executable file. Right? For instance, I can... Let me answer this. For instance, I could take... Pick any language of your choice. C, C++, Java, any code of that. And actually interpret it technically line by line. Right? So, I do not have to generate machine code. Because I already have an interpreter whose job is to take a statement and whatever the statement should do. Think of it this way. When you look at a code, in your mind you are running it as an interpreter. Right? Okay. So now, what can a compiler do? My... I mean, for example, I can write a code which is... So, portability is less of an issue with an interpreter. Right? Because the high level code now can be sent anywhere and all you need is an interpreter being running there. It needs an interpreter. Okay. What is your name? Badri. So, Badri is making an interesting point. He is saying, if you need an interpreter, the interpreter has to go to... You need an interpreter on every machine. If I want to send you a small a.out, you still need the big interpreter running. So, that is a good point. Right? But let us say I have an interpreter everywhere. For every hardware, one interpreter has been given. For every language, an interpreter has been given. See, now if I have different languages, I will come to you. If I have different languages, for each language I will give you an interpreter. But if you have... Yeah. There was a question. Okay. This is a misconception. Your name? Yes. So, what yes said is a common misconception that the interpreter looks at one instruction at a time. Now, the interpreter can execute one at a time, but it need not look at only one instruction. Right? Why it should only look at one? It is a perceived handicap. An interpreter can technically look at the whole code, do something and then execute one instruction at a time. As a matter of fact, there are interpreters which... For instance, how many of you have heard this language called Java? Right? In Java, when you run the code Java a dot class, what does it do? It supposedly interprets. Why interpreting if it finds a certain piece of code is executed too many times? This piece is executed lot of times. Let me do something smart for this. Let me either generate, let me generate the equivalent machine code for this compile or do some optimizations for this. That can be done. Right? No, something else that an interpreter has a drawback, serious drawback about. Yeah. Correct. Correct. Excellent point. Your name? Savit. Savit said, you can write a code and interpreter is one more software. Right? And now this software has to additionally run. So the interpretation makes it slower. Right? So interpreter code can be slower. Then people will say, okay fine, if it, the whichever part runs a lot of times, let me on the fly compile it and make it run fast. But even that compilation time gets added to your execution time. When you interpret some code, that is what your, is the execution of the code. If interpreter is taking time, then your code is taking time. So one gives you additional opportunities to do optimizations because it has the inputs, but it has the overheads of interpretation. So there is a nice pull and push. So different language designers choose different options. We can talk more about it later. But when an interpreter or a compiler invariably do things like this, they take the source code. From the source code, they do something and either if it is an interpreter, they will actually execute it. But if the interpreter has a JIT compiler, just-in-time compiler or normal GCC type of compiler, they generate machine code. But typically we can think of as a front end and the back end. Okay? From the front end, you take the source code, generate the IR and give it to back end. Right? IR stands for intermediate representation. Why do we need an IR? Any guesses? Enhance the portability of, to run on different back ends. Can you, you are using, I think, the right set of words, but probably they are connected not correctly. Can you, so the IR, the question is why do we need an IR? If there are m languages and n architectures, if I want to make for all the combinations, okay, so was this, someone discussed this standard m cross n? Very good. So, now the question is, if we have this m languages and n architectures, we will say, hey, let us have, let us trans, write all this to one IR, from one IR have many back ends. Right? So, the IR, if I have only one language and one, that is a good point, but if I have only one language and one architecture, why do I still need an IR? Why not in the same language? I mean, why do I need an IR? That is the question. I mean, it is like additional work, right? I want to generate code. I am saying, no, no, first I will do one set of compilation. This is also a compiler, right? This is also a compiler. So, I am saying, hey, to build this bigger compiler, let me build a smaller compiler. Why I cannot do optimizations on this? This word, why I will keep asking and I expect that you will keep asking. Whatever I say, there should be a reason why. What is your name? Dhaval. Dhaval. I will keep asking your name. Even if I ask, please do not mind. I have a very poor memory. So, Dhaval, what you said is interesting that to do some optimizations, certain things may not be visible in the higher level code. Can you give an example? So, for example, a loop, a loop in higher level just a false statement. You might not see any way of optimizing this any further. Whereas, in a primitive implementation, you might see, this thing is happening multiple times within that loop. Why not say optimizations? Very interesting. So, it is actually the other way around, I thought. The loops are more visible in the higher level code than a lower level code. Can you find the expression for that? This is a good point. This is one of the good points. Let us say, in the high level code, I have one operator called plus 1. If I do a plus 1, I need some instruction at lower level to either optimize it. I have some way to do, let us say, some fast way to do plus 1. Now, in high level, how can you express plus 1? Either something like a plus 1 or a plus plus. Now, if you, in the high level code, I do not know whether it is plus 1 or plus plus. If I keep the high level syntax as it is, in the back end, you need an optimizer to handle plus plus and plus 1. You have many such examples of syntactic sugars, right? If you want to keep your back end, which is a much more complex piece, what you want to do? You want to let it handle a smaller set of syntax. As you, whoever has covered IR, you would see that that syntax is much smaller compared to the syntax of the high level code. So, to make the back end life easier, we first generate an IR whose syntax is simpler. So, the front end maps legal code to IR, legal code to IR. Should I, okay. The back end maps the IR to the target machine. And this IR helps, that it can help, as you said, simplifies retargeting m cross n, m front ends, n back ends. It keeps the back end simpler and allows many front ends, okay. And typically, you make many passes over the IR. We understand this part, okay. A rough statement you can make that the code in the front end is, the passes in the front end are simpler or have been dealt with very well so far. Most of the work that is done in the current research world is all in the back end, okay. And the, but the back end problems, many are known to be undecidable. Some are known to be hard as in NP hard and in that range. So, the many of them are approximations, okay. Our focus is some part of the back end, okay. Our focus is some part of the, just this back end part. We would not touch anything on the front end, okay. Good. So, you have seen this seven pass compiler, right. So, what we will do, we will not, I mean, we will not look at the front end parts, whose job is to recognize the tokens and so on. So, this is the front end part and the back end part has these three phases. What we will do, we will, of the seven, we will focus on machine independent optimizations, okay. One order set. And if we require some other phases in between, we will go there, okay. Just let us take it for one more fun question. Let us say, you pick a production compiler say like GCC, right, or HPC compiler. I am sure it will hold for something like even NVIDIA C compiler. So, if I divide here, right, four phases here, three phases here, which phase has more lines of code you think? The code generator. Intermediate code generator. If you just divide the back end and front end, it so turns out the back end code is far, far more than the front end code. The older the compiler, the bigger the back end is. Because once the front end is settled, you do not touch much. You keep on adding more and more optimizations. So, the intermediate code generator is not touched much. You have it, it remains that way, okay. Fine. Our goal is to look at optimization. When we say optimization, what do we mean by it? Most of the time, when we say optimization, it means produce fast code. But is it, when we say optimization, is it optimum? We are not talking about optimum. We are not, okay. We are talking about some notion of optimality. Many of the times, the problems are hard and it so turns out, if I have N optimizations, if I apply all N, there is no guarantee that the code will be faster. There are times when if you apply two optimizations together, the generated code could be slower. Ideally, we do not want it that way, but it may. So, keep, so have that thing in the back of your mind, okay. So, when we say an optimization in more general sense, it is a transformation which is expected to improve the program. But when we say improve, what do you mean? It could be execution time. What else can it improve? Space, what else? Power consumption, what else? Size of the code. Why do I care for size of the code? It is a good point. If I want to send the code over the network, the smaller the code better. If I do not want to send it over the network, is there a reason why I may need, why I may want a small piece of code? Perfect. That is a more regular, more common need for compilers that can optimize for size. Let us say you have a pacemaker or you have a small watch or a small sensor, right. There you may have very small pieces of memory to hold the code. The answer is yes and no. It depends on the program, right. If I have a program that does not do dynamic memory allocation, right. I can easily write tons and tons of programs that do know dynamic memory allocation. And for instance, here is something, right. Let us say I am doing, I want to compute primes, right. All I need to do is keep on. So, that does not require too much, I mean this most naive thing is keep on dividing forever, right. So, now the question is when we are talking about the code that may run on a sensor, what type of code it is? So, in those codes, you normally do not require too much of dynamic memory. As a matter of fact, the code that have to run on sensors, they have to have certain guarantees that they will not need more than certain amount of memory including dynamic, runtime memory. Let us say it has a recursion. The recursion will not unfold beyond element. Think of it this way. Let us say I have a code which is running on my pacemaker, right. Suddenly it has taken so much memory that it says sorry, out of memory. So, it is a very important question that many, some of these software vendors have to worry about. So, when we say improved code, we are talking about improved not optimum or even optimal. Sometimes it may produce worse code, but our hope is that the speed ups can be starting from some small delta to some large factor, okay. In general, it is even undecidable whether in most cases a given optimization will give you improvement, okay. I do not like this. You should ask why. We are saying it optimization. I am saying it will not improve and none of you are even asking why. Does not it bother you? Sorry? But what am I saying? You pick any optimization of your choice. Pick any optimization of your choice. Even then I am saying there is no guarantee. Let us say dead code elimination. I am saying you eliminate dead code. There is a chance that the code may lead to worse performance. I am making a very strong statement. It should shake up your sleep and say, no, this guy is either stupid or we do not know something which he is talking about. Yes, yes. Do you see what I am saying? I am making a very strong statement. Take an optimization that you think, I mean dead code elimination. I think even then there may be some cases because of dead code elimination the code is running, taking more time. Okay, no, you are saying you are going further ahead. You are taking my statement as a given, but I am asking, question my statement. Good. It depends on the program we are considering. So can you give an example where because of dead code elimination my code may run slower. I did dead code elimination, but now my code runs slower. It may not happen most of the time, but there may be some cases. See what I am saying? I cannot give guarantee for all the scenarios. Let us say there was a memory fetch. I removed it. I avoided the memory fetch because of which you would assume that it should run faster, but now it is running slower. Why? Good point, right? So what he is saying? The dead code is doing something that is useful to me. It could be bringing in something to the cache. It could be changing the layout of my instruction cache. It could be prefetching something and dead code is just one example. It turns out there are so many factors in play. There is cache. There is hard disk. There is like our friend was talking about the pipelining, how things are there, how things are organized in the pipeline. We do not have any optimal solutions for any of these problems. Individually each of these problems are too hard. Now your question, if there is no guarantee for any of these, why should I even use them? Why should we sit in this air conditioning room and learn about this? Right? Good and those chances are very high. Right? The chances are very high. So when you walk on the street, is there a guarantee that you will cross the road? The chances are high. Even on police streets the chances are high. Right? So the point is most of the time we will, the optimizations most of the time you have. I mean those are the popular optimizations and most of the time you get better performance. Right? And he asked another question. What if you do not do? What if you do not do? If you do not do any optimizations, the impact, I mean the programs, I mean the optimizations give you speed ups which are unimaginable otherwise on this day. The handwritten code, it is very hard to optimize large pieces of code just by hand. I mean here is the deal. When you touch, do you have a phone or do you have a laptop? When you open an app, you have a choice. An unoptimized code that takes 20 seconds to just load the app and an optimized code that takes 1 second to load the app. Which one will you use? And when I said 20 seconds to 1, I was being very kind to the unoptimized code. The optimizations give you so much benefits. You just cannot ignore it. Fine. So it is not just dead code elimination. Even some simple things like algebraic simplification. If you know that multiplication by 2 is same as left shift. Left shift is faster than multiplication. Even then there is no guarantee that it will improve the performance. It may lead to some other hazard somewhere, someone else waiting for you, some other impact on cache. The typical goals of the optimization code are speed, space and power, energy and so on. And the interesting part, A does not imply B, B does not imply C. If you optimize for speed, it may increase the space, it may increase the size. If you optimize for one, it may impact the other one. Beautiful, right? So which one matters? But I am saying I cannot give you all. Dependent on? Depends on the end user. Depends on the specific target you have in mind. Traditionally when we say optimization, we talk about speed. We will mostly focus on speed in our discussion. Sometimes when you optimize for A, it may also optimize for B. Sometimes. For example, how does this thing called loop unrolling? So loop unrolling is nothing but let us say I have a loop that goes from say 1 to 100. I will repeat the body say 5 times and execute loop from 1 to 20. I do not need to jump back after every iteration. So it is faster but my size has increased. Now when I say look there are optimizations, some optimizations may because one optimization some other optimization may get impacted and optimizations may take time and so on. Or tomorrow you want to come up with your own optimization. In all these things you keep asking whatever the optimization I am coming up with, is it worth it? And I am not going to answer that. Then you will ask which optimization should I focus on or what should I optimize? If you are optimizing for speed, you optimize that part which takes more time, whichever is your bottleneck. So in the code which part takes more time? Typically loops take more time. So make sure you optimize loops. In the code you know that the memory access is slower, much slower compared to CPU. So what is the typical memory to register access ratio? How much are in now NVIDIA machines? So it is kind of in the order of 10 CPUs, sometimes even hundreds of times. If the register is X, register access is X then it is kind of if it is prefetched in the cache and all that it is kind of in tens and if it is kind of further away from memory then it can keep on increasing. So memory access are bad so you want to improve your register allocation so that as many things possible you have you keep them in the registers. Then instruction scheduling we will come to this later. Instruction scheduling is basically saying in which order you want the instructions to execute so that they run fast. And the choice of optimizations not only depend upon our goal of speed and so on, they also depend upon the input program. For instance if there is a program it is an OO program, object oriented program. How about object orientation? All of you? Great. Some optimizations like inlining can be very important. Can you guess why? What is inlining? Function inlining? Anyone? Whenever there is a call, wherever you see a call you replace that call with the function. Did any, has it been already covered inlining? No, right? But you have heard of it. Very good. So why is inlining very important for object oriented programs? Any guesses? Typically when you see this magenta colored text in my, when I teach back in my school when students answer this question they get half a mark. This half a marks are out of the 100. So without attending any exam you can start earning marks. But these questions are also very difficult to answer. Not easy. You have to think. Yes. Inheritance. Okay. Copy of? All of them, let us say at least will have access to those features. Yeah. Jumping back. What do you mean by jumping back? In the parent class let us say. Yeah. When they go back there? One minute, let me finish. Today at the end of the class, whenever the class ends, will those of you who are interested, I can spend a bit of time on how object oriented programs get translated. How they get, how they run. You do not go to up up up. You do not do that. You do not have to. It is a common, see it is how we see it. When we look at the code we say okay is the function defined in my class? No. Then go to the parent class. If it is not there, go to the parent class. It is so transferred it is not implemented that way. I am happy you brought it up. Remind me at the end of the class we will talk about it. If you have any, I do not want to hold up everyone when they are completely tired. So those who are asking questions they can stay longer. Okay. Yeah. Why do we need, why is inlining very important for OO programs? No, yeah, yeah, hands up. So what you are saying is if we inline, if you do not inline, call. So I have to push my local variables onto the stack. Go, start executing there. Come back, undo and all that. I mean pop up from the stack and all that. Good. But that is true for every time you inline. Why only OO? What you said holds the advantage of inlining. I am saying why when I said OO programs inlining is important, why OO programs inlining is more important, very important? Multiple objects of the same class. Okay. Not sure. Not sure. By the way, just one second. Those of you who are using the laptop to anything other than take notes, I strongly suggest please close the laptops. Because some of you may be, do you have internet here? Yeah, so some of you may be using it for different purposes and it does two harms. One, to yourself that you are probably missing out not on the lecture but an interesting discussion and questions that your friends are bringing up. And number two, you are distracting your neighbors. If you are taking notes or typing notes, that is perfectly fine. Why do we need inlining in OO programs? We call up methods often even in C programs or do we do more in OO programs? Small things, good point. Small things like what? Perfect. See in object oriented languages, you have this typical thing of encapsulation. Some private variables here, some variables which are hidden inside an object somewhere. You do not directly write to the field. You say okay, do a set, do a get. Even it is a very tiny method like our friend said, I have to store all of it, do a jump, return it immediately. Looks like a lot of overheads. So inlining is very important. So if you have some language corresponding to that language, you will do, you will make sure certain type of optimizations are there. If you have code the programs where you write lot of recursive, where lot of recursive functions, then you want to definitely have something called tail call optimization. Heard of this thing called tail call optimization? What is that? Yes, what is tail call? Tail call is the call which is present at the end of the function. After that I have nothing more to do. So when there is a tail call, why should I make a call? Every time there is a call, I have to save and then do something more and then come back, pop back and now if there is a tail call, I can directly jump there. It can be a simple jump. And then at the end of the tail call, I do not need to return to me. You can return to my caller. You can even think of an optimization where recursion can be replaced with loops. Those of you who care, every, but even the recursion and loops are equivalent. There is no difference in terms of power. So when we talk about optimizations, there are three types of optimizations you can overall think of. One is local optimizations which are within basic block. What is a basic block? It is a sequential piece of, it is a code where there are no jumps in between. So you can think of local optimizations, intra procedural, that is you optimize within one procedure and do not know anything about other procedures or inter procedural optimizations which impact across procedures. You can even think of optimizations based on their positioning. High level optimizations or low level optimizations. High level optimizations is optimizations which are based on the program structure and typically they are done first in the optimization chain. Most of these high level optimizations are machine independent. You have low level optimizations which are typically called the mid or low level which work on mid and low level IR. They do not need much of the program structure. I think Gowind is covering low level optimizations. That is coming up next. I mean later and I will be covering on high level optimizations. So a brief this thing between machine independent and machine dependent optimizations. These machine independent optimizations, they are applicable across a broad range of machines. So if I am saying optimization, this is applicable not just on machine X but maybe a class of machines. Not necessarily the whole world but much broader. I mean I could think of some code. Let us say there is some code which is executed very frequently. I move it to a less frequently executed code. That is machine independent. I removing redundant code, right. Dead code elimination. Dead code elimination can be done at many phases but a high level. The machine independent optimization sometimes themselves may not do much but they will create opportunities for the machine dependent part. We will come to that. The machine dependent optimizations typically they capitalize on machine specific properties. So they improve the mapping of IR onto machine. They can reduce the strength of the instructions, use more efficient instructions which are given by a specific hardware, right. You can think of using exotic hardware instructions to take advantage of the hardware properties, right. For instance, maybe this distinction between high level and low level is not always there. It is always very clear. There are some optimizations. One may say is it here or here. For instance, replace multiply with shift and adds, right. If you see a multiplication, replacing with adds you can do it at the high level code itself, right. Because I mean this is, some of these are on the border line. So there is no hard and fast rule but overall you get an idea, okay. Fine. So before we go into a high level optimization, what we are saying? We want to design an optimization which should have certain properties. What are the desirable properties? The code should be at least as good as a handwritten assembly code, okay. It should be stable, robust performance. What is the stable performance? You done some optimization. It should not happen that you toss a coin, okay, heads. Today it will run fast, tails it will run slow, right. The optimization should work consistently. So every time you run you should get some consistent performance. Ideally, you should design optimization that will take advantage of all the hardware specialties and give, take advantage all of them and generate very efficient code. It should, if there is some weakness of the architecture, the optimization should be able to hide that. The optimization should support a broad range of languages and it should be very fast. And the good news is most of the time, most of the time, most of the optimizations draw, they do not do all of them. They may do A not B, they may do C not D, okay. So it is okay. So it is okay to have, I mean sometimes the optimizations take slightly more time. They may not be doing all of them. So that is desirable properties. There is a required property of every optimization. Can you guess what it is? Correctness. What do you mean by correctness? Perfect. So the required property is the generated code of the after optimization should and do you think the GCC code that you use, all of you GCC are some, any compiler of your choice, right? Do you think it produces the correct code? Let me add a word on top of it, always. Sir, in the example that you have, in the example that you have, okay. So you do not like GCC. How about Intel's ICC or our sponsor NVIDIA's NVCC, the CUDA compiler, right? So by the way, it is nothing to do with Intel, NVIDIA or HP, HP, GCC. This is code written by someone, right? The code may also have bugs, but what we in general say is that most of the optimizations, at least in theory, they should be semantic preserving. Actual implementation, they are written by people like you and me or may be much smarter in case of some companies, right? But still there may be bugs, but modular bugs, we want that they should be semantic preserving, right? Okay. So we will continue with our, this thing, sorry, when we say semantic preserving, how do we guarantee that it is semantic preserving? Yes, correct. But the compiler does not run the code. The compiler takes some code, optimizes and gives you an output. How can the compiler be sure that the optimization it is doing is right? Sorry, we can? Good, let us keep that part. For whatever the input given, right? But the input, now the input can be any random input, right? I mean, given, so what you are saying is there is some understanding of what the, I mean, some classes of the inputs. How the program will behave for this input? The output program should behave similarly. So the compiler at some level should understand the input program as well, right? And that is where comes the branch of program analysis. The compiler has to analyze the program, make some sense out of it. So you will see that for optimizations, you will always need, you always have a phase which will analyze the program. It has to understand the program. Once it understands the program, it can do some optimizations, right? Let us take an example. Here is a piece of code that says if condition, I am writing to A, B, else AC. If the compiler wants to figure out which variables are assigned in this piece of the code, right? It has to go through the code and understand, right? Now this understanding can vary. There are different types of analysis. One of the, have you already been told about may analysis and must analysis? No? Good. So in this piece of the code, do you know which branch may be taken? No. The compiler cannot know. But if the compiler wants to figure out which, let us say there are four variables I have A, B, C, D. And now the compiler wants to know which variables may be assigned in this part of the code. Because any code that is variable which is not assigned or used, I may throw it away, right? But to throw it away, I need to know which variables are, which variables may be used. So in this part of the code, which variable may be used? A, B or C. But is there a guarantee that all A, B, C will be used? No. Why? Because the compiler does not know anything about the condition. So there is something called a may analysis which tells information like which may be assigned, which code may, which part of the code may be accessed, which part of the code may be executed, right? If I look at this part of the code and ask you a question, which variable is guaranteed to be accessed, must be accessed? A. So that is the must information. So there are two broad classification of the analysis, may analysis where we say whatever we infer that will hold at least on some path, rather it may hold on some path. It may, it may, let us say before this code there is some division A equal to B by C and C is all, sorry X equal to Y by Z. Z is always 0. So you will never execute this part of the code. So module all that. So the may analysis is the analysis holds on at least some data path, whatever I understand, within whatever I can understand it may hold. The must analysis says the analysis information will hold across all paths. We will use this understanding to do more optimization. But remember the idea of may and must. What is the opposite of may analysis? So let us take the, let us say I have four variables A, B, C, D. Definitely not or must not. So the opposite of may analysis is must not. So if you, if you complete some information that says may, the negation of it will give you must not. So if you have A, B, C, D variables and you ask this question, which variable must not be assigned in this part of the code? The code it is D. What is the opposite of must analysis? Never is it? So let us look at this way. What is the negation of, what is the negation of this one? Which of the variables must be assigned? A, what is the negation of this? B, C, D. So what is the question you will ask whose answer is B, C, D? Which variables may not be assigned? Which variables may not be assigned? We will take an example which is called as constant propagation. It is one of the most popular optimizations you can think of, I mean which is there in text and is used. We will use that to understand this may and must have been. So what is the idea of constant propagation? Let us say there is some piece of the code whose value is known to be constant. Then why should you execute it at run time? You take that piece of the code or that expression. We will call that expression as a constant expression. So I need to find out what is the constant expression and replace that constant expression with that constant. So here is a piece of code. Look at this piece of code and tell me what all constants are. Do you see any constants at all? Clearly there are constant literals 1, 2, 3 and all that. I is equal to 1 is used here and there is here. So I is a constant our friend says. So if I is a constant what I can do? Replace the occurrence. So I can replace the occurrence of I with its constant value. So what will happen to this code? Let us see. Can I use this board? I will be using this and this together. No I think it is better I write it here. It is more fun writing it here. Hello. So which one are we replacing now? So you are saying we do not need this. Every occurrence of I I will replace with 1. So we eliminated one constant expression. What else anyone? J. What about J? It is always 2. So first of all I need to replace this is a constant expression. I will replace it with 2 and now I have J equal to 2. What do I do? Wherever every occurrence of J I will replace with 2 and then I will replace it with 2. So I replace it with 2 and then what do I do? A of 2 is a constant and then I replace it with 2 and then K is a constant. Now what happens? I have a piece of code. If the name is J, what else whose body is empty? I can even throw this off. I am doing an assignment to an array. I am not using any other element. So you are left with a function that returns 2. Now we have the function is throw away the function call and return add put 2. Nice right? And guess what? A compiler can do quite a bit of these things. The programmer has written the code because there are some initial code. See initial code was using B right? It can inline this piece of code as well. It so turns out even if you do not inline some of these things can be done. Handling these arrays is bit tricky otherwise the rest of the things we can do pretty well. You will actually do it. Just give it some time. If you guys are excited about doing it manually, I think you would get lot more kind of excitement that this can actually be done automatically. I mean there is some conditional code. Just look at this code. It does not look like you can throw away the whole code right? So now what we are saying is that is what is constant propagation right? We will take in constant propagation there are different variations we will look at. One which is called why only constant propagation? In general analysis you can think of flow sensitive and flow insensitive. What is flow sensitive? Let us look at this. Here is another piece of code. In this piece of code I have some condition setting abc and I have print abc else abc and print abc. Now the question is are abc constants? Is the value of a constant in the program? Is the value of b a constant in the program? Is the value of c a constant in the program? Yes c is constant both of these. So the answers you have given is you have given me the constantness or constant information about the flow take variable throughout the function. But what if I ask you at this line is a a constant? At this line is a a constant. So now what I am saying you are now distinguishing between different program points the information at different program points. First when we said a is a constant what we wanted is a constant across the program. Now we are saying is a constant at that point. Make sense? So now flow sensitive analysis will give you information which can hold at different program points. Flow insensitive it should hold at every program point. It does not depend upon whether you take the then branch or the else branch. Similar to flow sensitive and flow insensitive you can also have context sensitive and context insensitive. What do we mean by that? Here is a piece of code that uses two functions foo and bar. Foo takes an argument x and returns x. Bar does x square and returns. Now I have a equal to foo 2, b equal to foo 3, c equal to bar 2, d equal to bar 2. Now the question are ABCD constants? Is a a constant? Let us ask this question. Is this x a constant? Does foo always return a constant value? What value does foo return? Let me repeat the question. The values that you may tell me has to be an integer value or do not know. Let me ask this question again. Does foo return a constant integer value or we do not know? We do not know. It may return 2 or 3 since it is not a single constant value. What about bar? We know because bar takes. In this program we know. Now if I do intra procedural analysis, if I look at one procedure at a time and do not look at any other code, when I look at a equal to foo, I say I do not know anything about foo. It must be returning some non-constant. B equal to foo, I do not know anything what foo does. But if I do intra procedural, I can look at other functions. When I look at other functions, what options do I have? When I do, when I look at this function foo, one option is every time there is a call, I go analyze foo and come back. So here is a call to foo. I will go here, analyze this function and give you answer 2. So here it returned a constant. Here again I will go here, it will return 3. Here again I will call bar, I will analyze bar and come back. I will say it returns a constant 4. Here it returns a constant 4 and all constants. So how many times you have to analyze the function? Four times in this case. In general how many times I may have to analyze the function? In this scheme of things. What is your name? Yes. So yes said something to a question. My question was if I am analyzing a function every time there is a call, yes said if there are n calls then I will analyze the function n times. How many of you agree? How many of you disagree? Those of you disagree why? Will it be more or less? You are saying it is less. Why? Because what I am saying is here itself there are two calls to foo. I have analyzed foo twice. So if there are n calls I will analyze it at least n times. That is very clear. So what you are saying if I have already analyzed the function bar with the same inputs why should I reanalyze it? But I did not go to that level yet. I am saying if I tell you that I have to analyze a function every time there is a call and if in the program you see there are n calls to foo how many times will you analyze foo? And he said n. How many of you agree that it will be n? Now you have more supporters. So your support base is increasing. What is the if statement? Yes, the scheme is that. The scheme is that we will analyze foo. No, let us not worry about the input. Let us say we have no way to know the inputs. All I am doing is whenever there is a call I will go to that function and come back. So I am saying how many times will I go to that function and come back? Yes sir there are n calls. I will do n times. How many of you agree? What is your name? No, no not Adhvith. Praful. Praful what do you think? N times. Why n times? Now I am making a statement. It can call exponential times, exponential number of times. So I am saying that if I have n, if the program size is n, I may have order of 2 to the power of n. Is it possible? Yes. No, let us not. All I am doing is I am looking at the call. Every time there is a call, I will just go there. I will analyze that function and come back. So I am not looking at variables let us say. You are saying if the function is calling itself, then it is going to be infinite loop. Then it may keep on calling itself, it will keep on visiting itself. So that will go into infinite loop. Let us say we are avoiding recursion to keep it simple. Very good point. So in recursion, how do you handle recursion? That is a difficult task but let us say we are not going to recursion for the time being. There is no recursion. You are trying to fit the answer. No, do not try to fit the answer to. Yes, guys. Power set is it? Power set is it? Yes. I am not really sure how I can map it to power set but here should I give the answer? No, right? Let me make your life simpler. No if conditions, no recursion. No, I did not say that. No, sorry what are you saying again? There must be a water bottle here that I was using. Must have been this guy. I am trying to understand so you have to complete the sentence. So those who have not answered so far, give it a try. Those who have not spoken so far, you have to complete the sentence. What is your name? Sushrath. Beautiful name. Yes, Sushrath. What do you think? Did you understand the question? No, let us say we always analyze the function. I am just saying, I am keeping life simple. Sure, do consider. Give me an example. Make an example. Example, example. So those of you who are trying to come up with a scheme, the best way is to write a small example in your textbook if you can come up with an example. Sorry, sorry. They know if blocks. Do not worry about the input. If you do not like it, let us say that it takes no arguments. I am just being deliberately making it ridiculously simple. Then, actually it is so simple. I do not think we should spend more time on this. It is a pattern that once you know, you know. Yes. Good. When will such a thing happen? When will that happen? So, your name? Rishabh said, to analyze, I will complete the analysis of one function only if I have analyzed some other functions. When will that happen? Good. One cause the other. Then, what will happen? Let us take this example. Very simple example. I have function f1 that calls f2 twice. I have code f2 that calls f3. How many times? Twice. I have f3 which calls f, no our friend Fu there. How many times will I analyze Fu? Right? So, twice, four times. So, if it is you keep on increasing it will be 4, 8, 16. So, doing context sensitive analysis is going to be very expensive. It is going to be super expensive. There is one more thing that is going to be pretty hard is when you are sitting in a lecture and the guy who is giving the lecture had a very heavy breakfast. He does not feel very hungry, but are you guys hungry? Yes. So, what is the scenario? How far can I see? I mean this is a good logical point to stop. We can continue further, but if you think these guys should go for lunch and they should. So, you should thank him then. Then, what time do we meet back? Okay. So, we will meet back. Before we go, let us quickly summarize what we did now. Let us try to recall. We came, we started with a brief overview of compilation process. We discussed about compilers, interpreters, IR and all that. We looked at what are the important characteristics of optimizations. We understood the desirable properties of optimizations and what is required for them. We looked at flow sensitive, flow insensitive, context sensitive, context insensitive. What do these terms mean? We understood what is may information and must information. So, let us keep this somewhere in our stack of our cache of things. We will come back and continue the discussion. This kind of brings to the introduction of the introduction to optimization part. We will go into a very interesting example of what all optimizations can do. If you thought this example was exciting, wait for the next example. So, we will meet after the lunch. Any questions so far? No? I thought you will ask when will you leave us? See you soon.