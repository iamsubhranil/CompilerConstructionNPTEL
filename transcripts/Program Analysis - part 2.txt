 So, just check if these these tools are there, there is a tool called Clang, are you able to run Clang? Clang. There should be a tool called OPT, this is the optimization pass in LLVM that is there and you will not need it, but still see LLC is there ok awesome. Now what we will do is just write a sample code, does not really matter what, let me just see if I have something you can just write that, I should have maybe sent you this. So I sent a mail yesterday, but ok. So can you see this? Let us just expand it, let us write some bit of code, little bit more code. If z is greater than 0, something else something ok. There is some program you have, does not matter what. And then essentially you should be the way to, so just check if you can do Clang, you can do Clang whatever is the file name a.c. Does it work for you? So now the first step in LLVM is to convert your program into the LLVM IR. So do you know this M cross N versus M plus N design of compilers? So essentially now the idea is that you would always like to, there can be multiple front ends and all the front ends would compile down to the same IR, the same intermediate presentation. Now you can have a bunch of compiler passes which will all transform the same IR and eventually there will be an M number of back end passes which will translate the output into the respective target language, the IR into the respective target language. So which means that you will not have to write the compiler, the optimization passes for every source target combination. So LLVM completely breaks down this division, I mean it makes everything explicit. So it has, you will be able to see the three passes completely differently. So the first pass is the pass which will convert a source language program into the IR that using the front end which is the client front end. Then you have the OPT pass which will run optimizations on your program and you can tell it which passes you want to learn, which passes you want to run your program through. And these passes can be given in a certain order, you can say run DCE, then CPE, then this you can actually run these passes in a certain order and it will exactly run these passes in that given order. And after that you can use the back end pass to transform your program which is the LLVM pass, you can transform your program to the respective target, whichever target language you want to target. So we will first use Clang to produce an IR for your program. So essentially the command for that is you say Clang minus emit LLVM and you say a dot c whichever program you want. Once you run it you will get an error. It says emit LLVM cannot be used when linking. Any idea what is the problem is? What would that do? But you would not like that. So essentially now what I want is essentially what has happened is but what is the error, what is the problem? Right, so right now I want to convert it into LLVM and it may be linking against a lot of libraries like printf, scanf, the gllipc library and I do not have their byte codes available, I do not have those definitions with me right now. So I do not want to do linking right now because I just want to do optimization on whatever code I have. I do not care, it will not produce complete program at this moment. So essentially you can simply say that skip linking by just saying minus c. So it will skip linking, it will not do linking. And once you do that you will get a file called, what file did you get? A.BC. So BC is the bytecode file. So the LLVM IR is also referred to as the LLVM bytecode. So this is the bytecode file. Bitcode, same thing. So it is referred to as, so now essentially what you would do is that you would, so if you want to, so if you try to look at this program you will not be able to look at this program because it is a binary representation but there is also a human readable format which is LL format. So we will do it when we want to examine the instructions. At this point in time we really do not care about, we do not want to examine the instructions. So now with this you can run the optimization pass. So the running the optimization pass is you say OPT and if you say minus minus help you will be able to see all optimizations that are available in LLVM at this moment. So you can, let us see if we can see some interesting optimizations. Let us try to do this simple thing. Print function. So let us try to just run this. So we say OPT print function a.bc. Now there is a problem, this guy will try to emit things onto the terminal which is not good. So you can redirect the output to dev null. So it actually shows you the body of the function that it has compiled. So this is the LLVM interpretive representation, the human readable form of the LLVM interpretive representation. So this IR looks very similar to machine code. So it is referred to as a low level IR, it is very close to the machine code. So you can see that, but it uses these what are called virtual registers or to store values, intermediate values. So these are like temporaries. So there are different instructions and maybe we will come back to it when we start doing data flow analysis. So at this point in time, we don't care about what these instructions are. But what are interesting is, let's only look at the branch instruction. So for instance, there is this conditional branch instruction which says that you try to, so it looks at 6, the result of 6. The result of 6 is a comparison SDT signed greater than. So it does a signed comparison between 5 and 0. I don't know, so 5, we had some variable I guess. 5 basically if you look at the temporary 5, the temporary 5 loads the value of Z. And then it essentially does a signed comparison between Z and a constant 0. So I think that was our if condition. We had I think if Z is less than 0 or something like that. And then depending on the value of 6, it branches to either label 7 or label 10. And essentially you can see that label 7 has a set of instructions and it says its predecessor is 0 and label 10 has these instructions and it says it comes from 2, 3, 4, 7 and 0. The code, okay. This was the code. Z is greater than 0. Where is it? %5. No, sorry. I don't know. What? That can be the naming can, so you are probably using a different version of. %5 is Z, right? But think, see what happens to Z. Z I think we have reassigned, right? So Z is Z was initially 2 and then it, so essentially it uses this notion of virtual registers. Virtual registers are basically it has an infinite set of registers. Every time you do a reassignment, it will just fetch a new register and write it. It will never reuse those values. So like given this, you should be able to see what your control flow graph looks like. Now okay, so you can, all of you can run OPT, right? No issues? Great. So once we have OPT, the next thing we will do is that we would like to build our own pass. So a very simple pass is something referred to as a hello world pass and maybe you can type it or I already have the code, so it is there in, so this is already available at this particular location. You can just copy it from here if you want to. So we will later see how to write a pass, but for the moment just let us try to see how to compile a pass. We will later see how to, so I think the code is there. You can just copy paste that code into an editor and we will try to just build it and run it. Okay, could you guys get that example? Right, so now the way to compile this is that you can say G plus plus, it was a C program. You will need to, you need to build that. So there are many ways of building a pass into LLVM. One is that you can actually add it to the LLVM system so that like the passes you are seeing, those are all passes in LLVM. When I said help, you could see a lot of things, right? All of these are passes in LLVM. So you can actually build it such that it becomes part of that. Problem is it will require you to have the whole of LLVM and you will have to put your code inside it and build the whole thing. The easier way is to build your program, build your pass as a separate, what is called a shared library, right? And then the advantage is that, well you do not have to do much work, that is it. So the way to build the shared object is, right? So you can use this command. So it is a long command. So make sure you, can you all of you see it or should I, okay let me just pull it out. So G++, Fpix says that I want position independent code. So essentially, let me not get into it. Then Rdynamic and Shared say that I want to build a shared library. You may or may not use this. So this is if you want to enable C11. Next these two have to be set and then you have the name of the file that you are compiling, that is example 1.cpp for the moment and minus O says what is the name of the shared object that you want to create. So the header files, if you are installed the LLVM depth, they are already there in your system path. So no, because it is already in the system searchable path. Try to run this command and see if you are able to build your pass. So here it will be the hello world pass. So it would be hello.cpp and hello1.o whatever it is. Have you, do you have the LLVM depth package installed? All of you, do you guys have LLVM depth installed? Okay, okay dictate to me. Tell me, tell me, tell me. Sir, just try to write. I will just write it here. With the, with the addition to it. I will just write it here. My thing will not compile with that. So I do not know what to do, but let you open up the, okay what is it? Hi-finite is for include path. Then you say which, what is the path? Slash home. Student. Student. School. LLVM. LLVM. Clang 8. Clang 8. Then build. Okay. Okay. Another is hi-finite. Okay. Instead of build, there is a LLVM and then include. Instead of build, you have LLVM. LLVM include. No, yeah. So, just add it to the end of your command. Maybe before over, I mean generally boot. Just check if you are able to build this. Works? Okay, awesome. So, if all of you have the same configuration, it should work. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Okay. So, let's see. Done, anybody still lagging? Not working? What is the error? No, so, this minus I did not work for you? Okay. So, let's see. Okay. So, let's see. Okay. Okay. So, let's see. So, let's see. Okay. So, let's see. Okay. Okay. Done, right? Okay, awesome. I think we are all set. So now, you can build your pass. Cool. Now, the next step is to load your pass. Now you have to make LLVM know that such a pass exists and it should be able to pick up the code and run it. To do that, essentially you have to tell LLVM where you are. Okay. So, now this is a shared library. So, whenever you have shared libraries, you have to tell the system. So, do you guys know what a shared library is? What libraries are, what shared libraries are? Okay. So, shared libraries are basically libraries which are loaded on demand. So, if you, let's say you are, let's say you write a library and you know that on certain conditions you might have to, you need that particular library to be used. Now, one option is to compile the whole code of that library and attach it with your whole program, right? And ship that program across. Problem is it will be a big executable, right? Instead what you can do is if you know, for instance, that let's say our G-Lib-C libraries, right? All of us need that library, printf, scanf, string libraries. We are all going to use those libraries. So, is it not good that, now think about it, think about the situation where I write some code and I want to share that code with you guys. One option is I compile it with all the G-Lib-C library, the whole binary is one package and I send it to you. It will be a huge binary. Like, think about how much time you will take to download it. My code might be three lines, like hello world, printf hello world. Instead the option is that you guys install the shared libraries on your machines. I just give you my code and that code knows where to pick up the G-Lib-C library on your particular machine, right? So that's, so essentially the idea is that certain code is there on the host machine and certain code is sent to you and they all work seamlessly nicely. Problem is that on your machine you should be able to know where the shared libraries are, right? Because in the system where does it start looking for that library? So there is this variable called LDLibraryPath which tells you the search path for a shared library, tells you that search a shared library at these locations, right? So here if you, like for instance, the way to load this thing is, the way to load your shared library is that you can say minus OPT, sorry OPT minus load, give the name of your library hello.so, invoke your library, okay we'll do that later, hello.so and then give the name of your, of the object file that you want to analyze, let's say a.bc and redirect it to Dev Null, right? What does it give you if you run this? Cannot find shared library, right? So we have to make it recognize where the shared library is, tell it where the shared library is. So the way to do that is to you can just say export LDLibraryPath equals, if you already have LDLibraryPath you can just keep that, probably will not have anything here anyway. And append, like one simple option is I just say present directory, dot, right? So if I do this, then see it is able to load it, there it does not come anymore. So it's able to find that whatever hello.so pass. Works for you? I think you are, this thing is not built, you do not have the packages. I think they just built Clang, they may not have built LLVM. Is it giving an error? Guys, the same error is it? Okay, so we'll have to fix that. Maybe you guys can do it over the lunch break, I would request the TAs to help out the students. Looks like they do not have all the libraries, all the libraries. Or maybe it is there, just search for this particular directory, whatever the include directories are, there would be a lib directory there. Is there a lib there? Do you have some files there in that, in that path instead of include, say lib? Okay, so what you should do is in the LD library path, you just append those paths, the same prefix that the eyes had, but instead of include, say lib, right? So in like wherever I'm setting the cell delivery part, I set it as dot, you give those paths and you can template it by colons. The same path that you gave for i, minus i, the same path replacing include by lib, right? So now if you load it, essentially what happens is that this guy does, like is able to load it, does not give an error, but essentially if you really want, but it is not doing anything. So to make LLVM do something, remember there was this switch, so you have to say that do something for this pass. So you can say minus hello. So this is the name of the pass. Whenever you say minus hello, that pass would be invoked, right? So essentially LLVM allows you to like construct an array of passes, right? You can say apply pass one, then pass two, then pass three, in that sequence you can put your passes. So if you do this, then see what it does, it gives you hello and mean. So it basically shows the name of all functions that are there in this file. So there was unfortunately only one function, had there been more functions, it would have shown all of them, right? So this is something that you should do. Then you can analyze your program and you will be able to see the output here. Okay, that is one part. Second part is that let us see how to write this pass, right? So let's try to analyze the, I hope all of you have the hello world pass with you. Right, so this is the hello world pass. Namespace and all, I hope you guys know C++, so I will not get into this. So the important part is that you have to give, so you have to derive. So there are multiple different ways you can construct a pass in LLVM. So there is something called a module pass, wherein, which allows you to analyze all the functions of the program. There is a function pass which will allow you to call every function separately. So for the moment, let's just concentrate on the function pass. So the function pass has this special method called runOn function. So what the program does is that on the binary that you give it to analyze, the bitcode that it analyzes, it will call this function runOn function for each of the methods. So it's a virtual function and this function has to be overridden. So you have to override it. So it will, for whenever you have your pass, it will call your pass on every function in that file and that function will be passed here. This function ampersand f you see, right? So your pass must derive from function pass and override this method. That is all that there is to it. Make sense? Right? So now on, so now you get this f, you can query f for the name. You can say f dot getName. It will just give you the name of this function and it just comes out. It just says hello, gives the name of the function, comes out. That is all it does. Right? So essentially what will happen is it will get called for every function. For every function it will print the name and come out. So it will say hello function 1, hello function 2, hello function 3, hello function 4, hello function 5. Then there is this id. Don't worry about it. You keep it here. But essentially the other important thing is you have to register your pass. Right? So you have to register the pass saying that I have a new pass hello. Where is this class name coming from? This is the class name that you gave. So you created this class, this hello class. Right? So you say register pass. I have a new pass that has to be registered. I have some instance of it. And this is the command line option that you have to run this pass. So if you say minus hello, it will run your thing. So if you say example here, you have to give an option minus example. Whatever option you give here, it will run your pass with that on that particular switch. Make sense? Okay. This is the command line. This is the description of your pass, the textual description of your pass. So when you say OPT help, it will show your pass and give you give this description against your pass. Right? So let's see this and the other two things you can ignore for the moment. Let us say tomorrow we might need it. So now if I say minus minus help. See? Yahoo! I have a new hello pass. Right? So LLVM recognizes this pass. But interestingly, if you do not, of course, I mean, if you do not give it this load, LLVM will not load it and it will not show your pass. So this is a dynamic pass, like it's a dynamic shared pass compatible shared object. Only if you ask LLVM to load it, it will know about this pass. If you do not tell LLVM about it, it will not even know that such a pass exists. This is a very nice way of isolating your pass from the rest of the LLVM system. You don't really have to tell it these passes exist. There's no need to bloat your LLVM with all the passes that you're writing. So load whatever pass you're writing and use it when you need it. Right? So over lunch, the task is that you guys should get LLVM running. If it allows NFS mounting, then you can do it. Otherwise, no, then all of you will have to switch with the same user. Otherwise, you will have all of you have users on that. All of you have got users on that. Then you can we can use that also. That's not a problem. So over lunch, I'll try to sit with one of you if possible. And I'll try to see if we are able to install the packages on this. If you can, then we have a decentralized thing. You can easily work. If not, then I'll try to see if we can use that particular server. Any questions on this so far? Are we clear on this? So first is use LLVM to compile it into a binary. Second is compile your pass as a shared library. Third is load LLVM, load your library, your pass into LLVM using minus load option. Fourth is invoke your pass using the option that you provide. Fifth is how to write a pass, right? Derive from the function pass and override the run on function method and register your pass. What is a pass? What should you register? Excellent question. Maybe I should have said more. So how is a compiler designed? So the compiler has a front end which compiles the source code into some sort of an intermediate representation. What is an intermediate representation? An intermediate representation is just a data structure, a data structure which holds the program, right? And towards the end of the compiler, there is a back end pass which essentially takes this data structure, right? And compiles it down to a target language. X86, MIPS, whatever you have, whatever you need. So between these passes sits a lot of transformations, a lot of optimizations. We try to make the program better for users, like maybe for better speed, for less memory, whatever it is. Now these passes, so these are called optimization passes, right? Now these optimization passes are structured as, so it's like a train, right? So the IR enters through one end of the pass and exits through the other end of the pass. Again enters the next coach and exits out of the next coach. So it just flows through the passes like this. So passes are like a train, they are like joined with each other. And this joining of coaches or passes you can do in any manner you wish, right? So in LLVM if you give it the option in that sequence, it will put up those passes in that sequence, right? Every pass accepts an IR, the IR data structure and emits an IR data structure. It's an in-memory data structure, right? So it takes in a data structure and exits the same data structure back. But in the meanwhile, it is allowed to change the data structure, right? It can, like now it's a data structure. So what does an IR data structure look like for this particular IR? It can simply be a linked list of, so every node in the linked list being a statement and it's a linked list of statements. As simple as that, right? That list is passed as an input to every pass and that linked list goes out from every pass and enters the next pass. In between this pass, if it is, for instance, does dead code elimination, what will it do? It will simply remove one node in the linked list, right? It has transformed the program. So the program has not been written yet, but it has only been in memory. We are changing the program, right? So each of these coaches in my train is basically a pass, is referred to as a pass. Now I can exploit the same architecture even to do analysis. I don't care. I'll not change the representation. But I can still look at the representation, right? I can still look at the representation and I can dump the output onto the screen or add it to a file. I'll not change that representation. So instead of doing an optimization which will change the representation of the program or change the program, it will simply look at the program, analyze the program, and write the result to a file or to the target output. So these are called passes. So now LLVM has to know, see, because it has such a strict notion of LLVM must know from it. So think about it. What is LLVM doing internally? So internally LLVM, whenever you say a register pass, LLVM is maintaining some sort of a hash table which says that, OK, I have a new pass and a function pointer to the run on function method for it, right? So whenever on the command line you give that pass, it fetches that function pointer and calls that run on method, run on function method for that. So there is a loop inside LLVM which will simply call the run on function method for every pass that you have mentioned on the command line. Just a loop. We're just calling it one after the other. That is all it is doing with every function that it has. So to be able to call that method, it is important that LLVM knows that what is the method to be called. That is why we have overwritten a derived classes method. So everybody must derive from that function pass so that I can run that loop. And I must be overriding this particular method, run on function, because it will be running the loop on that particular function. Does it make sense? That is, yeah, you had a question? Sir, every compiler has its own set of passes. Yes. Every compiler has its own set of passes and every compiler has its own intermediate representation. Right? And that is why I said there is no the intermediate representation. There is only a intermediate representation. If you write your own compiler, you can come up with whatever intermediate representation you think you want to come up with. So in intermediate representation, there can be many, many types of intermediate representations. There is something known as a HIR or high level intermediate representation. These are representations which are look very close to the source code. They look almost similar to the source code. They might even have. So what all they might do is they might remove for loop, then do while loop, repeat until they might remove those and it may replace it by one loop statement. Right? But it is still a loop. It is still not a if then else. Right? So it can still preserve the structure of the code. But array indices, the array offsets, everything might be maintained. Arrays might be even if they're multi-dimensional arrays, it might still maintain that. Then there is something called MIR or medium level intermediate representation, which is generally a three-address code. Right? Again, there can be variants of that MIR. Somewhere you might want to keep arrays. Somewhere you might say that I do not have multi-dimensional arrays. I only have single dimensional arrays. Somewhere you might say I don't even want an array. I just look to a point of the difference. Right? And eventually you can have a low level IR, LIR, which is very similar to what LLBM has, which looks very close to the machine code. So if you look at it, this is actually looks like machine code. Right? So you when you write your compiler, you write your own passes, you write your own data structure or IR on which you are going to work on. Again, a very good question. So seeing which order a set of passes have to be done is a very difficult problem. So this is what a phase ordering problem. So I'll not get into it. But essentially one option is that you tell the compiler that this is the order you want to pass this to be on. So you can on this command line, you can specify it. Otherwise, what compilers do it is that they already have a predefined sequence which seems to work well for most cases. Right? So compiler experts will come together, scratch their heads, tear their head apart, fight with each other and decide that, OK, on my compiler, this sequence of this sequence of running the passes works very well. And these are the passes that you see in a traditional compiler like like even LLBM or even for that matter, GCC. If you give the option minus O2 or minus O3, what it does is basically pull some sequence of some some order of these passes. It says that, well, I'll run these passes and I'll run them in this order. So you just say O2, it will do something good for you. That is all you know. That will not be best for you. If you really know what your program is doing, you may be able to do it better. But that is known to be doing well for most programs. In fact, figuring out what is the best ordering on passes is a very important question and an open question. Excellent question. Anything else? So do we understand the high level idea of what's going on and even the low level idea how to get it done? Works for you? OK, so now let's do one more small thing before we break. When do we break for lunch? One thirty. One thirty. One. Still not hungry. OK, so right. So let us now look at trying to do some control for analysis. How will we do control for analysis? So I don't really have too much of code, but I'll just show you something. So essentially now I can write this as a control flow again as a function pass. So because I will be doing control for analysis on a function to function basis, we are going to do intra procedural analysis. So so there are some IR. So you will see some new sorry, some include files and you'll see some new include files. So there is include file on basic blocks. You know what a basic block is. There is include file for a CFG. You know what a CFG is. So LLVM already constructs these data structures for you. You can directly use it as it is. Then so when you say run on function, essentially you can say FCAG get entry block, which will give you the entry basic block of your control flow graph of your CFG. Right. Then it has these methods successor begin and successor end. So if you say successor begin on a basic block, it will give an iterator over the successor successors of the basic block. Similarly, you can do it on predecessors also if you want to. Right. Plus it has support for like sets and stacks and all these things, whatever data structures you would like to get it running. So now what we would like to do is we will try to build one simple control flow analysis. Let us try to do the figuring out the basic blocks in a in a loop, then finding out a natural loop of a program. It's a simple algorithm that is not much there. Right. It's like maybe eight to nine lines of code. Right. But you will still end up writing some code in LLVM. And all you need is almost here. Right. Successor begins successor end. Instead, you do predecessor begin. So put it in a stack and then pop it off the stack and keep on iterating. After we have done this, we will spend some time on this. And after that, we will start with data flow analysis.