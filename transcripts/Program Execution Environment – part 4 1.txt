 And annotate wherever each variable begins. This is something which you can try in your free time. But I think we can begin. So the next topic, so the last session for today, this is also going to be bit heavy in terms of the information. But if you're feeling too sleepy or something, let me know, we'll see. But essentially the idea now is to, so what we have seen is primarily what all goes into the object file. Let's look at assemblers a bit just to figure out how assemblers are producing this information. So what do assemblers do? So essentially assemblers translate the textual assembly program into the binary object file. And it's more of a simple translation, not really a compilation. Essentially one of the primary tasks is to figure out how to convert the text instructions into the machine code. And we saw some examples prior where opc... 55 meant push EBP and so on. So every architecture publishes its instruction encoding information that this instruction needs to be encoded this way and so on. So assemblers will use this information to essentially translate the text program into the machine code. And it needs to do some resolution of the internal references and it needs to record some metadata for linker, which is what we will see now. So essentially let's look at this sample code. So let's say I have some instruction written and then I do jump to done. And done is defined here. Now in the machine code, there is nothing like done, right? There is no symbol done. It has to be a binary number. So done needs to really be an address, right? So how does assembler know what is address of the done, right? So essentially what assemblers do is typically they do a two pass algorithm. So what they will first do is they will first read the program, assign address to everything. So they know that move instruction takes five bytes, for example, move the instruction takes two bytes, JMP instruction takes four bytes. So done will come at four plus five plus five, 20 offset, something like that, right? So they will keep assigning address to each of the label, which is defined in the program, okay, according to size. So for example, whenever I declare a data of some size, I know that the next address will be after that, right? And this is what is the value field which we were seeing in the symbol table, right? Whenever we were seeing in it where was at offset four, this is how it kind of calculated it, okay? And in the second pass, what you do is you replace all the references with the actual address. So for example, in the first pass, you assign some address to done. And in the second pass, you go and change this instruction from gem done to JMP of address of done, which was assigned, okay? Now the question is, can you do this in single pass? Instead of doing two passes, can you do it in single pass? And it is possible. So there is an algorithm called as backpatching, which will actually do it in single pass. But that's a reading exercise. I don't want to get into that algorithm. It's unnecessary, okay? And one of the things you have to realize is most of the branch instructions in the processors by default have PC relative address, okay? By PC relative, I mean address of done is not really from start of the program. Address of done is relative to the current instruction, okay? So PC relative address means the address which is relative to the current instruction. So if you look at it, done itself has really three addresses, okay? Done can have an address which is PC relative, which is from the current instruction where we need its address. It could be section relative. That means within the text section, done occurs here. Or it could be file relative, where it says from start of the file, where is the done, okay? So all three are valid addresses. It just that depending on context where you need to use it, you need to use the appropriate address, okay? Yes, that is to some extent correct. Where will we use that is what was the actual question. But that we will see later. What we were trying to find is what is the address of the current instruction and what is the address of done and then if you subtract it, you get the PC relative offset, okay? Is this clear? So what link assembler is simply going to do since JMP instruction takes PC relative address, it is going to change this instruction to JMP with offset of whatever is done which is PC relative, okay? Now and what about data variables, right? So data variables are also handled in similar way, okay? So what assembler will do is it will do a first pass, say that var is at offset 0, section relative offset 0. Then X, this takes a byte, right? And then I see leave a line of 4, we will get to this. But essentially what this is saying is var is taking 1 byte whose value is 15, okay? Then I want to ensure X is aligned to 4 bytes, okay? And then X holds 1, 2 and 3, okay? So the section relative offset of var is 0 because it begins at the data section and section relative offset of X is 4 because I assigned address 0 to this and then I had to choose the next multiple of 4 to assign X, okay? So essentially these are the values which you are seeing in the ELF symbol table. So whenever you are seeing value field in the ELF symbol table, this is how assembler had allocated it, okay? Remember we were seeing in it var then arr was there, then something was there and so on, right? So this is how assembler would have allocated offsets to it, okay? Now any idea why is alignment needed? Why did I need this align for? Does everyone understand that? So essentially what happens is whenever you are accessing some data of some size s, if your address is multiple of s, then you can fetch it easily, okay? Now easily is actually dependent on processors, okay? So S86 allows you to do misaligned access. That means I could access 4 bytes at an address which is not multiple of 4 and the only problem with that is performance, okay? There is no other problem. But on some other processors like ARM or even NVIDIA GPUs for that matter, you are not even allowed to do unaligned access. So hardware will give an error if you try to access data which is not aligned to proper address. Is that clear? So whether unaligned accesses are supported or not is a property of processor. S86 supports it at cost of performance. Other processors may not even support it, okay? So let's say you had these 4 variables, char C, float F, double D, int X. What's the best order in which you should allocate them to reduce the padding? What do you mean by ascending or descending? Okay. So the answer should be as he said, you should probably try to allocate the variable with the highest alignment requirement first. So double is 8 bytes. So it is better to say D lives at offset 0. See because offset 0 is the best thing because it can be aligned to anything, right? So offset 0 is the best thing. Whatever is your highest thing, you allocate at offset 0. Then you can allocate either F or X because both of them have the same, this thing and then C. If you allocated it in other order, what will happen is if you allocate C, then C is at offset 0. Then no matter what you try to allocate, you have to create padding. Now if you create double as the next thing, then you have to create padding of 7 elements. Whereas if you do float F and float X, then you can do some, okay? So it's actually better to do it in descending order where you first always allocate a variable with the highest alignment requirement and then so on. And this is something you should remember even when you are declaring your structures, okay? So this is not just for independent variables. Even when you are defining a structure of something, it's better to write members in the order of decreasing alignment. That will reduce the total size of your structure, okay? Now, coming to the data addresses, right? So we assigned address 0 to this and address 4 to this, okay? Are these addresses final? Are these addresses final? So is var at offset 0 always going to be true? Okay, so at runtime, they will get picked at some address, but is it just adding offset of that address or is it something more? So for example, loader chooses to put .data section at address 1000, then is var at 1000 and X at 1004? So is it simply act of adding some base to it or something more? Any other things? So actually, one thing you have to just let's try to first go again in step by step order. So when I am accessing this instruction, what should I do for var? Should I say move value 10 into address 0? Can I encode a PC relative offset of var? offset of var will be? This is how far is var relative to current instruction? I mean, one way to refer to var in the text section will be to encode its PC relative offset. The problem with that is data could be fairly far from where the text is. So that offset cannot be encoded. Then we encode section relative offset. So if I encode 0 here, the problem still remains because the data might actually get allocated at some different address than 0. So what happens is we don't know really the final address when we are accessing this. So what assembler will actually do is it will assume value 0 and 4 for var and X, but it will keep some additional metadata that this needs to change. It is not really 0 and 4. It needs to change. So when assembler is assembling this code, it will actually put 0 here and it will actually put 4 here, but it will have some additional information to change that later. And we'll see how linker changes that. Same thing happens when you have external variables. So when I do say move 10 into var and let's say var was an external variable, then again assembler has no idea what is the address of var. So how does it produce this instruction in binary? So it will simply assume that var is at some location 0. I don't know what is that location, but it is at some location 0 and records some metadata which says change this. And that information is called as relocation. So relocations is essentially a piece of information generated by assembler which says how to change whatever assembler has produced. So assembler didn't have visibility of addresses of some of the things, but it still had to generate binary code. So it generated binary code, but kept some additional metadata which says these need to change. Does conceptually that sound okay? What is exactly in relocation and how it works we'll see later. But conceptually, just remember that assembler's generated code is not final. It will be modified in some way by the linker, especially with respect to addresses. So whenever data addresses or variables addresses are needed, that portion will change. So essentially if you look at it, what assembler will be generating is whatever are the labels within the text section, so whenever we had jump to done or jump to label, those things are actually resolved to the fixed thing because they are not going to change within the text section. Assembler was defined in the same file that was resolved to be the offset, but there was some additional metadata recorded here. And we'll see what that metadata is. Is it clear? So just to summarize on the assembler side, assembler generates machine code and the machine code is not final. The addresses used in the machine code need to be changed and assembler has produced some information for linker on how to change it. So what do linkers do? Yes. I'll come to that. So linker's job is essentially to merge the object files and linker will take multiple relocatable object files as the input and produce a single executable file. And one of the main task of linker is to be able to do symbol resolution, which is what we were trying to see in the quiz that whether this were and this were are same. So it somehow needs to associate a symbol with its use. That is called as symbol resolution. And we just now saw that linker also has to do something called as relocation, which is essentially changing addresses or filling in the addresses which assembler couldn't fill. So the section. Yes. Yes. So linker has optimizations also, which we'll see. I mean, I don't have time to cover how link time optimizations work, but I will mention what kind of things linker do as optimizations. So coming to your question. So essentially what if you think of elf linker, this is what it gets. It gets multiple object files as the input. What it is going to do is it is going to create, take all the text sections from all the elf files, put them together. And this is what forms a segment. So you can think of chunks of text sections which were pulled in from multiple files and put together forms a segment. Similarly, it will take data section from each of the object file and create a data segment out of it and so on. So segment, you can think of it as collects. It's a big text section conceptually. And what all goes into the segment, we'll see tomorrow when we actually look at the execution properties. But for now, you can assume a segment is collection of same sections, which came from different object files. Now as far as you can see here, what is linker going to do is linker is going to produce an object file, which actually pulled in data from multiple things. So what linker ended up doing is it took text section which was present at offset 500 in file 0, offset 300 in file 2 and put it at offset maybe 100 in the output file. So it is going to merge all these together. Now what all symbols linker care about? So linker cares about symbols which were global. Global are the symbols which are defined in the current object file and can be referenced in the other object file. External symbols which are essentially referenced in the object file but not defined in the object file. And local which is essentially defined in the object file but cannot be referred by the other object file. So we saw global and local. We were seeing that when we saw the MyWare example. When I declare something as static, it appeared as local and when I declared it as non-static, it appeared as global. And external is the one which had UND section index. So anything with the UND shn index is external. Anything which has global bind is global and anything which has local bind is local. So these are the only symbols which linker cares about. Now symbol resolution is act of associating each symbol with its references. So linker's job is to figure out these references correspond to this definition. Now if you look at this, var is a global variable, foo is an external variable, here var is an external variable and var2 is a local variable because it was static. And linker doesn't see v because it was allocated on stack. And symbol resolution is simply saying var2 is associated with this var2. But linker has no idea what is this foo referring to, what is this printf referring to and what is this var referring to. Now if you look at the object file, this is how it will look. The text section will have a reference to foo which it doesn't know about. Text section will have a reference to printf which it doesn't know about. Similarly here text section will have reference to var which it doesn't know about. And text section will have a reference to var2 which is say at this location 54. Now what linker is conceptually doing is merging two things together. So the resultant thing will look something like this. So it took text section from the first program, it took the text section from the second program and put them one after the other. So this became 0, 100, 150. Similarly it took the data section from the first program, data section from the second program so this became 150 and 154. And the resolution is just something like this. So now linker notes foo is at address 100 because foo is defined in the text section which starts at 100. Then this text section refers to the variable here which is defined at 150 and this variable refers to the second variable which is var2. Is that clear? What linker is conceptually trying to do? So it has put together all the things one after the other and then assigned addresses on what refers to what. So here in foo we refer to var so that reference what changed to address 150 and foo refers to var2 so that reference what changed to address 154. Is that clear? Now what I said is symbol resolution associates each reference with a single definition. What if there are multiple definitions? So what if something like this is done? So I have int var and I have int var. I have defined it twice and I assign var here and I assign var and I read var here. What will happen? Remember this is not external so both of them are trying to define it. How many of you think it is an error? How many of you think it is not an error? Or you have lost faith on blue linker to give any meaningful error? So whoever thinks it is not an error can you explain why it is not an error? So it is actually not an error. But it is defined twice. So let us look at it this way. So let us say they belong to so when I compile object file of this I will see var belongs in data section and when I compile this file I will see var belongs in data section. Now does this var refer to this var or so where will this var come from? So are you saying this program is going to print 0? How many of you think this program will print 0 after linking? Does everyone think it is 0? So it should have been error ideally but that is not the case. So what is the next meaningful answer? 0. Because we are printing var which belongs in this file and in this file var is 0. Let us try that. You guys are up for a surprise. I have this. I have file 2.c. So I say int var and in foo I do var is equal to 10. And here I print var. Gcc file 1.c file 2.c dash. Printed 10. So both the meaningful things which you were thinking. So first of all it did not issue error that you should have suspected by now that it does not give any errors. But on top of it, it says that this var is actually same as this var. So linker somehow said that both are var but both are actually same. So linker ended up saying that there is only one var which exists. This is one of the quirks in language c. It is called tentative definitions. How many of you have heard of this term? So the program which I showed in the morning, this one. This also works because of this quirk called tentative definitions. So c says, anything which you define which is uninitialized, the definition is actually tentative. It is not final definition. It is not. I mean you can think of it logically that way but it is not actually that. And c then allows everyone to define tentative definitions and so on. And finally only one will be chosen. So these are treated as something called as common block symbols. So whenever I define this variable var, this is not actually true definition. c says it is a tentative definition. When it encounters this, it is a tentative definition. And if it did not find any other definition, one of the tentative definitions became the true definition. And that is why this code worked. Same thing happened when we had this, when the file 2 defined it. So when linker saw var here and var here, it says one of them is tentative and I will still look for a final definition and it does not find it so it picks one of them. Arbitrary. We will come to that. So these are actually called as common block symbols. Remember we saw something like com here when we had uninitialized variable. So this was actually referring to common block symbols. The history is in Fortran. So Fortran had this concept called as common block symbols. So in Fortran the semantics were slightly different. In Fortran the semantics were every object file can define a variable with the same name of different sizes. So every file is not only allowed to define a tentative definition, but the sizes can actually be different across different files and the largest one will be chosen. That was the semantics in Fortran and those were called as common block symbols. This is a very crude way of implementing unions in C. So if you did not have unions in C, one of the ways to implement union was through common blocks in Fortran. So this actually forces C language to still carry forward that semantics because C programs have to be compatible with Fortran programs because there were tons of Fortran code written already and part of that code was ported to C, but things still had to be linked together and that would work only if the language semantics were same. That's where the problem comes in. So these codes actually work because of Fortran and you can actually avoid this by passing a flag called F no common. So let's look at magic of that. So if I say here it detects that there are some multiple definitions happening. Does that make sense? Now what happens in C++? How many of you have heard of this term called as one definition rule or ODR? So C++ has a different semantics. C++ says that every variable at link time must have a single definition and no more and no less. So C++ actually errors out on this code. So if you compile this code as C++ code, it errors out saying there are multiple definitions. It errors out in this case as well as it errors out at link stage. So C++ that way is slightly better because it says that every variable must be defined only once. So this will actually error out. But there are some exceptions to one definition rule. So nothing comes without caveat and this we will see tomorrow in what case two things can have multiple definitions even in C++. But got what we discussed so far? Now one of the things in C to avoid this pitfall, you don't want accidentally to something to link and even multiple definitions become allowed. What C says is only uninitialized variables have tentative definition. So if I initialize this variable, now C also errors out. So if you look at where it is no longer COM, it belongs in data section. If this was uninitialized, this belonged in COM. So any uninitialized variable belongs in COM and that's why these tentative definitions come into picture. So every time you write a global variable, initialize it in C to avoid these problems. Now how does linker, so we saw what it is in C, but how does linker actually deal with it? So linker actually treats every symbol in two categories. Linker says every symbol is either a strong symbol or a weak symbol. So as far as linker goes, every function or initialized global is a strong symbol. Anything uninitialized global and few other things which we will see later are categorized as weak. Is it clear? So as far as C goes, uninitialized globals are weak, everything else is strong. So this symbol is strong because it is initialized, this symbol is strong because it is a function, this symbol is strong because it is a function, this symbol is weak because it is uninitialized. Now there are rules of how to resolve things. So what linker says is multiple strong symbols are not allowed. So if you had two strong symbols, it is not allowed and linker will error out. Rule two is if you have a strong symbol and a weak symbol, choose the strong symbol. And all the references are changed to point to the strong symbol. So finally there will be only one symbol which will be the strong symbol variant. Is it clear? Rule three is about if there are multiple weak symbols, then choose any weak symbol. So if you had strong, you give preference to strong, but if you don't have any strong symbol, then you pick anyone. Is it clear? Now quizzes, what will happen in this case? Error out. You have faith in linker that it will error out. It will error out because var is strong here and strong here, two strong not allowed error. In this case, no error and only one copy of var will remain finally. So there are no two var's earlier as you were thinking that there is one var here and one var here. There is no, there is only single copy of var. What happens in this case? Remember the rule which I told says pick any weak symbol. It didn't say anything about size or anything. No error, but what will actually happen? Which var will be picked up? You can't say, right? So does everyone agree that there is no error in this? Because both var here and here are weak, right? So linker is free to choose any one of them. Now we don't even know whether linker will choose var which has 12 byte size or 8 byte size. Linker may choose any one of them. And let's hypothetically assume if linker chose the one which has 12 byte size, what will be output of this code? So link, sorry. What if linker chose this var to resolve? So, what will happen? So if linker chooses var to be 8 bytes, what will happen? Correct. So if a happens to be following var in terms of the memory addresses, a will actually get overwritten. What will happen in this case? In the prior case, you might get lucky because if linker chooses this to be var, in this case your luck runs out because linker has to choose this one because this is a strong definition. Yes. Sorry. So, if you look at the rules which I told, when linker is resolving it is not looking at any things like size and other things. Just saying that, okay. And this is why it said that even variable could be a function and function could be a variable which we saw just before the break. So when it's resolving references, it's not looking at anything. It's just looking at name. Yes. So, this typically actually will fall into undefined behavior because this code is logically incorrect. There is no sane way to say what will happen in this code and that's why you shouldn't be writing these kind of codes. These are use at your own risk kind of codes. So, don't say that we learned coding guidelines which said define two variables with the same name in multiple files. Don't do such things. So, does everyone understand subtle difference between this case and this case? In this case, linker, you are forcing linker to choose this as the definition. That means you are guaranteed to override something which falls in this memory location which in most likely case will be A. So, are you still up and we can continue for some more time or you are tired? So, the last thing which linker needs to do is relocation. So, what will linker essentially do is merge these things. As a part of that, it is going to change addresses because data section might be leaving here at address 100, but in this case it might leave at address 10,000 and vice versa. So, what linker is doing is relocating various sections which were present in the object file to a different layout. Now, after relocating these things and together what you have is you have a executable file which has the final addresses. Remember, assembler did not have this information. So, assembler had to somehow say that change these references. The way assembler does this is by doing something called as a relocation entry. So, there are two kinds of common relocations. One is R386PC32 and one is R38632 which we will see. So, R386PC32 says change this value with the PC relative offset and R38632 says change this value with the address of whatever it is. We will see the details. I am just trying to give abstract way of what these do. Who defines these relocations? These are again part of the ABI. So, ABI will say that assembler should generate these relocations for this type of use. Now, let us look at this code. Let us say I have file 1 and I am calling function foo. Now, when I do gcc dash c dash m32 foo dot c, sorry, file 1 dot c and let me do objdump dash d file 1 dot o. What you see here is you see a call. This was supposed to be called to foo. Remember? What you see here is some garbage stuff. This is not even address of foo. So, what is actually happening is link assembler is generating some placeholder number. We will see why that 7 came there. But for now, assume whenever call happened, assembler did not know what to generate. So, it puts 0 there. It generated additional relocation entry called r386pc32 with foo. We can see that here. So, if I do redelp dash r file 1 dot o, we can actually see that. So, it is something r386pc32 foo and some other information. What will happen is when linker is taking these two things together, linker will look at the relocations and after it is done merging things together, linker knows how to change this 0 to actual address of foo using this relocation entry. Is it clear? In nutshell, what linker is doing? So, linker will concatenate all the text sections together. So, linker will know what is address of foo. And then it will look at wherever this entry is there and it will go and change this somehow to point to address of foo. So, linker will essentially end up doing this. Somehow change this code to call foo. Now how it actually does that is this. So, if you look at this obj dump with dash dr. So, it is saying this instruction actually has this relocation associated with it. Now, we will see details of that. So, each relocation entry which is generated has offset. The offset is 7 and the reason offset is 7 is because this is 1, 2, 3, 4, 5, 6, 7. 4, 5, 6 and these are this is where the 7 points to. So, E8 what you are seeing here is actually the up code for call instruction. So, call instruction in x86 architecture is encoded as E8 followed by a 32 bit number which is supposed to give the address. Is it clear? So, these next 4 bytes are supposed to give the address. So, what this relocation is saying is at offset 7 within the text section apply this relocation. Now, the relocation has symbol associated with it. Now, what is this symbol saying is change address of this whatever is the content of this with address of foo. And what is this fc ffff this is actually minus 4 if you look at the 2's complement. I mean this number is actually 2's complement of I mean hex representation of minus 4 in 2's complement format. So, what this instruction is saying is this is E8 this address needs to be changed to foo and there is something called as addend which is minus 4. Now, what linker will do is linker will change this content with address of symbol plus addend minus the offset. The offset is 7 addend is minus 4 and symbol is foo. So, this is actually going to change it to something like this. Why because address of foo was this 80483 eaf it added minus 4 to it and it subtracted this current address from it. Current address was 80483 e4 is this clear. So, what we are seeing is essentially this content was being changed with function which changed which added address of foo subtracted minus 4 from it added offset of the current instruction itself to form this. And if you look at why this is 7 is if you actually calculate the PC relative address of foo from here it is 7 bytes away. So, 1 2 3 4 5 6 7. So, this instruction is saying that jump to PC relative address which is 7 bytes away. Does that make sense? Let us look at this in action. So, I have file 1 dot c and I have file 2 dot c for simplicity I will not do anything in foo. Now, let us do. So, what this is saying is this is saying call has this relocation. Now, I have file 1. Now, let us link these things together file 1 dot o file 2 dot o dash m 32. Now, let me dump a dot out dash dr. So, if you look at main main is at address this foo is at address this. Now, if you look at this instruction this earlier had let me copy paste this part. So, originally this instruction was looking something like this. The way I changed this instruction is I looked at what is address of foo. So, this then I added added value to it addend value is this which was here. So, I did minus 4 and I added address of the current where the relocation needs to be applied which happens to be 4 because this is 3. So, this address starts at 4. So, this computation actually results in. Something is wrong. Something is wrong. Sorry, this should have been minus. So, it results in 2 which is what you see encoded here and why it is 2 is because foo is actually 2 bytes away from this. So, what it essentially did is this relocation helped you compute the relative address of foo from main. Let us look at a slightly simpler example. Let us say I had in here I was referring to some data in and here I defined. Now, let us look at this. So, what you see is var is undefined here. Now, if I look at objdump dash dr of file 1 dot o, I see that this instruction is trying to move value 10 into an address 0 and address 0 is there because I do not know what is the address of var. So, there is a relocation called var with r38632. Now, let us look at file 2. So, I have file 2. Now, what I will do is file 2 defines this variable at some offset 0. Now let us link these together file 2 dot o. Now, when I look at a dot out, you will actually see this instruction it changed to move a to something like this and if you look at this was the exact address. So, what this did? Let us look at it. I will copy paste some part. So, this was the original code. This is the final var and this is how it looks in the text section. So, what this did is when assembler generated this reference to var, it did not know what address to generate. So, it generated address 0 and it says that I need to change the 32 bits here with the address of var. Now, when linker laid out all the things together, linker chose var to be at this address and what relocation told linker is I need to change this instruction to contain its address and linker ended up putting this address. Is this clear? This is kind of bit tricky because this is and this is the most complicated part of the linker where it needs to do the relocation application. Any doubts or questions so far? So, fundamental reason why relocations exist is fairly simple. When assembler is generating code, assembler does not have information about addresses of the symbols. So, it generates some placeholder saying it could be 0 and generates additional metadata for linker to say change these 0s to some values and linker after it has laid out everything will actually change them. So, this is what we actually did essentially. Now, we still have 5-10 minutes. So, what you can do is you can look at this sample code and see what relocations were generated for this code. You just have to observe what kind of things were generated. So, I have a external int i and I declare a pointer and take its address. Now, you can see that there is no way assembler knows what is the address of i. So, it has to generate some relocation. So, you can look at redelf-r and see what happens. Actually, let us try it ourselves here that it might be easier. So, let us say I have this file. Here I declare int star ptr and I have external int i. I do address of i and in file 2, I define i. Now, gcc. If we look at redelf, so it says i is undefined and pointer is a 4 byte value into data section into data section. If we observe the contents of data section, they should ideally contain address of i. So, if you look at it, the content is actually 0 0 because it has no idea what content to put there because it was supposed to be address of i. Now, if we look at redelf, what it is saying is at offset 0 in the data section, apply this relocation and put address of i. Does it make sense? So, in the data section at offset 0, offset 0 holds content of ptr. Put the address of i. Let us look at slightly more convoluted example. So, let us say I had int i and int j and I had two pointers, let us say. So, I see two relocations. One is at address 0 which says patch the address of i and other is at offset 4 which says patch the address of j. If you look at symbol table, i is at offset 0 in the data section and j, sorry ptr is at offset 0 in the data section and ptr 2 is at offset 4. So, are you getting how the relocation information is generated? So, relocation information in nutshell is saying go to this section, add this offset, change these values by address of this. Now, let us look at what happens in file 2.c. So, I have file 2.c which defined this. So, if I look at dot data section, I could see this. So, it says that the content of ptr is 0000, but it has a relocation which is going to change it with address of i and then ptr 2 is again 0000 and its content is going to change with address of j. Now, let us link these two things. So, these are now linked. Now let us look at, so we can see the content of data section is something like this 1cA408 and something like this. And if we look at i, this is actually at address this 1c0A408. So, you could see that. So, essentially what linker ended up doing is after it allocated i, it changed that content to whatever was address of i. Is this clear on what happened so far? So, just to summarize, relocation is going to change content of a section with address of some variables. And it is going to do that after linker has allocated addresses to everything. So when linker merged the input files, it assigned addresses to everything and after that it went over each relocation and changed the content to hold that address, whichever it was assigned. And by this mechanism, the executable file which you have does not have any unresolved references because all the move instructions were changed to point to actual address. Content of PTR was changed to point to the actual address of i. That is why executable files are self-sufficient. They do not have any other dependencies and they can actually be run directly. So, I think we will stop here for today. I am still here for some more time, so if you have questions, I can answer that. And tomorrow we will start with how static libraries are implemented in the linker and various other things with respect to how program will actually start executing in the system. Just to summarize today's discussion, so we kind of started off with what happens during the overall compilation flow, preprocessor, compiler, linker, assembler and so on. Then we looked into details of what all happens during a function call, how the return addresses are saved, how parameters are passed, how stack is used to allocate local variables. Then we looked into the linker and linker kind of tried to have details of how the object files are merged together, how the references are resolved and what are the rules about strong and weak symbols. And we also looked at content of the object file itself that it has sections which are organized and section itself are described using section header. Section headers are derived from the elf header which has a pointer to it. And each of the section may have relocations which dictate how to change content of the section to hold final date.