[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 13.040000000000001, 'text': ' My name is Krishna and this is the second year I am coming here for the ACM summer school.', 'tokens': [50364, 1222, 1315, 307, 27153, 293, 341, 307, 264, 1150, 1064, 286, 669, 1348, 510, 337, 264, 8157, 44, 4266, 1395, 13, 51016], 'temperature': 0.0, 'avg_logprob': -0.23158991614053415, 'compression_ratio': 1.6267281105990783, 'no_speech_prob': 0.06350335478782654}, {'id': 1, 'seek': 0, 'start': 13.040000000000001, 'end': 18.84, 'text': ' Last year we had a great time. I hope I will have something similar here. So, we will be', 'tokens': [51016, 5264, 1064, 321, 632, 257, 869, 565, 13, 286, 1454, 286, 486, 362, 746, 2531, 510, 13, 407, 11, 321, 486, 312, 51306], 'temperature': 0.0, 'avg_logprob': -0.23158991614053415, 'compression_ratio': 1.6267281105990783, 'no_speech_prob': 0.06350335478782654}, {'id': 2, 'seek': 0, 'start': 18.84, 'end': 22.56, 'text': ' talking about introduction to, we will be talking about optimizations and high level', 'tokens': [51306, 1417, 466, 9339, 281, 11, 321, 486, 312, 1417, 466, 5028, 14455, 293, 1090, 1496, 51492], 'temperature': 0.0, 'avg_logprob': -0.23158991614053415, 'compression_ratio': 1.6267281105990783, 'no_speech_prob': 0.06350335478782654}, {'id': 3, 'seek': 0, 'start': 22.56, 'end': 29.0, 'text': ' optimizations and I was seeing what Malay was covering. They are pretty kind of advanced', 'tokens': [51492, 5028, 14455, 293, 286, 390, 2577, 437, 5746, 320, 390, 10322, 13, 814, 366, 1238, 733, 295, 7339, 51814], 'temperature': 0.0, 'avg_logprob': -0.23158991614053415, 'compression_ratio': 1.6267281105990783, 'no_speech_prob': 0.06350335478782654}, {'id': 4, 'seek': 2900, 'start': 29.0, 'end': 33.4, 'text': ' stuff and I am happy to see lot of you are nodding and so that means you guys are all', 'tokens': [50364, 1507, 293, 286, 669, 2055, 281, 536, 688, 295, 291, 366, 15224, 3584, 293, 370, 300, 1355, 291, 1074, 366, 439, 50584], 'temperature': 0.0, 'avg_logprob': -0.22329511642456054, 'compression_ratio': 1.7175925925925926, 'no_speech_prob': 0.08424948155879974}, {'id': 5, 'seek': 2900, 'start': 33.4, 'end': 39.16, 'text': ' in great shape. I will start with a bit of high level overview that I am sure you have', 'tokens': [50584, 294, 869, 3909, 13, 286, 486, 722, 365, 257, 857, 295, 1090, 1496, 12492, 300, 286, 669, 988, 291, 362, 50872], 'temperature': 0.0, 'avg_logprob': -0.22329511642456054, 'compression_ratio': 1.7175925925925926, 'no_speech_prob': 0.08424948155879974}, {'id': 6, 'seek': 2900, 'start': 39.16, 'end': 41.519999999999996, 'text': ' already done it.', 'tokens': [50872, 1217, 1096, 309, 13, 50990], 'temperature': 0.0, 'avg_logprob': -0.22329511642456054, 'compression_ratio': 1.7175925925925926, 'no_speech_prob': 0.08424948155879974}, {'id': 7, 'seek': 2900, 'start': 41.519999999999996, 'end': 50.480000000000004, 'text': ' So you can think of the whole compiler business as there are some, what is a compiler? What', 'tokens': [50990, 407, 291, 393, 519, 295, 264, 1379, 31958, 1606, 382, 456, 366, 512, 11, 437, 307, 257, 31958, 30, 708, 51438], 'temperature': 0.0, 'avg_logprob': -0.22329511642456054, 'compression_ratio': 1.7175925925925926, 'no_speech_prob': 0.08424948155879974}, {'id': 8, 'seek': 2900, 'start': 50.480000000000004, 'end': 54.879999999999995, 'text': ' is a compiler? What you are saying is a word. What I have asked is a noun. You are saying', 'tokens': [51438, 307, 257, 31958, 30, 708, 291, 366, 1566, 307, 257, 1349, 13, 708, 286, 362, 2351, 307, 257, 23307, 13, 509, 366, 1566, 51658], 'temperature': 0.0, 'avg_logprob': -0.22329511642456054, 'compression_ratio': 1.7175925925925926, 'no_speech_prob': 0.08424948155879974}, {'id': 9, 'seek': 5488, 'start': 55.080000000000005, 'end': 65.2, 'text': ' what does a compiler do? What is a compiler? So you can rephrase it. Translate. You give', 'tokens': [50374, 437, 775, 257, 31958, 360, 30, 708, 307, 257, 31958, 30, 407, 291, 393, 319, 44598, 651, 309, 13, 6531, 17593, 13, 509, 976, 50880], 'temperature': 0.0, 'avg_logprob': -0.27519071918644317, 'compression_ratio': 1.6987179487179487, 'no_speech_prob': 0.09837207198143005}, {'id': 10, 'seek': 5488, 'start': 65.2, 'end': 71.28, 'text': ' me another word. So what does it translate? It is a tool, right? It is a translator. It', 'tokens': [50880, 385, 1071, 1349, 13, 407, 437, 775, 309, 13799, 30, 467, 307, 257, 2290, 11, 558, 30, 467, 307, 257, 35223, 13, 467, 51184], 'temperature': 0.0, 'avg_logprob': -0.27519071918644317, 'compression_ratio': 1.6987179487179487, 'no_speech_prob': 0.09837207198143005}, {'id': 11, 'seek': 5488, 'start': 71.28, 'end': 82.80000000000001, 'text': ' translates what? To? Machine level language. It has to be always machine level language.', 'tokens': [51184, 28468, 437, 30, 1407, 30, 22155, 1496, 2856, 13, 467, 575, 281, 312, 1009, 3479, 1496, 2856, 13, 51760], 'temperature': 0.0, 'avg_logprob': -0.27519071918644317, 'compression_ratio': 1.6987179487179487, 'no_speech_prob': 0.09837207198143005}, {'id': 12, 'seek': 8280, 'start': 82.8, 'end': 94.0, 'text': ' It should always lower the level of abstraction. If I take a, just to make it maybe slightly', 'tokens': [50364, 467, 820, 1009, 3126, 264, 1496, 295, 37765, 13, 759, 286, 747, 257, 11, 445, 281, 652, 309, 1310, 4748, 50924], 'temperature': 0.0, 'avg_logprob': -0.27873640191065124, 'compression_ratio': 1.4136125654450262, 'no_speech_prob': 0.01906970702111721}, {'id': 13, 'seek': 8280, 'start': 94.0, 'end': 99.16, 'text': ' kind of those who are sleeping. Let us say I will take my input is an assembly code and', 'tokens': [50924, 733, 295, 729, 567, 366, 8296, 13, 961, 505, 584, 286, 486, 747, 452, 4846, 307, 364, 12103, 3089, 293, 51182], 'temperature': 0.0, 'avg_logprob': -0.27873640191065124, 'compression_ratio': 1.4136125654450262, 'no_speech_prob': 0.01906970702111721}, {'id': 14, 'seek': 8280, 'start': 99.16, 'end': 111.36, 'text': ' I want to generate Java code or C code. Would that be a compiler? Yes sir, yes, no. Okay,', 'tokens': [51182, 286, 528, 281, 8460, 10745, 3089, 420, 383, 3089, 13, 6068, 300, 312, 257, 31958, 30, 1079, 4735, 11, 2086, 11, 572, 13, 1033, 11, 51792], 'temperature': 0.0, 'avg_logprob': -0.27873640191065124, 'compression_ratio': 1.4136125654450262, 'no_speech_prob': 0.01906970702111721}, {'id': 15, 'seek': 11136, 'start': 111.84, 'end': 123.88, 'text': ' good. You have heard of this thing called interpreter? What is the interpreter? It interprets', 'tokens': [50388, 665, 13, 509, 362, 2198, 295, 341, 551, 1219, 34132, 30, 708, 307, 264, 34132, 30, 467, 17489, 1373, 50990], 'temperature': 0.0, 'avg_logprob': -0.259068198826002, 'compression_ratio': 1.5138121546961325, 'no_speech_prob': 0.01118127815425396}, {'id': 16, 'seek': 11136, 'start': 123.88, 'end': 134.32, 'text': ' the single line of code. It executes line by? Aha. So now I, so let us take our traditional', 'tokens': [50990, 264, 2167, 1622, 295, 3089, 13, 467, 4454, 1819, 1622, 538, 30, 27448, 13, 407, 586, 286, 11, 370, 718, 505, 747, 527, 5164, 51512], 'temperature': 0.0, 'avg_logprob': -0.259068198826002, 'compression_ratio': 1.5138121546961325, 'no_speech_prob': 0.01118127815425396}, {'id': 17, 'seek': 11136, 'start': 134.32, 'end': 139.6, 'text': ' understanding of a compiler, right? It takes source code and outputs, machine coded. How', 'tokens': [51512, 3701, 295, 257, 31958, 11, 558, 30, 467, 2516, 4009, 3089, 293, 23930, 11, 3479, 34874, 13, 1012, 51776], 'temperature': 0.0, 'avg_logprob': -0.259068198826002, 'compression_ratio': 1.5138121546961325, 'no_speech_prob': 0.01118127815425396}, {'id': 18, 'seek': 13960, 'start': 139.6, 'end': 151.07999999999998, 'text': ' is the machine code executed? Line by line. But you do not call that interpreter, right?', 'tokens': [50364, 307, 264, 3479, 3089, 17577, 30, 14670, 538, 1622, 13, 583, 291, 360, 406, 818, 300, 34132, 11, 558, 30, 50938], 'temperature': 0.0, 'avg_logprob': -0.29156487782796225, 'compression_ratio': 1.4112903225806452, 'no_speech_prob': 0.026706045493483543}, {'id': 19, 'seek': 13960, 'start': 151.07999999999998, 'end': 160.51999999999998, 'text': ' Do you? Why do you call one guy interpreter, one guy the compiled code is executed but', 'tokens': [50938, 1144, 291, 30, 1545, 360, 291, 818, 472, 2146, 34132, 11, 472, 2146, 264, 36548, 3089, 307, 17577, 457, 51410], 'temperature': 0.0, 'avg_logprob': -0.29156487782796225, 'compression_ratio': 1.4112903225806452, 'no_speech_prob': 0.026706045493483543}, {'id': 20, 'seek': 16052, 'start': 161.36, 'end': 170.36, 'text': ' like say list code or say python code you call it interpreted. Why? What is the difference?', 'tokens': [50406, 411, 584, 1329, 3089, 420, 584, 38797, 3089, 291, 818, 309, 26749, 13, 1545, 30, 708, 307, 264, 2649, 30, 50856], 'temperature': 0.0, 'avg_logprob': -0.3424290596170628, 'compression_ratio': 1.3333333333333333, 'no_speech_prob': 0.21188931167125702}, {'id': 21, 'seek': 16052, 'start': 170.36, 'end': 177.36, 'text': ' Yeah, let us do one thing. There are multiple people who are very anxious. Let us just raise', 'tokens': [50856, 865, 11, 718, 505, 360, 472, 551, 13, 821, 366, 3866, 561, 567, 366, 588, 15166, 13, 961, 505, 445, 5300, 51206], 'temperature': 0.0, 'avg_logprob': -0.3424290596170628, 'compression_ratio': 1.3333333333333333, 'no_speech_prob': 0.21188931167125702}, {'id': 22, 'seek': 17736, 'start': 177.36, 'end': 192.28, 'text': ' hands. Interpreter has to generate something called a byte code. An interpreter generates', 'tokens': [50364, 2377, 13, 5751, 3712, 391, 575, 281, 8460, 746, 1219, 257, 40846, 3089, 13, 1107, 34132, 23815, 51110], 'temperature': 0.0, 'avg_logprob': -0.3050089563642229, 'compression_ratio': 1.141025641025641, 'no_speech_prob': 0.14503096044063568}, {'id': 23, 'seek': 19228, 'start': 192.28, 'end': 209.8, 'text': ' byte code, is it? What is your name? Rishabh. So Rishabh, where did you hear this word byte', 'tokens': [50364, 40846, 3089, 11, 307, 309, 30, 708, 307, 428, 1315, 30, 497, 742, 455, 71, 13, 407, 497, 742, 455, 71, 11, 689, 630, 291, 1568, 341, 1349, 40846, 51240], 'temperature': 0.0, 'avg_logprob': -0.21117150156121506, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.05468061938881874}, {'id': 24, 'seek': 19228, 'start': 209.8, 'end': 220.16, 'text': ' code? In what context? Sorry? Correct. So in what context did you hear the word byte code?', 'tokens': [51240, 3089, 30, 682, 437, 4319, 30, 4919, 30, 12753, 13, 407, 294, 437, 4319, 630, 291, 1568, 264, 1349, 40846, 3089, 30, 51758], 'temperature': 0.0, 'avg_logprob': -0.21117150156121506, 'compression_ratio': 1.5555555555555556, 'no_speech_prob': 0.05468061938881874}, {'id': 25, 'seek': 22016, 'start': 220.16, 'end': 238.6, 'text': ' So it is some low. But the, by the way, the interpreter does not generate or does not', 'tokens': [50364, 407, 309, 307, 512, 2295, 13, 583, 264, 11, 538, 264, 636, 11, 264, 34132, 775, 406, 8460, 420, 775, 406, 51286], 'temperature': 0.0, 'avg_logprob': -0.290137939453125, 'compression_ratio': 1.403225806451613, 'no_speech_prob': 0.022191088646650314}, {'id': 26, 'seek': 22016, 'start': 238.6, 'end': 243.88, 'text': ' have to generate a byte code, okay? Byte code is some IR. So for instance, you hear this', 'tokens': [51286, 362, 281, 8460, 257, 40846, 3089, 11, 1392, 30, 3146, 975, 3089, 307, 512, 16486, 13, 407, 337, 5197, 11, 291, 1568, 341, 51550], 'temperature': 0.0, 'avg_logprob': -0.290137939453125, 'compression_ratio': 1.403225806451613, 'no_speech_prob': 0.022191088646650314}, {'id': 27, 'seek': 24388, 'start': 244.44, 'end': 250.51999999999998, 'text': ' code typically in the context of languages like Java, right? So when you do Java C, it', 'tokens': [50392, 3089, 5850, 294, 264, 4319, 295, 8650, 411, 10745, 11, 558, 30, 407, 562, 291, 360, 10745, 383, 11, 309, 50696], 'temperature': 0.0, 'avg_logprob': -0.2971379294324277, 'compression_ratio': 1.5621301775147929, 'no_speech_prob': 0.4367062747478485}, {'id': 28, 'seek': 24388, 'start': 250.51999999999998, 'end': 257.52, 'text': ' takes Java code and generates the byte code. And then the byte code is interpreted. Why', 'tokens': [50696, 2516, 10745, 3089, 293, 23815, 264, 40846, 3089, 13, 400, 550, 264, 40846, 3089, 307, 26749, 13, 1545, 51046], 'temperature': 0.0, 'avg_logprob': -0.2971379294324277, 'compression_ratio': 1.5621301775147929, 'no_speech_prob': 0.4367062747478485}, {'id': 29, 'seek': 24388, 'start': 257.52, 'end': 268.52, 'text': ' do not we call it executed? Why do you call it interpreted? What is the difference? Yeah.', 'tokens': [51046, 360, 406, 321, 818, 309, 17577, 30, 1545, 360, 291, 818, 309, 26749, 30, 708, 307, 264, 2649, 30, 865, 13, 51596], 'temperature': 0.0, 'avg_logprob': -0.2971379294324277, 'compression_ratio': 1.5621301775147929, 'no_speech_prob': 0.4367062747478485}, {'id': 30, 'seek': 26852, 'start': 268.52, 'end': 286.12, 'text': ' If we need an, let us call it instead of abstraction, let us call it if we need a', 'tokens': [50364, 759, 321, 643, 364, 11, 718, 505, 818, 309, 2602, 295, 37765, 11, 718, 505, 818, 309, 498, 321, 643, 257, 51244], 'temperature': 0.0, 'avg_logprob': -0.2016003429889679, 'compression_ratio': 1.664516129032258, 'no_speech_prob': 0.09798451513051987}, {'id': 31, 'seek': 26852, 'start': 286.12, 'end': 294.35999999999996, 'text': ' software tool in between to execute, then we call it interpreted, right? So that is', 'tokens': [51244, 4722, 2290, 294, 1296, 281, 14483, 11, 550, 321, 818, 309, 26749, 11, 558, 30, 407, 300, 307, 51656], 'temperature': 0.0, 'avg_logprob': -0.2016003429889679, 'compression_ratio': 1.664516129032258, 'no_speech_prob': 0.09798451513051987}, {'id': 32, 'seek': 26852, 'start': 294.35999999999996, 'end': 298.24, 'text': ' the whole idea. So there is not much difference between interpretation and execution. We say', 'tokens': [51656, 264, 1379, 1558, 13, 407, 456, 307, 406, 709, 2649, 1296, 14174, 293, 15058, 13, 492, 584, 51850], 'temperature': 0.0, 'avg_logprob': -0.2016003429889679, 'compression_ratio': 1.664516129032258, 'no_speech_prob': 0.09798451513051987}, {'id': 33, 'seek': 29824, 'start': 298.96000000000004, 'end': 305.96000000000004, 'text': ' execution and the hardware executes it. When a software instead executes the same code,', 'tokens': [50400, 15058, 293, 264, 8837, 4454, 1819, 309, 13, 1133, 257, 4722, 2602, 4454, 1819, 264, 912, 3089, 11, 50750], 'temperature': 0.0, 'avg_logprob': -0.165130539373918, 'compression_ratio': 1.7715736040609138, 'no_speech_prob': 0.005713789723813534}, {'id': 34, 'seek': 29824, 'start': 305.96000000000004, 'end': 313.64, 'text': ' okay, or evaluates the same code, we call it interpretation, right? Okay. So when we', 'tokens': [50750, 1392, 11, 420, 6133, 1024, 264, 912, 3089, 11, 321, 818, 309, 14174, 11, 558, 30, 1033, 13, 407, 562, 321, 51134], 'temperature': 0.0, 'avg_logprob': -0.165130539373918, 'compression_ratio': 1.7715736040609138, 'no_speech_prob': 0.005713789723813534}, {'id': 35, 'seek': 29824, 'start': 313.64, 'end': 319.96000000000004, 'text': ' take a, when we say a compiler, a compiler takes some source code and outputs some other', 'tokens': [51134, 747, 257, 11, 562, 321, 584, 257, 31958, 11, 257, 31958, 2516, 512, 4009, 3089, 293, 23930, 512, 661, 51450], 'temperature': 0.0, 'avg_logprob': -0.165130539373918, 'compression_ratio': 1.7715736040609138, 'no_speech_prob': 0.005713789723813534}, {'id': 36, 'seek': 29824, 'start': 319.96000000000004, 'end': 326.72, 'text': ' code. But typically most of the compilers we deal with, they deal with some source code', 'tokens': [51450, 3089, 13, 583, 5850, 881, 295, 264, 715, 388, 433, 321, 2028, 365, 11, 436, 2028, 365, 512, 4009, 3089, 51788], 'temperature': 0.0, 'avg_logprob': -0.165130539373918, 'compression_ratio': 1.7715736040609138, 'no_speech_prob': 0.005713789723813534}, {'id': 37, 'seek': 32672, 'start': 326.72, 'end': 333.72, 'text': ' of high level language and generate machine code. Yeah.', 'tokens': [50364, 295, 1090, 1496, 2856, 293, 8460, 3479, 3089, 13, 865, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.2822670114451441, 'compression_ratio': 1.4573170731707317, 'no_speech_prob': 0.03255787491798401}, {'id': 38, 'seek': 32672, 'start': 333.72, 'end': 344.72, 'text': ' Aha. Good. So the question is when there is already a compiler, why think about interpretation?', 'tokens': [50714, 27448, 13, 2205, 13, 407, 264, 1168, 307, 562, 456, 307, 1217, 257, 31958, 11, 983, 519, 466, 14174, 30, 51264], 'temperature': 0.0, 'avg_logprob': -0.2822670114451441, 'compression_ratio': 1.4573170731707317, 'no_speech_prob': 0.03255787491798401}, {'id': 39, 'seek': 32672, 'start': 344.72, 'end': 356.6, 'text': ' There are things an interpreter can do that a compiler cannot. Can you guess what? See,', 'tokens': [51264, 821, 366, 721, 364, 34132, 393, 360, 300, 257, 31958, 2644, 13, 1664, 291, 2041, 437, 30, 3008, 11, 51858], 'temperature': 0.0, 'avg_logprob': -0.2822670114451441, 'compression_ratio': 1.4573170731707317, 'no_speech_prob': 0.03255787491798401}, {'id': 40, 'seek': 35660, 'start': 356.6, 'end': 360.16, 'text': ' I like these questions, you know, because for every question I will answer by another', 'tokens': [50364, 286, 411, 613, 1651, 11, 291, 458, 11, 570, 337, 633, 1168, 286, 486, 1867, 538, 1071, 50542], 'temperature': 0.0, 'avg_logprob': -0.26947511411180686, 'compression_ratio': 1.7877358490566038, 'no_speech_prob': 0.011652300134301186}, {'id': 41, 'seek': 35660, 'start': 360.16, 'end': 367.64000000000004, 'text': ' question. But yeah, it is a very good question, right? What is your name?', 'tokens': [50542, 1168, 13, 583, 1338, 11, 309, 307, 257, 588, 665, 1168, 11, 558, 30, 708, 307, 428, 1315, 30, 50916], 'temperature': 0.0, 'avg_logprob': -0.26947511411180686, 'compression_ratio': 1.7877358490566038, 'no_speech_prob': 0.011652300134301186}, {'id': 42, 'seek': 35660, 'start': 367.64000000000004, 'end': 370.64000000000004, 'text': ' Fahad. Fahad. Yeah. So the question is if there is', 'tokens': [50916, 479, 545, 345, 13, 479, 545, 345, 13, 865, 13, 407, 264, 1168, 307, 498, 456, 307, 51066], 'temperature': 0.0, 'avg_logprob': -0.26947511411180686, 'compression_ratio': 1.7877358490566038, 'no_speech_prob': 0.011652300134301186}, {'id': 43, 'seek': 35660, 'start': 370.64000000000004, 'end': 374.04, 'text': ' a compiler, why think about interpreters? Or if there is an interpreter, why think of', 'tokens': [51066, 257, 31958, 11, 983, 519, 466, 17489, 1559, 30, 1610, 498, 456, 307, 364, 34132, 11, 983, 519, 295, 51236], 'temperature': 0.0, 'avg_logprob': -0.26947511411180686, 'compression_ratio': 1.7877358490566038, 'no_speech_prob': 0.011652300134301186}, {'id': 44, 'seek': 35660, 'start': 374.04, 'end': 379.24, 'text': ' compilers? And I said because an interpreter can do things that a compiler cannot.', 'tokens': [51236, 715, 388, 433, 30, 400, 286, 848, 570, 364, 34132, 393, 360, 721, 300, 257, 31958, 2644, 13, 51496], 'temperature': 0.0, 'avg_logprob': -0.26947511411180686, 'compression_ratio': 1.7877358490566038, 'no_speech_prob': 0.011652300134301186}, {'id': 45, 'seek': 37924, 'start': 380.24, 'end': 386.24, 'text': ' Debugging simpler. Yeah.', 'tokens': [50414, 27347, 697, 3249, 18587, 13, 865, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.7161852248171543, 'compression_ratio': 1.282442748091603, 'no_speech_prob': 0.888867199420929}, {'id': 46, 'seek': 37924, 'start': 386.24, 'end': 394.24, 'text': ' Aha. How? Because executing line by line, I mean, the', 'tokens': [50714, 27448, 13, 1012, 30, 1436, 32368, 1622, 538, 1622, 11, 286, 914, 11, 264, 51114], 'temperature': 0.0, 'avg_logprob': -0.7161852248171543, 'compression_ratio': 1.282442748091603, 'no_speech_prob': 0.888867199420929}, {'id': 47, 'seek': 37924, 'start': 394.24, 'end': 403.24, 'text': ' interpreter stops. So you know that that line or the line before it has finished. Whereas', 'tokens': [51114, 34132, 10094, 13, 407, 291, 458, 300, 300, 1622, 420, 264, 1622, 949, 309, 575, 4335, 13, 13813, 51564], 'temperature': 0.0, 'avg_logprob': -0.7161852248171543, 'compression_ratio': 1.282442748091603, 'no_speech_prob': 0.888867199420929}, {'id': 48, 'seek': 40324, 'start': 403.24, 'end': 407.84000000000003, 'text': ' the interpreter is ready to go to place back what exactly went wrong.', 'tokens': [50364, 264, 34132, 307, 1919, 281, 352, 281, 1081, 646, 437, 2293, 1437, 2085, 13, 50594], 'temperature': 0.0, 'avg_logprob': -0.3957012545677923, 'compression_ratio': 1.625531914893617, 'no_speech_prob': 0.003980039618909359}, {'id': 49, 'seek': 40324, 'start': 407.84000000000003, 'end': 412.28000000000003, 'text': ' Not entirely right. So if you are running, we are using a debugger.', 'tokens': [50594, 1726, 7696, 558, 13, 407, 498, 291, 366, 2614, 11, 321, 366, 1228, 257, 24083, 1321, 13, 50816], 'temperature': 0.0, 'avg_logprob': -0.3957012545677923, 'compression_ratio': 1.625531914893617, 'no_speech_prob': 0.003980039618909359}, {'id': 50, 'seek': 40324, 'start': 412.28000000000003, 'end': 418.16, 'text': ' Inside BDD is a... You need some way to stop the execution or', 'tokens': [50816, 15123, 363, 20818, 307, 257, 485, 509, 643, 512, 636, 281, 1590, 264, 15058, 420, 51110], 'temperature': 0.0, 'avg_logprob': -0.3957012545677923, 'compression_ratio': 1.625531914893617, 'no_speech_prob': 0.003980039618909359}, {'id': 51, 'seek': 40324, 'start': 418.16, 'end': 424.44, 'text': ' pause the execution, right? So there is something more fundamental about an interpreter. So', 'tokens': [51110, 10465, 264, 15058, 11, 558, 30, 407, 456, 307, 746, 544, 8088, 466, 364, 34132, 13, 407, 51424], 'temperature': 0.0, 'avg_logprob': -0.3957012545677923, 'compression_ratio': 1.625531914893617, 'no_speech_prob': 0.003980039618909359}, {'id': 52, 'seek': 40324, 'start': 424.44, 'end': 430.76, 'text': ' a compiler does not have something that an interpreter has. Both of them need the program,', 'tokens': [51424, 257, 31958, 775, 406, 362, 746, 300, 364, 34132, 575, 13, 6767, 295, 552, 643, 264, 1461, 11, 51740], 'temperature': 0.0, 'avg_logprob': -0.3957012545677923, 'compression_ratio': 1.625531914893617, 'no_speech_prob': 0.003980039618909359}, {'id': 53, 'seek': 43076, 'start': 430.76, 'end': 436.03999999999996, 'text': ' right? But besides that, the compiler has, does not have something that the interpreter', 'tokens': [50364, 558, 30, 583, 11868, 300, 11, 264, 31958, 575, 11, 775, 406, 362, 746, 300, 264, 34132, 50628], 'temperature': 0.0, 'avg_logprob': -0.23589876253310949, 'compression_ratio': 1.6900584795321638, 'no_speech_prob': 0.012325390242040157}, {'id': 54, 'seek': 43076, 'start': 436.03999999999996, 'end': 440.36, 'text': ' has. User input.', 'tokens': [50628, 575, 13, 32127, 4846, 13, 50844], 'temperature': 0.0, 'avg_logprob': -0.23589876253310949, 'compression_ratio': 1.6900584795321638, 'no_speech_prob': 0.012325390242040157}, {'id': 55, 'seek': 43076, 'start': 440.36, 'end': 449.36, 'text': ' User input. So given a program, the compiler generates an executable without knowing what', 'tokens': [50844, 32127, 4846, 13, 407, 2212, 257, 1461, 11, 264, 31958, 23815, 364, 7568, 712, 1553, 5276, 437, 51294], 'temperature': 0.0, 'avg_logprob': -0.23589876253310949, 'compression_ratio': 1.6900584795321638, 'no_speech_prob': 0.012325390242040157}, {'id': 56, 'seek': 43076, 'start': 449.36, 'end': 456.0, 'text': ' the input can be, the user input. An interpreter has that. As a result, it can do more things.', 'tokens': [51294, 264, 4846, 393, 312, 11, 264, 4195, 4846, 13, 1107, 34132, 575, 300, 13, 1018, 257, 1874, 11, 309, 393, 360, 544, 721, 13, 51626], 'temperature': 0.0, 'avg_logprob': -0.23589876253310949, 'compression_ratio': 1.6900584795321638, 'no_speech_prob': 0.012325390242040157}, {'id': 57, 'seek': 45600, 'start': 456.0, 'end': 463.0, 'text': ' So there are advantages of having an interpreter. Okay? And as a matter of fact, when you design', 'tokens': [50364, 407, 456, 366, 14906, 295, 1419, 364, 34132, 13, 1033, 30, 400, 382, 257, 1871, 295, 1186, 11, 562, 291, 1715, 50714], 'temperature': 0.0, 'avg_logprob': -0.23224813673231337, 'compression_ratio': 1.6962616822429906, 'no_speech_prob': 0.008813695050776005}, {'id': 58, 'seek': 45600, 'start': 465.68, 'end': 472.68, 'text': ' a language, invariably the first thing you have, you design keeping an interpreter in', 'tokens': [50848, 257, 2856, 11, 33270, 1188, 264, 700, 551, 291, 362, 11, 291, 1715, 5145, 364, 34132, 294, 51198], 'temperature': 0.0, 'avg_logprob': -0.23224813673231337, 'compression_ratio': 1.6962616822429906, 'no_speech_prob': 0.008813695050776005}, {'id': 59, 'seek': 45600, 'start': 472.68, 'end': 479.68, 'text': ' mind. Because every language construct needs a semantics. And that semantics is given...', 'tokens': [51198, 1575, 13, 1436, 633, 2856, 7690, 2203, 257, 4361, 45298, 13, 400, 300, 4361, 45298, 307, 2212, 485, 51548], 'temperature': 0.0, 'avg_logprob': -0.23224813673231337, 'compression_ratio': 1.6962616822429906, 'no_speech_prob': 0.008813695050776005}, {'id': 60, 'seek': 45600, 'start': 480.24, 'end': 485.0, 'text': ' I mean, think of the... You design an interpreter at some level. And then you say, hey, no,', 'tokens': [51576, 286, 914, 11, 519, 295, 264, 485, 509, 1715, 364, 34132, 412, 512, 1496, 13, 400, 550, 291, 584, 11, 4177, 11, 572, 11, 51814], 'temperature': 0.0, 'avg_logprob': -0.23224813673231337, 'compression_ratio': 1.6962616822429906, 'no_speech_prob': 0.008813695050776005}, {'id': 61, 'seek': 48500, 'start': 485.0, 'end': 489.76, 'text': ' I would like to have an A.out for this. You say, I will generate a compiler. But there', 'tokens': [50364, 286, 576, 411, 281, 362, 364, 316, 13, 346, 337, 341, 13, 509, 584, 11, 286, 486, 8460, 257, 31958, 13, 583, 456, 50602], 'temperature': 0.0, 'avg_logprob': -0.21461204952663845, 'compression_ratio': 1.6587677725118484, 'no_speech_prob': 0.0006840134738013148}, {'id': 62, 'seek': 48500, 'start': 489.76, 'end': 495.96, 'text': ' are languages which... I mean, there are languages who say, like, we want only an interpreter', 'tokens': [50602, 366, 8650, 597, 485, 286, 914, 11, 456, 366, 8650, 567, 584, 11, 411, 11, 321, 528, 787, 364, 34132, 50912], 'temperature': 0.0, 'avg_logprob': -0.21461204952663845, 'compression_ratio': 1.6587677725118484, 'no_speech_prob': 0.0006840134738013148}, {'id': 63, 'seek': 48500, 'start': 495.96, 'end': 502.96, 'text': ' because we get more advantages of it. Right? Any questions? Now, I will ask a question.', 'tokens': [50912, 570, 321, 483, 544, 14906, 295, 309, 13, 1779, 30, 2639, 1651, 30, 823, 11, 286, 486, 1029, 257, 1168, 13, 51262], 'temperature': 0.0, 'avg_logprob': -0.21461204952663845, 'compression_ratio': 1.6587677725118484, 'no_speech_prob': 0.0006840134738013148}, {'id': 64, 'seek': 48500, 'start': 505.6, 'end': 512.6, 'text': ' I gave you an advantage of an interpreter. Then why not only keep an interpreter?', 'tokens': [51394, 286, 2729, 291, 364, 5002, 295, 364, 34132, 13, 1396, 983, 406, 787, 1066, 364, 34132, 30, 51744], 'temperature': 0.0, 'avg_logprob': -0.21461204952663845, 'compression_ratio': 1.6587677725118484, 'no_speech_prob': 0.0006840134738013148}, {'id': 65, 'seek': 51500, 'start': 515.0, 'end': 522.0, 'text': ' No, no. Interpreter need not actually generate an executable file. Right? For instance, I', 'tokens': [50364, 883, 11, 572, 13, 5751, 3712, 391, 643, 406, 767, 8460, 364, 7568, 712, 3991, 13, 1779, 30, 1171, 5197, 11, 286, 50714], 'temperature': 0.0, 'avg_logprob': -0.31615855242754964, 'compression_ratio': 1.489010989010989, 'no_speech_prob': 0.0020497827790677547}, {'id': 66, 'seek': 51500, 'start': 523.88, 'end': 530.88, 'text': ' can... Let me answer this. For instance, I could take... Pick any language of your choice.', 'tokens': [50808, 393, 485, 961, 385, 1867, 341, 13, 1171, 5197, 11, 286, 727, 747, 485, 14129, 604, 2856, 295, 428, 3922, 13, 51158], 'temperature': 0.0, 'avg_logprob': -0.31615855242754964, 'compression_ratio': 1.489010989010989, 'no_speech_prob': 0.0020497827790677547}, {'id': 67, 'seek': 51500, 'start': 530.88, 'end': 537.88, 'text': ' C, C++, Java, any code of that. And actually interpret it technically line by line. Right?', 'tokens': [51158, 383, 11, 383, 25472, 11, 10745, 11, 604, 3089, 295, 300, 13, 400, 767, 7302, 309, 12120, 1622, 538, 1622, 13, 1779, 30, 51508], 'temperature': 0.0, 'avg_logprob': -0.31615855242754964, 'compression_ratio': 1.489010989010989, 'no_speech_prob': 0.0020497827790677547}, {'id': 68, 'seek': 53788, 'start': 538.88, 'end': 545.88, 'text': ' So, I do not have to generate machine code. Because I already have an interpreter whose', 'tokens': [50414, 407, 11, 286, 360, 406, 362, 281, 8460, 3479, 3089, 13, 1436, 286, 1217, 362, 364, 34132, 6104, 50764], 'temperature': 0.0, 'avg_logprob': -0.3096527099609375, 'compression_ratio': 1.5360360360360361, 'no_speech_prob': 0.0008265667711384594}, {'id': 69, 'seek': 53788, 'start': 549.32, 'end': 553.2, 'text': ' job is to take a statement and whatever the statement should do. Think of it this way.', 'tokens': [50936, 1691, 307, 281, 747, 257, 5629, 293, 2035, 264, 5629, 820, 360, 13, 6557, 295, 309, 341, 636, 13, 51130], 'temperature': 0.0, 'avg_logprob': -0.3096527099609375, 'compression_ratio': 1.5360360360360361, 'no_speech_prob': 0.0008265667711384594}, {'id': 70, 'seek': 53788, 'start': 553.2, 'end': 558.88, 'text': ' When you look at a code, in your mind you are running it as an interpreter. Right? Okay.', 'tokens': [51130, 1133, 291, 574, 412, 257, 3089, 11, 294, 428, 1575, 291, 366, 2614, 309, 382, 364, 34132, 13, 1779, 30, 1033, 13, 51414], 'temperature': 0.0, 'avg_logprob': -0.3096527099609375, 'compression_ratio': 1.5360360360360361, 'no_speech_prob': 0.0008265667711384594}, {'id': 71, 'seek': 53788, 'start': 558.88, 'end': 565.88, 'text': ' So now, what can a compiler do? My... I mean, for example, I can write a code', 'tokens': [51414, 407, 586, 11, 437, 393, 257, 31958, 360, 30, 1222, 485, 286, 914, 11, 337, 1365, 11, 286, 393, 2464, 257, 3089, 51764], 'temperature': 0.0, 'avg_logprob': -0.3096527099609375, 'compression_ratio': 1.5360360360360361, 'no_speech_prob': 0.0008265667711384594}, {'id': 72, 'seek': 56788, 'start': 567.88, 'end': 570.84, 'text': ' which is... So, portability is less of an issue with an interpreter. Right? Because', 'tokens': [50364, 597, 307, 485, 407, 11, 2436, 2310, 307, 1570, 295, 364, 2734, 365, 364, 34132, 13, 1779, 30, 1436, 50512], 'temperature': 0.0, 'avg_logprob': -0.3286967116795229, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.003067321376875043}, {'id': 73, 'seek': 56788, 'start': 570.84, 'end': 574.56, 'text': ' the high level code now can be sent anywhere and all you need is an interpreter being running', 'tokens': [50512, 264, 1090, 1496, 3089, 586, 393, 312, 2279, 4992, 293, 439, 291, 643, 307, 364, 34132, 885, 2614, 50698], 'temperature': 0.0, 'avg_logprob': -0.3286967116795229, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.003067321376875043}, {'id': 74, 'seek': 56788, 'start': 574.56, 'end': 581.56, 'text': ' there. It needs an interpreter. Okay. What is your name? Badri. So, Badri is making an', 'tokens': [50698, 456, 13, 467, 2203, 364, 34132, 13, 1033, 13, 708, 307, 428, 1315, 30, 11523, 470, 13, 407, 11, 11523, 470, 307, 1455, 364, 51048], 'temperature': 0.0, 'avg_logprob': -0.3286967116795229, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.003067321376875043}, {'id': 75, 'seek': 56788, 'start': 587.16, 'end': 591.72, 'text': ' interesting point. He is saying, if you need an interpreter, the interpreter has to go', 'tokens': [51328, 1880, 935, 13, 634, 307, 1566, 11, 498, 291, 643, 364, 34132, 11, 264, 34132, 575, 281, 352, 51556], 'temperature': 0.0, 'avg_logprob': -0.3286967116795229, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.003067321376875043}, {'id': 76, 'seek': 59172, 'start': 591.72, 'end': 598.72, 'text': ' to... You need an interpreter on every machine. If I want to send you a small a.out, you still', 'tokens': [50364, 281, 485, 509, 643, 364, 34132, 322, 633, 3479, 13, 759, 286, 528, 281, 2845, 291, 257, 1359, 257, 13, 346, 11, 291, 920, 50714], 'temperature': 0.0, 'avg_logprob': -0.1591201883501711, 'compression_ratio': 1.9484978540772533, 'no_speech_prob': 0.0027945160400122404}, {'id': 77, 'seek': 59172, 'start': 599.4, 'end': 605.12, 'text': ' need the big interpreter running. So, that is a good point. Right? But let us say I have', 'tokens': [50748, 643, 264, 955, 34132, 2614, 13, 407, 11, 300, 307, 257, 665, 935, 13, 1779, 30, 583, 718, 505, 584, 286, 362, 51034], 'temperature': 0.0, 'avg_logprob': -0.1591201883501711, 'compression_ratio': 1.9484978540772533, 'no_speech_prob': 0.0027945160400122404}, {'id': 78, 'seek': 59172, 'start': 605.12, 'end': 610.4, 'text': ' an interpreter everywhere. For every hardware, one interpreter has been given. For every', 'tokens': [51034, 364, 34132, 5315, 13, 1171, 633, 8837, 11, 472, 34132, 575, 668, 2212, 13, 1171, 633, 51298], 'temperature': 0.0, 'avg_logprob': -0.1591201883501711, 'compression_ratio': 1.9484978540772533, 'no_speech_prob': 0.0027945160400122404}, {'id': 79, 'seek': 59172, 'start': 610.4, 'end': 615.4, 'text': ' language, an interpreter has been given. See, now if I have different languages, I will', 'tokens': [51298, 2856, 11, 364, 34132, 575, 668, 2212, 13, 3008, 11, 586, 498, 286, 362, 819, 8650, 11, 286, 486, 51548], 'temperature': 0.0, 'avg_logprob': -0.1591201883501711, 'compression_ratio': 1.9484978540772533, 'no_speech_prob': 0.0027945160400122404}, {'id': 80, 'seek': 59172, 'start': 615.4, 'end': 621.4, 'text': ' come to you. If I have different languages, for each language I will give you an interpreter.', 'tokens': [51548, 808, 281, 291, 13, 759, 286, 362, 819, 8650, 11, 337, 1184, 2856, 286, 486, 976, 291, 364, 34132, 13, 51848], 'temperature': 0.0, 'avg_logprob': -0.1591201883501711, 'compression_ratio': 1.9484978540772533, 'no_speech_prob': 0.0027945160400122404}, {'id': 81, 'seek': 62140, 'start': 621.4, 'end': 628.4, 'text': ' But if you have... Yeah. There was a question. Okay. This is a misconception. Your name?', 'tokens': [50364, 583, 498, 291, 362, 485, 865, 13, 821, 390, 257, 1168, 13, 1033, 13, 639, 307, 257, 41350, 13, 2260, 1315, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.30413853781563893, 'compression_ratio': 1.5574712643678161, 'no_speech_prob': 0.0037005054764449596}, {'id': 82, 'seek': 62140, 'start': 631.4, 'end': 638.4, 'text': ' Yes. So, what yes said is a common misconception that the interpreter looks at one instruction', 'tokens': [50864, 1079, 13, 407, 11, 437, 2086, 848, 307, 257, 2689, 41350, 300, 264, 34132, 1542, 412, 472, 10951, 51214], 'temperature': 0.0, 'avg_logprob': -0.30413853781563893, 'compression_ratio': 1.5574712643678161, 'no_speech_prob': 0.0037005054764449596}, {'id': 83, 'seek': 62140, 'start': 639.68, 'end': 646.28, 'text': ' at a time. Now, the interpreter can execute one at a time, but it need not look at only', 'tokens': [51278, 412, 257, 565, 13, 823, 11, 264, 34132, 393, 14483, 472, 412, 257, 565, 11, 457, 309, 643, 406, 574, 412, 787, 51608], 'temperature': 0.0, 'avg_logprob': -0.30413853781563893, 'compression_ratio': 1.5574712643678161, 'no_speech_prob': 0.0037005054764449596}, {'id': 84, 'seek': 64628, 'start': 646.28, 'end': 653.28, 'text': ' one instruction. Right? Why it should only look at one? It is a perceived handicap.', 'tokens': [50364, 472, 10951, 13, 1779, 30, 1545, 309, 820, 787, 574, 412, 472, 30, 467, 307, 257, 19049, 45975, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.20933286155142436, 'compression_ratio': 1.5674418604651164, 'no_speech_prob': 0.0010960644576698542}, {'id': 85, 'seek': 64628, 'start': 655.56, 'end': 659.12, 'text': ' An interpreter can technically look at the whole code, do something and then execute', 'tokens': [50828, 1107, 34132, 393, 12120, 574, 412, 264, 1379, 3089, 11, 360, 746, 293, 550, 14483, 51006], 'temperature': 0.0, 'avg_logprob': -0.20933286155142436, 'compression_ratio': 1.5674418604651164, 'no_speech_prob': 0.0010960644576698542}, {'id': 86, 'seek': 64628, 'start': 659.12, 'end': 666.12, 'text': ' one instruction at a time. As a matter of fact, there are interpreters which... For', 'tokens': [51006, 472, 10951, 412, 257, 565, 13, 1018, 257, 1871, 295, 1186, 11, 456, 366, 17489, 1559, 597, 485, 1171, 51356], 'temperature': 0.0, 'avg_logprob': -0.20933286155142436, 'compression_ratio': 1.5674418604651164, 'no_speech_prob': 0.0010960644576698542}, {'id': 87, 'seek': 64628, 'start': 667.64, 'end': 673.24, 'text': ' instance, how many of you have heard this language called Java? Right? In Java, when', 'tokens': [51432, 5197, 11, 577, 867, 295, 291, 362, 2198, 341, 2856, 1219, 10745, 30, 1779, 30, 682, 10745, 11, 562, 51712], 'temperature': 0.0, 'avg_logprob': -0.20933286155142436, 'compression_ratio': 1.5674418604651164, 'no_speech_prob': 0.0010960644576698542}, {'id': 88, 'seek': 67324, 'start': 673.24, 'end': 680.24, 'text': ' you run the code Java a dot class, what does it do? It supposedly interprets. Why interpreting', 'tokens': [50364, 291, 1190, 264, 3089, 10745, 257, 5893, 1508, 11, 437, 775, 309, 360, 30, 467, 20581, 17489, 1373, 13, 1545, 37395, 50714], 'temperature': 0.0, 'avg_logprob': -0.20701092832228718, 'compression_ratio': 1.5625, 'no_speech_prob': 0.0011691540712490678}, {'id': 89, 'seek': 67324, 'start': 683.2, 'end': 689.44, 'text': ' if it finds a certain piece of code is executed too many times? This piece is executed lot', 'tokens': [50862, 498, 309, 10704, 257, 1629, 2522, 295, 3089, 307, 17577, 886, 867, 1413, 30, 639, 2522, 307, 17577, 688, 51174], 'temperature': 0.0, 'avg_logprob': -0.20701092832228718, 'compression_ratio': 1.5625, 'no_speech_prob': 0.0011691540712490678}, {'id': 90, 'seek': 67324, 'start': 689.44, 'end': 696.44, 'text': ' of times. Let me do something smart for this. Let me either generate, let me generate the', 'tokens': [51174, 295, 1413, 13, 961, 385, 360, 746, 4069, 337, 341, 13, 961, 385, 2139, 8460, 11, 718, 385, 8460, 264, 51524], 'temperature': 0.0, 'avg_logprob': -0.20701092832228718, 'compression_ratio': 1.5625, 'no_speech_prob': 0.0011691540712490678}, {'id': 91, 'seek': 69644, 'start': 696.5600000000001, 'end': 702.2800000000001, 'text': ' equivalent machine code for this compile or do some optimizations for this. That can be', 'tokens': [50370, 10344, 3479, 3089, 337, 341, 31413, 420, 360, 512, 5028, 14455, 337, 341, 13, 663, 393, 312, 50656], 'temperature': 0.0, 'avg_logprob': -0.43433380126953125, 'compression_ratio': 1.478494623655914, 'no_speech_prob': 0.0016953799640759826}, {'id': 92, 'seek': 69644, 'start': 702.2800000000001, 'end': 709.2800000000001, 'text': ' done. Right? No, something else that an interpreter has a drawback, serious drawback about. Yeah.', 'tokens': [50656, 1096, 13, 1779, 30, 883, 11, 746, 1646, 300, 364, 34132, 575, 257, 2642, 3207, 11, 3156, 2642, 3207, 466, 13, 865, 13, 51006], 'temperature': 0.0, 'avg_logprob': -0.43433380126953125, 'compression_ratio': 1.478494623655914, 'no_speech_prob': 0.0016953799640759826}, {'id': 93, 'seek': 69644, 'start': 710.5200000000001, 'end': 717.5200000000001, 'text': ' Correct. Correct. Excellent point. Your name? Savit. Savit said, you can write a code and', 'tokens': [51068, 12753, 13, 12753, 13, 16723, 935, 13, 2260, 1315, 30, 12346, 270, 13, 12346, 270, 848, 11, 291, 393, 2464, 257, 3089, 293, 51418], 'temperature': 0.0, 'avg_logprob': -0.43433380126953125, 'compression_ratio': 1.478494623655914, 'no_speech_prob': 0.0016953799640759826}, {'id': 94, 'seek': 72644, 'start': 727.2, 'end': 734.2, 'text': ' interpreter is one more software. Right? And now this software has to additionally run.', 'tokens': [50402, 34132, 307, 472, 544, 4722, 13, 1779, 30, 400, 586, 341, 4722, 575, 281, 43181, 1190, 13, 50752], 'temperature': 0.0, 'avg_logprob': -0.3051414489746094, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.0020062937401235104}, {'id': 95, 'seek': 72644, 'start': 737.0, 'end': 744.0, 'text': ' So the interpretation makes it slower. Right? So interpreter code can be slower. Then people', 'tokens': [50892, 407, 264, 14174, 1669, 309, 14009, 13, 1779, 30, 407, 34132, 3089, 393, 312, 14009, 13, 1396, 561, 51242], 'temperature': 0.0, 'avg_logprob': -0.3051414489746094, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.0020062937401235104}, {'id': 96, 'seek': 72644, 'start': 744.1600000000001, 'end': 751.1600000000001, 'text': ' will say, okay fine, if it, the whichever part runs a lot of times, let me on the fly', 'tokens': [51250, 486, 584, 11, 1392, 2489, 11, 498, 309, 11, 264, 24123, 644, 6676, 257, 688, 295, 1413, 11, 718, 385, 322, 264, 3603, 51600], 'temperature': 0.0, 'avg_logprob': -0.3051414489746094, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.0020062937401235104}, {'id': 97, 'seek': 75116, 'start': 752.12, 'end': 757.1999999999999, 'text': ' compile it and make it run fast. But even that compilation time gets added to your execution', 'tokens': [50412, 31413, 309, 293, 652, 309, 1190, 2370, 13, 583, 754, 300, 40261, 565, 2170, 3869, 281, 428, 15058, 50666], 'temperature': 0.0, 'avg_logprob': -0.1467790144035615, 'compression_ratio': 1.7303921568627452, 'no_speech_prob': 0.0008039359236136079}, {'id': 98, 'seek': 75116, 'start': 757.1999999999999, 'end': 764.1999999999999, 'text': ' time. When you interpret some code, that is what your, is the execution of the code. If', 'tokens': [50666, 565, 13, 1133, 291, 7302, 512, 3089, 11, 300, 307, 437, 428, 11, 307, 264, 15058, 295, 264, 3089, 13, 759, 51016], 'temperature': 0.0, 'avg_logprob': -0.1467790144035615, 'compression_ratio': 1.7303921568627452, 'no_speech_prob': 0.0008039359236136079}, {'id': 99, 'seek': 75116, 'start': 764.9599999999999, 'end': 771.9599999999999, 'text': ' interpreter is taking time, then your code is taking time. So one gives you additional', 'tokens': [51054, 34132, 307, 1940, 565, 11, 550, 428, 3089, 307, 1940, 565, 13, 407, 472, 2709, 291, 4497, 51404], 'temperature': 0.0, 'avg_logprob': -0.1467790144035615, 'compression_ratio': 1.7303921568627452, 'no_speech_prob': 0.0008039359236136079}, {'id': 100, 'seek': 75116, 'start': 773.36, 'end': 778.3199999999999, 'text': ' opportunities to do optimizations because it has the inputs, but it has the overheads', 'tokens': [51474, 4786, 281, 360, 5028, 14455, 570, 309, 575, 264, 15743, 11, 457, 309, 575, 264, 19922, 82, 51722], 'temperature': 0.0, 'avg_logprob': -0.1467790144035615, 'compression_ratio': 1.7303921568627452, 'no_speech_prob': 0.0008039359236136079}, {'id': 101, 'seek': 77832, 'start': 778.32, 'end': 784.48, 'text': ' of interpretation. So there is a nice pull and push. So different language designers', 'tokens': [50364, 295, 14174, 13, 407, 456, 307, 257, 1481, 2235, 293, 2944, 13, 407, 819, 2856, 16196, 50672], 'temperature': 0.0, 'avg_logprob': -0.20229809100811297, 'compression_ratio': 1.7290836653386454, 'no_speech_prob': 0.0017497548833489418}, {'id': 102, 'seek': 77832, 'start': 784.48, 'end': 790.0, 'text': ' choose different options. We can talk more about it later. But when an interpreter or', 'tokens': [50672, 2826, 819, 3956, 13, 492, 393, 751, 544, 466, 309, 1780, 13, 583, 562, 364, 34132, 420, 50948], 'temperature': 0.0, 'avg_logprob': -0.20229809100811297, 'compression_ratio': 1.7290836653386454, 'no_speech_prob': 0.0017497548833489418}, {'id': 103, 'seek': 77832, 'start': 790.0, 'end': 797.0, 'text': ' a compiler invariably do things like this, they take the source code. From the source', 'tokens': [50948, 257, 31958, 33270, 1188, 360, 721, 411, 341, 11, 436, 747, 264, 4009, 3089, 13, 3358, 264, 4009, 51298], 'temperature': 0.0, 'avg_logprob': -0.20229809100811297, 'compression_ratio': 1.7290836653386454, 'no_speech_prob': 0.0017497548833489418}, {'id': 104, 'seek': 77832, 'start': 797.08, 'end': 801.5600000000001, 'text': ' code, they do something and either if it is an interpreter, they will actually execute', 'tokens': [51302, 3089, 11, 436, 360, 746, 293, 2139, 498, 309, 307, 364, 34132, 11, 436, 486, 767, 14483, 51526], 'temperature': 0.0, 'avg_logprob': -0.20229809100811297, 'compression_ratio': 1.7290836653386454, 'no_speech_prob': 0.0017497548833489418}, {'id': 105, 'seek': 77832, 'start': 801.5600000000001, 'end': 808.08, 'text': ' it. But if the interpreter has a JIT compiler, just-in-time compiler or normal GCC type of', 'tokens': [51526, 309, 13, 583, 498, 264, 34132, 575, 257, 508, 3927, 31958, 11, 445, 12, 259, 12, 3766, 31958, 420, 2710, 460, 11717, 2010, 295, 51852], 'temperature': 0.0, 'avg_logprob': -0.20229809100811297, 'compression_ratio': 1.7290836653386454, 'no_speech_prob': 0.0017497548833489418}, {'id': 106, 'seek': 80808, 'start': 808.08, 'end': 812.08, 'text': ' compiler, they generate machine code. But typically we can think of as a front end', 'tokens': [50364, 31958, 11, 436, 8460, 3479, 3089, 13, 583, 5850, 321, 393, 519, 295, 382, 257, 1868, 917, 50564], 'temperature': 0.0, 'avg_logprob': -0.21705788832444411, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.0005864761769771576}, {'id': 107, 'seek': 80808, 'start': 812.08, 'end': 818.12, 'text': ' and the back end. Okay? From the front end, you take the source code, generate the IR', 'tokens': [50564, 293, 264, 646, 917, 13, 1033, 30, 3358, 264, 1868, 917, 11, 291, 747, 264, 4009, 3089, 11, 8460, 264, 16486, 50866], 'temperature': 0.0, 'avg_logprob': -0.21705788832444411, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.0005864761769771576}, {'id': 108, 'seek': 80808, 'start': 818.12, 'end': 825.12, 'text': ' and give it to back end. Right? IR stands for intermediate representation. Why do we', 'tokens': [50866, 293, 976, 309, 281, 646, 917, 13, 1779, 30, 16486, 7382, 337, 19376, 10290, 13, 1545, 360, 321, 51216], 'temperature': 0.0, 'avg_logprob': -0.21705788832444411, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.0005864761769771576}, {'id': 109, 'seek': 80808, 'start': 825.5200000000001, 'end': 832.5200000000001, 'text': ' need an IR? Any guesses? Enhance the portability of, to run on different back ends. Can you,', 'tokens': [51236, 643, 364, 16486, 30, 2639, 42703, 30, 2193, 71, 719, 264, 2436, 2310, 295, 11, 281, 1190, 322, 819, 646, 5314, 13, 1664, 291, 11, 51586], 'temperature': 0.0, 'avg_logprob': -0.21705788832444411, 'compression_ratio': 1.5446428571428572, 'no_speech_prob': 0.0005864761769771576}, {'id': 110, 'seek': 83252, 'start': 833.52, 'end': 840.52, 'text': ' you are using, I think, the right set of words, but probably they are connected not correctly.', 'tokens': [50414, 291, 366, 1228, 11, 286, 519, 11, 264, 558, 992, 295, 2283, 11, 457, 1391, 436, 366, 4582, 406, 8944, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.24551083290413633, 'compression_ratio': 1.454054054054054, 'no_speech_prob': 0.0025092714931815863}, {'id': 111, 'seek': 83252, 'start': 841.56, 'end': 848.56, 'text': ' Can you, so the IR, the question is why do we need an IR? If there are m languages and', 'tokens': [50816, 1664, 291, 11, 370, 264, 16486, 11, 264, 1168, 307, 983, 360, 321, 643, 364, 16486, 30, 759, 456, 366, 275, 8650, 293, 51166], 'temperature': 0.0, 'avg_logprob': -0.24551083290413633, 'compression_ratio': 1.454054054054054, 'no_speech_prob': 0.0025092714931815863}, {'id': 112, 'seek': 83252, 'start': 848.96, 'end': 855.96, 'text': ' n architectures, if I want to make for all the combinations, okay, so was this, someone', 'tokens': [51186, 297, 6331, 1303, 11, 498, 286, 528, 281, 652, 337, 439, 264, 21267, 11, 1392, 11, 370, 390, 341, 11, 1580, 51536], 'temperature': 0.0, 'avg_logprob': -0.24551083290413633, 'compression_ratio': 1.454054054054054, 'no_speech_prob': 0.0025092714931815863}, {'id': 113, 'seek': 85596, 'start': 855.96, 'end': 862.96, 'text': ' discussed this standard m cross n? Very good. So, now the question is, if we have this m', 'tokens': [50364, 7152, 341, 3832, 275, 3278, 297, 30, 4372, 665, 13, 407, 11, 586, 264, 1168, 307, 11, 498, 321, 362, 341, 275, 50714], 'temperature': 0.0, 'avg_logprob': -0.22564250946044923, 'compression_ratio': 1.748768472906404, 'no_speech_prob': 0.0048252297565341}, {'id': 114, 'seek': 85596, 'start': 865.44, 'end': 871.52, 'text': ' languages and n architectures, we will say, hey, let us have, let us trans, write all', 'tokens': [50838, 8650, 293, 297, 6331, 1303, 11, 321, 486, 584, 11, 4177, 11, 718, 505, 362, 11, 718, 505, 1145, 11, 2464, 439, 51142], 'temperature': 0.0, 'avg_logprob': -0.22564250946044923, 'compression_ratio': 1.748768472906404, 'no_speech_prob': 0.0048252297565341}, {'id': 115, 'seek': 85596, 'start': 871.52, 'end': 878.52, 'text': ' this to one IR, from one IR have many back ends. Right? So, the IR, if I have only one', 'tokens': [51142, 341, 281, 472, 16486, 11, 490, 472, 16486, 362, 867, 646, 5314, 13, 1779, 30, 407, 11, 264, 16486, 11, 498, 286, 362, 787, 472, 51492], 'temperature': 0.0, 'avg_logprob': -0.22564250946044923, 'compression_ratio': 1.748768472906404, 'no_speech_prob': 0.0048252297565341}, {'id': 116, 'seek': 85596, 'start': 879.48, 'end': 884.24, 'text': ' language and one, that is a good point, but if I have only one language and one architecture,', 'tokens': [51540, 2856, 293, 472, 11, 300, 307, 257, 665, 935, 11, 457, 498, 286, 362, 787, 472, 2856, 293, 472, 9482, 11, 51778], 'temperature': 0.0, 'avg_logprob': -0.22564250946044923, 'compression_ratio': 1.748768472906404, 'no_speech_prob': 0.0048252297565341}, {'id': 117, 'seek': 88424, 'start': 884.24, 'end': 889.24, 'text': ' why do I still need an IR? Why not in the same language? I mean, why do I need an IR?', 'tokens': [50364, 983, 360, 286, 920, 643, 364, 16486, 30, 1545, 406, 294, 264, 912, 2856, 30, 286, 914, 11, 983, 360, 286, 643, 364, 16486, 30, 50614], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 118, 'seek': 88424, 'start': 889.24, 'end': 894.24, 'text': ' That is the question. I mean, it is like additional work, right? I want to generate code. I am', 'tokens': [50614, 663, 307, 264, 1168, 13, 286, 914, 11, 309, 307, 411, 4497, 589, 11, 558, 30, 286, 528, 281, 8460, 3089, 13, 286, 669, 50864], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 119, 'seek': 88424, 'start': 894.24, 'end': 897.84, 'text': ' saying, no, no, first I will do one set of compilation. This is also a compiler, right?', 'tokens': [50864, 1566, 11, 572, 11, 572, 11, 700, 286, 486, 360, 472, 992, 295, 40261, 13, 639, 307, 611, 257, 31958, 11, 558, 30, 51044], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 120, 'seek': 88424, 'start': 897.84, 'end': 901.44, 'text': ' This is also a compiler. So, I am saying, hey, to build this bigger compiler, let me', 'tokens': [51044, 639, 307, 611, 257, 31958, 13, 407, 11, 286, 669, 1566, 11, 4177, 11, 281, 1322, 341, 3801, 31958, 11, 718, 385, 51224], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 121, 'seek': 88424, 'start': 901.44, 'end': 907.24, 'text': ' build a smaller compiler. Why I cannot do optimizations on this? This word, why I will', 'tokens': [51224, 1322, 257, 4356, 31958, 13, 1545, 286, 2644, 360, 5028, 14455, 322, 341, 30, 639, 1349, 11, 983, 286, 486, 51514], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 122, 'seek': 88424, 'start': 907.24, 'end': 911.24, 'text': ' keep asking and I expect that you will keep asking. Whatever I say, there should be a', 'tokens': [51514, 1066, 3365, 293, 286, 2066, 300, 291, 486, 1066, 3365, 13, 8541, 286, 584, 11, 456, 820, 312, 257, 51714], 'temperature': 0.0, 'avg_logprob': -0.22849354127637383, 'compression_ratio': 1.8652482269503545, 'no_speech_prob': 0.0006457773270085454}, {'id': 123, 'seek': 91124, 'start': 911.24, 'end': 913.24, 'text': ' reason why. What is your name?', 'tokens': [50364, 1778, 983, 13, 708, 307, 428, 1315, 30, 50464], 'temperature': 0.0, 'avg_logprob': -0.29324966879451975, 'compression_ratio': 1.49746192893401, 'no_speech_prob': 0.34072214365005493}, {'id': 124, 'seek': 91124, 'start': 913.24, 'end': 914.24, 'text': ' Dhaval.', 'tokens': [50464, 34414, 46868, 13, 50514], 'temperature': 0.0, 'avg_logprob': -0.29324966879451975, 'compression_ratio': 1.49746192893401, 'no_speech_prob': 0.34072214365005493}, {'id': 125, 'seek': 91124, 'start': 914.24, 'end': 920.24, 'text': ' Dhaval. I will keep asking your name. Even if I ask, please do not mind. I have a very', 'tokens': [50514, 34414, 46868, 13, 286, 486, 1066, 3365, 428, 1315, 13, 2754, 498, 286, 1029, 11, 1767, 360, 406, 1575, 13, 286, 362, 257, 588, 50814], 'temperature': 0.0, 'avg_logprob': -0.29324966879451975, 'compression_ratio': 1.49746192893401, 'no_speech_prob': 0.34072214365005493}, {'id': 126, 'seek': 91124, 'start': 920.24, 'end': 927.24, 'text': ' poor memory. So, Dhaval, what you said is interesting that to do some optimizations,', 'tokens': [50814, 4716, 4675, 13, 407, 11, 34414, 46868, 11, 437, 291, 848, 307, 1880, 300, 281, 360, 512, 5028, 14455, 11, 51164], 'temperature': 0.0, 'avg_logprob': -0.29324966879451975, 'compression_ratio': 1.49746192893401, 'no_speech_prob': 0.34072214365005493}, {'id': 127, 'seek': 91124, 'start': 927.24, 'end': 930.24, 'text': ' certain things may not be visible in the higher level code. Can you give an example?', 'tokens': [51164, 1629, 721, 815, 406, 312, 8974, 294, 264, 2946, 1496, 3089, 13, 1664, 291, 976, 364, 1365, 30, 51314], 'temperature': 0.0, 'avg_logprob': -0.29324966879451975, 'compression_ratio': 1.49746192893401, 'no_speech_prob': 0.34072214365005493}, {'id': 128, 'seek': 93024, 'start': 930.24, 'end': 948.24, 'text': ' So, for example, a loop, a loop in higher level just a false statement. You might not', 'tokens': [50364, 407, 11, 337, 1365, 11, 257, 6367, 11, 257, 6367, 294, 2946, 1496, 445, 257, 7908, 5629, 13, 509, 1062, 406, 51264], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 129, 'seek': 93024, 'start': 948.24, 'end': 949.24, 'text': ' see any way of optimizing this any further. Whereas, in a primitive implementation, you', 'tokens': [51264, 536, 604, 636, 295, 40425, 341, 604, 3052, 13, 13813, 11, 294, 257, 28540, 11420, 11, 291, 51314], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 130, 'seek': 93024, 'start': 949.24, 'end': 950.24, 'text': ' might see, this thing is happening multiple times within that loop. Why not say optimizations?', 'tokens': [51314, 1062, 536, 11, 341, 551, 307, 2737, 3866, 1413, 1951, 300, 6367, 13, 1545, 406, 584, 5028, 14455, 30, 51364], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 131, 'seek': 93024, 'start': 950.24, 'end': 952.28, 'text': ' Very interesting. So, it is actually the other way around, I thought. The loops are more', 'tokens': [51364, 4372, 1880, 13, 407, 11, 309, 307, 767, 264, 661, 636, 926, 11, 286, 1194, 13, 440, 16121, 366, 544, 51466], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 132, 'seek': 93024, 'start': 952.28, 'end': 955.28, 'text': ' visible in the higher level code than a lower level code.', 'tokens': [51466, 8974, 294, 264, 2946, 1496, 3089, 813, 257, 3126, 1496, 3089, 13, 51616], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 133, 'seek': 93024, 'start': 955.28, 'end': 957.88, 'text': ' Can you find the expression for that?', 'tokens': [51616, 1664, 291, 915, 264, 6114, 337, 300, 30, 51746], 'temperature': 0.0, 'avg_logprob': -0.34555448927320875, 'compression_ratio': 1.6840148698884758, 'no_speech_prob': 0.0774865597486496}, {'id': 134, 'seek': 95788, 'start': 958.52, 'end': 963.4399999999999, 'text': ' This is a good point. This is one of the good points. Let us say, in the high level code,', 'tokens': [50396, 639, 307, 257, 665, 935, 13, 639, 307, 472, 295, 264, 665, 2793, 13, 961, 505, 584, 11, 294, 264, 1090, 1496, 3089, 11, 50642], 'temperature': 0.0, 'avg_logprob': -0.218870715091103, 'compression_ratio': 1.6296296296296295, 'no_speech_prob': 0.771877646446228}, {'id': 135, 'seek': 95788, 'start': 963.4399999999999, 'end': 971.88, 'text': ' I have one operator called plus 1. If I do a plus 1, I need some instruction at lower', 'tokens': [50642, 286, 362, 472, 12973, 1219, 1804, 502, 13, 759, 286, 360, 257, 1804, 502, 11, 286, 643, 512, 10951, 412, 3126, 51064], 'temperature': 0.0, 'avg_logprob': -0.218870715091103, 'compression_ratio': 1.6296296296296295, 'no_speech_prob': 0.771877646446228}, {'id': 136, 'seek': 95788, 'start': 971.88, 'end': 978.36, 'text': ' level to either optimize it. I have some way to do, let us say, some fast way to do plus', 'tokens': [51064, 1496, 281, 2139, 19719, 309, 13, 286, 362, 512, 636, 281, 360, 11, 718, 505, 584, 11, 512, 2370, 636, 281, 360, 1804, 51388], 'temperature': 0.0, 'avg_logprob': -0.218870715091103, 'compression_ratio': 1.6296296296296295, 'no_speech_prob': 0.771877646446228}, {'id': 137, 'seek': 97836, 'start': 979.36, 'end': 989.96, 'text': ' 1. Now, in high level, how can you express plus 1? Either something like a plus 1 or', 'tokens': [50414, 502, 13, 823, 11, 294, 1090, 1496, 11, 577, 393, 291, 5109, 1804, 502, 30, 13746, 746, 411, 257, 1804, 502, 420, 50944], 'temperature': 0.0, 'avg_logprob': -0.20641648014889488, 'compression_ratio': 1.65, 'no_speech_prob': 0.17663192749023438}, {'id': 138, 'seek': 97836, 'start': 989.96, 'end': 996.16, 'text': ' a plus plus. Now, if you, in the high level code, I do not know whether it is plus 1 or', 'tokens': [50944, 257, 1804, 1804, 13, 823, 11, 498, 291, 11, 294, 264, 1090, 1496, 3089, 11, 286, 360, 406, 458, 1968, 309, 307, 1804, 502, 420, 51254], 'temperature': 0.0, 'avg_logprob': -0.20641648014889488, 'compression_ratio': 1.65, 'no_speech_prob': 0.17663192749023438}, {'id': 139, 'seek': 97836, 'start': 996.16, 'end': 1002.04, 'text': ' plus plus. If I keep the high level syntax as it is, in the back end, you need an optimizer', 'tokens': [51254, 1804, 1804, 13, 759, 286, 1066, 264, 1090, 1496, 28431, 382, 309, 307, 11, 294, 264, 646, 917, 11, 291, 643, 364, 5028, 6545, 51548], 'temperature': 0.0, 'avg_logprob': -0.20641648014889488, 'compression_ratio': 1.65, 'no_speech_prob': 0.17663192749023438}, {'id': 140, 'seek': 100204, 'start': 1002.04, 'end': 1009.04, 'text': ' to handle plus plus and plus 1. You have many such examples of syntactic sugars, right?', 'tokens': [50364, 281, 4813, 1804, 1804, 293, 1804, 502, 13, 509, 362, 867, 1270, 5110, 295, 23980, 19892, 37551, 11, 558, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.17940154282943063, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.11257880181074142}, {'id': 141, 'seek': 100204, 'start': 1013.52, 'end': 1017.9599999999999, 'text': ' If you want to keep your back end, which is a much more complex piece, what you want to', 'tokens': [50938, 759, 291, 528, 281, 1066, 428, 646, 917, 11, 597, 307, 257, 709, 544, 3997, 2522, 11, 437, 291, 528, 281, 51160], 'temperature': 0.0, 'avg_logprob': -0.17940154282943063, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.11257880181074142}, {'id': 142, 'seek': 100204, 'start': 1017.9599999999999, 'end': 1024.96, 'text': ' do? You want to let it handle a smaller set of syntax. As you, whoever has covered IR,', 'tokens': [51160, 360, 30, 509, 528, 281, 718, 309, 4813, 257, 4356, 992, 295, 28431, 13, 1018, 291, 11, 11387, 575, 5343, 16486, 11, 51510], 'temperature': 0.0, 'avg_logprob': -0.17940154282943063, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.11257880181074142}, {'id': 143, 'seek': 100204, 'start': 1025.36, 'end': 1030.8, 'text': ' you would see that that syntax is much smaller compared to the syntax of the high level code.', 'tokens': [51530, 291, 576, 536, 300, 300, 28431, 307, 709, 4356, 5347, 281, 264, 28431, 295, 264, 1090, 1496, 3089, 13, 51802], 'temperature': 0.0, 'avg_logprob': -0.17940154282943063, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.11257880181074142}, {'id': 144, 'seek': 103080, 'start': 1030.8, 'end': 1037.8, 'text': ' So, to make the back end life easier, we first generate an IR whose syntax is simpler. So,', 'tokens': [50364, 407, 11, 281, 652, 264, 646, 917, 993, 3571, 11, 321, 700, 8460, 364, 16486, 6104, 28431, 307, 18587, 13, 407, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.22879670795641446, 'compression_ratio': 1.5254237288135593, 'no_speech_prob': 0.005051291082054377}, {'id': 145, 'seek': 103080, 'start': 1039.44, 'end': 1046.44, 'text': ' the front end maps legal code to IR, legal code to IR. Should I, okay. The back end maps', 'tokens': [50796, 264, 1868, 917, 11317, 5089, 3089, 281, 16486, 11, 5089, 3089, 281, 16486, 13, 6454, 286, 11, 1392, 13, 440, 646, 917, 11317, 51146], 'temperature': 0.0, 'avg_logprob': -0.22879670795641446, 'compression_ratio': 1.5254237288135593, 'no_speech_prob': 0.005051291082054377}, {'id': 146, 'seek': 103080, 'start': 1052.76, 'end': 1059.76, 'text': ' the IR to the target machine. And this IR helps, that it can help, as you said, simplifies', 'tokens': [51462, 264, 16486, 281, 264, 3779, 3479, 13, 400, 341, 16486, 3665, 11, 300, 309, 393, 854, 11, 382, 291, 848, 11, 6883, 11221, 51812], 'temperature': 0.0, 'avg_logprob': -0.22879670795641446, 'compression_ratio': 1.5254237288135593, 'no_speech_prob': 0.005051291082054377}, {'id': 147, 'seek': 105976, 'start': 1059.76, 'end': 1066.76, 'text': ' retargeting m cross n, m front ends, n back ends. It keeps the back end simpler and allows', 'tokens': [50364, 1533, 289, 847, 278, 275, 3278, 297, 11, 275, 1868, 5314, 11, 297, 646, 5314, 13, 467, 5965, 264, 646, 917, 18587, 293, 4045, 50714], 'temperature': 0.0, 'avg_logprob': -0.21724095908544397, 'compression_ratio': 1.7024390243902439, 'no_speech_prob': 0.0005183870671316981}, {'id': 148, 'seek': 105976, 'start': 1067.4, 'end': 1073.96, 'text': ' many front ends, okay. And typically, you make many passes over the IR. We understand', 'tokens': [50746, 867, 1868, 5314, 11, 1392, 13, 400, 5850, 11, 291, 652, 867, 11335, 670, 264, 16486, 13, 492, 1223, 51074], 'temperature': 0.0, 'avg_logprob': -0.21724095908544397, 'compression_ratio': 1.7024390243902439, 'no_speech_prob': 0.0005183870671316981}, {'id': 149, 'seek': 105976, 'start': 1073.96, 'end': 1080.96, 'text': ' this part, okay. A rough statement you can make that the code in the front end is, the', 'tokens': [51074, 341, 644, 11, 1392, 13, 316, 5903, 5629, 291, 393, 652, 300, 264, 3089, 294, 264, 1868, 917, 307, 11, 264, 51424], 'temperature': 0.0, 'avg_logprob': -0.21724095908544397, 'compression_ratio': 1.7024390243902439, 'no_speech_prob': 0.0005183870671316981}, {'id': 150, 'seek': 105976, 'start': 1082.08, 'end': 1088.04, 'text': ' passes in the front end are simpler or have been dealt with very well so far. Most of', 'tokens': [51480, 11335, 294, 264, 1868, 917, 366, 18587, 420, 362, 668, 15991, 365, 588, 731, 370, 1400, 13, 4534, 295, 51778], 'temperature': 0.0, 'avg_logprob': -0.21724095908544397, 'compression_ratio': 1.7024390243902439, 'no_speech_prob': 0.0005183870671316981}, {'id': 151, 'seek': 108804, 'start': 1088.04, 'end': 1094.6399999999999, 'text': ' the work that is done in the current research world is all in the back end, okay. And the,', 'tokens': [50364, 264, 589, 300, 307, 1096, 294, 264, 2190, 2132, 1002, 307, 439, 294, 264, 646, 917, 11, 1392, 13, 400, 264, 11, 50694], 'temperature': 0.0, 'avg_logprob': -0.1887140531797667, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.001335786422714591}, {'id': 152, 'seek': 108804, 'start': 1094.6399999999999, 'end': 1101.6399999999999, 'text': ' but the back end problems, many are known to be undecidable. Some are known to be hard', 'tokens': [50694, 457, 264, 646, 917, 2740, 11, 867, 366, 2570, 281, 312, 674, 3045, 38089, 13, 2188, 366, 2570, 281, 312, 1152, 51044], 'temperature': 0.0, 'avg_logprob': -0.1887140531797667, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.001335786422714591}, {'id': 153, 'seek': 108804, 'start': 1105.6, 'end': 1112.6, 'text': ' as in NP hard and in that range. So, the many of them are approximations, okay. Our focus', 'tokens': [51242, 382, 294, 38611, 1152, 293, 294, 300, 3613, 13, 407, 11, 264, 867, 295, 552, 366, 8542, 763, 11, 1392, 13, 2621, 1879, 51592], 'temperature': 0.0, 'avg_logprob': -0.1887140531797667, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.001335786422714591}, {'id': 154, 'seek': 111260, 'start': 1113.6, 'end': 1120.6, 'text': ' is some part of the back end, okay. Our focus is some part of the, just this back end part.', 'tokens': [50414, 307, 512, 644, 295, 264, 646, 917, 11, 1392, 13, 2621, 1879, 307, 512, 644, 295, 264, 11, 445, 341, 646, 917, 644, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.16798799014785915, 'compression_ratio': 1.7745098039215685, 'no_speech_prob': 0.0015240457141771913}, {'id': 155, 'seek': 111260, 'start': 1122.1599999999999, 'end': 1129.1599999999999, 'text': ' We would not touch anything on the front end, okay. Good. So, you have seen this seven pass', 'tokens': [50842, 492, 576, 406, 2557, 1340, 322, 264, 1868, 917, 11, 1392, 13, 2205, 13, 407, 11, 291, 362, 1612, 341, 3407, 1320, 51192], 'temperature': 0.0, 'avg_logprob': -0.16798799014785915, 'compression_ratio': 1.7745098039215685, 'no_speech_prob': 0.0015240457141771913}, {'id': 156, 'seek': 111260, 'start': 1130.24, 'end': 1135.32, 'text': ' compiler, right. So, what we will do, we will not, I mean, we will not look at the front', 'tokens': [51246, 31958, 11, 558, 13, 407, 11, 437, 321, 486, 360, 11, 321, 486, 406, 11, 286, 914, 11, 321, 486, 406, 574, 412, 264, 1868, 51500], 'temperature': 0.0, 'avg_logprob': -0.16798799014785915, 'compression_ratio': 1.7745098039215685, 'no_speech_prob': 0.0015240457141771913}, {'id': 157, 'seek': 111260, 'start': 1135.32, 'end': 1141.56, 'text': ' end parts, whose job is to recognize the tokens and so on. So, this is the front end part', 'tokens': [51500, 917, 3166, 11, 6104, 1691, 307, 281, 5521, 264, 22667, 293, 370, 322, 13, 407, 11, 341, 307, 264, 1868, 917, 644, 51812], 'temperature': 0.0, 'avg_logprob': -0.16798799014785915, 'compression_ratio': 1.7745098039215685, 'no_speech_prob': 0.0015240457141771913}, {'id': 158, 'seek': 114156, 'start': 1141.72, 'end': 1147.3999999999999, 'text': ' and the back end part has these three phases. What we will do, we will, of the seven, we', 'tokens': [50372, 293, 264, 646, 917, 644, 575, 613, 1045, 18764, 13, 708, 321, 486, 360, 11, 321, 486, 11, 295, 264, 3407, 11, 321, 50656], 'temperature': 0.0, 'avg_logprob': -0.24564438774472191, 'compression_ratio': 1.5609756097560976, 'no_speech_prob': 0.001432065269909799}, {'id': 159, 'seek': 114156, 'start': 1147.3999999999999, 'end': 1154.12, 'text': ' will focus on machine independent optimizations, okay. One order set. And if we require some', 'tokens': [50656, 486, 1879, 322, 3479, 6695, 5028, 14455, 11, 1392, 13, 1485, 1668, 992, 13, 400, 498, 321, 3651, 512, 50992], 'temperature': 0.0, 'avg_logprob': -0.24564438774472191, 'compression_ratio': 1.5609756097560976, 'no_speech_prob': 0.001432065269909799}, {'id': 160, 'seek': 114156, 'start': 1154.12, 'end': 1161.12, 'text': ' other phases in between, we will go there, okay.', 'tokens': [50992, 661, 18764, 294, 1296, 11, 321, 486, 352, 456, 11, 1392, 13, 51342], 'temperature': 0.0, 'avg_logprob': -0.24564438774472191, 'compression_ratio': 1.5609756097560976, 'no_speech_prob': 0.001432065269909799}, {'id': 161, 'seek': 114156, 'start': 1163.0, 'end': 1168.72, 'text': ' Just let us take it for one more fun question. Let us say, you pick a production compiler', 'tokens': [51436, 1449, 718, 505, 747, 309, 337, 472, 544, 1019, 1168, 13, 961, 505, 584, 11, 291, 1888, 257, 4265, 31958, 51722], 'temperature': 0.0, 'avg_logprob': -0.24564438774472191, 'compression_ratio': 1.5609756097560976, 'no_speech_prob': 0.001432065269909799}, {'id': 162, 'seek': 116872, 'start': 1168.72, 'end': 1175.72, 'text': ' say like GCC, right, or HPC compiler. I am sure it will hold for something like even', 'tokens': [50364, 584, 411, 460, 11717, 11, 558, 11, 420, 12557, 34, 31958, 13, 286, 669, 988, 309, 486, 1797, 337, 746, 411, 754, 50714], 'temperature': 0.0, 'avg_logprob': -0.3969980004715593, 'compression_ratio': 1.5260115606936415, 'no_speech_prob': 0.0028887230437248945}, {'id': 163, 'seek': 116872, 'start': 1175.72, 'end': 1182.72, 'text': ' NVIDIA C compiler. So, if I divide here, right, four phases here, three phases here, which', 'tokens': [50714, 426, 3958, 6914, 383, 31958, 13, 407, 11, 498, 286, 9845, 510, 11, 558, 11, 1451, 18764, 510, 11, 1045, 18764, 510, 11, 597, 51064], 'temperature': 0.0, 'avg_logprob': -0.3969980004715593, 'compression_ratio': 1.5260115606936415, 'no_speech_prob': 0.0028887230437248945}, {'id': 164, 'seek': 116872, 'start': 1182.72, 'end': 1189.72, 'text': ' phase has more lines of code you think? The code generator. Intermediate code generator.', 'tokens': [51064, 5574, 575, 544, 3876, 295, 3089, 291, 519, 30, 440, 3089, 19265, 13, 5751, 3130, 473, 3089, 19265, 13, 51414], 'temperature': 0.0, 'avg_logprob': -0.3969980004715593, 'compression_ratio': 1.5260115606936415, 'no_speech_prob': 0.0028887230437248945}, {'id': 165, 'seek': 118972, 'start': 1189.72, 'end': 1196.72, 'text': ' If you just divide the back end and front end, it so turns out the back end code is', 'tokens': [50364, 759, 291, 445, 9845, 264, 646, 917, 293, 1868, 917, 11, 309, 370, 4523, 484, 264, 646, 917, 3089, 307, 50714], 'temperature': 0.0, 'avg_logprob': -0.2170876474941478, 'compression_ratio': 1.6037735849056605, 'no_speech_prob': 0.0014074415666982532}, {'id': 166, 'seek': 118972, 'start': 1204.32, 'end': 1209.32, 'text': ' far, far more than the front end code. The older the compiler, the bigger the back end', 'tokens': [51094, 1400, 11, 1400, 544, 813, 264, 1868, 917, 3089, 13, 440, 4906, 264, 31958, 11, 264, 3801, 264, 646, 917, 51344], 'temperature': 0.0, 'avg_logprob': -0.2170876474941478, 'compression_ratio': 1.6037735849056605, 'no_speech_prob': 0.0014074415666982532}, {'id': 167, 'seek': 118972, 'start': 1209.32, 'end': 1214.44, 'text': ' is. Because once the front end is settled, you do not touch much. You keep on adding', 'tokens': [51344, 307, 13, 1436, 1564, 264, 1868, 917, 307, 14819, 11, 291, 360, 406, 2557, 709, 13, 509, 1066, 322, 5127, 51600], 'temperature': 0.0, 'avg_logprob': -0.2170876474941478, 'compression_ratio': 1.6037735849056605, 'no_speech_prob': 0.0014074415666982532}, {'id': 168, 'seek': 121444, 'start': 1214.44, 'end': 1221.44, 'text': ' more and more optimizations. So, the intermediate code generator is not touched much. You have', 'tokens': [50364, 544, 293, 544, 5028, 14455, 13, 407, 11, 264, 19376, 3089, 19265, 307, 406, 9828, 709, 13, 509, 362, 50714], 'temperature': 0.0, 'avg_logprob': -0.22202705012427437, 'compression_ratio': 1.554945054945055, 'no_speech_prob': 0.004327952861785889}, {'id': 169, 'seek': 121444, 'start': 1223.64, 'end': 1230.64, 'text': ' it, it remains that way, okay. Fine. Our goal is to look at optimization. When we say optimization,', 'tokens': [50824, 309, 11, 309, 7023, 300, 636, 11, 1392, 13, 12024, 13, 2621, 3387, 307, 281, 574, 412, 19618, 13, 1133, 321, 584, 19618, 11, 51174], 'temperature': 0.0, 'avg_logprob': -0.22202705012427437, 'compression_ratio': 1.554945054945055, 'no_speech_prob': 0.004327952861785889}, {'id': 170, 'seek': 121444, 'start': 1233.0, 'end': 1237.64, 'text': ' what do we mean by it? Most of the time, when we say optimization, it means produce fast', 'tokens': [51292, 437, 360, 321, 914, 538, 309, 30, 4534, 295, 264, 565, 11, 562, 321, 584, 19618, 11, 309, 1355, 5258, 2370, 51524], 'temperature': 0.0, 'avg_logprob': -0.22202705012427437, 'compression_ratio': 1.554945054945055, 'no_speech_prob': 0.004327952861785889}, {'id': 171, 'seek': 123764, 'start': 1237.64, 'end': 1244.64, 'text': ' code. But is it, when we say optimization, is it optimum? We are not talking about optimum.', 'tokens': [50364, 3089, 13, 583, 307, 309, 11, 562, 321, 584, 19618, 11, 307, 309, 39326, 30, 492, 366, 406, 1417, 466, 39326, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.19727717360405073, 'compression_ratio': 1.6196319018404908, 'no_speech_prob': 0.00488567678257823}, {'id': 172, 'seek': 123764, 'start': 1250.6000000000001, 'end': 1257.6000000000001, 'text': ' We are not, okay. We are talking about some notion of optimality. Many of the times, the', 'tokens': [51012, 492, 366, 406, 11, 1392, 13, 492, 366, 1417, 466, 512, 10710, 295, 5028, 1860, 13, 5126, 295, 264, 1413, 11, 264, 51362], 'temperature': 0.0, 'avg_logprob': -0.19727717360405073, 'compression_ratio': 1.6196319018404908, 'no_speech_prob': 0.00488567678257823}, {'id': 173, 'seek': 123764, 'start': 1257.6000000000001, 'end': 1264.6000000000001, 'text': ' problems are hard and it so turns out, if I have N optimizations, if I apply all N,', 'tokens': [51362, 2740, 366, 1152, 293, 309, 370, 4523, 484, 11, 498, 286, 362, 426, 5028, 14455, 11, 498, 286, 3079, 439, 426, 11, 51712], 'temperature': 0.0, 'avg_logprob': -0.19727717360405073, 'compression_ratio': 1.6196319018404908, 'no_speech_prob': 0.00488567678257823}, {'id': 174, 'seek': 126764, 'start': 1267.64, 'end': 1274.16, 'text': ' there is no guarantee that the code will be faster. There are times when if you apply', 'tokens': [50364, 456, 307, 572, 10815, 300, 264, 3089, 486, 312, 4663, 13, 821, 366, 1413, 562, 498, 291, 3079, 50690], 'temperature': 0.0, 'avg_logprob': -0.173041566212972, 'compression_ratio': 1.6210045662100456, 'no_speech_prob': 0.0009398080292157829}, {'id': 175, 'seek': 126764, 'start': 1274.16, 'end': 1280.68, 'text': ' two optimizations together, the generated code could be slower. Ideally, we do not want', 'tokens': [50690, 732, 5028, 14455, 1214, 11, 264, 10833, 3089, 727, 312, 14009, 13, 40817, 11, 321, 360, 406, 528, 51016], 'temperature': 0.0, 'avg_logprob': -0.173041566212972, 'compression_ratio': 1.6210045662100456, 'no_speech_prob': 0.0009398080292157829}, {'id': 176, 'seek': 126764, 'start': 1280.68, 'end': 1287.68, 'text': ' it that way, but it may. So, keep, so have that thing in the back of your mind, okay.', 'tokens': [51016, 309, 300, 636, 11, 457, 309, 815, 13, 407, 11, 1066, 11, 370, 362, 300, 551, 294, 264, 646, 295, 428, 1575, 11, 1392, 13, 51366], 'temperature': 0.0, 'avg_logprob': -0.173041566212972, 'compression_ratio': 1.6210045662100456, 'no_speech_prob': 0.0009398080292157829}, {'id': 177, 'seek': 126764, 'start': 1288.68, 'end': 1295.68, 'text': ' So, when we say an optimization in more general sense, it is a transformation which is expected', 'tokens': [51416, 407, 11, 562, 321, 584, 364, 19618, 294, 544, 2674, 2020, 11, 309, 307, 257, 9887, 597, 307, 5176, 51766], 'temperature': 0.0, 'avg_logprob': -0.173041566212972, 'compression_ratio': 1.6210045662100456, 'no_speech_prob': 0.0009398080292157829}, {'id': 178, 'seek': 129568, 'start': 1295.96, 'end': 1302.96, 'text': ' to improve the program. But when we say improve, what do you mean? It could be execution time.', 'tokens': [50378, 281, 3470, 264, 1461, 13, 583, 562, 321, 584, 3470, 11, 437, 360, 291, 914, 30, 467, 727, 312, 15058, 565, 13, 50728], 'temperature': 0.0, 'avg_logprob': -0.2077414592107137, 'compression_ratio': 1.3846153846153846, 'no_speech_prob': 0.0013236987870186567}, {'id': 179, 'seek': 129568, 'start': 1309.64, 'end': 1316.64, 'text': ' What else can it improve? Space, what else? Power consumption, what else? Size of the', 'tokens': [51062, 708, 1646, 393, 309, 3470, 30, 8705, 11, 437, 1646, 30, 7086, 12126, 11, 437, 1646, 30, 35818, 295, 264, 51412], 'temperature': 0.0, 'avg_logprob': -0.2077414592107137, 'compression_ratio': 1.3846153846153846, 'no_speech_prob': 0.0013236987870186567}, {'id': 180, 'seek': 131664, 'start': 1316.64, 'end': 1323.64, 'text': ' code. Why do I care for size of the code? It is a good point. If I want to send the', 'tokens': [50364, 3089, 13, 1545, 360, 286, 1127, 337, 2744, 295, 264, 3089, 30, 467, 307, 257, 665, 935, 13, 759, 286, 528, 281, 2845, 264, 50714], 'temperature': 0.0, 'avg_logprob': -0.16434664408365884, 'compression_ratio': 1.6903225806451614, 'no_speech_prob': 0.0017534060170874}, {'id': 181, 'seek': 131664, 'start': 1332.88, 'end': 1337.88, 'text': ' code over the network, the smaller the code better. If I do not want to send it over the', 'tokens': [51176, 3089, 670, 264, 3209, 11, 264, 4356, 264, 3089, 1101, 13, 759, 286, 360, 406, 528, 281, 2845, 309, 670, 264, 51426], 'temperature': 0.0, 'avg_logprob': -0.16434664408365884, 'compression_ratio': 1.6903225806451614, 'no_speech_prob': 0.0017534060170874}, {'id': 182, 'seek': 131664, 'start': 1337.88, 'end': 1344.88, 'text': ' network, is there a reason why I may need, why I may want a small piece of code? Perfect.', 'tokens': [51426, 3209, 11, 307, 456, 257, 1778, 983, 286, 815, 643, 11, 983, 286, 815, 528, 257, 1359, 2522, 295, 3089, 30, 10246, 13, 51776], 'temperature': 0.0, 'avg_logprob': -0.16434664408365884, 'compression_ratio': 1.6903225806451614, 'no_speech_prob': 0.0017534060170874}, {'id': 183, 'seek': 134664, 'start': 1346.76, 'end': 1353.76, 'text': ' That is a more regular, more common need for compilers that can optimize for size. Let', 'tokens': [50370, 663, 307, 257, 544, 3890, 11, 544, 2689, 643, 337, 715, 388, 433, 300, 393, 19719, 337, 2744, 13, 961, 50720], 'temperature': 0.0, 'avg_logprob': -0.19523453031267438, 'compression_ratio': 1.5116279069767442, 'no_speech_prob': 0.00039166538044810295}, {'id': 184, 'seek': 134664, 'start': 1355.0, 'end': 1362.0, 'text': ' us say you have a pacemaker or you have a small watch or a small sensor, right. There', 'tokens': [50782, 505, 584, 291, 362, 257, 15165, 49523, 420, 291, 362, 257, 1359, 1159, 420, 257, 1359, 10200, 11, 558, 13, 821, 51132], 'temperature': 0.0, 'avg_logprob': -0.19523453031267438, 'compression_ratio': 1.5116279069767442, 'no_speech_prob': 0.00039166538044810295}, {'id': 185, 'seek': 134664, 'start': 1367.96, 'end': 1374.96, 'text': ' you may have very small pieces of memory to hold the code. The answer is yes and no. It', 'tokens': [51430, 291, 815, 362, 588, 1359, 3755, 295, 4675, 281, 1797, 264, 3089, 13, 440, 1867, 307, 2086, 293, 572, 13, 467, 51780], 'temperature': 0.0, 'avg_logprob': -0.19523453031267438, 'compression_ratio': 1.5116279069767442, 'no_speech_prob': 0.00039166538044810295}, {'id': 186, 'seek': 137496, 'start': 1375.68, 'end': 1382.68, 'text': ' depends on the program, right. If I have a program that does not do dynamic memory allocation,', 'tokens': [50400, 5946, 322, 264, 1461, 11, 558, 13, 759, 286, 362, 257, 1461, 300, 775, 406, 360, 8546, 4675, 27599, 11, 50750], 'temperature': 0.0, 'avg_logprob': -0.2244006974356515, 'compression_ratio': 1.6607142857142858, 'no_speech_prob': 0.001063917181454599}, {'id': 187, 'seek': 137496, 'start': 1383.96, 'end': 1390.96, 'text': ' right. I can easily write tons and tons of programs that do know dynamic memory allocation.', 'tokens': [50814, 558, 13, 286, 393, 3612, 2464, 9131, 293, 9131, 295, 4268, 300, 360, 458, 8546, 4675, 27599, 13, 51164], 'temperature': 0.0, 'avg_logprob': -0.2244006974356515, 'compression_ratio': 1.6607142857142858, 'no_speech_prob': 0.001063917181454599}, {'id': 188, 'seek': 137496, 'start': 1395.24, 'end': 1401.24, 'text': ' And for instance, here is something, right. Let us say I am doing, I want to compute primes,', 'tokens': [51378, 400, 337, 5197, 11, 510, 307, 746, 11, 558, 13, 961, 505, 584, 286, 669, 884, 11, 286, 528, 281, 14722, 582, 1532, 11, 51678], 'temperature': 0.0, 'avg_logprob': -0.2244006974356515, 'compression_ratio': 1.6607142857142858, 'no_speech_prob': 0.001063917181454599}, {'id': 189, 'seek': 140124, 'start': 1401.8, 'end': 1408.8, 'text': ' right. All I need to do is keep on. So, that does not require too much, I mean this most', 'tokens': [50392, 558, 13, 1057, 286, 643, 281, 360, 307, 1066, 322, 13, 407, 11, 300, 775, 406, 3651, 886, 709, 11, 286, 914, 341, 881, 50742], 'temperature': 0.0, 'avg_logprob': -0.2423247403876726, 'compression_ratio': 1.6102564102564103, 'no_speech_prob': 0.0005407428834587336}, {'id': 190, 'seek': 140124, 'start': 1409.16, 'end': 1413.8, 'text': ' naive thing is keep on dividing forever, right.', 'tokens': [50760, 29052, 551, 307, 1066, 322, 26764, 5680, 11, 558, 13, 50992], 'temperature': 0.0, 'avg_logprob': -0.2423247403876726, 'compression_ratio': 1.6102564102564103, 'no_speech_prob': 0.0005407428834587336}, {'id': 191, 'seek': 140124, 'start': 1413.8, 'end': 1420.8, 'text': ' So, now the question is when we are talking about the code that may run on a sensor, what', 'tokens': [50992, 407, 11, 586, 264, 1168, 307, 562, 321, 366, 1417, 466, 264, 3089, 300, 815, 1190, 322, 257, 10200, 11, 437, 51342], 'temperature': 0.0, 'avg_logprob': -0.2423247403876726, 'compression_ratio': 1.6102564102564103, 'no_speech_prob': 0.0005407428834587336}, {'id': 192, 'seek': 140124, 'start': 1423.28, 'end': 1430.28, 'text': ' type of code it is? So, in those codes, you normally do not require too much of dynamic', 'tokens': [51466, 2010, 295, 3089, 309, 307, 30, 407, 11, 294, 729, 14211, 11, 291, 5646, 360, 406, 3651, 886, 709, 295, 8546, 51816], 'temperature': 0.0, 'avg_logprob': -0.2423247403876726, 'compression_ratio': 1.6102564102564103, 'no_speech_prob': 0.0005407428834587336}, {'id': 193, 'seek': 143028, 'start': 1430.28, 'end': 1436.2, 'text': ' memory. As a matter of fact, the code that have to run on sensors, they have to have', 'tokens': [50364, 4675, 13, 1018, 257, 1871, 295, 1186, 11, 264, 3089, 300, 362, 281, 1190, 322, 14840, 11, 436, 362, 281, 362, 50660], 'temperature': 0.0, 'avg_logprob': -0.18480362148459897, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 6.395405944203958e-05}, {'id': 194, 'seek': 143028, 'start': 1436.2, 'end': 1443.2, 'text': ' certain guarantees that they will not need more than certain amount of memory including', 'tokens': [50660, 1629, 32567, 300, 436, 486, 406, 643, 544, 813, 1629, 2372, 295, 4675, 3009, 51010], 'temperature': 0.0, 'avg_logprob': -0.18480362148459897, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 6.395405944203958e-05}, {'id': 195, 'seek': 143028, 'start': 1443.28, 'end': 1449.68, 'text': ' dynamic, runtime memory. Let us say it has a recursion. The recursion will not unfold', 'tokens': [51014, 8546, 11, 34474, 4675, 13, 961, 505, 584, 309, 575, 257, 20560, 313, 13, 440, 20560, 313, 486, 406, 17980, 51334], 'temperature': 0.0, 'avg_logprob': -0.18480362148459897, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 6.395405944203958e-05}, {'id': 196, 'seek': 143028, 'start': 1449.68, 'end': 1453.48, 'text': ' beyond element. Think of it this way. Let us say I have a code which is running on my', 'tokens': [51334, 4399, 4478, 13, 6557, 295, 309, 341, 636, 13, 961, 505, 584, 286, 362, 257, 3089, 597, 307, 2614, 322, 452, 51524], 'temperature': 0.0, 'avg_logprob': -0.18480362148459897, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 6.395405944203958e-05}, {'id': 197, 'seek': 143028, 'start': 1453.48, 'end': 1460.0, 'text': ' pacemaker, right. Suddenly it has taken so much memory that it says sorry, out of memory.', 'tokens': [51524, 15165, 49523, 11, 558, 13, 21194, 309, 575, 2726, 370, 709, 4675, 300, 309, 1619, 2597, 11, 484, 295, 4675, 13, 51850], 'temperature': 0.0, 'avg_logprob': -0.18480362148459897, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 6.395405944203958e-05}, {'id': 198, 'seek': 146000, 'start': 1460.72, 'end': 1467.72, 'text': ' So, it is a very important question that many, some of these software vendors have to worry', 'tokens': [50400, 407, 11, 309, 307, 257, 588, 1021, 1168, 300, 867, 11, 512, 295, 613, 4722, 22056, 362, 281, 3292, 50750], 'temperature': 0.0, 'avg_logprob': -0.25669241685133715, 'compression_ratio': 1.552325581395349, 'no_speech_prob': 0.0001692365185590461}, {'id': 199, 'seek': 146000, 'start': 1472.08, 'end': 1477.52, 'text': ' about. So, when we say improved code, we are talking about improved not optimum or even', 'tokens': [50968, 466, 13, 407, 11, 562, 321, 584, 9689, 3089, 11, 321, 366, 1417, 466, 9689, 406, 39326, 420, 754, 51240], 'temperature': 0.0, 'avg_logprob': -0.25669241685133715, 'compression_ratio': 1.552325581395349, 'no_speech_prob': 0.0001692365185590461}, {'id': 200, 'seek': 146000, 'start': 1477.52, 'end': 1483.8, 'text': ' optimal. Sometimes it may produce worse code, but our hope is that the speed ups can be', 'tokens': [51240, 16252, 13, 4803, 309, 815, 5258, 5324, 3089, 11, 457, 527, 1454, 307, 300, 264, 3073, 15497, 393, 312, 51554], 'temperature': 0.0, 'avg_logprob': -0.25669241685133715, 'compression_ratio': 1.552325581395349, 'no_speech_prob': 0.0001692365185590461}, {'id': 201, 'seek': 148380, 'start': 1484.1599999999999, 'end': 1491.1599999999999, 'text': ' starting from some small delta to some large factor, okay. In general, it is even undecidable', 'tokens': [50382, 2891, 490, 512, 1359, 8289, 281, 512, 2416, 5952, 11, 1392, 13, 682, 2674, 11, 309, 307, 754, 674, 3045, 38089, 50732], 'temperature': 0.0, 'avg_logprob': -0.2417713295329701, 'compression_ratio': 1.37984496124031, 'no_speech_prob': 0.007365959230810404}, {'id': 202, 'seek': 148380, 'start': 1494.1599999999999, 'end': 1501.1599999999999, 'text': ' whether in most cases a given optimization will give you improvement, okay. I do not', 'tokens': [50882, 1968, 294, 881, 3331, 257, 2212, 19618, 486, 976, 291, 10444, 11, 1392, 13, 286, 360, 406, 51232], 'temperature': 0.0, 'avg_logprob': -0.2417713295329701, 'compression_ratio': 1.37984496124031, 'no_speech_prob': 0.007365959230810404}, {'id': 203, 'seek': 150116, 'start': 1501.16, 'end': 1514.76, 'text': ' like this. You should ask why. We are saying it optimization. I am saying it will not improve', 'tokens': [50364, 411, 341, 13, 509, 820, 1029, 983, 13, 492, 366, 1566, 309, 19618, 13, 286, 669, 1566, 309, 486, 406, 3470, 51044], 'temperature': 0.0, 'avg_logprob': -0.2925582504272461, 'compression_ratio': 1.3555555555555556, 'no_speech_prob': 0.01845826953649521}, {'id': 204, 'seek': 150116, 'start': 1514.76, 'end': 1521.76, 'text': ' and none of you are even asking why. Does not it bother you? Sorry? But what am I saying?', 'tokens': [51044, 293, 6022, 295, 291, 366, 754, 3365, 983, 13, 4402, 406, 309, 8677, 291, 30, 4919, 30, 583, 437, 669, 286, 1566, 30, 51394], 'temperature': 0.0, 'avg_logprob': -0.2925582504272461, 'compression_ratio': 1.3555555555555556, 'no_speech_prob': 0.01845826953649521}, {'id': 205, 'seek': 152176, 'start': 1521.76, 'end': 1528.76, 'text': ' You pick any optimization of your choice. Pick any optimization of your choice. Even', 'tokens': [50364, 509, 1888, 604, 19618, 295, 428, 3922, 13, 14129, 604, 19618, 295, 428, 3922, 13, 2754, 50714], 'temperature': 0.0, 'avg_logprob': -0.21048716248058882, 'compression_ratio': 1.7086092715231789, 'no_speech_prob': 0.008257389068603516}, {'id': 206, 'seek': 152176, 'start': 1534.8799999999999, 'end': 1540.8799999999999, 'text': ' then I am saying there is no guarantee. Let us say dead code elimination. I am saying', 'tokens': [51020, 550, 286, 669, 1566, 456, 307, 572, 10815, 13, 961, 505, 584, 3116, 3089, 29224, 13, 286, 669, 1566, 51320], 'temperature': 0.0, 'avg_logprob': -0.21048716248058882, 'compression_ratio': 1.7086092715231789, 'no_speech_prob': 0.008257389068603516}, {'id': 207, 'seek': 152176, 'start': 1540.8799999999999, 'end': 1545.8799999999999, 'text': ' you eliminate dead code. There is a chance that the code may lead to worse performance.', 'tokens': [51320, 291, 13819, 3116, 3089, 13, 821, 307, 257, 2931, 300, 264, 3089, 815, 1477, 281, 5324, 3389, 13, 51570], 'temperature': 0.0, 'avg_logprob': -0.21048716248058882, 'compression_ratio': 1.7086092715231789, 'no_speech_prob': 0.008257389068603516}, {'id': 208, 'seek': 154588, 'start': 1545.88, 'end': 1552.88, 'text': ' I am making a very strong statement. It should shake up your sleep and say, no, this guy', 'tokens': [50364, 286, 669, 1455, 257, 588, 2068, 5629, 13, 467, 820, 10283, 493, 428, 2817, 293, 584, 11, 572, 11, 341, 2146, 50714], 'temperature': 0.0, 'avg_logprob': -0.3134514714630557, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.008033969439566135}, {'id': 209, 'seek': 154588, 'start': 1553.1200000000001, 'end': 1560.1200000000001, 'text': ' is either stupid or we do not know something which he is talking about. Yes, yes. Do you', 'tokens': [50726, 307, 2139, 6631, 420, 321, 360, 406, 458, 746, 597, 415, 307, 1417, 466, 13, 1079, 11, 2086, 13, 1144, 291, 51076], 'temperature': 0.0, 'avg_logprob': -0.3134514714630557, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.008033969439566135}, {'id': 210, 'seek': 154588, 'start': 1565.3200000000002, 'end': 1569.3200000000002, 'text': ' see what I am saying? I am making a very strong statement. Take an optimization that you think,', 'tokens': [51336, 536, 437, 286, 669, 1566, 30, 286, 669, 1455, 257, 588, 2068, 5629, 13, 3664, 364, 19618, 300, 291, 519, 11, 51536], 'temperature': 0.0, 'avg_logprob': -0.3134514714630557, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.008033969439566135}, {'id': 211, 'seek': 156932, 'start': 1569.8799999999999, 'end': 1576.52, 'text': ' I mean dead code elimination. I think even then there may be some cases because of dead', 'tokens': [50392, 286, 914, 3116, 3089, 29224, 13, 286, 519, 754, 550, 456, 815, 312, 512, 3331, 570, 295, 3116, 50724], 'temperature': 0.0, 'avg_logprob': -0.2827850553724501, 'compression_ratio': 1.7110091743119267, 'no_speech_prob': 0.05833159387111664}, {'id': 212, 'seek': 156932, 'start': 1576.52, 'end': 1583.52, 'text': ' code elimination the code is running, taking more time. Okay, no, you are saying you are', 'tokens': [50724, 3089, 29224, 264, 3089, 307, 2614, 11, 1940, 544, 565, 13, 1033, 11, 572, 11, 291, 366, 1566, 291, 366, 51074], 'temperature': 0.0, 'avg_logprob': -0.2827850553724501, 'compression_ratio': 1.7110091743119267, 'no_speech_prob': 0.05833159387111664}, {'id': 213, 'seek': 156932, 'start': 1583.52, 'end': 1590.52, 'text': ' going further ahead. You are taking my statement as a given, but I am asking, question my statement.', 'tokens': [51074, 516, 3052, 2286, 13, 509, 366, 1940, 452, 5629, 382, 257, 2212, 11, 457, 286, 669, 3365, 11, 1168, 452, 5629, 13, 51424], 'temperature': 0.0, 'avg_logprob': -0.2827850553724501, 'compression_ratio': 1.7110091743119267, 'no_speech_prob': 0.05833159387111664}, {'id': 214, 'seek': 156932, 'start': 1591.52, 'end': 1598.28, 'text': ' Good. It depends on the program we are considering. So can you give an example where because of', 'tokens': [51474, 2205, 13, 467, 5946, 322, 264, 1461, 321, 366, 8079, 13, 407, 393, 291, 976, 364, 1365, 689, 570, 295, 51812], 'temperature': 0.0, 'avg_logprob': -0.2827850553724501, 'compression_ratio': 1.7110091743119267, 'no_speech_prob': 0.05833159387111664}, {'id': 215, 'seek': 159828, 'start': 1598.28, 'end': 1605.28, 'text': ' dead code elimination my code may run slower. I did dead code elimination, but now my code', 'tokens': [50364, 3116, 3089, 29224, 452, 3089, 815, 1190, 14009, 13, 286, 630, 3116, 3089, 29224, 11, 457, 586, 452, 3089, 50714], 'temperature': 0.0, 'avg_logprob': -0.20143866539001465, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.003941169939935207}, {'id': 216, 'seek': 159828, 'start': 1606.72, 'end': 1613.72, 'text': ' runs slower. It may not happen most of the time, but there may be some cases. See what', 'tokens': [50786, 6676, 14009, 13, 467, 815, 406, 1051, 881, 295, 264, 565, 11, 457, 456, 815, 312, 512, 3331, 13, 3008, 437, 51136], 'temperature': 0.0, 'avg_logprob': -0.20143866539001465, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.003941169939935207}, {'id': 217, 'seek': 159828, 'start': 1618.2, 'end': 1625.2, 'text': ' I am saying? I cannot give guarantee for all the scenarios. Let us say there was a memory', 'tokens': [51360, 286, 669, 1566, 30, 286, 2644, 976, 10815, 337, 439, 264, 15077, 13, 961, 505, 584, 456, 390, 257, 4675, 51710], 'temperature': 0.0, 'avg_logprob': -0.20143866539001465, 'compression_ratio': 1.608433734939759, 'no_speech_prob': 0.003941169939935207}, {'id': 218, 'seek': 162520, 'start': 1625.96, 'end': 1632.24, 'text': ' fetch. I removed it. I avoided the memory fetch because of which you would assume that', 'tokens': [50402, 23673, 13, 286, 7261, 309, 13, 286, 24890, 264, 4675, 23673, 570, 295, 597, 291, 576, 6552, 300, 50716], 'temperature': 0.0, 'avg_logprob': -0.17859568379142068, 'compression_ratio': 1.6650943396226414, 'no_speech_prob': 0.0023823813535273075}, {'id': 219, 'seek': 162520, 'start': 1632.24, 'end': 1639.24, 'text': ' it should run faster, but now it is running slower. Why? Good point, right? So what he', 'tokens': [50716, 309, 820, 1190, 4663, 11, 457, 586, 309, 307, 2614, 14009, 13, 1545, 30, 2205, 935, 11, 558, 30, 407, 437, 415, 51066], 'temperature': 0.0, 'avg_logprob': -0.17859568379142068, 'compression_ratio': 1.6650943396226414, 'no_speech_prob': 0.0023823813535273075}, {'id': 220, 'seek': 162520, 'start': 1639.24, 'end': 1643.88, 'text': ' is saying? The dead code is doing something that is useful to me. It could be bringing', 'tokens': [51066, 307, 1566, 30, 440, 3116, 3089, 307, 884, 746, 300, 307, 4420, 281, 385, 13, 467, 727, 312, 5062, 51298], 'temperature': 0.0, 'avg_logprob': -0.17859568379142068, 'compression_ratio': 1.6650943396226414, 'no_speech_prob': 0.0023823813535273075}, {'id': 221, 'seek': 162520, 'start': 1643.88, 'end': 1650.88, 'text': ' in something to the cache. It could be changing the layout of my instruction cache. It could', 'tokens': [51298, 294, 746, 281, 264, 19459, 13, 467, 727, 312, 4473, 264, 13333, 295, 452, 10951, 19459, 13, 467, 727, 51648], 'temperature': 0.0, 'avg_logprob': -0.17859568379142068, 'compression_ratio': 1.6650943396226414, 'no_speech_prob': 0.0023823813535273075}, {'id': 222, 'seek': 165088, 'start': 1651.88, 'end': 1658.88, 'text': ' be prefetching something and dead code is just one example. It turns out there are so', 'tokens': [50414, 312, 18417, 7858, 278, 746, 293, 3116, 3089, 307, 445, 472, 1365, 13, 467, 4523, 484, 456, 366, 370, 50764], 'temperature': 0.0, 'avg_logprob': -0.20655697495190065, 'compression_ratio': 1.6419753086419753, 'no_speech_prob': 0.001166889793239534}, {'id': 223, 'seek': 165088, 'start': 1661.44, 'end': 1668.44, 'text': ' many factors in play. There is cache. There is hard disk. There is like our friend was', 'tokens': [50892, 867, 6771, 294, 862, 13, 821, 307, 19459, 13, 821, 307, 1152, 12355, 13, 821, 307, 411, 527, 1277, 390, 51242], 'temperature': 0.0, 'avg_logprob': -0.20655697495190065, 'compression_ratio': 1.6419753086419753, 'no_speech_prob': 0.001166889793239534}, {'id': 224, 'seek': 165088, 'start': 1668.6200000000001, 'end': 1675.6200000000001, 'text': ' talking about the pipelining, how things are there, how things are organized in the pipeline.', 'tokens': [51251, 1417, 466, 264, 8489, 338, 1760, 11, 577, 721, 366, 456, 11, 577, 721, 366, 9983, 294, 264, 15517, 13, 51601], 'temperature': 0.0, 'avg_logprob': -0.20655697495190065, 'compression_ratio': 1.6419753086419753, 'no_speech_prob': 0.001166889793239534}, {'id': 225, 'seek': 167562, 'start': 1676.1799999999998, 'end': 1681.06, 'text': ' We do not have any optimal solutions for any of these problems. Individually each of these', 'tokens': [50392, 492, 360, 406, 362, 604, 16252, 6547, 337, 604, 295, 613, 2740, 13, 2333, 1843, 671, 1184, 295, 613, 50636], 'temperature': 0.0, 'avg_logprob': -0.20443641571771531, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.0026756608858704567}, {'id': 226, 'seek': 167562, 'start': 1681.06, 'end': 1688.06, 'text': ' problems are too hard. Now your question, if there is no guarantee for any of these,', 'tokens': [50636, 2740, 366, 886, 1152, 13, 823, 428, 1168, 11, 498, 456, 307, 572, 10815, 337, 604, 295, 613, 11, 50986], 'temperature': 0.0, 'avg_logprob': -0.20443641571771531, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.0026756608858704567}, {'id': 227, 'seek': 167562, 'start': 1689.1399999999999, 'end': 1694.62, 'text': ' why should I even use them? Why should we sit in this air conditioning room and learn', 'tokens': [51040, 983, 820, 286, 754, 764, 552, 30, 1545, 820, 321, 1394, 294, 341, 1988, 21901, 1808, 293, 1466, 51314], 'temperature': 0.0, 'avg_logprob': -0.20443641571771531, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.0026756608858704567}, {'id': 228, 'seek': 167562, 'start': 1694.62, 'end': 1701.62, 'text': ' about this? Right? Good and those chances are very high. Right? The chances are very', 'tokens': [51314, 466, 341, 30, 1779, 30, 2205, 293, 729, 10486, 366, 588, 1090, 13, 1779, 30, 440, 10486, 366, 588, 51664], 'temperature': 0.0, 'avg_logprob': -0.20443641571771531, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.0026756608858704567}, {'id': 229, 'seek': 170562, 'start': 1705.86, 'end': 1710.86, 'text': ' high. So when you walk on the street, is there a guarantee that you will cross the road?', 'tokens': [50376, 1090, 13, 407, 562, 291, 1792, 322, 264, 4838, 11, 307, 456, 257, 10815, 300, 291, 486, 3278, 264, 3060, 30, 50626], 'temperature': 0.0, 'avg_logprob': -0.2659352334697595, 'compression_ratio': 1.8238341968911918, 'no_speech_prob': 0.0009394986554980278}, {'id': 230, 'seek': 170562, 'start': 1710.86, 'end': 1717.86, 'text': ' The chances are high. Even on police streets the chances are high. Right? So the point', 'tokens': [50626, 440, 10486, 366, 1090, 13, 2754, 322, 3804, 8481, 264, 10486, 366, 1090, 13, 1779, 30, 407, 264, 935, 50976], 'temperature': 0.0, 'avg_logprob': -0.2659352334697595, 'compression_ratio': 1.8238341968911918, 'no_speech_prob': 0.0009394986554980278}, {'id': 231, 'seek': 170562, 'start': 1721.4599999999998, 'end': 1728.4599999999998, 'text': ' is most of the time we will, the optimizations most of the time you have. I mean those are', 'tokens': [51156, 307, 881, 295, 264, 565, 321, 486, 11, 264, 5028, 14455, 881, 295, 264, 565, 291, 362, 13, 286, 914, 729, 366, 51506], 'temperature': 0.0, 'avg_logprob': -0.2659352334697595, 'compression_ratio': 1.8238341968911918, 'no_speech_prob': 0.0009394986554980278}, {'id': 232, 'seek': 170562, 'start': 1728.7399999999998, 'end': 1734.78, 'text': ' the popular optimizations and most of the time you get better performance. Right? And', 'tokens': [51520, 264, 3743, 5028, 14455, 293, 881, 295, 264, 565, 291, 483, 1101, 3389, 13, 1779, 30, 400, 51822], 'temperature': 0.0, 'avg_logprob': -0.2659352334697595, 'compression_ratio': 1.8238341968911918, 'no_speech_prob': 0.0009394986554980278}, {'id': 233, 'seek': 173478, 'start': 1734.8999999999999, 'end': 1741.8999999999999, 'text': ' he asked another question. What if you do not do? What if you do not do? If you do not', 'tokens': [50370, 415, 2351, 1071, 1168, 13, 708, 498, 291, 360, 406, 360, 30, 708, 498, 291, 360, 406, 360, 30, 759, 291, 360, 406, 50720], 'temperature': 0.0, 'avg_logprob': -0.2655372350988254, 'compression_ratio': 1.65, 'no_speech_prob': 0.0020497299265116453}, {'id': 234, 'seek': 173478, 'start': 1743.34, 'end': 1750.34, 'text': ' do any optimizations, the impact, I mean the programs, I mean the optimizations give you', 'tokens': [50792, 360, 604, 5028, 14455, 11, 264, 2712, 11, 286, 914, 264, 4268, 11, 286, 914, 264, 5028, 14455, 976, 291, 51142], 'temperature': 0.0, 'avg_logprob': -0.2655372350988254, 'compression_ratio': 1.65, 'no_speech_prob': 0.0020497299265116453}, {'id': 235, 'seek': 173478, 'start': 1751.62, 'end': 1758.62, 'text': ' speed ups which are unimaginable otherwise on this day. The handwritten code, it is very', 'tokens': [51206, 3073, 15497, 597, 366, 517, 44976, 712, 5911, 322, 341, 786, 13, 440, 1011, 26859, 3089, 11, 309, 307, 588, 51556], 'temperature': 0.0, 'avg_logprob': -0.2655372350988254, 'compression_ratio': 1.65, 'no_speech_prob': 0.0020497299265116453}, {'id': 236, 'seek': 175862, 'start': 1759.62, 'end': 1766.62, 'text': ' hard to optimize large pieces of code just by hand. I mean here is the deal. When you', 'tokens': [50414, 1152, 281, 19719, 2416, 3755, 295, 3089, 445, 538, 1011, 13, 286, 914, 510, 307, 264, 2028, 13, 1133, 291, 50764], 'temperature': 0.0, 'avg_logprob': -0.1815433099236287, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.001062734518200159}, {'id': 237, 'seek': 175862, 'start': 1770.1399999999999, 'end': 1777.1399999999999, 'text': ' touch, do you have a phone or do you have a laptop? When you open an app, you have a', 'tokens': [50940, 2557, 11, 360, 291, 362, 257, 2593, 420, 360, 291, 362, 257, 10732, 30, 1133, 291, 1269, 364, 724, 11, 291, 362, 257, 51290], 'temperature': 0.0, 'avg_logprob': -0.1815433099236287, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.001062734518200159}, {'id': 238, 'seek': 175862, 'start': 1777.8999999999999, 'end': 1784.8999999999999, 'text': ' choice. An unoptimized code that takes 20 seconds to just load the app and an optimized', 'tokens': [51328, 3922, 13, 1107, 517, 5747, 332, 1602, 3089, 300, 2516, 945, 3949, 281, 445, 3677, 264, 724, 293, 364, 26941, 51678], 'temperature': 0.0, 'avg_logprob': -0.1815433099236287, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.001062734518200159}, {'id': 239, 'seek': 178490, 'start': 1785.9, 'end': 1792.9, 'text': ' code that takes 1 second to load the app. Which one will you use? And when I said 20', 'tokens': [50414, 3089, 300, 2516, 502, 1150, 281, 3677, 264, 724, 13, 3013, 472, 486, 291, 764, 30, 400, 562, 286, 848, 945, 50764], 'temperature': 0.0, 'avg_logprob': -0.23172529538472494, 'compression_ratio': 1.434782608695652, 'no_speech_prob': 0.0006158861215226352}, {'id': 240, 'seek': 178490, 'start': 1793.26, 'end': 1800.26, 'text': ' seconds to 1, I was being very kind to the unoptimized code. The optimizations give you', 'tokens': [50782, 3949, 281, 502, 11, 286, 390, 885, 588, 733, 281, 264, 517, 5747, 332, 1602, 3089, 13, 440, 5028, 14455, 976, 291, 51132], 'temperature': 0.0, 'avg_logprob': -0.23172529538472494, 'compression_ratio': 1.434782608695652, 'no_speech_prob': 0.0006158861215226352}, {'id': 241, 'seek': 178490, 'start': 1801.22, 'end': 1808.22, 'text': ' so much benefits. You just cannot ignore it. Fine. So it is not just dead code elimination.', 'tokens': [51180, 370, 709, 5311, 13, 509, 445, 2644, 11200, 309, 13, 12024, 13, 407, 309, 307, 406, 445, 3116, 3089, 29224, 13, 51530], 'temperature': 0.0, 'avg_logprob': -0.23172529538472494, 'compression_ratio': 1.434782608695652, 'no_speech_prob': 0.0006158861215226352}, {'id': 242, 'seek': 180822, 'start': 1808.22, 'end': 1815.22, 'text': ' Even some simple things like algebraic simplification. If you know that multiplication by 2 is same', 'tokens': [50364, 2754, 512, 2199, 721, 411, 21989, 299, 6883, 3774, 13, 759, 291, 458, 300, 27290, 538, 568, 307, 912, 50714], 'temperature': 0.0, 'avg_logprob': -0.1540673119681222, 'compression_ratio': 1.572972972972973, 'no_speech_prob': 0.0020784863736480474}, {'id': 243, 'seek': 180822, 'start': 1824.02, 'end': 1830.02, 'text': ' as left shift. Left shift is faster than multiplication. Even then there is no guarantee that it will', 'tokens': [51154, 382, 1411, 5513, 13, 16405, 5513, 307, 4663, 813, 27290, 13, 2754, 550, 456, 307, 572, 10815, 300, 309, 486, 51454], 'temperature': 0.0, 'avg_logprob': -0.1540673119681222, 'compression_ratio': 1.572972972972973, 'no_speech_prob': 0.0020784863736480474}, {'id': 244, 'seek': 180822, 'start': 1830.02, 'end': 1837.02, 'text': ' improve the performance. It may lead to some other hazard somewhere, someone else waiting', 'tokens': [51454, 3470, 264, 3389, 13, 467, 815, 1477, 281, 512, 661, 20790, 4079, 11, 1580, 1646, 3806, 51804], 'temperature': 0.0, 'avg_logprob': -0.1540673119681222, 'compression_ratio': 1.572972972972973, 'no_speech_prob': 0.0020784863736480474}, {'id': 245, 'seek': 183702, 'start': 1838.02, 'end': 1845.02, 'text': ' for you, some other impact on cache. The typical goals of the optimization code are speed,', 'tokens': [50414, 337, 291, 11, 512, 661, 2712, 322, 19459, 13, 440, 7476, 5493, 295, 264, 19618, 3089, 366, 3073, 11, 50764], 'temperature': 0.0, 'avg_logprob': -0.17814206385958023, 'compression_ratio': 1.5963855421686748, 'no_speech_prob': 0.0012226757826283574}, {'id': 246, 'seek': 183702, 'start': 1846.02, 'end': 1853.02, 'text': ' space and power, energy and so on. And the interesting part, A does not imply B, B does', 'tokens': [50814, 1901, 293, 1347, 11, 2281, 293, 370, 322, 13, 400, 264, 1880, 644, 11, 316, 775, 406, 33616, 363, 11, 363, 775, 51164], 'temperature': 0.0, 'avg_logprob': -0.17814206385958023, 'compression_ratio': 1.5963855421686748, 'no_speech_prob': 0.0012226757826283574}, {'id': 247, 'seek': 183702, 'start': 1855.1, 'end': 1862.1, 'text': ' not imply C. If you optimize for speed, it may increase the space, it may increase the', 'tokens': [51268, 406, 33616, 383, 13, 759, 291, 19719, 337, 3073, 11, 309, 815, 3488, 264, 1901, 11, 309, 815, 3488, 264, 51618], 'temperature': 0.0, 'avg_logprob': -0.17814206385958023, 'compression_ratio': 1.5963855421686748, 'no_speech_prob': 0.0012226757826283574}, {'id': 248, 'seek': 186210, 'start': 1862.8999999999999, 'end': 1869.8999999999999, 'text': ' size. If you optimize for one, it may impact the other one. Beautiful, right? So which', 'tokens': [50404, 2744, 13, 759, 291, 19719, 337, 472, 11, 309, 815, 2712, 264, 661, 472, 13, 14724, 11, 558, 30, 407, 597, 50754], 'temperature': 0.0, 'avg_logprob': -0.25731351852416995, 'compression_ratio': 1.3053435114503817, 'no_speech_prob': 0.0009104701457545161}, {'id': 249, 'seek': 186210, 'start': 1872.3, 'end': 1879.3, 'text': ' one matters? But I am saying I cannot give you all. Dependent on? Depends on the end', 'tokens': [50874, 472, 7001, 30, 583, 286, 669, 1566, 286, 2644, 976, 291, 439, 13, 4056, 521, 317, 322, 30, 4056, 2581, 322, 264, 917, 51224], 'temperature': 0.0, 'avg_logprob': -0.25731351852416995, 'compression_ratio': 1.3053435114503817, 'no_speech_prob': 0.0009104701457545161}, {'id': 250, 'seek': 187930, 'start': 1879.3, 'end': 1886.3, 'text': ' user. Depends on the specific target you have in mind. Traditionally when we say optimization,', 'tokens': [50364, 4195, 13, 4056, 2581, 322, 264, 2685, 3779, 291, 362, 294, 1575, 13, 22017, 15899, 562, 321, 584, 19618, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.193479249643725, 'compression_ratio': 1.335820895522388, 'no_speech_prob': 0.005510416813194752}, {'id': 251, 'seek': 187930, 'start': 1896.4199999999998, 'end': 1903.4199999999998, 'text': ' we talk about speed. We will mostly focus on speed in our discussion. Sometimes when', 'tokens': [51220, 321, 751, 466, 3073, 13, 492, 486, 5240, 1879, 322, 3073, 294, 527, 5017, 13, 4803, 562, 51570], 'temperature': 0.0, 'avg_logprob': -0.193479249643725, 'compression_ratio': 1.335820895522388, 'no_speech_prob': 0.005510416813194752}, {'id': 252, 'seek': 190342, 'start': 1904.42, 'end': 1911.42, 'text': ' you optimize for A, it may also optimize for B. Sometimes. For example, how does this thing', 'tokens': [50414, 291, 19719, 337, 316, 11, 309, 815, 611, 19719, 337, 363, 13, 4803, 13, 1171, 1365, 11, 577, 775, 341, 551, 50764], 'temperature': 0.0, 'avg_logprob': -0.2154129845755441, 'compression_ratio': 1.5380116959064327, 'no_speech_prob': 0.003281397745013237}, {'id': 253, 'seek': 190342, 'start': 1917.3400000000001, 'end': 1922.94, 'text': ' called loop unrolling? So loop unrolling is nothing but let us say I have a loop that', 'tokens': [51060, 1219, 6367, 517, 18688, 30, 407, 6367, 517, 18688, 307, 1825, 457, 718, 505, 584, 286, 362, 257, 6367, 300, 51340], 'temperature': 0.0, 'avg_logprob': -0.2154129845755441, 'compression_ratio': 1.5380116959064327, 'no_speech_prob': 0.003281397745013237}, {'id': 254, 'seek': 190342, 'start': 1922.94, 'end': 1929.94, 'text': ' goes from say 1 to 100. I will repeat the body say 5 times and execute loop from 1 to', 'tokens': [51340, 1709, 490, 584, 502, 281, 2319, 13, 286, 486, 7149, 264, 1772, 584, 1025, 1413, 293, 14483, 6367, 490, 502, 281, 51690], 'temperature': 0.0, 'avg_logprob': -0.2154129845755441, 'compression_ratio': 1.5380116959064327, 'no_speech_prob': 0.003281397745013237}, {'id': 255, 'seek': 192994, 'start': 1929.94, 'end': 1936.94, 'text': ' 20. I do not need to jump back after every iteration. So it is faster but my size has', 'tokens': [50364, 945, 13, 286, 360, 406, 643, 281, 3012, 646, 934, 633, 24784, 13, 407, 309, 307, 4663, 457, 452, 2744, 575, 50714], 'temperature': 0.0, 'avg_logprob': -0.3472357418226159, 'compression_ratio': 1.4104477611940298, 'no_speech_prob': 0.0014997230609878898}, {'id': 256, 'seek': 192994, 'start': 1941.5800000000002, 'end': 1948.5800000000002, 'text': ' increased. Now when I say look there are optimizations, some optimizations may because one optimization', 'tokens': [50946, 6505, 13, 823, 562, 286, 584, 574, 456, 366, 5028, 14455, 11, 512, 5028, 14455, 815, 570, 472, 19618, 51296], 'temperature': 0.0, 'avg_logprob': -0.3472357418226159, 'compression_ratio': 1.4104477611940298, 'no_speech_prob': 0.0014997230609878898}, {'id': 257, 'seek': 194858, 'start': 1948.58, 'end': 1955.58, 'text': ' some other optimization may get impacted and optimizations may take time and so on.', 'tokens': [50364, 512, 661, 19618, 815, 483, 15653, 293, 5028, 14455, 815, 747, 565, 293, 370, 322, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.3586775779724121, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 0.0041187722235918045}, {'id': 258, 'seek': 194858, 'start': 1965.3799999999999, 'end': 1970.26, 'text': ' Or tomorrow you want to come up with your own optimization. In all these things you', 'tokens': [51204, 1610, 4153, 291, 528, 281, 808, 493, 365, 428, 1065, 19618, 13, 682, 439, 613, 721, 291, 51448], 'temperature': 0.0, 'avg_logprob': -0.3586775779724121, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 0.0041187722235918045}, {'id': 259, 'seek': 194858, 'start': 1970.26, 'end': 1977.26, 'text': ' keep asking whatever the optimization I am coming up with, is it worth it? And I am not', 'tokens': [51448, 1066, 3365, 2035, 264, 19618, 286, 669, 1348, 493, 365, 11, 307, 309, 3163, 309, 30, 400, 286, 669, 406, 51798], 'temperature': 0.0, 'avg_logprob': -0.3586775779724121, 'compression_ratio': 1.624203821656051, 'no_speech_prob': 0.0041187722235918045}, {'id': 260, 'seek': 197858, 'start': 1978.58, 'end': 1983.1399999999999, 'text': ' going to answer that. Then you will ask which optimization should I focus on or what should', 'tokens': [50364, 516, 281, 1867, 300, 13, 1396, 291, 486, 1029, 597, 19618, 820, 286, 1879, 322, 420, 437, 820, 50592], 'temperature': 0.0, 'avg_logprob': -0.25755777813139413, 'compression_ratio': 1.8121827411167513, 'no_speech_prob': 0.0014948674943298101}, {'id': 261, 'seek': 197858, 'start': 1983.1399999999999, 'end': 1990.1399999999999, 'text': ' I optimize? If you are optimizing for speed, you optimize that part which takes more time,', 'tokens': [50592, 286, 19719, 30, 759, 291, 366, 40425, 337, 3073, 11, 291, 19719, 300, 644, 597, 2516, 544, 565, 11, 50942], 'temperature': 0.0, 'avg_logprob': -0.25755777813139413, 'compression_ratio': 1.8121827411167513, 'no_speech_prob': 0.0014948674943298101}, {'id': 262, 'seek': 197858, 'start': 1990.6999999999998, 'end': 1996.6999999999998, 'text': ' whichever is your bottleneck. So in the code which part takes more time? Typically loops', 'tokens': [50970, 24123, 307, 428, 44641, 547, 13, 407, 294, 264, 3089, 597, 644, 2516, 544, 565, 30, 23129, 16121, 51270], 'temperature': 0.0, 'avg_logprob': -0.25755777813139413, 'compression_ratio': 1.8121827411167513, 'no_speech_prob': 0.0014948674943298101}, {'id': 263, 'seek': 197858, 'start': 1996.6999999999998, 'end': 2003.6999999999998, 'text': ' take more time. So make sure you optimize loops. In the code you know that the memory', 'tokens': [51270, 747, 544, 565, 13, 407, 652, 988, 291, 19719, 16121, 13, 682, 264, 3089, 291, 458, 300, 264, 4675, 51620], 'temperature': 0.0, 'avg_logprob': -0.25755777813139413, 'compression_ratio': 1.8121827411167513, 'no_speech_prob': 0.0014948674943298101}, {'id': 264, 'seek': 200370, 'start': 2003.7, 'end': 2010.7, 'text': ' access is slower, much slower compared to CPU. So what is the typical memory to register', 'tokens': [50364, 2105, 307, 14009, 11, 709, 14009, 5347, 281, 13199, 13, 407, 437, 307, 264, 7476, 4675, 281, 7280, 50714], 'temperature': 0.0, 'avg_logprob': -0.3754018666792889, 'compression_ratio': 1.3021582733812949, 'no_speech_prob': 0.0029681657906621695}, {'id': 265, 'seek': 200370, 'start': 2016.8600000000001, 'end': 2023.8600000000001, 'text': ' access ratio? How much are in now NVIDIA machines? So it is kind of in the order of 10 CPUs,', 'tokens': [51022, 2105, 8509, 30, 1012, 709, 366, 294, 586, 426, 3958, 6914, 8379, 30, 407, 309, 307, 733, 295, 294, 264, 1668, 295, 1266, 13199, 82, 11, 51372], 'temperature': 0.0, 'avg_logprob': -0.3754018666792889, 'compression_ratio': 1.3021582733812949, 'no_speech_prob': 0.0029681657906621695}, {'id': 266, 'seek': 203370, 'start': 2033.7, 'end': 2040.22, 'text': ' sometimes even hundreds of times. If the register is X, register access is X then it', 'tokens': [50364, 2171, 754, 6779, 295, 1413, 13, 759, 264, 7280, 307, 1783, 11, 7280, 2105, 307, 1783, 550, 309, 50690], 'temperature': 0.0, 'avg_logprob': -0.25226233987247243, 'compression_ratio': 1.7563451776649746, 'no_speech_prob': 0.002390627982094884}, {'id': 267, 'seek': 203370, 'start': 2040.22, 'end': 2047.22, 'text': ' is kind of if it is prefetched in the cache and all that it is kind of in tens and if', 'tokens': [50690, 307, 733, 295, 498, 309, 307, 18417, 7858, 292, 294, 264, 19459, 293, 439, 300, 309, 307, 733, 295, 294, 10688, 293, 498, 51040], 'temperature': 0.0, 'avg_logprob': -0.25226233987247243, 'compression_ratio': 1.7563451776649746, 'no_speech_prob': 0.002390627982094884}, {'id': 268, 'seek': 203370, 'start': 2049.94, 'end': 2055.6, 'text': ' it is kind of further away from memory then it can keep on increasing. So memory access', 'tokens': [51176, 309, 307, 733, 295, 3052, 1314, 490, 4675, 550, 309, 393, 1066, 322, 5662, 13, 407, 4675, 2105, 51459], 'temperature': 0.0, 'avg_logprob': -0.25226233987247243, 'compression_ratio': 1.7563451776649746, 'no_speech_prob': 0.002390627982094884}, {'id': 269, 'seek': 203370, 'start': 2055.6, 'end': 2060.62, 'text': ' are bad so you want to improve your register allocation so that as many things possible', 'tokens': [51459, 366, 1578, 370, 291, 528, 281, 3470, 428, 7280, 27599, 370, 300, 382, 867, 721, 1944, 51710], 'temperature': 0.0, 'avg_logprob': -0.25226233987247243, 'compression_ratio': 1.7563451776649746, 'no_speech_prob': 0.002390627982094884}, {'id': 270, 'seek': 206062, 'start': 2060.62, 'end': 2067.02, 'text': ' you have you keep them in the registers. Then instruction scheduling we will come to this', 'tokens': [50364, 291, 362, 291, 1066, 552, 294, 264, 38351, 13, 1396, 10951, 29055, 321, 486, 808, 281, 341, 50684], 'temperature': 0.0, 'avg_logprob': -0.1870081092737898, 'compression_ratio': 1.6775700934579438, 'no_speech_prob': 0.0068946960382163525}, {'id': 271, 'seek': 206062, 'start': 2067.02, 'end': 2071.62, 'text': ' later. Instruction scheduling is basically saying in which order you want the instructions', 'tokens': [50684, 1780, 13, 2730, 3826, 29055, 307, 1936, 1566, 294, 597, 1668, 291, 528, 264, 9415, 50914], 'temperature': 0.0, 'avg_logprob': -0.1870081092737898, 'compression_ratio': 1.6775700934579438, 'no_speech_prob': 0.0068946960382163525}, {'id': 272, 'seek': 206062, 'start': 2071.62, 'end': 2078.62, 'text': ' to execute so that they run fast. And the choice of optimizations not only depend upon', 'tokens': [50914, 281, 14483, 370, 300, 436, 1190, 2370, 13, 400, 264, 3922, 295, 5028, 14455, 406, 787, 5672, 3564, 51264], 'temperature': 0.0, 'avg_logprob': -0.1870081092737898, 'compression_ratio': 1.6775700934579438, 'no_speech_prob': 0.0068946960382163525}, {'id': 273, 'seek': 206062, 'start': 2081.62, 'end': 2088.62, 'text': ' our goal of speed and so on, they also depend upon the input program. For instance if there', 'tokens': [51414, 527, 3387, 295, 3073, 293, 370, 322, 11, 436, 611, 5672, 3564, 264, 4846, 1461, 13, 1171, 5197, 498, 456, 51764], 'temperature': 0.0, 'avg_logprob': -0.1870081092737898, 'compression_ratio': 1.6775700934579438, 'no_speech_prob': 0.0068946960382163525}, {'id': 274, 'seek': 209062, 'start': 2090.62, 'end': 2096.46, 'text': ' is a program it is an OO program, object oriented program. How about object orientation?', 'tokens': [50364, 307, 257, 1461, 309, 307, 364, 422, 46, 1461, 11, 2657, 21841, 1461, 13, 1012, 466, 2657, 14764, 30, 50656], 'temperature': 0.0, 'avg_logprob': -0.2847342759035946, 'compression_ratio': 1.613953488372093, 'no_speech_prob': 0.0011299240868538618}, {'id': 275, 'seek': 209062, 'start': 2096.46, 'end': 2102.2999999999997, 'text': ' All of you? Great. Some optimizations like inlining can be very important. Can you guess', 'tokens': [50656, 1057, 295, 291, 30, 3769, 13, 2188, 5028, 14455, 411, 294, 31079, 393, 312, 588, 1021, 13, 1664, 291, 2041, 50948], 'temperature': 0.0, 'avg_logprob': -0.2847342759035946, 'compression_ratio': 1.613953488372093, 'no_speech_prob': 0.0011299240868538618}, {'id': 276, 'seek': 209062, 'start': 2102.2999999999997, 'end': 2109.2999999999997, 'text': ' why? What is inlining? Function inlining? Anyone? Whenever there is a call, wherever', 'tokens': [50948, 983, 30, 708, 307, 294, 31079, 30, 11166, 882, 294, 31079, 30, 14643, 30, 14159, 456, 307, 257, 818, 11, 8660, 51298], 'temperature': 0.0, 'avg_logprob': -0.2847342759035946, 'compression_ratio': 1.613953488372093, 'no_speech_prob': 0.0011299240868538618}, {'id': 277, 'seek': 209062, 'start': 2112.38, 'end': 2119.38, 'text': ' you see a call you replace that call with the function. Did any, has it been already', 'tokens': [51452, 291, 536, 257, 818, 291, 7406, 300, 818, 365, 264, 2445, 13, 2589, 604, 11, 575, 309, 668, 1217, 51802], 'temperature': 0.0, 'avg_logprob': -0.2847342759035946, 'compression_ratio': 1.613953488372093, 'no_speech_prob': 0.0011299240868538618}, {'id': 278, 'seek': 211938, 'start': 2119.38, 'end': 2125.1, 'text': ' covered inlining? No, right? But you have heard of it. Very good. So why is inlining', 'tokens': [50364, 5343, 294, 31079, 30, 883, 11, 558, 30, 583, 291, 362, 2198, 295, 309, 13, 4372, 665, 13, 407, 983, 307, 294, 31079, 50650], 'temperature': 0.0, 'avg_logprob': -0.26155111789703367, 'compression_ratio': 1.4928909952606635, 'no_speech_prob': 0.0014305704971775413}, {'id': 279, 'seek': 211938, 'start': 2125.1, 'end': 2132.1, 'text': ' very important for object oriented programs? Any guesses?', 'tokens': [50650, 588, 1021, 337, 2657, 21841, 4268, 30, 2639, 42703, 30, 51000], 'temperature': 0.0, 'avg_logprob': -0.26155111789703367, 'compression_ratio': 1.4928909952606635, 'no_speech_prob': 0.0014305704971775413}, {'id': 280, 'seek': 211938, 'start': 2132.9, 'end': 2139.9, 'text': ' Typically when you see this magenta colored text in my, when I teach back in my school', 'tokens': [51040, 23129, 562, 291, 536, 341, 2258, 8938, 14332, 2487, 294, 452, 11, 562, 286, 2924, 646, 294, 452, 1395, 51390], 'temperature': 0.0, 'avg_logprob': -0.26155111789703367, 'compression_ratio': 1.4928909952606635, 'no_speech_prob': 0.0014305704971775413}, {'id': 281, 'seek': 211938, 'start': 2141.1800000000003, 'end': 2146.6600000000003, 'text': ' when students answer this question they get half a mark. This half a marks are out of', 'tokens': [51454, 562, 1731, 1867, 341, 1168, 436, 483, 1922, 257, 1491, 13, 639, 1922, 257, 10640, 366, 484, 295, 51728], 'temperature': 0.0, 'avg_logprob': -0.26155111789703367, 'compression_ratio': 1.4928909952606635, 'no_speech_prob': 0.0014305704971775413}, {'id': 282, 'seek': 214666, 'start': 2146.66, 'end': 2153.46, 'text': ' the 100. So without attending any exam you can start earning marks. But these questions', 'tokens': [50364, 264, 2319, 13, 407, 1553, 15862, 604, 1139, 291, 393, 722, 12353, 10640, 13, 583, 613, 1651, 50704], 'temperature': 0.0, 'avg_logprob': -0.3902038652069715, 'compression_ratio': 1.2773722627737227, 'no_speech_prob': 0.00804866198450327}, {'id': 283, 'seek': 214666, 'start': 2153.46, 'end': 2160.46, 'text': ' are also very difficult to answer. Not easy. You have to think. Yes.', 'tokens': [50704, 366, 611, 588, 2252, 281, 1867, 13, 1726, 1858, 13, 509, 362, 281, 519, 13, 1079, 13, 51054], 'temperature': 0.0, 'avg_logprob': -0.3902038652069715, 'compression_ratio': 1.2773722627737227, 'no_speech_prob': 0.00804866198450327}, {'id': 284, 'seek': 214666, 'start': 2161.46, 'end': 2168.46, 'text': ' Inheritance. Okay.', 'tokens': [51104, 682, 511, 270, 719, 13, 1033, 13, 51454], 'temperature': 0.0, 'avg_logprob': -0.3902038652069715, 'compression_ratio': 1.2773722627737227, 'no_speech_prob': 0.00804866198450327}, {'id': 285, 'seek': 216846, 'start': 2168.98, 'end': 2175.98, 'text': ' Copy of? All of them, let us say at least will have', 'tokens': [50390, 25653, 295, 30, 1057, 295, 552, 11, 718, 505, 584, 412, 1935, 486, 362, 50740], 'temperature': 0.0, 'avg_logprob': -0.3901816322689965, 'compression_ratio': 1.2083333333333333, 'no_speech_prob': 0.03189254179596901}, {'id': 286, 'seek': 216846, 'start': 2180.38, 'end': 2187.38, 'text': ' access to those features. Yeah. Jumping back. What do you mean by jumping back? In the parent', 'tokens': [50960, 2105, 281, 729, 4122, 13, 865, 13, 18697, 278, 646, 13, 708, 360, 291, 914, 538, 11233, 646, 30, 682, 264, 2596, 51310], 'temperature': 0.0, 'avg_logprob': -0.3901816322689965, 'compression_ratio': 1.2083333333333333, 'no_speech_prob': 0.03189254179596901}, {'id': 287, 'seek': 218738, 'start': 2187.38, 'end': 2194.38, 'text': ' class let us say. Yeah. When they go back there? One minute, let me finish. Today at', 'tokens': [50364, 1508, 718, 505, 584, 13, 865, 13, 1133, 436, 352, 646, 456, 30, 1485, 3456, 11, 718, 385, 2413, 13, 2692, 412, 50714], 'temperature': 0.0, 'avg_logprob': -0.3682437309852013, 'compression_ratio': 1.0120481927710843, 'no_speech_prob': 0.017953433096408844}, {'id': 288, 'seek': 219438, 'start': 2194.38, 'end': 2201.38, 'text': ' the end of the class, whenever the class ends, will those of you who are interested,', 'tokens': [50364, 264, 917, 295, 264, 1508, 11, 5699, 264, 1508, 5314, 11, 486, 729, 295, 291, 567, 366, 3102, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.29543360419895337, 'compression_ratio': 1.1830985915492958, 'no_speech_prob': 0.08021824061870575}, {'id': 289, 'seek': 220138, 'start': 2201.38, 'end': 2208.38, 'text': ' I can spend a bit of time on how object oriented programs get translated. How they get, how', 'tokens': [50364, 286, 393, 3496, 257, 857, 295, 565, 322, 577, 2657, 21841, 4268, 483, 16805, 13, 1012, 436, 483, 11, 577, 50714], 'temperature': 0.0, 'avg_logprob': -0.28464223941167194, 'compression_ratio': 1.123456790123457, 'no_speech_prob': 0.020314613357186317}, {'id': 290, 'seek': 220838, 'start': 2208.38, 'end': 2215.38, 'text': ' they run. You do not go to up up up. You do not do that. You do not have to. It is', 'tokens': [50364, 436, 1190, 13, 509, 360, 406, 352, 281, 493, 493, 493, 13, 509, 360, 406, 360, 300, 13, 509, 360, 406, 362, 281, 13, 467, 307, 50714], 'temperature': 0.0, 'avg_logprob': -0.27138576507568357, 'compression_ratio': 1.3442622950819672, 'no_speech_prob': 0.03728267177939415}, {'id': 291, 'seek': 221538, 'start': 2215.38, 'end': 2242.78, 'text': ' a common, see it is how we see it. When we look at the code we say okay is the function', 'tokens': [50364, 257, 2689, 11, 536, 309, 307, 577, 321, 536, 309, 13, 1133, 321, 574, 412, 264, 3089, 321, 584, 1392, 307, 264, 2445, 51734], 'temperature': 0.0, 'avg_logprob': -0.25927248707524053, 'compression_ratio': 1.12987012987013, 'no_speech_prob': 0.08993686735630035}, {'id': 292, 'seek': 224278, 'start': 2242.78, 'end': 2247.6600000000003, 'text': ' defined in my class? No. Then go to the parent class. If it is not there, go to the parent', 'tokens': [50364, 7642, 294, 452, 1508, 30, 883, 13, 1396, 352, 281, 264, 2596, 1508, 13, 759, 309, 307, 406, 456, 11, 352, 281, 264, 2596, 50608], 'temperature': 0.0, 'avg_logprob': -0.22106919406859343, 'compression_ratio': 1.6556776556776556, 'no_speech_prob': 0.03825414925813675}, {'id': 293, 'seek': 224278, 'start': 2247.6600000000003, 'end': 2254.6600000000003, 'text': ' class. It is so transferred it is not implemented that way. I am happy you brought it up. Remind', 'tokens': [50608, 1508, 13, 467, 307, 370, 15809, 309, 307, 406, 12270, 300, 636, 13, 286, 669, 2055, 291, 3038, 309, 493, 13, 4080, 471, 50958], 'temperature': 0.0, 'avg_logprob': -0.22106919406859343, 'compression_ratio': 1.6556776556776556, 'no_speech_prob': 0.03825414925813675}, {'id': 294, 'seek': 224278, 'start': 2254.6600000000003, 'end': 2259.78, 'text': ' me at the end of the class we will talk about it. If you have any, I do not want to hold', 'tokens': [50958, 385, 412, 264, 917, 295, 264, 1508, 321, 486, 751, 466, 309, 13, 759, 291, 362, 604, 11, 286, 360, 406, 528, 281, 1797, 51214], 'temperature': 0.0, 'avg_logprob': -0.22106919406859343, 'compression_ratio': 1.6556776556776556, 'no_speech_prob': 0.03825414925813675}, {'id': 295, 'seek': 224278, 'start': 2259.78, 'end': 2265.1800000000003, 'text': ' up everyone when they are completely tired. So those who are asking questions they can', 'tokens': [51214, 493, 1518, 562, 436, 366, 2584, 5868, 13, 407, 729, 567, 366, 3365, 1651, 436, 393, 51484], 'temperature': 0.0, 'avg_logprob': -0.22106919406859343, 'compression_ratio': 1.6556776556776556, 'no_speech_prob': 0.03825414925813675}, {'id': 296, 'seek': 224278, 'start': 2265.1800000000003, 'end': 2272.1800000000003, 'text': ' stay longer. Okay. Yeah. Why do we need, why is inlining very important for OO programs?', 'tokens': [51484, 1754, 2854, 13, 1033, 13, 865, 13, 1545, 360, 321, 643, 11, 983, 307, 294, 31079, 588, 1021, 337, 422, 46, 4268, 30, 51834], 'temperature': 0.0, 'avg_logprob': -0.22106919406859343, 'compression_ratio': 1.6556776556776556, 'no_speech_prob': 0.03825414925813675}, {'id': 297, 'seek': 227278, 'start': 2272.78, 'end': 2298.86, 'text': ' No, yeah, yeah, hands up. So what you are saying is if we inline, if you do not inline,', 'tokens': [50364, 883, 11, 1338, 11, 1338, 11, 2377, 493, 13, 407, 437, 291, 366, 1566, 307, 498, 321, 294, 1889, 11, 498, 291, 360, 406, 294, 1889, 11, 51668], 'temperature': 0.0, 'avg_logprob': -0.5301154967277281, 'compression_ratio': 1.144736842105263, 'no_speech_prob': 0.22724848985671997}, {'id': 298, 'seek': 229886, 'start': 2299.86, 'end': 2307.1800000000003, 'text': ' call. So I have to push my local variables onto the stack. Go, start executing there.', 'tokens': [50414, 818, 13, 407, 286, 362, 281, 2944, 452, 2654, 9102, 3911, 264, 8630, 13, 1037, 11, 722, 32368, 456, 13, 50780], 'temperature': 0.0, 'avg_logprob': -0.21363037109375, 'compression_ratio': 1.4725274725274726, 'no_speech_prob': 0.47523409128189087}, {'id': 299, 'seek': 229886, 'start': 2307.1800000000003, 'end': 2313.38, 'text': ' Come back, undo and all that. I mean pop up from the stack and all that. Good. But that', 'tokens': [50780, 2492, 646, 11, 23779, 293, 439, 300, 13, 286, 914, 1665, 493, 490, 264, 8630, 293, 439, 300, 13, 2205, 13, 583, 300, 51090], 'temperature': 0.0, 'avg_logprob': -0.21363037109375, 'compression_ratio': 1.4725274725274726, 'no_speech_prob': 0.47523409128189087}, {'id': 300, 'seek': 229886, 'start': 2313.38, 'end': 2323.38, 'text': ' is true for every time you inline. Why only OO? What you said holds the advantage of inlining.', 'tokens': [51090, 307, 2074, 337, 633, 565, 291, 294, 1889, 13, 1545, 787, 422, 46, 30, 708, 291, 848, 9190, 264, 5002, 295, 294, 31079, 13, 51590], 'temperature': 0.0, 'avg_logprob': -0.21363037109375, 'compression_ratio': 1.4725274725274726, 'no_speech_prob': 0.47523409128189087}, {'id': 301, 'seek': 232338, 'start': 2324.38, 'end': 2331.38, 'text': ' I am saying why when I said OO programs inlining is important, why OO programs inlining is', 'tokens': [50414, 286, 669, 1566, 983, 562, 286, 848, 422, 46, 4268, 294, 31079, 307, 1021, 11, 983, 422, 46, 4268, 294, 31079, 307, 50764], 'temperature': 0.0, 'avg_logprob': -0.28002210344587053, 'compression_ratio': 1.5917159763313609, 'no_speech_prob': 0.07992969453334808}, {'id': 302, 'seek': 232338, 'start': 2331.5, 'end': 2338.5, 'text': ' more important, very important? Multiple objects of the same class. Okay. Not sure. Not sure.', 'tokens': [50770, 544, 1021, 11, 588, 1021, 30, 40056, 6565, 295, 264, 912, 1508, 13, 1033, 13, 1726, 988, 13, 1726, 988, 13, 51120], 'temperature': 0.0, 'avg_logprob': -0.28002210344587053, 'compression_ratio': 1.5917159763313609, 'no_speech_prob': 0.07992969453334808}, {'id': 303, 'seek': 232338, 'start': 2346.26, 'end': 2352.62, 'text': ' By the way, just one second. Those of you who are using the laptop to anything other', 'tokens': [51508, 3146, 264, 636, 11, 445, 472, 1150, 13, 3950, 295, 291, 567, 366, 1228, 264, 10732, 281, 1340, 661, 51826], 'temperature': 0.0, 'avg_logprob': -0.28002210344587053, 'compression_ratio': 1.5917159763313609, 'no_speech_prob': 0.07992969453334808}, {'id': 304, 'seek': 235262, 'start': 2352.62, 'end': 2359.62, 'text': ' than take notes, I strongly suggest please close the laptops. Because some of you may', 'tokens': [50364, 813, 747, 5570, 11, 286, 10613, 3402, 1767, 1998, 264, 27642, 13, 1436, 512, 295, 291, 815, 50714], 'temperature': 0.0, 'avg_logprob': -0.20298417792262802, 'compression_ratio': 1.5955555555555556, 'no_speech_prob': 0.0026279333978891373}, {'id': 305, 'seek': 235262, 'start': 2360.38, 'end': 2367.38, 'text': ' be, do you have internet here? Yeah, so some of you may be using it for different purposes', 'tokens': [50752, 312, 11, 360, 291, 362, 4705, 510, 30, 865, 11, 370, 512, 295, 291, 815, 312, 1228, 309, 337, 819, 9932, 51102], 'temperature': 0.0, 'avg_logprob': -0.20298417792262802, 'compression_ratio': 1.5955555555555556, 'no_speech_prob': 0.0026279333978891373}, {'id': 306, 'seek': 235262, 'start': 2368.2999999999997, 'end': 2375.2999999999997, 'text': ' and it does two harms. One, to yourself that you are probably missing out not on the lecture', 'tokens': [51148, 293, 309, 775, 732, 48505, 13, 1485, 11, 281, 1803, 300, 291, 366, 1391, 5361, 484, 406, 322, 264, 7991, 51498], 'temperature': 0.0, 'avg_logprob': -0.20298417792262802, 'compression_ratio': 1.5955555555555556, 'no_speech_prob': 0.0026279333978891373}, {'id': 307, 'seek': 235262, 'start': 2377.22, 'end': 2381.8199999999997, 'text': ' but an interesting discussion and questions that your friends are bringing up. And number', 'tokens': [51594, 457, 364, 1880, 5017, 293, 1651, 300, 428, 1855, 366, 5062, 493, 13, 400, 1230, 51824], 'temperature': 0.0, 'avg_logprob': -0.20298417792262802, 'compression_ratio': 1.5955555555555556, 'no_speech_prob': 0.0026279333978891373}, {'id': 308, 'seek': 238182, 'start': 2381.82, 'end': 2388.82, 'text': ' two, you are distracting your neighbors. If you are taking notes or typing notes, that', 'tokens': [50364, 732, 11, 291, 366, 36689, 428, 12512, 13, 759, 291, 366, 1940, 5570, 420, 18444, 5570, 11, 300, 50714], 'temperature': 0.0, 'avg_logprob': -0.28309611950890495, 'compression_ratio': 1.48, 'no_speech_prob': 0.001699691521935165}, {'id': 309, 'seek': 238182, 'start': 2388.82, 'end': 2395.82, 'text': ' is perfectly fine. Why do we need inlining in OO programs?', 'tokens': [50714, 307, 6239, 2489, 13, 1545, 360, 321, 643, 294, 31079, 294, 422, 46, 4268, 30, 51064], 'temperature': 0.0, 'avg_logprob': -0.28309611950890495, 'compression_ratio': 1.48, 'no_speech_prob': 0.001699691521935165}, {'id': 310, 'seek': 238182, 'start': 2403.1400000000003, 'end': 2410.1400000000003, 'text': ' We call up methods often even in C programs or do we do more in OO programs?', 'tokens': [51430, 492, 818, 493, 7150, 2049, 754, 294, 383, 4268, 420, 360, 321, 360, 544, 294, 422, 46, 4268, 30, 51780], 'temperature': 0.0, 'avg_logprob': -0.28309611950890495, 'compression_ratio': 1.48, 'no_speech_prob': 0.001699691521935165}, {'id': 311, 'seek': 241182, 'start': 2412.38, 'end': 2419.38, 'text': ' Small things, good point. Small things like what?', 'tokens': [50392, 15287, 721, 11, 665, 935, 13, 15287, 721, 411, 437, 30, 50742], 'temperature': 0.0, 'avg_logprob': -0.2908831203685087, 'compression_ratio': 1.493421052631579, 'no_speech_prob': 0.0031719005201011896}, {'id': 312, 'seek': 241182, 'start': 2419.38, 'end': 2426.38, 'text': ' Perfect. See in object oriented languages, you have this typical thing of encapsulation.', 'tokens': [50742, 10246, 13, 3008, 294, 2657, 21841, 8650, 11, 291, 362, 341, 7476, 551, 295, 38745, 2776, 13, 51092], 'temperature': 0.0, 'avg_logprob': -0.2908831203685087, 'compression_ratio': 1.493421052631579, 'no_speech_prob': 0.0031719005201011896}, {'id': 313, 'seek': 241182, 'start': 2432.5, 'end': 2437.6200000000003, 'text': ' Some private variables here, some variables which are hidden inside an object somewhere.', 'tokens': [51398, 2188, 4551, 9102, 510, 11, 512, 9102, 597, 366, 7633, 1854, 364, 2657, 4079, 13, 51654], 'temperature': 0.0, 'avg_logprob': -0.2908831203685087, 'compression_ratio': 1.493421052631579, 'no_speech_prob': 0.0031719005201011896}, {'id': 314, 'seek': 243762, 'start': 2437.62, 'end': 2444.62, 'text': ' You do not directly write to the field. You say okay, do a set, do a get. Even it is a', 'tokens': [50364, 509, 360, 406, 3838, 2464, 281, 264, 2519, 13, 509, 584, 1392, 11, 360, 257, 992, 11, 360, 257, 483, 13, 2754, 309, 307, 257, 50714], 'temperature': 0.0, 'avg_logprob': -0.2239869954634686, 'compression_ratio': 1.592274678111588, 'no_speech_prob': 0.005199082661420107}, {'id': 315, 'seek': 243762, 'start': 2444.62, 'end': 2451.62, 'text': ' very tiny method like our friend said, I have to store all of it, do a jump, return it immediately.', 'tokens': [50714, 588, 5870, 3170, 411, 527, 1277, 848, 11, 286, 362, 281, 3531, 439, 295, 309, 11, 360, 257, 3012, 11, 2736, 309, 4258, 13, 51064], 'temperature': 0.0, 'avg_logprob': -0.2239869954634686, 'compression_ratio': 1.592274678111588, 'no_speech_prob': 0.005199082661420107}, {'id': 316, 'seek': 243762, 'start': 2455.5, 'end': 2462.38, 'text': ' Looks like a lot of overheads. So inlining is very important. So if you have some language', 'tokens': [51258, 10027, 411, 257, 688, 295, 19922, 82, 13, 407, 294, 31079, 307, 588, 1021, 13, 407, 498, 291, 362, 512, 2856, 51602], 'temperature': 0.0, 'avg_logprob': -0.2239869954634686, 'compression_ratio': 1.592274678111588, 'no_speech_prob': 0.005199082661420107}, {'id': 317, 'seek': 243762, 'start': 2462.38, 'end': 2467.1, 'text': ' corresponding to that language, you will do, you will make sure certain type of optimizations', 'tokens': [51602, 11760, 281, 300, 2856, 11, 291, 486, 360, 11, 291, 486, 652, 988, 1629, 2010, 295, 5028, 14455, 51838], 'temperature': 0.0, 'avg_logprob': -0.2239869954634686, 'compression_ratio': 1.592274678111588, 'no_speech_prob': 0.005199082661420107}, {'id': 318, 'seek': 246710, 'start': 2467.1, 'end': 2474.1, 'text': ' are there. If you have code the programs where you write lot of recursive, where lot of recursive', 'tokens': [50364, 366, 456, 13, 759, 291, 362, 3089, 264, 4268, 689, 291, 2464, 688, 295, 20560, 488, 11, 689, 688, 295, 20560, 488, 50714], 'temperature': 0.0, 'avg_logprob': -0.2525768866905799, 'compression_ratio': 1.7483870967741935, 'no_speech_prob': 0.005691790487617254}, {'id': 319, 'seek': 246710, 'start': 2479.7, 'end': 2486.7, 'text': ' functions, then you want to definitely have something called tail call optimization. Heard', 'tokens': [50994, 6828, 11, 550, 291, 528, 281, 2138, 362, 746, 1219, 6838, 818, 19618, 13, 634, 515, 51344], 'temperature': 0.0, 'avg_logprob': -0.2525768866905799, 'compression_ratio': 1.7483870967741935, 'no_speech_prob': 0.005691790487617254}, {'id': 320, 'seek': 246710, 'start': 2486.7, 'end': 2493.7, 'text': ' of this thing called tail call optimization? What is that? Yes, what is tail call?', 'tokens': [51344, 295, 341, 551, 1219, 6838, 818, 19618, 30, 708, 307, 300, 30, 1079, 11, 437, 307, 6838, 818, 30, 51694], 'temperature': 0.0, 'avg_logprob': -0.2525768866905799, 'compression_ratio': 1.7483870967741935, 'no_speech_prob': 0.005691790487617254}, {'id': 321, 'seek': 249370, 'start': 2493.7, 'end': 2500.7, 'text': ' Tail call is the call which is present at the end of the function. After that I have', 'tokens': [50364, 46074, 818, 307, 264, 818, 597, 307, 1974, 412, 264, 917, 295, 264, 2445, 13, 2381, 300, 286, 362, 50714], 'temperature': 0.0, 'avg_logprob': -0.21158714294433595, 'compression_ratio': 1.5987654320987654, 'no_speech_prob': 0.0022459374740719795}, {'id': 322, 'seek': 249370, 'start': 2504.9399999999996, 'end': 2511.9399999999996, 'text': ' nothing more to do. So when there is a tail call, why should I make a call? Every time', 'tokens': [50926, 1825, 544, 281, 360, 13, 407, 562, 456, 307, 257, 6838, 818, 11, 983, 820, 286, 652, 257, 818, 30, 2048, 565, 51276], 'temperature': 0.0, 'avg_logprob': -0.21158714294433595, 'compression_ratio': 1.5987654320987654, 'no_speech_prob': 0.0022459374740719795}, {'id': 323, 'seek': 249370, 'start': 2511.9399999999996, 'end': 2517.74, 'text': ' there is a call, I have to save and then do something more and then come back, pop back', 'tokens': [51276, 456, 307, 257, 818, 11, 286, 362, 281, 3155, 293, 550, 360, 746, 544, 293, 550, 808, 646, 11, 1665, 646, 51566], 'temperature': 0.0, 'avg_logprob': -0.21158714294433595, 'compression_ratio': 1.5987654320987654, 'no_speech_prob': 0.0022459374740719795}, {'id': 324, 'seek': 251774, 'start': 2517.74, 'end': 2524.74, 'text': ' and now if there is a tail call, I can directly jump there. It can be a simple jump. And then', 'tokens': [50364, 293, 586, 498, 456, 307, 257, 6838, 818, 11, 286, 393, 3838, 3012, 456, 13, 467, 393, 312, 257, 2199, 3012, 13, 400, 550, 50714], 'temperature': 0.0, 'avg_logprob': -0.2072157271920818, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.002315511927008629}, {'id': 325, 'seek': 251774, 'start': 2524.74, 'end': 2531.74, 'text': ' at the end of the tail call, I do not need to return to me. You can return to my caller.', 'tokens': [50714, 412, 264, 917, 295, 264, 6838, 818, 11, 286, 360, 406, 643, 281, 2736, 281, 385, 13, 509, 393, 2736, 281, 452, 48324, 13, 51064], 'temperature': 0.0, 'avg_logprob': -0.2072157271920818, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.002315511927008629}, {'id': 326, 'seek': 251774, 'start': 2535.62, 'end': 2541.8999999999996, 'text': ' You can even think of an optimization where recursion can be replaced with loops. Those', 'tokens': [51258, 509, 393, 754, 519, 295, 364, 19618, 689, 20560, 313, 393, 312, 10772, 365, 16121, 13, 3950, 51572], 'temperature': 0.0, 'avg_logprob': -0.2072157271920818, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.002315511927008629}, {'id': 327, 'seek': 254190, 'start': 2541.9, 'end': 2548.9, 'text': ' of you who care, every, but even the recursion and loops are equivalent. There is no difference', 'tokens': [50364, 295, 291, 567, 1127, 11, 633, 11, 457, 754, 264, 20560, 313, 293, 16121, 366, 10344, 13, 821, 307, 572, 2649, 50714], 'temperature': 0.0, 'avg_logprob': -0.22679467327826847, 'compression_ratio': 1.8132295719844358, 'no_speech_prob': 0.003943948075175285}, {'id': 328, 'seek': 254190, 'start': 2549.58, 'end': 2555.94, 'text': ' in terms of power. So when we talk about optimizations, there are three types of optimizations you', 'tokens': [50748, 294, 2115, 295, 1347, 13, 407, 562, 321, 751, 466, 5028, 14455, 11, 456, 366, 1045, 3467, 295, 5028, 14455, 291, 51066], 'temperature': 0.0, 'avg_logprob': -0.22679467327826847, 'compression_ratio': 1.8132295719844358, 'no_speech_prob': 0.003943948075175285}, {'id': 329, 'seek': 254190, 'start': 2555.94, 'end': 2560.86, 'text': ' can overall think of. One is local optimizations which are within basic block. What is a basic', 'tokens': [51066, 393, 4787, 519, 295, 13, 1485, 307, 2654, 5028, 14455, 597, 366, 1951, 3875, 3461, 13, 708, 307, 257, 3875, 51312], 'temperature': 0.0, 'avg_logprob': -0.22679467327826847, 'compression_ratio': 1.8132295719844358, 'no_speech_prob': 0.003943948075175285}, {'id': 330, 'seek': 254190, 'start': 2560.86, 'end': 2566.54, 'text': ' block? It is a sequential piece of, it is a code where there are no jumps in between.', 'tokens': [51312, 3461, 30, 467, 307, 257, 42881, 2522, 295, 11, 309, 307, 257, 3089, 689, 456, 366, 572, 16704, 294, 1296, 13, 51596], 'temperature': 0.0, 'avg_logprob': -0.22679467327826847, 'compression_ratio': 1.8132295719844358, 'no_speech_prob': 0.003943948075175285}, {'id': 331, 'seek': 254190, 'start': 2566.54, 'end': 2571.62, 'text': ' So you can think of local optimizations, intra procedural, that is you optimize within one', 'tokens': [51596, 407, 291, 393, 519, 295, 2654, 5028, 14455, 11, 43358, 43951, 11, 300, 307, 291, 19719, 1951, 472, 51850], 'temperature': 0.0, 'avg_logprob': -0.22679467327826847, 'compression_ratio': 1.8132295719844358, 'no_speech_prob': 0.003943948075175285}, {'id': 332, 'seek': 257162, 'start': 2571.62, 'end': 2577.22, 'text': ' procedure and do not know anything about other procedures or inter procedural optimizations', 'tokens': [50364, 10747, 293, 360, 406, 458, 1340, 466, 661, 13846, 420, 728, 43951, 5028, 14455, 50644], 'temperature': 0.0, 'avg_logprob': -0.1953561682450144, 'compression_ratio': 2.075675675675676, 'no_speech_prob': 0.0003919641603715718}, {'id': 333, 'seek': 257162, 'start': 2577.22, 'end': 2584.22, 'text': ' which impact across procedures. You can even think of optimizations based on their positioning.', 'tokens': [50644, 597, 2712, 2108, 13846, 13, 509, 393, 754, 519, 295, 5028, 14455, 2361, 322, 641, 26381, 13, 50994], 'temperature': 0.0, 'avg_logprob': -0.1953561682450144, 'compression_ratio': 2.075675675675676, 'no_speech_prob': 0.0003919641603715718}, {'id': 334, 'seek': 257162, 'start': 2586.62, 'end': 2593.62, 'text': ' High level optimizations or low level optimizations. High level optimizations is optimizations which', 'tokens': [51114, 5229, 1496, 5028, 14455, 420, 2295, 1496, 5028, 14455, 13, 5229, 1496, 5028, 14455, 307, 5028, 14455, 597, 51464], 'temperature': 0.0, 'avg_logprob': -0.1953561682450144, 'compression_ratio': 2.075675675675676, 'no_speech_prob': 0.0003919641603715718}, {'id': 335, 'seek': 257162, 'start': 2593.62, 'end': 2600.62, 'text': ' are based on the program structure and typically they are done first in the optimization chain.', 'tokens': [51464, 366, 2361, 322, 264, 1461, 3877, 293, 5850, 436, 366, 1096, 700, 294, 264, 19618, 5021, 13, 51814], 'temperature': 0.0, 'avg_logprob': -0.1953561682450144, 'compression_ratio': 2.075675675675676, 'no_speech_prob': 0.0003919641603715718}, {'id': 336, 'seek': 260062, 'start': 2600.7799999999997, 'end': 2607.7799999999997, 'text': ' Most of these high level optimizations are machine independent. You have low level optimizations', 'tokens': [50372, 4534, 295, 613, 1090, 1496, 5028, 14455, 366, 3479, 6695, 13, 509, 362, 2295, 1496, 5028, 14455, 50722], 'temperature': 0.0, 'avg_logprob': -0.21270000751201923, 'compression_ratio': 1.6766467065868262, 'no_speech_prob': 0.0005032728658989072}, {'id': 337, 'seek': 260062, 'start': 2608.2999999999997, 'end': 2612.62, 'text': ' which are typically called the mid or low level which work on mid and low level IR.', 'tokens': [50748, 597, 366, 5850, 1219, 264, 2062, 420, 2295, 1496, 597, 589, 322, 2062, 293, 2295, 1496, 16486, 13, 50964], 'temperature': 0.0, 'avg_logprob': -0.21270000751201923, 'compression_ratio': 1.6766467065868262, 'no_speech_prob': 0.0005032728658989072}, {'id': 338, 'seek': 260062, 'start': 2612.62, 'end': 2619.62, 'text': ' They do not need much of the program structure. I think Gowind is covering low level optimizations.', 'tokens': [50964, 814, 360, 406, 643, 709, 295, 264, 1461, 3877, 13, 286, 519, 460, 305, 471, 307, 10322, 2295, 1496, 5028, 14455, 13, 51314], 'temperature': 0.0, 'avg_logprob': -0.21270000751201923, 'compression_ratio': 1.6766467065868262, 'no_speech_prob': 0.0005032728658989072}, {'id': 339, 'seek': 261962, 'start': 2619.62, 'end': 2626.62, 'text': ' That is coming up next. I mean later and I will be covering on high level optimizations.', 'tokens': [50364, 663, 307, 1348, 493, 958, 13, 286, 914, 1780, 293, 286, 486, 312, 10322, 322, 1090, 1496, 5028, 14455, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.26310508251190184, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.005728691816329956}, {'id': 340, 'seek': 261962, 'start': 2631.06, 'end': 2636.42, 'text': ' So a brief this thing between machine independent and machine dependent optimizations. These', 'tokens': [50936, 407, 257, 5353, 341, 551, 1296, 3479, 6695, 293, 3479, 12334, 5028, 14455, 13, 1981, 51204], 'temperature': 0.0, 'avg_logprob': -0.26310508251190184, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.005728691816329956}, {'id': 341, 'seek': 261962, 'start': 2636.42, 'end': 2642.3399999999997, 'text': ' machine independent optimizations, they are applicable across a broad range of machines.', 'tokens': [51204, 3479, 6695, 5028, 14455, 11, 436, 366, 21142, 2108, 257, 4152, 3613, 295, 8379, 13, 51500], 'temperature': 0.0, 'avg_logprob': -0.26310508251190184, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.005728691816329956}, {'id': 342, 'seek': 261962, 'start': 2642.3399999999997, 'end': 2648.38, 'text': ' So if I am saying optimization, this is applicable not just on machine X but maybe a class of', 'tokens': [51500, 407, 498, 286, 669, 1566, 19618, 11, 341, 307, 21142, 406, 445, 322, 3479, 1783, 457, 1310, 257, 1508, 295, 51802], 'temperature': 0.0, 'avg_logprob': -0.26310508251190184, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.005728691816329956}, {'id': 343, 'seek': 264838, 'start': 2648.46, 'end': 2655.46, 'text': ' machines. Not necessarily the whole world but much broader. I mean I could think of', 'tokens': [50368, 8379, 13, 1726, 4725, 264, 1379, 1002, 457, 709, 13227, 13, 286, 914, 286, 727, 519, 295, 50718], 'temperature': 0.0, 'avg_logprob': -0.2774709065755208, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.0005697879823856056}, {'id': 344, 'seek': 264838, 'start': 2657.54, 'end': 2663.86, 'text': ' some code. Let us say there is some code which is executed very frequently. I move it to', 'tokens': [50822, 512, 3089, 13, 961, 505, 584, 456, 307, 512, 3089, 597, 307, 17577, 588, 10374, 13, 286, 1286, 309, 281, 51138], 'temperature': 0.0, 'avg_logprob': -0.2774709065755208, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.0005697879823856056}, {'id': 345, 'seek': 264838, 'start': 2663.86, 'end': 2670.86, 'text': ' a less frequently executed code. That is machine independent. I removing redundant code, right.', 'tokens': [51138, 257, 1570, 10374, 17577, 3089, 13, 663, 307, 3479, 6695, 13, 286, 12720, 40997, 3089, 11, 558, 13, 51488], 'temperature': 0.0, 'avg_logprob': -0.2774709065755208, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.0005697879823856056}, {'id': 346, 'seek': 267086, 'start': 2671.26, 'end': 2678.26, 'text': ' Dead code elimination. Dead code elimination can be done at many phases but a high level.', 'tokens': [50384, 12550, 3089, 29224, 13, 12550, 3089, 29224, 393, 312, 1096, 412, 867, 18764, 457, 257, 1090, 1496, 13, 50734], 'temperature': 0.0, 'avg_logprob': -0.2610345491221253, 'compression_ratio': 1.7920792079207921, 'no_speech_prob': 0.004605322610586882}, {'id': 347, 'seek': 267086, 'start': 2682.1, 'end': 2685.6600000000003, 'text': ' The machine independent optimization sometimes themselves may not do much but they will create', 'tokens': [50926, 440, 3479, 6695, 19618, 2171, 2969, 815, 406, 360, 709, 457, 436, 486, 1884, 51104], 'temperature': 0.0, 'avg_logprob': -0.2610345491221253, 'compression_ratio': 1.7920792079207921, 'no_speech_prob': 0.004605322610586882}, {'id': 348, 'seek': 267086, 'start': 2685.6600000000003, 'end': 2690.98, 'text': ' opportunities for the machine dependent part. We will come to that. The machine dependent', 'tokens': [51104, 4786, 337, 264, 3479, 12334, 644, 13, 492, 486, 808, 281, 300, 13, 440, 3479, 12334, 51370], 'temperature': 0.0, 'avg_logprob': -0.2610345491221253, 'compression_ratio': 1.7920792079207921, 'no_speech_prob': 0.004605322610586882}, {'id': 349, 'seek': 267086, 'start': 2690.98, 'end': 2696.86, 'text': ' optimizations typically they capitalize on machine specific properties. So they improve', 'tokens': [51370, 5028, 14455, 5850, 436, 48114, 322, 3479, 2685, 7221, 13, 407, 436, 3470, 51664], 'temperature': 0.0, 'avg_logprob': -0.2610345491221253, 'compression_ratio': 1.7920792079207921, 'no_speech_prob': 0.004605322610586882}, {'id': 350, 'seek': 269686, 'start': 2696.86, 'end': 2701.1400000000003, 'text': ' the mapping of IR onto machine. They can reduce the strength of the instructions, use', 'tokens': [50364, 264, 18350, 295, 16486, 3911, 3479, 13, 814, 393, 5407, 264, 3800, 295, 264, 9415, 11, 764, 50578], 'temperature': 0.0, 'avg_logprob': -0.29960065274625214, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.0021769762970507145}, {'id': 351, 'seek': 269686, 'start': 2701.1400000000003, 'end': 2708.1400000000003, 'text': ' more efficient instructions which are given by a specific hardware, right. You can think', 'tokens': [50578, 544, 7148, 9415, 597, 366, 2212, 538, 257, 2685, 8837, 11, 558, 13, 509, 393, 519, 50928], 'temperature': 0.0, 'avg_logprob': -0.29960065274625214, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.0021769762970507145}, {'id': 352, 'seek': 269686, 'start': 2708.82, 'end': 2715.82, 'text': ' of using exotic hardware instructions to take advantage of the hardware properties, right.', 'tokens': [50962, 295, 1228, 27063, 8837, 9415, 281, 747, 5002, 295, 264, 8837, 7221, 11, 558, 13, 51312], 'temperature': 0.0, 'avg_logprob': -0.29960065274625214, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.0021769762970507145}, {'id': 353, 'seek': 269686, 'start': 2717.06, 'end': 2724.06, 'text': ' For instance, maybe this distinction between high level and low level is not always there.', 'tokens': [51374, 1171, 5197, 11, 1310, 341, 16844, 1296, 1090, 1496, 293, 2295, 1496, 307, 406, 1009, 456, 13, 51724], 'temperature': 0.0, 'avg_logprob': -0.29960065274625214, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.0021769762970507145}, {'id': 354, 'seek': 272686, 'start': 2726.86, 'end': 2733.86, 'text': ' It is always very clear. There are some optimizations. One may say is it here or here. For instance,', 'tokens': [50364, 467, 307, 1009, 588, 1850, 13, 821, 366, 512, 5028, 14455, 13, 1485, 815, 584, 307, 309, 510, 420, 510, 13, 1171, 5197, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.2976818084716797, 'compression_ratio': 1.6160714285714286, 'no_speech_prob': 0.003269101493060589}, {'id': 355, 'seek': 272686, 'start': 2734.6600000000003, 'end': 2741.26, 'text': ' replace multiply with shift and adds, right. If you see a multiplication, replacing with', 'tokens': [50754, 7406, 12972, 365, 5513, 293, 10860, 11, 558, 13, 759, 291, 536, 257, 27290, 11, 19139, 365, 51084], 'temperature': 0.0, 'avg_logprob': -0.2976818084716797, 'compression_ratio': 1.6160714285714286, 'no_speech_prob': 0.003269101493060589}, {'id': 356, 'seek': 272686, 'start': 2741.26, 'end': 2748.26, 'text': ' adds you can do it at the high level code itself, right. Because I mean this is, some', 'tokens': [51084, 10860, 291, 393, 360, 309, 412, 264, 1090, 1496, 3089, 2564, 11, 558, 13, 1436, 286, 914, 341, 307, 11, 512, 51434], 'temperature': 0.0, 'avg_logprob': -0.2976818084716797, 'compression_ratio': 1.6160714285714286, 'no_speech_prob': 0.003269101493060589}, {'id': 357, 'seek': 272686, 'start': 2748.9, 'end': 2753.1800000000003, 'text': ' of these are on the border line. So there is no hard and fast rule but overall you get', 'tokens': [51466, 295, 613, 366, 322, 264, 7838, 1622, 13, 407, 456, 307, 572, 1152, 293, 2370, 4978, 457, 4787, 291, 483, 51680], 'temperature': 0.0, 'avg_logprob': -0.2976818084716797, 'compression_ratio': 1.6160714285714286, 'no_speech_prob': 0.003269101493060589}, {'id': 358, 'seek': 275318, 'start': 2753.18, 'end': 2760.18, 'text': ' an idea, okay. Fine. So before we go into a high level optimization, what we are saying?', 'tokens': [50364, 364, 1558, 11, 1392, 13, 12024, 13, 407, 949, 321, 352, 666, 257, 1090, 1496, 19618, 11, 437, 321, 366, 1566, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.189690061715933, 'compression_ratio': 1.5284090909090908, 'no_speech_prob': 0.0025442529004067183}, {'id': 359, 'seek': 275318, 'start': 2761.74, 'end': 2767.98, 'text': ' We want to design an optimization which should have certain properties. What are the desirable', 'tokens': [50792, 492, 528, 281, 1715, 364, 19618, 597, 820, 362, 1629, 7221, 13, 708, 366, 264, 30533, 51104], 'temperature': 0.0, 'avg_logprob': -0.189690061715933, 'compression_ratio': 1.5284090909090908, 'no_speech_prob': 0.0025442529004067183}, {'id': 360, 'seek': 275318, 'start': 2767.98, 'end': 2774.98, 'text': ' properties? The code should be at least as good as a handwritten assembly code, okay.', 'tokens': [51104, 7221, 30, 440, 3089, 820, 312, 412, 1935, 382, 665, 382, 257, 1011, 26859, 12103, 3089, 11, 1392, 13, 51454], 'temperature': 0.0, 'avg_logprob': -0.189690061715933, 'compression_ratio': 1.5284090909090908, 'no_speech_prob': 0.0025442529004067183}, {'id': 361, 'seek': 277498, 'start': 2775.98, 'end': 2782.98, 'text': ' It should be stable, robust performance. What is the stable performance? You done some optimization.', 'tokens': [50414, 467, 820, 312, 8351, 11, 13956, 3389, 13, 708, 307, 264, 8351, 3389, 30, 509, 1096, 512, 19618, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.2519117448388076, 'compression_ratio': 1.7804878048780488, 'no_speech_prob': 0.0018093266990035772}, {'id': 362, 'seek': 277498, 'start': 2784.26, 'end': 2788.86, 'text': ' It should not happen that you toss a coin, okay, heads. Today it will run fast, tails', 'tokens': [50828, 467, 820, 406, 1051, 300, 291, 14432, 257, 11464, 11, 1392, 11, 8050, 13, 2692, 309, 486, 1190, 2370, 11, 28537, 51058], 'temperature': 0.0, 'avg_logprob': -0.2519117448388076, 'compression_ratio': 1.7804878048780488, 'no_speech_prob': 0.0018093266990035772}, {'id': 363, 'seek': 277498, 'start': 2788.86, 'end': 2795.86, 'text': ' it will run slow, right. The optimization should work consistently. So every time you', 'tokens': [51058, 309, 486, 1190, 2964, 11, 558, 13, 440, 19618, 820, 589, 14961, 13, 407, 633, 565, 291, 51408], 'temperature': 0.0, 'avg_logprob': -0.2519117448388076, 'compression_ratio': 1.7804878048780488, 'no_speech_prob': 0.0018093266990035772}, {'id': 364, 'seek': 277498, 'start': 2797.14, 'end': 2803.14, 'text': ' run you should get some consistent performance. Ideally, you should design optimization that', 'tokens': [51472, 1190, 291, 820, 483, 512, 8398, 3389, 13, 40817, 11, 291, 820, 1715, 19618, 300, 51772], 'temperature': 0.0, 'avg_logprob': -0.2519117448388076, 'compression_ratio': 1.7804878048780488, 'no_speech_prob': 0.0018093266990035772}, {'id': 365, 'seek': 280314, 'start': 2803.14, 'end': 2809.54, 'text': ' will take advantage of all the hardware specialties and give, take advantage all of them and generate', 'tokens': [50364, 486, 747, 5002, 295, 439, 264, 8837, 2121, 6097, 293, 976, 11, 747, 5002, 439, 295, 552, 293, 8460, 50684], 'temperature': 0.0, 'avg_logprob': -0.21627405952004825, 'compression_ratio': 1.8115942028985508, 'no_speech_prob': 0.0011154517997056246}, {'id': 366, 'seek': 280314, 'start': 2809.54, 'end': 2815.58, 'text': ' very efficient code. It should, if there is some weakness of the architecture, the optimization', 'tokens': [50684, 588, 7148, 3089, 13, 467, 820, 11, 498, 456, 307, 512, 12772, 295, 264, 9482, 11, 264, 19618, 50986], 'temperature': 0.0, 'avg_logprob': -0.21627405952004825, 'compression_ratio': 1.8115942028985508, 'no_speech_prob': 0.0011154517997056246}, {'id': 367, 'seek': 280314, 'start': 2815.58, 'end': 2822.58, 'text': ' should be able to hide that. The optimization should support a broad range of languages', 'tokens': [50986, 820, 312, 1075, 281, 6479, 300, 13, 440, 19618, 820, 1406, 257, 4152, 3613, 295, 8650, 51336], 'temperature': 0.0, 'avg_logprob': -0.21627405952004825, 'compression_ratio': 1.8115942028985508, 'no_speech_prob': 0.0011154517997056246}, {'id': 368, 'seek': 280314, 'start': 2824.2599999999998, 'end': 2831.2599999999998, 'text': ' and it should be very fast. And the good news is most of the time, most of the time, most', 'tokens': [51420, 293, 309, 820, 312, 588, 2370, 13, 400, 264, 665, 2583, 307, 881, 295, 264, 565, 11, 881, 295, 264, 565, 11, 881, 51770], 'temperature': 0.0, 'avg_logprob': -0.21627405952004825, 'compression_ratio': 1.8115942028985508, 'no_speech_prob': 0.0011154517997056246}, {'id': 369, 'seek': 283314, 'start': 2833.42, 'end': 2840.42, 'text': ' of the optimizations draw, they do not do all of them. They may do A not B, they may', 'tokens': [50378, 295, 264, 5028, 14455, 2642, 11, 436, 360, 406, 360, 439, 295, 552, 13, 814, 815, 360, 316, 406, 363, 11, 436, 815, 50728], 'temperature': 0.0, 'avg_logprob': -0.2619120539451132, 'compression_ratio': 1.7843137254901962, 'no_speech_prob': 0.0028887782245874405}, {'id': 370, 'seek': 283314, 'start': 2840.46, 'end': 2846.7799999999997, 'text': ' do C not D, okay. So it is okay. So it is okay to have, I mean sometimes the optimizations', 'tokens': [50730, 360, 383, 406, 413, 11, 1392, 13, 407, 309, 307, 1392, 13, 407, 309, 307, 1392, 281, 362, 11, 286, 914, 2171, 264, 5028, 14455, 51046], 'temperature': 0.0, 'avg_logprob': -0.2619120539451132, 'compression_ratio': 1.7843137254901962, 'no_speech_prob': 0.0028887782245874405}, {'id': 371, 'seek': 283314, 'start': 2846.7799999999997, 'end': 2852.02, 'text': ' take slightly more time. They may not be doing all of them. So that is desirable properties.', 'tokens': [51046, 747, 4748, 544, 565, 13, 814, 815, 406, 312, 884, 439, 295, 552, 13, 407, 300, 307, 30533, 7221, 13, 51308], 'temperature': 0.0, 'avg_logprob': -0.2619120539451132, 'compression_ratio': 1.7843137254901962, 'no_speech_prob': 0.0028887782245874405}, {'id': 372, 'seek': 283314, 'start': 2852.02, 'end': 2859.02, 'text': ' There is a required property of every optimization. Can you guess what it is? Correctness. What', 'tokens': [51308, 821, 307, 257, 4739, 4707, 295, 633, 19618, 13, 1664, 291, 2041, 437, 309, 307, 30, 12753, 1287, 13, 708, 51658], 'temperature': 0.0, 'avg_logprob': -0.2619120539451132, 'compression_ratio': 1.7843137254901962, 'no_speech_prob': 0.0028887782245874405}, {'id': 373, 'seek': 285902, 'start': 2859.02, 'end': 2866.02, 'text': ' do you mean by correctness? Perfect. So the required property is the generated code of', 'tokens': [50364, 360, 291, 914, 538, 3006, 1287, 30, 10246, 13, 407, 264, 4739, 4707, 307, 264, 10833, 3089, 295, 50714], 'temperature': 0.0, 'avg_logprob': -0.29646294911702475, 'compression_ratio': 1.3461538461538463, 'no_speech_prob': 0.0032721322495490313}, {'id': 374, 'seek': 285902, 'start': 2868.98, 'end': 2875.98, 'text': ' the after optimization should and do you think the GCC code that you use, all of you GCC', 'tokens': [50862, 264, 934, 19618, 820, 293, 360, 291, 519, 264, 460, 11717, 3089, 300, 291, 764, 11, 439, 295, 291, 460, 11717, 51212], 'temperature': 0.0, 'avg_logprob': -0.29646294911702475, 'compression_ratio': 1.3461538461538463, 'no_speech_prob': 0.0032721322495490313}, {'id': 375, 'seek': 287598, 'start': 2875.98, 'end': 2882.98, 'text': ' are some, any compiler of your choice, right? Do you think it produces the correct code?', 'tokens': [50364, 366, 512, 11, 604, 31958, 295, 428, 3922, 11, 558, 30, 1144, 291, 519, 309, 14725, 264, 3006, 3089, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.43107791822783803, 'compression_ratio': 1.3587786259541985, 'no_speech_prob': 0.002670455491170287}, {'id': 376, 'seek': 287598, 'start': 2895.7400000000002, 'end': 2902.7400000000002, 'text': ' Let me add a word on top of it, always. Sir, in the example that you have, in the example', 'tokens': [51352, 961, 385, 909, 257, 1349, 322, 1192, 295, 309, 11, 1009, 13, 6144, 11, 294, 264, 1365, 300, 291, 362, 11, 294, 264, 1365, 51702], 'temperature': 0.0, 'avg_logprob': -0.43107791822783803, 'compression_ratio': 1.3587786259541985, 'no_speech_prob': 0.002670455491170287}, {'id': 377, 'seek': 290598, 'start': 2906.98, 'end': 2913.98, 'text': " that you have, okay. So you do not like GCC. How about Intel's ICC or our sponsor NVIDIA's", 'tokens': [50414, 300, 291, 362, 11, 1392, 13, 407, 291, 360, 406, 411, 460, 11717, 13, 1012, 466, 19762, 311, 286, 11717, 420, 527, 16198, 426, 3958, 6914, 311, 50764], 'temperature': 0.0, 'avg_logprob': -0.35315817493503376, 'compression_ratio': 1.2571428571428571, 'no_speech_prob': 0.01007271371781826}, {'id': 378, 'seek': 290598, 'start': 2920.38, 'end': 2927.38, 'text': ' NVCC, the CUDA compiler, right? So by the way, it is nothing to do with Intel, NVIDIA', 'tokens': [51084, 46512, 11717, 11, 264, 29777, 7509, 31958, 11, 558, 30, 407, 538, 264, 636, 11, 309, 307, 1825, 281, 360, 365, 19762, 11, 426, 3958, 6914, 51434], 'temperature': 0.0, 'avg_logprob': -0.35315817493503376, 'compression_ratio': 1.2571428571428571, 'no_speech_prob': 0.01007271371781826}, {'id': 379, 'seek': 292738, 'start': 2927.38, 'end': 2934.38, 'text': ' or HP, HP, GCC. This is code written by someone, right? The code may also have bugs, but what', 'tokens': [50364, 420, 12557, 11, 12557, 11, 460, 11717, 13, 639, 307, 3089, 3720, 538, 1580, 11, 558, 30, 440, 3089, 815, 611, 362, 15120, 11, 457, 437, 50714], 'temperature': 0.0, 'avg_logprob': -0.21782565443483118, 'compression_ratio': 1.470899470899471, 'no_speech_prob': 0.005218393635004759}, {'id': 380, 'seek': 292738, 'start': 2942.86, 'end': 2947.7400000000002, 'text': ' we in general say is that most of the optimizations, at least in theory, they should be semantic', 'tokens': [51138, 321, 294, 2674, 584, 307, 300, 881, 295, 264, 5028, 14455, 11, 412, 1935, 294, 5261, 11, 436, 820, 312, 47982, 51382], 'temperature': 0.0, 'avg_logprob': -0.21782565443483118, 'compression_ratio': 1.470899470899471, 'no_speech_prob': 0.005218393635004759}, {'id': 381, 'seek': 292738, 'start': 2947.7400000000002, 'end': 2953.34, 'text': ' preserving. Actual implementation, they are written by people like you and me or may be', 'tokens': [51382, 33173, 13, 3251, 901, 11420, 11, 436, 366, 3720, 538, 561, 411, 291, 293, 385, 420, 815, 312, 51662], 'temperature': 0.0, 'avg_logprob': -0.21782565443483118, 'compression_ratio': 1.470899470899471, 'no_speech_prob': 0.005218393635004759}, {'id': 382, 'seek': 295334, 'start': 2953.34, 'end': 2960.34, 'text': ' much smarter in case of some companies, right? But still there may be bugs, but modular bugs,', 'tokens': [50364, 709, 20294, 294, 1389, 295, 512, 3431, 11, 558, 30, 583, 920, 456, 815, 312, 15120, 11, 457, 31111, 15120, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.2503832832711642, 'compression_ratio': 1.535031847133758, 'no_speech_prob': 0.009407197125256062}, {'id': 383, 'seek': 295334, 'start': 2962.7400000000002, 'end': 2968.42, 'text': ' we want that they should be semantic preserving, right? Okay.', 'tokens': [50834, 321, 528, 300, 436, 820, 312, 47982, 33173, 11, 558, 30, 1033, 13, 51118], 'temperature': 0.0, 'avg_logprob': -0.2503832832711642, 'compression_ratio': 1.535031847133758, 'no_speech_prob': 0.009407197125256062}, {'id': 384, 'seek': 295334, 'start': 2968.42, 'end': 2975.42, 'text': ' So we will continue with our, this thing, sorry, when we say semantic preserving, how', 'tokens': [51118, 407, 321, 486, 2354, 365, 527, 11, 341, 551, 11, 2597, 11, 562, 321, 584, 47982, 33173, 11, 577, 51468], 'temperature': 0.0, 'avg_logprob': -0.2503832832711642, 'compression_ratio': 1.535031847133758, 'no_speech_prob': 0.009407197125256062}, {'id': 385, 'seek': 297542, 'start': 2976.42, 'end': 2983.42, 'text': ' do we guarantee that it is semantic preserving? Yes, correct. But the compiler does not run', 'tokens': [50414, 360, 321, 10815, 300, 309, 307, 47982, 33173, 30, 1079, 11, 3006, 13, 583, 264, 31958, 775, 406, 1190, 50764], 'temperature': 0.0, 'avg_logprob': -0.14455162269481714, 'compression_ratio': 1.5454545454545454, 'no_speech_prob': 0.0021136493887752295}, {'id': 386, 'seek': 297542, 'start': 2985.1800000000003, 'end': 2992.1800000000003, 'text': ' the code. The compiler takes some code, optimizes and gives you an output. How can the compiler', 'tokens': [50852, 264, 3089, 13, 440, 31958, 2516, 512, 3089, 11, 5028, 5660, 293, 2709, 291, 364, 5598, 13, 1012, 393, 264, 31958, 51202], 'temperature': 0.0, 'avg_logprob': -0.14455162269481714, 'compression_ratio': 1.5454545454545454, 'no_speech_prob': 0.0021136493887752295}, {'id': 387, 'seek': 297542, 'start': 2993.7400000000002, 'end': 3000.7400000000002, 'text': ' be sure that the optimization it is doing is right? Sorry, we can? Good, let us keep', 'tokens': [51280, 312, 988, 300, 264, 19618, 309, 307, 884, 307, 558, 30, 4919, 11, 321, 393, 30, 2205, 11, 718, 505, 1066, 51630], 'temperature': 0.0, 'avg_logprob': -0.14455162269481714, 'compression_ratio': 1.5454545454545454, 'no_speech_prob': 0.0021136493887752295}, {'id': 388, 'seek': 300074, 'start': 3001.74, 'end': 3008.74, 'text': ' that part. For whatever the input given, right? But the input, now the input can be any random', 'tokens': [50414, 300, 644, 13, 1171, 2035, 264, 4846, 2212, 11, 558, 30, 583, 264, 4846, 11, 586, 264, 4846, 393, 312, 604, 4974, 50764], 'temperature': 0.0, 'avg_logprob': -0.22955383194817436, 'compression_ratio': 1.630952380952381, 'no_speech_prob': 0.0035900555085390806}, {'id': 389, 'seek': 300074, 'start': 3011.9399999999996, 'end': 3018.9399999999996, 'text': ' input, right? I mean, given, so what you are saying is there is some understanding of what', 'tokens': [50924, 4846, 11, 558, 30, 286, 914, 11, 2212, 11, 370, 437, 291, 366, 1566, 307, 456, 307, 512, 3701, 295, 437, 51274], 'temperature': 0.0, 'avg_logprob': -0.22955383194817436, 'compression_ratio': 1.630952380952381, 'no_speech_prob': 0.0035900555085390806}, {'id': 390, 'seek': 300074, 'start': 3021.3799999999997, 'end': 3028.3799999999997, 'text': ' the, I mean, some classes of the inputs. How the program will behave for this input? The', 'tokens': [51396, 264, 11, 286, 914, 11, 512, 5359, 295, 264, 15743, 13, 1012, 264, 1461, 486, 15158, 337, 341, 4846, 30, 440, 51746], 'temperature': 0.0, 'avg_logprob': -0.22955383194817436, 'compression_ratio': 1.630952380952381, 'no_speech_prob': 0.0035900555085390806}, {'id': 391, 'seek': 302838, 'start': 3028.54, 'end': 3034.1, 'text': ' output program should behave similarly. So the compiler at some level should understand', 'tokens': [50372, 5598, 1461, 820, 15158, 14138, 13, 407, 264, 31958, 412, 512, 1496, 820, 1223, 50650], 'temperature': 0.0, 'avg_logprob': -0.13018008809030793, 'compression_ratio': 1.77, 'no_speech_prob': 0.0002269234391860664}, {'id': 392, 'seek': 302838, 'start': 3034.1, 'end': 3041.1, 'text': ' the input program as well, right? And that is where comes the branch of program analysis.', 'tokens': [50650, 264, 4846, 1461, 382, 731, 11, 558, 30, 400, 300, 307, 689, 1487, 264, 9819, 295, 1461, 5215, 13, 51000], 'temperature': 0.0, 'avg_logprob': -0.13018008809030793, 'compression_ratio': 1.77, 'no_speech_prob': 0.0002269234391860664}, {'id': 393, 'seek': 302838, 'start': 3041.1400000000003, 'end': 3047.1, 'text': ' The compiler has to analyze the program, make some sense out of it. So you will see that', 'tokens': [51002, 440, 31958, 575, 281, 12477, 264, 1461, 11, 652, 512, 2020, 484, 295, 309, 13, 407, 291, 486, 536, 300, 51300], 'temperature': 0.0, 'avg_logprob': -0.13018008809030793, 'compression_ratio': 1.77, 'no_speech_prob': 0.0002269234391860664}, {'id': 394, 'seek': 302838, 'start': 3047.1, 'end': 3054.1, 'text': ' for optimizations, you will always need, you always have a phase which will analyze the', 'tokens': [51300, 337, 5028, 14455, 11, 291, 486, 1009, 643, 11, 291, 1009, 362, 257, 5574, 597, 486, 12477, 264, 51650], 'temperature': 0.0, 'avg_logprob': -0.13018008809030793, 'compression_ratio': 1.77, 'no_speech_prob': 0.0002269234391860664}, {'id': 395, 'seek': 305410, 'start': 3054.1, 'end': 3061.1, 'text': ' program. It has to understand the program. Once it understands the program, it can do', 'tokens': [50364, 1461, 13, 467, 575, 281, 1223, 264, 1461, 13, 3443, 309, 15146, 264, 1461, 11, 309, 393, 360, 50714], 'temperature': 0.0, 'avg_logprob': -0.2026874982393705, 'compression_ratio': 1.4814814814814814, 'no_speech_prob': 0.0003353289212100208}, {'id': 396, 'seek': 305410, 'start': 3061.3399999999997, 'end': 3068.3399999999997, 'text': ' some optimizations, right? Let us take an example. Here is a piece of', 'tokens': [50726, 512, 5028, 14455, 11, 558, 30, 961, 505, 747, 364, 1365, 13, 1692, 307, 257, 2522, 295, 51076], 'temperature': 0.0, 'avg_logprob': -0.2026874982393705, 'compression_ratio': 1.4814814814814814, 'no_speech_prob': 0.0003353289212100208}, {'id': 397, 'seek': 305410, 'start': 3070.2599999999998, 'end': 3077.2599999999998, 'text': ' code that says if condition, I am writing to A, B, else AC. If the compiler wants to', 'tokens': [51172, 3089, 300, 1619, 498, 4188, 11, 286, 669, 3579, 281, 316, 11, 363, 11, 1646, 8157, 13, 759, 264, 31958, 2738, 281, 51522], 'temperature': 0.0, 'avg_logprob': -0.2026874982393705, 'compression_ratio': 1.4814814814814814, 'no_speech_prob': 0.0003353289212100208}, {'id': 398, 'seek': 307726, 'start': 3077.26, 'end': 3084.26, 'text': ' figure out which variables are assigned in this piece of the code, right? It has to go', 'tokens': [50364, 2573, 484, 597, 9102, 366, 13279, 294, 341, 2522, 295, 264, 3089, 11, 558, 30, 467, 575, 281, 352, 50714], 'temperature': 0.0, 'avg_logprob': -0.2024994194507599, 'compression_ratio': 1.5714285714285714, 'no_speech_prob': 0.0005355637986212969}, {'id': 399, 'seek': 307726, 'start': 3088.3, 'end': 3095.3, 'text': ' through the code and understand, right? Now this understanding can vary. There are different', 'tokens': [50916, 807, 264, 3089, 293, 1223, 11, 558, 30, 823, 341, 3701, 393, 10559, 13, 821, 366, 819, 51266], 'temperature': 0.0, 'avg_logprob': -0.2024994194507599, 'compression_ratio': 1.5714285714285714, 'no_speech_prob': 0.0005355637986212969}, {'id': 400, 'seek': 307726, 'start': 3095.38, 'end': 3102.38, 'text': ' types of analysis. One of the, have you already been told about may analysis and must analysis?', 'tokens': [51270, 3467, 295, 5215, 13, 1485, 295, 264, 11, 362, 291, 1217, 668, 1907, 466, 815, 5215, 293, 1633, 5215, 30, 51620], 'temperature': 0.0, 'avg_logprob': -0.2024994194507599, 'compression_ratio': 1.5714285714285714, 'no_speech_prob': 0.0005355637986212969}, {'id': 401, 'seek': 310238, 'start': 3103.06, 'end': 3110.06, 'text': ' No? Good. So in this piece of the code, do you know which branch may be taken? No. The', 'tokens': [50398, 883, 30, 2205, 13, 407, 294, 341, 2522, 295, 264, 3089, 11, 360, 291, 458, 597, 9819, 815, 312, 2726, 30, 883, 13, 440, 50748], 'temperature': 0.0, 'avg_logprob': -0.25814481403516687, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.00262927683070302}, {'id': 402, 'seek': 310238, 'start': 3112.46, 'end': 3118.46, 'text': ' compiler cannot know. But if the compiler wants to figure out which, let us say there', 'tokens': [50868, 31958, 2644, 458, 13, 583, 498, 264, 31958, 2738, 281, 2573, 484, 597, 11, 718, 505, 584, 456, 51168], 'temperature': 0.0, 'avg_logprob': -0.25814481403516687, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.00262927683070302}, {'id': 403, 'seek': 310238, 'start': 3118.46, 'end': 3125.46, 'text': ' are four variables I have A, B, C, D. And now the compiler wants to know which variables', 'tokens': [51168, 366, 1451, 9102, 286, 362, 316, 11, 363, 11, 383, 11, 413, 13, 400, 586, 264, 31958, 2738, 281, 458, 597, 9102, 51518], 'temperature': 0.0, 'avg_logprob': -0.25814481403516687, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.00262927683070302}, {'id': 404, 'seek': 310238, 'start': 3125.7000000000003, 'end': 3132.1, 'text': ' may be assigned in this part of the code. Because any code that is variable which is', 'tokens': [51530, 815, 312, 13279, 294, 341, 644, 295, 264, 3089, 13, 1436, 604, 3089, 300, 307, 7006, 597, 307, 51850], 'temperature': 0.0, 'avg_logprob': -0.25814481403516687, 'compression_ratio': 1.696078431372549, 'no_speech_prob': 0.00262927683070302}, {'id': 405, 'seek': 313210, 'start': 3132.1, 'end': 3136.7799999999997, 'text': ' not assigned or used, I may throw it away, right? But to throw it away, I need to know', 'tokens': [50364, 406, 13279, 420, 1143, 11, 286, 815, 3507, 309, 1314, 11, 558, 30, 583, 281, 3507, 309, 1314, 11, 286, 643, 281, 458, 50598], 'temperature': 0.0, 'avg_logprob': -0.1412285313461766, 'compression_ratio': 1.7285714285714286, 'no_speech_prob': 0.00022679049288854003}, {'id': 406, 'seek': 313210, 'start': 3136.7799999999997, 'end': 3143.22, 'text': ' which variables are, which variables may be used. So in this part of the code, which variable', 'tokens': [50598, 597, 9102, 366, 11, 597, 9102, 815, 312, 1143, 13, 407, 294, 341, 644, 295, 264, 3089, 11, 597, 7006, 50920], 'temperature': 0.0, 'avg_logprob': -0.1412285313461766, 'compression_ratio': 1.7285714285714286, 'no_speech_prob': 0.00022679049288854003}, {'id': 407, 'seek': 313210, 'start': 3143.22, 'end': 3150.22, 'text': ' may be used? A, B or C. But is there a guarantee that all A, B, C will be used? No. Why? Because', 'tokens': [50920, 815, 312, 1143, 30, 316, 11, 363, 420, 383, 13, 583, 307, 456, 257, 10815, 300, 439, 316, 11, 363, 11, 383, 486, 312, 1143, 30, 883, 13, 1545, 30, 1436, 51270], 'temperature': 0.0, 'avg_logprob': -0.1412285313461766, 'compression_ratio': 1.7285714285714286, 'no_speech_prob': 0.00022679049288854003}, {'id': 408, 'seek': 313210, 'start': 3154.58, 'end': 3159.1, 'text': ' the compiler does not know anything about the condition. So there is something called', 'tokens': [51488, 264, 31958, 775, 406, 458, 1340, 466, 264, 4188, 13, 407, 456, 307, 746, 1219, 51714], 'temperature': 0.0, 'avg_logprob': -0.1412285313461766, 'compression_ratio': 1.7285714285714286, 'no_speech_prob': 0.00022679049288854003}, {'id': 409, 'seek': 315910, 'start': 3159.1, 'end': 3166.1, 'text': ' a may analysis which tells information like which may be assigned, which code may, which', 'tokens': [50364, 257, 815, 5215, 597, 5112, 1589, 411, 597, 815, 312, 13279, 11, 597, 3089, 815, 11, 597, 50714], 'temperature': 0.0, 'avg_logprob': -0.16862600241134415, 'compression_ratio': 1.82, 'no_speech_prob': 0.0014542073477059603}, {'id': 410, 'seek': 315910, 'start': 3168.2999999999997, 'end': 3175.2999999999997, 'text': ' part of the code may be accessed, which part of the code may be executed, right? If I look', 'tokens': [50824, 644, 295, 264, 3089, 815, 312, 34211, 11, 597, 644, 295, 264, 3089, 815, 312, 17577, 11, 558, 30, 759, 286, 574, 51174], 'temperature': 0.0, 'avg_logprob': -0.16862600241134415, 'compression_ratio': 1.82, 'no_speech_prob': 0.0014542073477059603}, {'id': 411, 'seek': 315910, 'start': 3179.02, 'end': 3184.8199999999997, 'text': ' at this part of the code and ask you a question, which variable is guaranteed to be accessed,', 'tokens': [51360, 412, 341, 644, 295, 264, 3089, 293, 1029, 291, 257, 1168, 11, 597, 7006, 307, 18031, 281, 312, 34211, 11, 51650], 'temperature': 0.0, 'avg_logprob': -0.16862600241134415, 'compression_ratio': 1.82, 'no_speech_prob': 0.0014542073477059603}, {'id': 412, 'seek': 318482, 'start': 3184.82, 'end': 3191.82, 'text': ' must be accessed? A. So that is the must information. So there are two broad classification of', 'tokens': [50364, 1633, 312, 34211, 30, 316, 13, 407, 300, 307, 264, 1633, 1589, 13, 407, 456, 366, 732, 4152, 21538, 295, 50714], 'temperature': 0.0, 'avg_logprob': -0.253612436567034, 'compression_ratio': 1.6140350877192982, 'no_speech_prob': 0.0023555264342576265}, {'id': 413, 'seek': 318482, 'start': 3195.98, 'end': 3202.98, 'text': ' the analysis, may analysis where we say whatever we infer that will hold at least on some path,', 'tokens': [50922, 264, 5215, 11, 815, 5215, 689, 321, 584, 2035, 321, 13596, 300, 486, 1797, 412, 1935, 322, 512, 3100, 11, 51272], 'temperature': 0.0, 'avg_logprob': -0.253612436567034, 'compression_ratio': 1.6140350877192982, 'no_speech_prob': 0.0023555264342576265}, {'id': 414, 'seek': 318482, 'start': 3205.86, 'end': 3212.86, 'text': ' rather it may hold on some path. It may, it may, let us say before this code there is', 'tokens': [51416, 2831, 309, 815, 1797, 322, 512, 3100, 13, 467, 815, 11, 309, 815, 11, 718, 505, 584, 949, 341, 3089, 456, 307, 51766], 'temperature': 0.0, 'avg_logprob': -0.253612436567034, 'compression_ratio': 1.6140350877192982, 'no_speech_prob': 0.0023555264342576265}, {'id': 415, 'seek': 321286, 'start': 3213.5, 'end': 3220.5, 'text': ' some division A equal to B by C and C is all, sorry X equal to Y by Z. Z is always 0. So', 'tokens': [50396, 512, 10044, 316, 2681, 281, 363, 538, 383, 293, 383, 307, 439, 11, 2597, 1783, 2681, 281, 398, 538, 1176, 13, 1176, 307, 1009, 1958, 13, 407, 50746], 'temperature': 0.0, 'avg_logprob': -0.22496819169553992, 'compression_ratio': 1.5027932960893855, 'no_speech_prob': 0.0004578385269269347}, {'id': 416, 'seek': 321286, 'start': 3220.5, 'end': 3227.5, 'text': ' you will never execute this part of the code. So module all that. So the may analysis is', 'tokens': [50746, 291, 486, 1128, 14483, 341, 644, 295, 264, 3089, 13, 407, 10088, 439, 300, 13, 407, 264, 815, 5215, 307, 51096], 'temperature': 0.0, 'avg_logprob': -0.22496819169553992, 'compression_ratio': 1.5027932960893855, 'no_speech_prob': 0.0004578385269269347}, {'id': 417, 'seek': 321286, 'start': 3232.3, 'end': 3238.7000000000003, 'text': ' the analysis holds on at least some data path, whatever I understand, within whatever I can', 'tokens': [51336, 264, 5215, 9190, 322, 412, 1935, 512, 1412, 3100, 11, 2035, 286, 1223, 11, 1951, 2035, 286, 393, 51656], 'temperature': 0.0, 'avg_logprob': -0.22496819169553992, 'compression_ratio': 1.5027932960893855, 'no_speech_prob': 0.0004578385269269347}, {'id': 418, 'seek': 323870, 'start': 3238.7, 'end': 3245.7, 'text': ' understand it may hold. The must analysis says the analysis information will hold across', 'tokens': [50364, 1223, 309, 815, 1797, 13, 440, 1633, 5215, 1619, 264, 5215, 1589, 486, 1797, 2108, 50714], 'temperature': 0.0, 'avg_logprob': -0.1918972638937143, 'compression_ratio': 1.5466666666666666, 'no_speech_prob': 0.0014544499572366476}, {'id': 419, 'seek': 323870, 'start': 3247.62, 'end': 3254.62, 'text': ' all paths. We will use this understanding to do more optimization. But remember the', 'tokens': [50810, 439, 14518, 13, 492, 486, 764, 341, 3701, 281, 360, 544, 19618, 13, 583, 1604, 264, 51160], 'temperature': 0.0, 'avg_logprob': -0.1918972638937143, 'compression_ratio': 1.5466666666666666, 'no_speech_prob': 0.0014544499572366476}, {'id': 420, 'seek': 323870, 'start': 3256.4199999999996, 'end': 3263.4199999999996, 'text': ' idea of may and must. What is the opposite of may analysis?', 'tokens': [51250, 1558, 295, 815, 293, 1633, 13, 708, 307, 264, 6182, 295, 815, 5215, 30, 51600], 'temperature': 0.0, 'avg_logprob': -0.1918972638937143, 'compression_ratio': 1.5466666666666666, 'no_speech_prob': 0.0014544499572366476}, {'id': 421, 'seek': 326870, 'start': 3268.9399999999996, 'end': 3275.9399999999996, 'text': ' So let us take the, let us say I have four variables A, B, C, D. Definitely not or must', 'tokens': [50376, 407, 718, 505, 747, 264, 11, 718, 505, 584, 286, 362, 1451, 9102, 316, 11, 363, 11, 383, 11, 413, 13, 12151, 406, 420, 1633, 50726], 'temperature': 0.0, 'avg_logprob': -0.14611167718868445, 'compression_ratio': 1.7169811320754718, 'no_speech_prob': 0.0014096969971433282}, {'id': 422, 'seek': 326870, 'start': 3276.46, 'end': 3283.46, 'text': ' not. So the opposite of may analysis is must not. So if you, if you complete some information', 'tokens': [50752, 406, 13, 407, 264, 6182, 295, 815, 5215, 307, 1633, 406, 13, 407, 498, 291, 11, 498, 291, 3566, 512, 1589, 51102], 'temperature': 0.0, 'avg_logprob': -0.14611167718868445, 'compression_ratio': 1.7169811320754718, 'no_speech_prob': 0.0014096969971433282}, {'id': 423, 'seek': 326870, 'start': 3284.2999999999997, 'end': 3290.66, 'text': ' that says may, the negation of it will give you must not. So if you have A, B, C, D variables', 'tokens': [51144, 300, 1619, 815, 11, 264, 2485, 399, 295, 309, 486, 976, 291, 1633, 406, 13, 407, 498, 291, 362, 316, 11, 363, 11, 383, 11, 413, 9102, 51462], 'temperature': 0.0, 'avg_logprob': -0.14611167718868445, 'compression_ratio': 1.7169811320754718, 'no_speech_prob': 0.0014096969971433282}, {'id': 424, 'seek': 326870, 'start': 3290.66, 'end': 3297.66, 'text': ' and you ask this question, which variable must not be assigned in this part of the code?', 'tokens': [51462, 293, 291, 1029, 341, 1168, 11, 597, 7006, 1633, 406, 312, 13279, 294, 341, 644, 295, 264, 3089, 30, 51812], 'temperature': 0.0, 'avg_logprob': -0.14611167718868445, 'compression_ratio': 1.7169811320754718, 'no_speech_prob': 0.0014096969971433282}, {'id': 425, 'seek': 329870, 'start': 3298.9399999999996, 'end': 3305.9399999999996, 'text': ' The code it is D. What is the opposite of must analysis? Never is it? So let us look', 'tokens': [50376, 440, 3089, 309, 307, 413, 13, 708, 307, 264, 6182, 295, 1633, 5215, 30, 7344, 307, 309, 30, 407, 718, 505, 574, 50726], 'temperature': 0.0, 'avg_logprob': -0.18411699930826822, 'compression_ratio': 1.456896551724138, 'no_speech_prob': 0.0004753862740471959}, {'id': 426, 'seek': 329870, 'start': 3319.62, 'end': 3326.62, 'text': ' at this way. What is the negation of, what is the negation of this one? Which of the', 'tokens': [51410, 412, 341, 636, 13, 708, 307, 264, 2485, 399, 295, 11, 437, 307, 264, 2485, 399, 295, 341, 472, 30, 3013, 295, 264, 51760], 'temperature': 0.0, 'avg_logprob': -0.18411699930826822, 'compression_ratio': 1.456896551724138, 'no_speech_prob': 0.0004753862740471959}, {'id': 427, 'seek': 332662, 'start': 3327.1, 'end': 3333.38, 'text': ' variables must be assigned? A, what is the negation of this? B, C, D. So what is the', 'tokens': [50388, 9102, 1633, 312, 13279, 30, 316, 11, 437, 307, 264, 2485, 399, 295, 341, 30, 363, 11, 383, 11, 413, 13, 407, 437, 307, 264, 50702], 'temperature': 0.0, 'avg_logprob': -0.18826074115300584, 'compression_ratio': 1.653225806451613, 'no_speech_prob': 0.0022851277608424425}, {'id': 428, 'seek': 332662, 'start': 3333.38, 'end': 3340.38, 'text': ' question you will ask whose answer is B, C, D? Which variables may not be assigned? Which', 'tokens': [50702, 1168, 291, 486, 1029, 6104, 1867, 307, 363, 11, 383, 11, 413, 30, 3013, 9102, 815, 406, 312, 13279, 30, 3013, 51052], 'temperature': 0.0, 'avg_logprob': -0.18826074115300584, 'compression_ratio': 1.653225806451613, 'no_speech_prob': 0.0022851277608424425}, {'id': 429, 'seek': 332662, 'start': 3346.58, 'end': 3353.58, 'text': ' variables may not be assigned?', 'tokens': [51362, 9102, 815, 406, 312, 13279, 30, 51712], 'temperature': 0.0, 'avg_logprob': -0.18826074115300584, 'compression_ratio': 1.653225806451613, 'no_speech_prob': 0.0022851277608424425}, {'id': 430, 'seek': 335662, 'start': 3356.62, 'end': 3363.62, 'text': ' We will take an example which is called as constant propagation. It is one of the most', 'tokens': [50364, 492, 486, 747, 364, 1365, 597, 307, 1219, 382, 5754, 38377, 13, 467, 307, 472, 295, 264, 881, 50714], 'temperature': 0.0, 'avg_logprob': -0.20531383780545967, 'compression_ratio': 1.669811320754717, 'no_speech_prob': 0.0013249333715066314}, {'id': 431, 'seek': 335662, 'start': 3368.06, 'end': 3372.54, 'text': ' popular optimizations you can think of, I mean which is there in text and is used. We', 'tokens': [50936, 3743, 5028, 14455, 291, 393, 519, 295, 11, 286, 914, 597, 307, 456, 294, 2487, 293, 307, 1143, 13, 492, 51160], 'temperature': 0.0, 'avg_logprob': -0.20531383780545967, 'compression_ratio': 1.669811320754717, 'no_speech_prob': 0.0013249333715066314}, {'id': 432, 'seek': 335662, 'start': 3372.54, 'end': 3377.8599999999997, 'text': ' will use that to understand this may and must have been. So what is the idea of constant', 'tokens': [51160, 486, 764, 300, 281, 1223, 341, 815, 293, 1633, 362, 668, 13, 407, 437, 307, 264, 1558, 295, 5754, 51426], 'temperature': 0.0, 'avg_logprob': -0.20531383780545967, 'compression_ratio': 1.669811320754717, 'no_speech_prob': 0.0013249333715066314}, {'id': 433, 'seek': 335662, 'start': 3377.8599999999997, 'end': 3384.8599999999997, 'text': ' propagation? Let us say there is some piece of the code whose value is known to be constant.', 'tokens': [51426, 38377, 30, 961, 505, 584, 456, 307, 512, 2522, 295, 264, 3089, 6104, 2158, 307, 2570, 281, 312, 5754, 13, 51776], 'temperature': 0.0, 'avg_logprob': -0.20531383780545967, 'compression_ratio': 1.669811320754717, 'no_speech_prob': 0.0013249333715066314}, {'id': 434, 'seek': 338662, 'start': 3386.7, 'end': 3393.7, 'text': ' Then why should you execute it at run time? You take that piece of the code or that expression.', 'tokens': [50368, 1396, 983, 820, 291, 14483, 309, 412, 1190, 565, 30, 509, 747, 300, 2522, 295, 264, 3089, 420, 300, 6114, 13, 50718], 'temperature': 0.0, 'avg_logprob': -0.22404075250393007, 'compression_ratio': 1.9234972677595628, 'no_speech_prob': 0.00039808006840758026}, {'id': 435, 'seek': 338662, 'start': 3393.94, 'end': 3399.62, 'text': ' We will call that expression as a constant expression. So I need to find out what is', 'tokens': [50730, 492, 486, 818, 300, 6114, 382, 257, 5754, 6114, 13, 407, 286, 643, 281, 915, 484, 437, 307, 51014], 'temperature': 0.0, 'avg_logprob': -0.22404075250393007, 'compression_ratio': 1.9234972677595628, 'no_speech_prob': 0.00039808006840758026}, {'id': 436, 'seek': 338662, 'start': 3399.62, 'end': 3406.62, 'text': ' the constant expression and replace that constant expression with that constant. So here is', 'tokens': [51014, 264, 5754, 6114, 293, 7406, 300, 5754, 6114, 365, 300, 5754, 13, 407, 510, 307, 51364], 'temperature': 0.0, 'avg_logprob': -0.22404075250393007, 'compression_ratio': 1.9234972677595628, 'no_speech_prob': 0.00039808006840758026}, {'id': 437, 'seek': 338662, 'start': 3407.98, 'end': 3414.98, 'text': ' a piece of code. Look at this piece of code and tell me what all constants are.', 'tokens': [51432, 257, 2522, 295, 3089, 13, 2053, 412, 341, 2522, 295, 3089, 293, 980, 385, 437, 439, 35870, 366, 13, 51782], 'temperature': 0.0, 'avg_logprob': -0.22404075250393007, 'compression_ratio': 1.9234972677595628, 'no_speech_prob': 0.00039808006840758026}, {'id': 438, 'seek': 341662, 'start': 3416.94, 'end': 3423.94, 'text': ' Do you see any constants at all? Clearly there are constant literals 1, 2, 3 and all that.', 'tokens': [50380, 1144, 291, 536, 604, 35870, 412, 439, 30, 24120, 456, 366, 5754, 2733, 1124, 502, 11, 568, 11, 805, 293, 439, 300, 13, 50730], 'temperature': 0.0, 'avg_logprob': -0.3762478441805453, 'compression_ratio': 1.6898734177215189, 'no_speech_prob': 0.04203043505549431}, {'id': 439, 'seek': 341662, 'start': 3427.74, 'end': 3434.74, 'text': ' I is equal to 1 is used here and there is here. So I is a constant our friend says.', 'tokens': [50920, 286, 307, 2681, 281, 502, 307, 1143, 510, 293, 456, 307, 510, 13, 407, 286, 307, 257, 5754, 527, 1277, 1619, 13, 51270], 'temperature': 0.0, 'avg_logprob': -0.3762478441805453, 'compression_ratio': 1.6898734177215189, 'no_speech_prob': 0.04203043505549431}, {'id': 440, 'seek': 341662, 'start': 3436.46, 'end': 3443.46, 'text': ' So if I is a constant what I can do? Replace the occurrence. So I can replace the occurrence', 'tokens': [51356, 407, 498, 286, 307, 257, 5754, 437, 286, 393, 360, 30, 1300, 6742, 264, 36122, 13, 407, 286, 393, 7406, 264, 36122, 51706], 'temperature': 0.0, 'avg_logprob': -0.3762478441805453, 'compression_ratio': 1.6898734177215189, 'no_speech_prob': 0.04203043505549431}, {'id': 441, 'seek': 344662, 'start': 3447.02, 'end': 3454.02, 'text': ' of I with its constant value. So what will happen to this code? Let us see. Can I use', 'tokens': [50384, 295, 286, 365, 1080, 5754, 2158, 13, 407, 437, 486, 1051, 281, 341, 3089, 30, 961, 505, 536, 13, 1664, 286, 764, 50734], 'temperature': 0.0, 'avg_logprob': -0.3209986686706543, 'compression_ratio': 1.3412698412698412, 'no_speech_prob': 0.0024721648078411818}, {'id': 442, 'seek': 344662, 'start': 3464.3399999999997, 'end': 3471.3399999999997, 'text': ' this board? I will be using this and this together. No I think it is better I write', 'tokens': [51250, 341, 3150, 30, 286, 486, 312, 1228, 341, 293, 341, 1214, 13, 883, 286, 519, 309, 307, 1101, 286, 2464, 51600], 'temperature': 0.0, 'avg_logprob': -0.3209986686706543, 'compression_ratio': 1.3412698412698412, 'no_speech_prob': 0.0024721648078411818}, {'id': 443, 'seek': 347134, 'start': 3471.34, 'end': 3479.34, 'text': ' it here. It is more fun writing it here. Hello.', 'tokens': [50414, 309, 510, 13, 467, 307, 544, 1019, 3579, 309, 510, 13, 2425, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.2786520719528198, 'compression_ratio': 0.9591836734693877, 'no_speech_prob': 0.08139920234680176}, {'id': 444, 'seek': 350134, 'start': 3501.34, 'end': 3508.34, 'text': ' So which one are we replacing now? So you are saying we do not need this. Every occurrence', 'tokens': [50364, 407, 597, 472, 366, 321, 19139, 586, 30, 407, 291, 366, 1566, 321, 360, 406, 643, 341, 13, 2048, 36122, 50714], 'temperature': 0.0, 'avg_logprob': -0.29075327979193794, 'compression_ratio': 1.3088235294117647, 'no_speech_prob': 0.01762254536151886}, {'id': 445, 'seek': 350134, 'start': 3517.5, 'end': 3524.5, 'text': ' of I I will replace with 1. So we eliminated one constant expression. What else anyone?', 'tokens': [51172, 295, 286, 286, 486, 7406, 365, 502, 13, 407, 321, 20308, 472, 5754, 6114, 13, 708, 1646, 2878, 30, 51522], 'temperature': 0.0, 'avg_logprob': -0.29075327979193794, 'compression_ratio': 1.3088235294117647, 'no_speech_prob': 0.01762254536151886}, {'id': 446, 'seek': 352450, 'start': 3524.5, 'end': 3531.5, 'text': ' J. What about J? It is always 2. So first of all I need to replace this is a constant', 'tokens': [50364, 508, 13, 708, 466, 508, 30, 467, 307, 1009, 568, 13, 407, 700, 295, 439, 286, 643, 281, 7406, 341, 307, 257, 5754, 50714], 'temperature': 0.0, 'avg_logprob': -0.3237881856421902, 'compression_ratio': 1.6024844720496894, 'no_speech_prob': 0.010826745070517063}, {'id': 447, 'seek': 352450, 'start': 3540.74, 'end': 3546.34, 'text': ' expression. I will replace it with 2 and now I have J equal to 2. What do I do? Wherever', 'tokens': [51176, 6114, 13, 286, 486, 7406, 309, 365, 568, 293, 586, 286, 362, 508, 2681, 281, 568, 13, 708, 360, 286, 360, 30, 30903, 51456], 'temperature': 0.0, 'avg_logprob': -0.3237881856421902, 'compression_ratio': 1.6024844720496894, 'no_speech_prob': 0.010826745070517063}, {'id': 448, 'seek': 352450, 'start': 3546.34, 'end': 3553.34, 'text': ' every occurrence of J I will replace with 2 and then I will replace it with 2. So I', 'tokens': [51456, 633, 36122, 295, 508, 286, 486, 7406, 365, 568, 293, 550, 286, 486, 7406, 309, 365, 568, 13, 407, 286, 51806], 'temperature': 0.0, 'avg_logprob': -0.3237881856421902, 'compression_ratio': 1.6024844720496894, 'no_speech_prob': 0.010826745070517063}, {'id': 449, 'seek': 355450, 'start': 3554.5, 'end': 3561.5, 'text': ' replace it with 2 and then what do I do? A of 2 is a constant and then I replace it', 'tokens': [50364, 7406, 309, 365, 568, 293, 550, 437, 360, 286, 360, 30, 316, 295, 568, 307, 257, 5754, 293, 550, 286, 7406, 309, 50714], 'temperature': 0.0, 'avg_logprob': -0.2240418815612793, 'compression_ratio': 1.5044247787610618, 'no_speech_prob': 0.048559971153736115}, {'id': 450, 'seek': 355450, 'start': 3568.74, 'end': 3575.74, 'text': ' with 2 and then K is a constant. Now what happens? I have a piece of code. If the name', 'tokens': [51076, 365, 568, 293, 550, 591, 307, 257, 5754, 13, 823, 437, 2314, 30, 286, 362, 257, 2522, 295, 3089, 13, 759, 264, 1315, 51426], 'temperature': 0.0, 'avg_logprob': -0.2240418815612793, 'compression_ratio': 1.5044247787610618, 'no_speech_prob': 0.048559971153736115}, {'id': 451, 'seek': 358450, 'start': 3584.5, 'end': 3591.5, 'text': ' is J, what else whose body is empty? I can even throw this off. I am doing an assignment', 'tokens': [50364, 307, 508, 11, 437, 1646, 6104, 1772, 307, 6707, 30, 286, 393, 754, 3507, 341, 766, 13, 286, 669, 884, 364, 15187, 50714], 'temperature': 0.0, 'avg_logprob': -0.3733809879847935, 'compression_ratio': 1.5344827586206897, 'no_speech_prob': 0.040654245764017105}, {'id': 452, 'seek': 358450, 'start': 3593.94, 'end': 3600.94, 'text': ' to an array. I am not using any other element. So you are left with a function that returns', 'tokens': [50836, 281, 364, 10225, 13, 286, 669, 406, 1228, 604, 661, 4478, 13, 407, 291, 366, 1411, 365, 257, 2445, 300, 11247, 51186], 'temperature': 0.0, 'avg_logprob': -0.3733809879847935, 'compression_ratio': 1.5344827586206897, 'no_speech_prob': 0.040654245764017105}, {'id': 453, 'seek': 358450, 'start': 3606.66, 'end': 3613.66, 'text': ' 2. Now we have the function is throw away the function call and return add put 2. Nice', 'tokens': [51472, 568, 13, 823, 321, 362, 264, 2445, 307, 3507, 1314, 264, 2445, 818, 293, 2736, 909, 829, 568, 13, 5490, 51822], 'temperature': 0.0, 'avg_logprob': -0.3733809879847935, 'compression_ratio': 1.5344827586206897, 'no_speech_prob': 0.040654245764017105}, {'id': 454, 'seek': 361450, 'start': 3614.9, 'end': 3621.02, 'text': ' right? And guess what? A compiler can do quite a bit of these things. The programmer has', 'tokens': [50384, 558, 30, 400, 2041, 437, 30, 316, 31958, 393, 360, 1596, 257, 857, 295, 613, 721, 13, 440, 32116, 575, 50690], 'temperature': 0.0, 'avg_logprob': -0.26366847211664374, 'compression_ratio': 1.6556603773584906, 'no_speech_prob': 0.0070619117468595505}, {'id': 455, 'seek': 361450, 'start': 3621.02, 'end': 3625.54, 'text': ' written the code because there are some initial code. See initial code was using B right?', 'tokens': [50690, 3720, 264, 3089, 570, 456, 366, 512, 5883, 3089, 13, 3008, 5883, 3089, 390, 1228, 363, 558, 30, 50916], 'temperature': 0.0, 'avg_logprob': -0.26366847211664374, 'compression_ratio': 1.6556603773584906, 'no_speech_prob': 0.0070619117468595505}, {'id': 456, 'seek': 361450, 'start': 3625.54, 'end': 3632.54, 'text': ' It can inline this piece of code as well. It so turns out even if you do not inline', 'tokens': [50916, 467, 393, 294, 1889, 341, 2522, 295, 3089, 382, 731, 13, 467, 370, 4523, 484, 754, 498, 291, 360, 406, 294, 1889, 51266], 'temperature': 0.0, 'avg_logprob': -0.26366847211664374, 'compression_ratio': 1.6556603773584906, 'no_speech_prob': 0.0070619117468595505}, {'id': 457, 'seek': 361450, 'start': 3634.38, 'end': 3641.38, 'text': ' some of these things can be done. Handling these arrays is bit tricky otherwise the rest', 'tokens': [51358, 512, 295, 613, 721, 393, 312, 1096, 13, 8854, 1688, 613, 41011, 307, 857, 12414, 5911, 264, 1472, 51708], 'temperature': 0.0, 'avg_logprob': -0.26366847211664374, 'compression_ratio': 1.6556603773584906, 'no_speech_prob': 0.0070619117468595505}, {'id': 458, 'seek': 364138, 'start': 3642.38, 'end': 3649.38, 'text': ' of the things we can do pretty well. You will actually do it. Just give it some time. If', 'tokens': [50414, 295, 264, 721, 321, 393, 360, 1238, 731, 13, 509, 486, 767, 360, 309, 13, 1449, 976, 309, 512, 565, 13, 759, 50764], 'temperature': 0.0, 'avg_logprob': -0.22830230539495294, 'compression_ratio': 1.5393258426966292, 'no_speech_prob': 0.0006862328154966235}, {'id': 459, 'seek': 364138, 'start': 3655.1400000000003, 'end': 3662.1400000000003, 'text': ' you guys are excited about doing it manually, I think you would get lot more kind of excitement', 'tokens': [51052, 291, 1074, 366, 2919, 466, 884, 309, 16945, 11, 286, 519, 291, 576, 483, 688, 544, 733, 295, 14755, 51402], 'temperature': 0.0, 'avg_logprob': -0.22830230539495294, 'compression_ratio': 1.5393258426966292, 'no_speech_prob': 0.0006862328154966235}, {'id': 460, 'seek': 364138, 'start': 3663.1400000000003, 'end': 3670.1400000000003, 'text': ' that this can actually be done automatically. I mean there is some conditional code. Just', 'tokens': [51452, 300, 341, 393, 767, 312, 1096, 6772, 13, 286, 914, 456, 307, 512, 27708, 3089, 13, 1449, 51802], 'temperature': 0.0, 'avg_logprob': -0.22830230539495294, 'compression_ratio': 1.5393258426966292, 'no_speech_prob': 0.0006862328154966235}, {'id': 461, 'seek': 367014, 'start': 3670.62, 'end': 3677.62, 'text': ' look at this code. It does not look like you can throw away the whole code right?', 'tokens': [50388, 574, 412, 341, 3089, 13, 467, 775, 406, 574, 411, 291, 393, 3507, 1314, 264, 1379, 3089, 558, 30, 50738], 'temperature': 0.0, 'avg_logprob': -0.32738979527207673, 'compression_ratio': 1.608695652173913, 'no_speech_prob': 0.0005154189420863986}, {'id': 462, 'seek': 367014, 'start': 3679.98, 'end': 3686.98, 'text': ' So now what we are saying is that is what is constant propagation right? We will take', 'tokens': [50856, 407, 586, 437, 321, 366, 1566, 307, 300, 307, 437, 307, 5754, 38377, 558, 30, 492, 486, 747, 51206], 'temperature': 0.0, 'avg_logprob': -0.32738979527207673, 'compression_ratio': 1.608695652173913, 'no_speech_prob': 0.0005154189420863986}, {'id': 463, 'seek': 367014, 'start': 3686.98, 'end': 3693.98, 'text': ' in constant propagation there are different variations we will look at. One which is called', 'tokens': [51206, 294, 5754, 38377, 456, 366, 819, 17840, 321, 486, 574, 412, 13, 1485, 597, 307, 1219, 51556], 'temperature': 0.0, 'avg_logprob': -0.32738979527207673, 'compression_ratio': 1.608695652173913, 'no_speech_prob': 0.0005154189420863986}, {'id': 464, 'seek': 369398, 'start': 3693.98, 'end': 3700.98, 'text': ' why only constant propagation? In general analysis you can think of flow sensitive and', 'tokens': [50364, 983, 787, 5754, 38377, 30, 682, 2674, 5215, 291, 393, 519, 295, 3095, 9477, 293, 50714], 'temperature': 0.0, 'avg_logprob': -0.19332890451690296, 'compression_ratio': 1.693121693121693, 'no_speech_prob': 0.0022164639085531235}, {'id': 465, 'seek': 369398, 'start': 3702.46, 'end': 3706.42, 'text': ' flow insensitive. What is flow sensitive? Let us look at this. Here is another piece', 'tokens': [50788, 3095, 1028, 34465, 13, 708, 307, 3095, 9477, 30, 961, 505, 574, 412, 341, 13, 1692, 307, 1071, 2522, 50986], 'temperature': 0.0, 'avg_logprob': -0.19332890451690296, 'compression_ratio': 1.693121693121693, 'no_speech_prob': 0.0022164639085531235}, {'id': 466, 'seek': 369398, 'start': 3706.42, 'end': 3713.42, 'text': ' of code. In this piece of code I have some condition setting abc and I have print abc', 'tokens': [50986, 295, 3089, 13, 682, 341, 2522, 295, 3089, 286, 362, 512, 4188, 3287, 410, 66, 293, 286, 362, 4482, 410, 66, 51336], 'temperature': 0.0, 'avg_logprob': -0.19332890451690296, 'compression_ratio': 1.693121693121693, 'no_speech_prob': 0.0022164639085531235}, {'id': 467, 'seek': 369398, 'start': 3714.22, 'end': 3721.22, 'text': ' else abc and print abc. Now the question is are abc constants?', 'tokens': [51376, 1646, 410, 66, 293, 4482, 410, 66, 13, 823, 264, 1168, 307, 366, 410, 66, 35870, 30, 51726], 'temperature': 0.0, 'avg_logprob': -0.19332890451690296, 'compression_ratio': 1.693121693121693, 'no_speech_prob': 0.0022164639085531235}, {'id': 468, 'seek': 372398, 'start': 3723.98, 'end': 3730.98, 'text': ' Is the value of a constant in the program? Is the value of b a constant in the program?', 'tokens': [50364, 1119, 264, 2158, 295, 257, 5754, 294, 264, 1461, 30, 1119, 264, 2158, 295, 272, 257, 5754, 294, 264, 1461, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.2904690540198124, 'compression_ratio': 2.1023622047244093, 'no_speech_prob': 0.006899842526763678}, {'id': 469, 'seek': 372398, 'start': 3735.5, 'end': 3742.5, 'text': ' Is the value of c a constant in the program? Yes c is constant both of these. So the answers', 'tokens': [50940, 1119, 264, 2158, 295, 269, 257, 5754, 294, 264, 1461, 30, 1079, 269, 307, 5754, 1293, 295, 613, 13, 407, 264, 6338, 51290], 'temperature': 0.0, 'avg_logprob': -0.2904690540198124, 'compression_ratio': 2.1023622047244093, 'no_speech_prob': 0.006899842526763678}, {'id': 470, 'seek': 372398, 'start': 3745.06, 'end': 3752.06, 'text': ' you have given is you have given me the constantness or constant information about the', 'tokens': [51418, 291, 362, 2212, 307, 291, 362, 2212, 385, 264, 5754, 1287, 420, 5754, 1589, 466, 264, 51768], 'temperature': 0.0, 'avg_logprob': -0.2904690540198124, 'compression_ratio': 2.1023622047244093, 'no_speech_prob': 0.006899842526763678}, {'id': 471, 'seek': 375398, 'start': 3753.98, 'end': 3760.98, 'text': ' flow take variable throughout the function. But what if I ask you at this line is a a', 'tokens': [50364, 3095, 747, 7006, 3710, 264, 2445, 13, 583, 437, 498, 286, 1029, 291, 412, 341, 1622, 307, 257, 257, 50714], 'temperature': 0.0, 'avg_logprob': -0.30519544667211074, 'compression_ratio': 1.6710526315789473, 'no_speech_prob': 0.0018931786762550473}, {'id': 472, 'seek': 375398, 'start': 3764.7, 'end': 3771.7, 'text': ' constant? At this line is a a constant. So now what I am saying you are now distinguishing', 'tokens': [50900, 5754, 30, 1711, 341, 1622, 307, 257, 257, 5754, 13, 407, 586, 437, 286, 669, 1566, 291, 366, 586, 11365, 3807, 51250], 'temperature': 0.0, 'avg_logprob': -0.30519544667211074, 'compression_ratio': 1.6710526315789473, 'no_speech_prob': 0.0018931786762550473}, {'id': 473, 'seek': 375398, 'start': 3776.46, 'end': 3783.46, 'text': ' between different program points the information at different program points.', 'tokens': [51488, 1296, 819, 1461, 2793, 264, 1589, 412, 819, 1461, 2793, 13, 51838], 'temperature': 0.0, 'avg_logprob': -0.30519544667211074, 'compression_ratio': 1.6710526315789473, 'no_speech_prob': 0.0018931786762550473}, {'id': 474, 'seek': 378398, 'start': 3784.62, 'end': 3791.22, 'text': ' First when we said a is a constant what we wanted is a constant across the program. Now', 'tokens': [50396, 2386, 562, 321, 848, 257, 307, 257, 5754, 437, 321, 1415, 307, 257, 5754, 2108, 264, 1461, 13, 823, 50726], 'temperature': 0.0, 'avg_logprob': -0.18936812726757193, 'compression_ratio': 1.7114427860696517, 'no_speech_prob': 0.001111149089410901}, {'id': 475, 'seek': 378398, 'start': 3791.22, 'end': 3798.22, 'text': ' we are saying is a constant at that point. Make sense? So now flow sensitive analysis', 'tokens': [50726, 321, 366, 1566, 307, 257, 5754, 412, 300, 935, 13, 4387, 2020, 30, 407, 586, 3095, 9477, 5215, 51076], 'temperature': 0.0, 'avg_logprob': -0.18936812726757193, 'compression_ratio': 1.7114427860696517, 'no_speech_prob': 0.001111149089410901}, {'id': 476, 'seek': 378398, 'start': 3801.42, 'end': 3808.14, 'text': ' will give you information which can hold at different program points. Flow insensitive', 'tokens': [51236, 486, 976, 291, 1589, 597, 393, 1797, 412, 819, 1461, 2793, 13, 32792, 1028, 34465, 51572], 'temperature': 0.0, 'avg_logprob': -0.18936812726757193, 'compression_ratio': 1.7114427860696517, 'no_speech_prob': 0.001111149089410901}, {'id': 477, 'seek': 378398, 'start': 3808.14, 'end': 3813.66, 'text': ' it should hold at every program point. It does not depend upon whether you take the', 'tokens': [51572, 309, 820, 1797, 412, 633, 1461, 935, 13, 467, 775, 406, 5672, 3564, 1968, 291, 747, 264, 51848], 'temperature': 0.0, 'avg_logprob': -0.18936812726757193, 'compression_ratio': 1.7114427860696517, 'no_speech_prob': 0.001111149089410901}, {'id': 478, 'seek': 381366, 'start': 3813.66, 'end': 3820.66, 'text': ' then branch or the else branch. Similar to flow sensitive and flow insensitive you can', 'tokens': [50364, 550, 9819, 420, 264, 1646, 9819, 13, 10905, 281, 3095, 9477, 293, 3095, 1028, 34465, 291, 393, 50714], 'temperature': 0.0, 'avg_logprob': -0.15484259101781953, 'compression_ratio': 1.6699507389162562, 'no_speech_prob': 0.00044415908632799983}, {'id': 479, 'seek': 381366, 'start': 3821.7, 'end': 3828.7, 'text': ' also have context sensitive and context insensitive. What do we mean by that? Here is a piece of', 'tokens': [50766, 611, 362, 4319, 9477, 293, 4319, 1028, 34465, 13, 708, 360, 321, 914, 538, 300, 30, 1692, 307, 257, 2522, 295, 51116], 'temperature': 0.0, 'avg_logprob': -0.15484259101781953, 'compression_ratio': 1.6699507389162562, 'no_speech_prob': 0.00044415908632799983}, {'id': 480, 'seek': 381366, 'start': 3828.94, 'end': 3835.94, 'text': ' code that uses two functions foo and bar. Foo takes an argument x and returns x. Bar', 'tokens': [51128, 3089, 300, 4960, 732, 6828, 726, 78, 293, 2159, 13, 8564, 78, 2516, 364, 6770, 2031, 293, 11247, 2031, 13, 4156, 51478], 'temperature': 0.0, 'avg_logprob': -0.15484259101781953, 'compression_ratio': 1.6699507389162562, 'no_speech_prob': 0.00044415908632799983}, {'id': 481, 'seek': 381366, 'start': 3835.94, 'end': 3842.94, 'text': ' does x square and returns. Now I have a equal to foo 2, b equal to foo', 'tokens': [51478, 775, 2031, 3732, 293, 11247, 13, 823, 286, 362, 257, 2681, 281, 726, 78, 568, 11, 272, 2681, 281, 726, 78, 51828], 'temperature': 0.0, 'avg_logprob': -0.15484259101781953, 'compression_ratio': 1.6699507389162562, 'no_speech_prob': 0.00044415908632799983}, {'id': 482, 'seek': 384366, 'start': 3843.98, 'end': 3850.98, 'text': ' 3, c equal to bar 2, d equal to bar 2. Now the question are ABCD constants? Is a a constant?', 'tokens': [50380, 805, 11, 269, 2681, 281, 2159, 568, 11, 274, 2681, 281, 2159, 568, 13, 823, 264, 1168, 366, 22342, 35, 35870, 30, 1119, 257, 257, 5754, 30, 50730], 'temperature': 0.0, 'avg_logprob': -0.20467878737539616, 'compression_ratio': 1.4715447154471544, 'no_speech_prob': 0.0008685081265866756}, {'id': 483, 'seek': 384366, 'start': 3863.2599999999998, 'end': 3870.2599999999998, 'text': ' Let us ask this question. Is this x a constant? Does foo always return a constant value?', 'tokens': [51344, 961, 505, 1029, 341, 1168, 13, 1119, 341, 2031, 257, 5754, 30, 4402, 726, 78, 1009, 2736, 257, 5754, 2158, 30, 51694], 'temperature': 0.0, 'avg_logprob': -0.20467878737539616, 'compression_ratio': 1.4715447154471544, 'no_speech_prob': 0.0008685081265866756}, {'id': 484, 'seek': 387366, 'start': 3874.66, 'end': 3881.66, 'text': ' What value does foo return? Let me repeat the question. The values that you may tell', 'tokens': [50414, 708, 2158, 775, 726, 78, 2736, 30, 961, 385, 7149, 264, 1168, 13, 440, 4190, 300, 291, 815, 980, 50764], 'temperature': 0.0, 'avg_logprob': -0.1529693118596481, 'compression_ratio': 1.6204379562043796, 'no_speech_prob': 0.006020271684974432}, {'id': 485, 'seek': 387366, 'start': 3885.2999999999997, 'end': 3892.2999999999997, 'text': ' me has to be an integer value or do not know. Let me ask this question again. Does foo return', 'tokens': [50946, 385, 575, 281, 312, 364, 24922, 2158, 420, 360, 406, 458, 13, 961, 385, 1029, 341, 1168, 797, 13, 4402, 726, 78, 2736, 51296], 'temperature': 0.0, 'avg_logprob': -0.1529693118596481, 'compression_ratio': 1.6204379562043796, 'no_speech_prob': 0.006020271684974432}, {'id': 486, 'seek': 387366, 'start': 3894.8999999999996, 'end': 3901.8999999999996, 'text': ' a constant integer value or we do not know?', 'tokens': [51426, 257, 5754, 24922, 2158, 420, 321, 360, 406, 458, 30, 51776], 'temperature': 0.0, 'avg_logprob': -0.1529693118596481, 'compression_ratio': 1.6204379562043796, 'no_speech_prob': 0.006020271684974432}, {'id': 487, 'seek': 390366, 'start': 3903.66, 'end': 3910.66, 'text': ' We do not know. It may return 2 or 3 since it is not a single constant value. What about', 'tokens': [50364, 492, 360, 406, 458, 13, 467, 815, 2736, 568, 420, 805, 1670, 309, 307, 406, 257, 2167, 5754, 2158, 13, 708, 466, 50714], 'temperature': 0.0, 'avg_logprob': -0.31282379150390627, 'compression_ratio': 1.3237410071942446, 'no_speech_prob': 0.0014982755528762937}, {'id': 488, 'seek': 390366, 'start': 3911.42, 'end': 3918.42, 'text': ' bar? We know because bar takes. In this program we know. Now if I do intra procedural analysis,', 'tokens': [50752, 2159, 30, 492, 458, 570, 2159, 2516, 13, 682, 341, 1461, 321, 458, 13, 823, 498, 286, 360, 43358, 43951, 5215, 11, 51102], 'temperature': 0.0, 'avg_logprob': -0.31282379150390627, 'compression_ratio': 1.3237410071942446, 'no_speech_prob': 0.0014982755528762937}, {'id': 489, 'seek': 391842, 'start': 3918.42, 'end': 3925.42, 'text': ' if I look at one procedure at a time and do not look at any other code, when I look at', 'tokens': [50364, 498, 286, 574, 412, 472, 10747, 412, 257, 565, 293, 360, 406, 574, 412, 604, 661, 3089, 11, 562, 286, 574, 412, 50714], 'temperature': 0.0, 'avg_logprob': -0.19786420280550732, 'compression_ratio': 1.7070063694267517, 'no_speech_prob': 0.004897645674645901}, {'id': 490, 'seek': 391842, 'start': 3933.9, 'end': 3938.9, 'text': ' a equal to foo, I say I do not know anything about foo. It must be returning some non-constant.', 'tokens': [51138, 257, 2681, 281, 726, 78, 11, 286, 584, 286, 360, 406, 458, 1340, 466, 726, 78, 13, 467, 1633, 312, 12678, 512, 2107, 12, 25279, 394, 13, 51388], 'temperature': 0.0, 'avg_logprob': -0.19786420280550732, 'compression_ratio': 1.7070063694267517, 'no_speech_prob': 0.004897645674645901}, {'id': 491, 'seek': 391842, 'start': 3938.9, 'end': 3945.9, 'text': ' B equal to foo, I do not know anything what foo does. But if I do intra procedural, I', 'tokens': [51388, 363, 2681, 281, 726, 78, 11, 286, 360, 406, 458, 1340, 437, 726, 78, 775, 13, 583, 498, 286, 360, 43358, 43951, 11, 286, 51738], 'temperature': 0.0, 'avg_logprob': -0.19786420280550732, 'compression_ratio': 1.7070063694267517, 'no_speech_prob': 0.004897645674645901}, {'id': 492, 'seek': 394590, 'start': 3946.78, 'end': 3953.78, 'text': ' can look at other functions. When I look at other functions, what options do I have? When', 'tokens': [50408, 393, 574, 412, 661, 6828, 13, 1133, 286, 574, 412, 661, 6828, 11, 437, 3956, 360, 286, 362, 30, 1133, 50758], 'temperature': 0.0, 'avg_logprob': -0.12032181338260048, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.0015675316099077463}, {'id': 493, 'seek': 394590, 'start': 3956.54, 'end': 3963.54, 'text': ' I do, when I look at this function foo, one option is every time there is a call, I go', 'tokens': [50896, 286, 360, 11, 562, 286, 574, 412, 341, 2445, 726, 78, 11, 472, 3614, 307, 633, 565, 456, 307, 257, 818, 11, 286, 352, 51246], 'temperature': 0.0, 'avg_logprob': -0.12032181338260048, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.0015675316099077463}, {'id': 494, 'seek': 394590, 'start': 3964.26, 'end': 3971.26, 'text': ' analyze foo and come back. So here is a call to foo. I will go here, analyze this function', 'tokens': [51282, 12477, 726, 78, 293, 808, 646, 13, 407, 510, 307, 257, 818, 281, 726, 78, 13, 286, 486, 352, 510, 11, 12477, 341, 2445, 51632], 'temperature': 0.0, 'avg_logprob': -0.12032181338260048, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.0015675316099077463}, {'id': 495, 'seek': 397126, 'start': 3972.2200000000003, 'end': 3979.2200000000003, 'text': ' and give you answer 2. So here it returned a constant. Here again I will go here, it', 'tokens': [50412, 293, 976, 291, 1867, 568, 13, 407, 510, 309, 8752, 257, 5754, 13, 1692, 797, 286, 486, 352, 510, 11, 309, 50762], 'temperature': 0.0, 'avg_logprob': -0.26863326607169685, 'compression_ratio': 1.8810810810810812, 'no_speech_prob': 0.002495293039828539}, {'id': 496, 'seek': 397126, 'start': 3979.2200000000003, 'end': 3983.94, 'text': ' will return 3. Here again I will call bar, I will analyze bar and come back. I will say', 'tokens': [50762, 486, 2736, 805, 13, 1692, 797, 286, 486, 818, 2159, 11, 286, 486, 12477, 2159, 293, 808, 646, 13, 286, 486, 584, 50998], 'temperature': 0.0, 'avg_logprob': -0.26863326607169685, 'compression_ratio': 1.8810810810810812, 'no_speech_prob': 0.002495293039828539}, {'id': 497, 'seek': 397126, 'start': 3983.94, 'end': 3990.94, 'text': ' it returns a constant 4. Here it returns a constant 4 and all constants. So how many', 'tokens': [50998, 309, 11247, 257, 5754, 1017, 13, 1692, 309, 11247, 257, 5754, 1017, 293, 439, 35870, 13, 407, 577, 867, 51348], 'temperature': 0.0, 'avg_logprob': -0.26863326607169685, 'compression_ratio': 1.8810810810810812, 'no_speech_prob': 0.002495293039828539}, {'id': 498, 'seek': 397126, 'start': 3990.98, 'end': 3997.98, 'text': ' times you have to analyze the function? Four times in this case. In general how many times', 'tokens': [51350, 1413, 291, 362, 281, 12477, 264, 2445, 30, 7451, 1413, 294, 341, 1389, 13, 682, 2674, 577, 867, 1413, 51700], 'temperature': 0.0, 'avg_logprob': -0.26863326607169685, 'compression_ratio': 1.8810810810810812, 'no_speech_prob': 0.002495293039828539}, {'id': 499, 'seek': 399798, 'start': 3998.42, 'end': 4005.42, 'text': ' I may have to analyze the function? In this scheme of things. What is your name? Yes.', 'tokens': [50386, 286, 815, 362, 281, 12477, 264, 2445, 30, 682, 341, 12232, 295, 721, 13, 708, 307, 428, 1315, 30, 1079, 13, 50736], 'temperature': 0.0, 'avg_logprob': -0.23802657749341882, 'compression_ratio': 1.390625, 'no_speech_prob': 0.0027937046252191067}, {'id': 500, 'seek': 399798, 'start': 4014.5, 'end': 4021.02, 'text': ' So yes said something to a question. My question was if I am analyzing a function every time', 'tokens': [51190, 407, 2086, 848, 746, 281, 257, 1168, 13, 1222, 1168, 390, 498, 286, 669, 23663, 257, 2445, 633, 565, 51516], 'temperature': 0.0, 'avg_logprob': -0.23802657749341882, 'compression_ratio': 1.390625, 'no_speech_prob': 0.0027937046252191067}, {'id': 501, 'seek': 402102, 'start': 4021.02, 'end': 4028.02, 'text': ' there is a call, yes said if there are n calls then I will analyze the function n times.', 'tokens': [50364, 456, 307, 257, 818, 11, 2086, 848, 498, 456, 366, 297, 5498, 550, 286, 486, 12477, 264, 2445, 297, 1413, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.23111374524174905, 'compression_ratio': 1.4754098360655739, 'no_speech_prob': 0.004884031135588884}, {'id': 502, 'seek': 402102, 'start': 4033.38, 'end': 4040.38, 'text': ' How many of you agree? How many of you disagree? Those of you disagree why? Will it be more', 'tokens': [50982, 1012, 867, 295, 291, 3986, 30, 1012, 867, 295, 291, 14091, 30, 3950, 295, 291, 14091, 983, 30, 3099, 309, 312, 544, 51332], 'temperature': 0.0, 'avg_logprob': -0.23111374524174905, 'compression_ratio': 1.4754098360655739, 'no_speech_prob': 0.004884031135588884}, {'id': 503, 'seek': 404038, 'start': 4040.38, 'end': 4047.38, 'text': ' or less? You are saying it is less. Why? Because what I am saying is here itself there are', 'tokens': [50364, 420, 1570, 30, 509, 366, 1566, 309, 307, 1570, 13, 1545, 30, 1436, 437, 286, 669, 1566, 307, 510, 2564, 456, 366, 50714], 'temperature': 0.0, 'avg_logprob': -0.28758448939169606, 'compression_ratio': 1.4726027397260273, 'no_speech_prob': 0.01270017959177494}, {'id': 504, 'seek': 404038, 'start': 4056.94, 'end': 4061.94, 'text': ' two calls to foo. I have analyzed foo twice. So if there are n calls I will analyze it', 'tokens': [51192, 732, 5498, 281, 726, 78, 13, 286, 362, 28181, 726, 78, 6091, 13, 407, 498, 456, 366, 297, 5498, 286, 486, 12477, 309, 51442], 'temperature': 0.0, 'avg_logprob': -0.28758448939169606, 'compression_ratio': 1.4726027397260273, 'no_speech_prob': 0.01270017959177494}, {'id': 505, 'seek': 404038, 'start': 4061.94, 'end': 4068.94, 'text': ' at least n times. That is very clear.', 'tokens': [51442, 412, 1935, 297, 1413, 13, 663, 307, 588, 1850, 13, 51792], 'temperature': 0.0, 'avg_logprob': -0.28758448939169606, 'compression_ratio': 1.4726027397260273, 'no_speech_prob': 0.01270017959177494}, {'id': 506, 'seek': 407038, 'start': 4070.38, 'end': 4077.38, 'text': ' So what you are saying if I have already analyzed the function bar with the same inputs why', 'tokens': [50364, 407, 437, 291, 366, 1566, 498, 286, 362, 1217, 28181, 264, 2445, 2159, 365, 264, 912, 15743, 983, 50714], 'temperature': 0.0, 'avg_logprob': -0.15405586787632533, 'compression_ratio': 1.5654761904761905, 'no_speech_prob': 0.005132389720529318}, {'id': 507, 'seek': 407038, 'start': 4081.1400000000003, 'end': 4087.78, 'text': ' should I reanalyze it? But I did not go to that level yet. I am saying if I tell you', 'tokens': [50902, 820, 286, 319, 282, 5222, 1381, 309, 30, 583, 286, 630, 406, 352, 281, 300, 1496, 1939, 13, 286, 669, 1566, 498, 286, 980, 291, 51234], 'temperature': 0.0, 'avg_logprob': -0.15405586787632533, 'compression_ratio': 1.5654761904761905, 'no_speech_prob': 0.005132389720529318}, {'id': 508, 'seek': 407038, 'start': 4087.78, 'end': 4093.86, 'text': ' that I have to analyze a function every time there is a call and if in the program you', 'tokens': [51234, 300, 286, 362, 281, 12477, 257, 2445, 633, 565, 456, 307, 257, 818, 293, 498, 294, 264, 1461, 291, 51538], 'temperature': 0.0, 'avg_logprob': -0.15405586787632533, 'compression_ratio': 1.5654761904761905, 'no_speech_prob': 0.005132389720529318}, {'id': 509, 'seek': 409386, 'start': 4093.86, 'end': 4100.860000000001, 'text': ' see there are n calls to foo how many times will you analyze foo? And he said n. How many', 'tokens': [50364, 536, 456, 366, 297, 5498, 281, 726, 78, 577, 867, 1413, 486, 291, 12477, 726, 78, 30, 400, 415, 848, 297, 13, 1012, 867, 50714], 'temperature': 0.0, 'avg_logprob': -0.221005818615221, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.0075423019006848335}, {'id': 510, 'seek': 409386, 'start': 4101.1, 'end': 4108.1, 'text': ' of you agree that it will be n? Now you have more supporters. So your support base is increasing.', 'tokens': [50726, 295, 291, 3986, 300, 309, 486, 312, 297, 30, 823, 291, 362, 544, 17683, 13, 407, 428, 1406, 3096, 307, 5662, 13, 51076], 'temperature': 0.0, 'avg_logprob': -0.221005818615221, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.0075423019006848335}, {'id': 511, 'seek': 409386, 'start': 4110.46, 'end': 4117.46, 'text': ' What is the if statement? Yes, the scheme is that. The scheme is that we will analyze', 'tokens': [51194, 708, 307, 264, 498, 5629, 30, 1079, 11, 264, 12232, 307, 300, 13, 440, 12232, 307, 300, 321, 486, 12477, 51544], 'temperature': 0.0, 'avg_logprob': -0.221005818615221, 'compression_ratio': 1.5780346820809248, 'no_speech_prob': 0.0075423019006848335}, {'id': 512, 'seek': 412386, 'start': 4123.86, 'end': 4128.0599999999995, 'text': ' foo. No, let us not worry about the input. Let us say we have no way to know the inputs.', 'tokens': [50364, 726, 78, 13, 883, 11, 718, 505, 406, 3292, 466, 264, 4846, 13, 961, 505, 584, 321, 362, 572, 636, 281, 458, 264, 15743, 13, 50574], 'temperature': 0.0, 'avg_logprob': -0.254050045921689, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.0102631701156497}, {'id': 513, 'seek': 412386, 'start': 4128.0599999999995, 'end': 4132.82, 'text': ' All I am doing is whenever there is a call I will go to that function and come back.', 'tokens': [50574, 1057, 286, 669, 884, 307, 5699, 456, 307, 257, 818, 286, 486, 352, 281, 300, 2445, 293, 808, 646, 13, 50812], 'temperature': 0.0, 'avg_logprob': -0.254050045921689, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.0102631701156497}, {'id': 514, 'seek': 412386, 'start': 4132.82, 'end': 4139.259999999999, 'text': ' So I am saying how many times will I go to that function and come back? Yes sir there', 'tokens': [50812, 407, 286, 669, 1566, 577, 867, 1413, 486, 286, 352, 281, 300, 2445, 293, 808, 646, 30, 1079, 4735, 456, 51134], 'temperature': 0.0, 'avg_logprob': -0.254050045921689, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.0102631701156497}, {'id': 515, 'seek': 412386, 'start': 4139.259999999999, 'end': 4146.259999999999, 'text': ' are n calls. I will do n times. How many of you agree? What is your name? No, no not Adhvith.', 'tokens': [51134, 366, 297, 5498, 13, 286, 486, 360, 297, 1413, 13, 1012, 867, 295, 291, 3986, 30, 708, 307, 428, 1315, 30, 883, 11, 572, 406, 1999, 71, 85, 355, 13, 51484], 'temperature': 0.0, 'avg_logprob': -0.254050045921689, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.0102631701156497}, {'id': 516, 'seek': 414626, 'start': 4146.26, 'end': 4153.26, 'text': ' Praful. Praful what do you think? N times. Why n times? Now I am making a statement.', 'tokens': [50364, 12133, 906, 13, 12133, 906, 437, 360, 291, 519, 30, 426, 1413, 13, 1545, 297, 1413, 30, 823, 286, 669, 1455, 257, 5629, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.5409245186663688, 'compression_ratio': 1.3412698412698412, 'no_speech_prob': 0.032931696623563766}, {'id': 517, 'seek': 414626, 'start': 4167.7, 'end': 4174.7, 'text': ' It can call exponential times, exponential number of times. So I am saying that if I', 'tokens': [51436, 467, 393, 818, 21510, 1413, 11, 21510, 1230, 295, 1413, 13, 407, 286, 669, 1566, 300, 498, 286, 51786], 'temperature': 0.0, 'avg_logprob': -0.5409245186663688, 'compression_ratio': 1.3412698412698412, 'no_speech_prob': 0.032931696623563766}, {'id': 518, 'seek': 417626, 'start': 4176.26, 'end': 4183.26, 'text': ' have n, if the program size is n, I may have order of 2 to the power of n. Is it possible?', 'tokens': [50364, 362, 297, 11, 498, 264, 1461, 2744, 307, 297, 11, 286, 815, 362, 1668, 295, 568, 281, 264, 1347, 295, 297, 13, 1119, 309, 1944, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.4345458348592122, 'compression_ratio': 1.0975609756097562, 'no_speech_prob': 0.10580352693796158}, {'id': 519, 'seek': 418326, 'start': 4183.26, 'end': 4190.26, 'text': ' Yes. No, let us not. All I am doing is I am looking at the call. Every time there is a', 'tokens': [50364, 1079, 13, 883, 11, 718, 505, 406, 13, 1057, 286, 669, 884, 307, 286, 669, 1237, 412, 264, 818, 13, 2048, 565, 456, 307, 257, 50714], 'temperature': 0.0, 'avg_logprob': -0.35301280843800514, 'compression_ratio': 1.0617283950617284, 'no_speech_prob': 0.1458113044500351}, {'id': 520, 'seek': 419026, 'start': 4190.26, 'end': 4197.26, 'text': ' call, I will just go there. I will analyze that function and come back. So I am not looking', 'tokens': [50364, 818, 11, 286, 486, 445, 352, 456, 13, 286, 486, 12477, 300, 2445, 293, 808, 646, 13, 407, 286, 669, 406, 1237, 50714], 'temperature': 0.0, 'avg_logprob': -0.34384833849393404, 'compression_ratio': 1.0963855421686748, 'no_speech_prob': 0.07141781598329544}, {'id': 521, 'seek': 419726, 'start': 4197.26, 'end': 4204.26, 'text': ' at variables let us say. You are saying if the function is calling itself, then it is', 'tokens': [50364, 412, 9102, 718, 505, 584, 13, 509, 366, 1566, 498, 264, 2445, 307, 5141, 2564, 11, 550, 309, 307, 50714], 'temperature': 0.0, 'avg_logprob': -0.5276639678261497, 'compression_ratio': 1.118421052631579, 'no_speech_prob': 0.13622018694877625}, {'id': 522, 'seek': 422726, 'start': 4228.26, 'end': 4231.5, 'text': ' going to be infinite loop. Then it may keep on calling itself, it will keep on visiting', 'tokens': [50414, 516, 281, 312, 13785, 6367, 13, 1396, 309, 815, 1066, 322, 5141, 2564, 11, 309, 486, 1066, 322, 11700, 50576], 'temperature': 0.0, 'avg_logprob': -0.24662338419163482, 'compression_ratio': 1.7707317073170732, 'no_speech_prob': 0.05091516673564911}, {'id': 523, 'seek': 422726, 'start': 4231.5, 'end': 4238.5, 'text': ' itself. So that will go into infinite loop. Let us say we are avoiding recursion to keep', 'tokens': [50576, 2564, 13, 407, 300, 486, 352, 666, 13785, 6367, 13, 961, 505, 584, 321, 366, 20220, 20560, 313, 281, 1066, 50926], 'temperature': 0.0, 'avg_logprob': -0.24662338419163482, 'compression_ratio': 1.7707317073170732, 'no_speech_prob': 0.05091516673564911}, {'id': 524, 'seek': 422726, 'start': 4239.38, 'end': 4246.38, 'text': ' it simple. Very good point. So in recursion, how do you handle recursion? That is a difficult', 'tokens': [50970, 309, 2199, 13, 4372, 665, 935, 13, 407, 294, 20560, 313, 11, 577, 360, 291, 4813, 20560, 313, 30, 663, 307, 257, 2252, 51320], 'temperature': 0.0, 'avg_logprob': -0.24662338419163482, 'compression_ratio': 1.7707317073170732, 'no_speech_prob': 0.05091516673564911}, {'id': 525, 'seek': 422726, 'start': 4246.5, 'end': 4253.5, 'text': ' task but let us say we are not going to recursion for the time being. There is no recursion.', 'tokens': [51326, 5633, 457, 718, 505, 584, 321, 366, 406, 516, 281, 20560, 313, 337, 264, 565, 885, 13, 821, 307, 572, 20560, 313, 13, 51676], 'temperature': 0.0, 'avg_logprob': -0.24662338419163482, 'compression_ratio': 1.7707317073170732, 'no_speech_prob': 0.05091516673564911}, {'id': 526, 'seek': 425726, 'start': 4257.26, 'end': 4264.26, 'text': ' You are trying to fit the answer. No, do not try to fit the answer to. Yes, guys.', 'tokens': [50364, 509, 366, 1382, 281, 3318, 264, 1867, 13, 883, 11, 360, 406, 853, 281, 3318, 264, 1867, 281, 13, 1079, 11, 1074, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.5467928780449761, 'compression_ratio': 1.1571428571428573, 'no_speech_prob': 0.08566618710756302}, {'id': 527, 'seek': 426426, 'start': 4264.26, 'end': 4272.26, 'text': ' Power set is it? Power set is it? Yes.', 'tokens': [50414, 7086, 992, 307, 309, 30, 7086, 992, 307, 309, 30, 1079, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.883046277364095, 'compression_ratio': 1.1875, 'no_speech_prob': 0.16583460569381714}, {'id': 528, 'seek': 429426, 'start': 4295.26, 'end': 4302.26, 'text': ' I am not really sure how I can map it to power set but here should I give the answer? No,', 'tokens': [50414, 286, 669, 406, 534, 988, 577, 286, 393, 4471, 309, 281, 1347, 992, 457, 510, 820, 286, 976, 264, 1867, 30, 883, 11, 50764], 'temperature': 0.0, 'avg_logprob': -0.351076534816197, 'compression_ratio': 1.316546762589928, 'no_speech_prob': 0.0249574463814497}, {'id': 529, 'seek': 429426, 'start': 4307.26, 'end': 4314.26, 'text': ' right? Let me make your life simpler. No if conditions, no recursion. No, I did not say', 'tokens': [51014, 558, 30, 961, 385, 652, 428, 993, 18587, 13, 883, 498, 4487, 11, 572, 20560, 313, 13, 883, 11, 286, 630, 406, 584, 51364], 'temperature': 0.0, 'avg_logprob': -0.351076534816197, 'compression_ratio': 1.316546762589928, 'no_speech_prob': 0.0249574463814497}, {'id': 530, 'seek': 429426, 'start': 4316.780000000001, 'end': 4318.26, 'text': ' that.', 'tokens': [51490, 300, 13, 51564], 'temperature': 0.0, 'avg_logprob': -0.351076534816197, 'compression_ratio': 1.316546762589928, 'no_speech_prob': 0.0249574463814497}, {'id': 531, 'seek': 431826, 'start': 4318.26, 'end': 4325.26, 'text': ' No, sorry what are you saying again? There must be a water bottle here that I was using.', 'tokens': [50364, 883, 11, 2597, 437, 366, 291, 1566, 797, 30, 821, 1633, 312, 257, 1281, 7817, 510, 300, 286, 390, 1228, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.2799887858646017, 'compression_ratio': 1.583815028901734, 'no_speech_prob': 0.036460619419813156}, {'id': 532, 'seek': 431826, 'start': 4330.66, 'end': 4336.58, 'text': ' Must have been this guy. I am trying to understand so you have to complete the sentence. So those', 'tokens': [50984, 13252, 362, 668, 341, 2146, 13, 286, 669, 1382, 281, 1223, 370, 291, 362, 281, 3566, 264, 8174, 13, 407, 729, 51280], 'temperature': 0.0, 'avg_logprob': -0.2799887858646017, 'compression_ratio': 1.583815028901734, 'no_speech_prob': 0.036460619419813156}, {'id': 533, 'seek': 431826, 'start': 4336.58, 'end': 4343.58, 'text': ' who have not answered so far, give it a try. Those who have not spoken so far, you have', 'tokens': [51280, 567, 362, 406, 10103, 370, 1400, 11, 976, 309, 257, 853, 13, 3950, 567, 362, 406, 10759, 370, 1400, 11, 291, 362, 51630], 'temperature': 0.0, 'avg_logprob': -0.2799887858646017, 'compression_ratio': 1.583815028901734, 'no_speech_prob': 0.036460619419813156}, {'id': 534, 'seek': 434826, 'start': 4348.26, 'end': 4355.26, 'text': ' to complete the sentence. What is your name? Sushrath. Beautiful name. Yes, Sushrath. What', 'tokens': [50364, 281, 3566, 264, 8174, 13, 708, 307, 428, 1315, 30, 318, 1498, 81, 998, 13, 14724, 1315, 13, 1079, 11, 318, 1498, 81, 998, 13, 708, 50714], 'temperature': 0.0, 'avg_logprob': -0.3451337938184862, 'compression_ratio': 1.439153439153439, 'no_speech_prob': 0.022700952365994453}, {'id': 535, 'seek': 434826, 'start': 4356.9400000000005, 'end': 4363.9400000000005, 'text': ' do you think? Did you understand the question? No, let us say we always analyze the function.', 'tokens': [50798, 360, 291, 519, 30, 2589, 291, 1223, 264, 1168, 30, 883, 11, 718, 505, 584, 321, 1009, 12477, 264, 2445, 13, 51148], 'temperature': 0.0, 'avg_logprob': -0.3451337938184862, 'compression_ratio': 1.439153439153439, 'no_speech_prob': 0.022700952365994453}, {'id': 536, 'seek': 434826, 'start': 4368.62, 'end': 4375.42, 'text': ' I am just saying, I am keeping life simple. Sure, do consider. Give me an example. Make', 'tokens': [51382, 286, 669, 445, 1566, 11, 286, 669, 5145, 993, 2199, 13, 4894, 11, 360, 1949, 13, 5303, 385, 364, 1365, 13, 4387, 51722], 'temperature': 0.0, 'avg_logprob': -0.3451337938184862, 'compression_ratio': 1.439153439153439, 'no_speech_prob': 0.022700952365994453}, {'id': 537, 'seek': 437542, 'start': 4375.42, 'end': 4382.42, 'text': ' an example. Example, example. So those of you who are trying to come up with a scheme,', 'tokens': [50364, 364, 1365, 13, 24755, 781, 11, 1365, 13, 407, 729, 295, 291, 567, 366, 1382, 281, 808, 493, 365, 257, 12232, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.33921051025390625, 'compression_ratio': 1.5467625899280575, 'no_speech_prob': 0.0030737449415028095}, {'id': 538, 'seek': 437542, 'start': 4383.02, 'end': 4390.02, 'text': ' the best way is to write a small example in your textbook if you can come up with an example.', 'tokens': [50744, 264, 1151, 636, 307, 281, 2464, 257, 1359, 1365, 294, 428, 25591, 498, 291, 393, 808, 493, 365, 364, 1365, 13, 51094], 'temperature': 0.0, 'avg_logprob': -0.33921051025390625, 'compression_ratio': 1.5467625899280575, 'no_speech_prob': 0.0030737449415028095}, {'id': 539, 'seek': 437542, 'start': 4392.22, 'end': 4399.22, 'text': ' Sorry, sorry. They know if blocks.', 'tokens': [51204, 4919, 11, 2597, 13, 814, 458, 498, 8474, 13, 51554], 'temperature': 0.0, 'avg_logprob': -0.33921051025390625, 'compression_ratio': 1.5467625899280575, 'no_speech_prob': 0.0030737449415028095}, {'id': 540, 'seek': 440542, 'start': 4405.42, 'end': 4412.42, 'text': ' Do not worry about the input. If you do not like it, let us say that it takes no arguments.', 'tokens': [50364, 1144, 406, 3292, 466, 264, 4846, 13, 759, 291, 360, 406, 411, 309, 11, 718, 505, 584, 300, 309, 2516, 572, 12869, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.3690795409373748, 'compression_ratio': 1.3017241379310345, 'no_speech_prob': 0.021520650014281273}, {'id': 541, 'seek': 440542, 'start': 4414.9400000000005, 'end': 4421.9400000000005, 'text': ' I am just being deliberately making it ridiculously simple.', 'tokens': [50840, 286, 669, 445, 885, 23506, 1455, 309, 41358, 2199, 13, 51190], 'temperature': 0.0, 'avg_logprob': -0.3690795409373748, 'compression_ratio': 1.3017241379310345, 'no_speech_prob': 0.021520650014281273}, {'id': 542, 'seek': 442194, 'start': 4421.94, 'end': 4428.94, 'text': ' Then, actually it is so simple. I do not think we should spend more time on this. It is a', 'tokens': [50364, 1396, 11, 767, 309, 307, 370, 2199, 13, 286, 360, 406, 519, 321, 820, 3496, 544, 565, 322, 341, 13, 467, 307, 257, 50714], 'temperature': 0.0, 'avg_logprob': -0.3391361970167894, 'compression_ratio': 1.2571428571428571, 'no_speech_prob': 0.030190112069249153}, {'id': 543, 'seek': 442194, 'start': 4441.219999999999, 'end': 4448.219999999999, 'text': ' pattern that once you know, you know. Yes.', 'tokens': [51328, 5102, 300, 1564, 291, 458, 11, 291, 458, 13, 1079, 13, 51678], 'temperature': 0.0, 'avg_logprob': -0.3391361970167894, 'compression_ratio': 1.2571428571428571, 'no_speech_prob': 0.030190112069249153}, {'id': 544, 'seek': 445194, 'start': 4451.94, 'end': 4458.94, 'text': ' Good. When will such a thing happen? When will that happen? So, your name? Rishabh said,', 'tokens': [50364, 2205, 13, 1133, 486, 1270, 257, 551, 1051, 30, 1133, 486, 300, 1051, 30, 407, 11, 428, 1315, 30, 497, 742, 455, 71, 848, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.24018704051702794, 'compression_ratio': 1.6358024691358024, 'no_speech_prob': 0.03709729388356209}, {'id': 545, 'seek': 445194, 'start': 4462.98, 'end': 4468.419999999999, 'text': ' to analyze, I will complete the analysis of one function only if I have analyzed some', 'tokens': [50916, 281, 12477, 11, 286, 486, 3566, 264, 5215, 295, 472, 2445, 787, 498, 286, 362, 28181, 512, 51188], 'temperature': 0.0, 'avg_logprob': -0.24018704051702794, 'compression_ratio': 1.6358024691358024, 'no_speech_prob': 0.03709729388356209}, {'id': 546, 'seek': 445194, 'start': 4468.419999999999, 'end': 4475.419999999999, 'text': ' other functions. When will that happen? Good. One cause the other. Then, what will happen?', 'tokens': [51188, 661, 6828, 13, 1133, 486, 300, 1051, 30, 2205, 13, 1485, 3082, 264, 661, 13, 1396, 11, 437, 486, 1051, 30, 51538], 'temperature': 0.0, 'avg_logprob': -0.24018704051702794, 'compression_ratio': 1.6358024691358024, 'no_speech_prob': 0.03709729388356209}, {'id': 547, 'seek': 447542, 'start': 4475.9400000000005, 'end': 4482.9400000000005, 'text': ' Let us take this example. Very simple example. I have function f1 that calls f2 twice. I', 'tokens': [50390, 961, 505, 747, 341, 1365, 13, 4372, 2199, 1365, 13, 286, 362, 2445, 283, 16, 300, 5498, 283, 17, 6091, 13, 286, 50740], 'temperature': 0.0, 'avg_logprob': -0.24670687428227178, 'compression_ratio': 1.4471544715447155, 'no_speech_prob': 0.008538544178009033}, {'id': 548, 'seek': 447542, 'start': 4491.18, 'end': 4498.18, 'text': ' have code f2 that calls f3. How many times? Twice. I have f3 which calls f, no our friend', 'tokens': [51152, 362, 3089, 283, 17, 300, 5498, 283, 18, 13, 1012, 867, 1413, 30, 46964, 13, 286, 362, 283, 18, 597, 5498, 283, 11, 572, 527, 1277, 51502], 'temperature': 0.0, 'avg_logprob': -0.24670687428227178, 'compression_ratio': 1.4471544715447155, 'no_speech_prob': 0.008538544178009033}, {'id': 549, 'seek': 449818, 'start': 4498.18, 'end': 4505.18, 'text': ' Fu there. How many times will I analyze Fu? Right? So, twice, four times. So, if it is', 'tokens': [50364, 12807, 456, 13, 1012, 867, 1413, 486, 286, 12477, 12807, 30, 1779, 30, 407, 11, 6091, 11, 1451, 1413, 13, 407, 11, 498, 309, 307, 50714], 'temperature': 0.0, 'avg_logprob': -0.24015183108193533, 'compression_ratio': 1.036144578313253, 'no_speech_prob': 0.05697488412261009}, {'id': 550, 'seek': 452818, 'start': 4528.38, 'end': 4535.38, 'text': ' you keep on increasing it will be 4, 8, 16. So, doing context sensitive analysis is going', 'tokens': [50374, 291, 1066, 322, 5662, 309, 486, 312, 1017, 11, 1649, 11, 3165, 13, 407, 11, 884, 4319, 9477, 5215, 307, 516, 50724], 'temperature': 0.0, 'avg_logprob': -0.1972948571910029, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.01444909255951643}, {'id': 551, 'seek': 452818, 'start': 4537.22, 'end': 4544.22, 'text': ' to be very expensive. It is going to be super expensive. There is one more thing that is', 'tokens': [50816, 281, 312, 588, 5124, 13, 467, 307, 516, 281, 312, 1687, 5124, 13, 821, 307, 472, 544, 551, 300, 307, 51166], 'temperature': 0.0, 'avg_logprob': -0.1972948571910029, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.01444909255951643}, {'id': 552, 'seek': 452818, 'start': 4546.06, 'end': 4553.06, 'text': ' going to be pretty hard is when you are sitting in a lecture and the guy who is giving the', 'tokens': [51258, 516, 281, 312, 1238, 1152, 307, 562, 291, 366, 3798, 294, 257, 7991, 293, 264, 2146, 567, 307, 2902, 264, 51608], 'temperature': 0.0, 'avg_logprob': -0.1972948571910029, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.01444909255951643}, {'id': 553, 'seek': 455306, 'start': 4553.660000000001, 'end': 4560.660000000001, 'text': ' lecture had a very heavy breakfast. He does not feel very hungry, but are you guys hungry?', 'tokens': [50394, 7991, 632, 257, 588, 4676, 8201, 13, 634, 775, 406, 841, 588, 8067, 11, 457, 366, 291, 1074, 8067, 30, 50744], 'temperature': 0.0, 'avg_logprob': -0.3229846954345703, 'compression_ratio': 1.5657894736842106, 'no_speech_prob': 0.002399652963504195}, {'id': 554, 'seek': 455306, 'start': 4562.660000000001, 'end': 4568.700000000001, 'text': ' Yes. So, what is the scenario? How far can I see? I mean this is a good logical point', 'tokens': [50844, 1079, 13, 407, 11, 437, 307, 264, 9005, 30, 1012, 1400, 393, 286, 536, 30, 286, 914, 341, 307, 257, 665, 14978, 935, 51146], 'temperature': 0.0, 'avg_logprob': -0.3229846954345703, 'compression_ratio': 1.5657894736842106, 'no_speech_prob': 0.002399652963504195}, {'id': 555, 'seek': 455306, 'start': 4568.700000000001, 'end': 4575.700000000001, 'text': ' to stop. We can continue further, but if you think these guys should go for lunch and they', 'tokens': [51146, 281, 1590, 13, 492, 393, 2354, 3052, 11, 457, 498, 291, 519, 613, 1074, 820, 352, 337, 6349, 293, 436, 51496], 'temperature': 0.0, 'avg_logprob': -0.3229846954345703, 'compression_ratio': 1.5657894736842106, 'no_speech_prob': 0.002399652963504195}, {'id': 556, 'seek': 455306, 'start': 4576.34, 'end': 4582.860000000001, 'text': ' should. So, you should thank him then. Then, what time do we meet back? Okay. So, we will', 'tokens': [51528, 820, 13, 407, 11, 291, 820, 1309, 796, 550, 13, 1396, 11, 437, 565, 360, 321, 1677, 646, 30, 1033, 13, 407, 11, 321, 486, 51854], 'temperature': 0.0, 'avg_logprob': -0.3229846954345703, 'compression_ratio': 1.5657894736842106, 'no_speech_prob': 0.002399652963504195}, {'id': 557, 'seek': 458286, 'start': 4583.42, 'end': 4588.42, 'text': ' meet back. Before we go, let us quickly summarize what we did now. Let us try to recall. We', 'tokens': [50392, 1677, 646, 13, 4546, 321, 352, 11, 718, 505, 2661, 20858, 437, 321, 630, 586, 13, 961, 505, 853, 281, 9901, 13, 492, 50642], 'temperature': 0.0, 'avg_logprob': -0.26857398805164157, 'compression_ratio': 1.6017699115044248, 'no_speech_prob': 0.0029796971939504147}, {'id': 558, 'seek': 458286, 'start': 4588.42, 'end': 4595.42, 'text': ' came, we started with a brief overview of compilation process. We discussed about compilers,', 'tokens': [50642, 1361, 11, 321, 1409, 365, 257, 5353, 12492, 295, 40261, 1399, 13, 492, 7152, 466, 715, 388, 433, 11, 50992], 'temperature': 0.0, 'avg_logprob': -0.26857398805164157, 'compression_ratio': 1.6017699115044248, 'no_speech_prob': 0.0029796971939504147}, {'id': 559, 'seek': 458286, 'start': 4596.98, 'end': 4602.86, 'text': ' interpreters, IR and all that. We looked at what are the important characteristics of', 'tokens': [51070, 17489, 1559, 11, 16486, 293, 439, 300, 13, 492, 2956, 412, 437, 366, 264, 1021, 10891, 295, 51364], 'temperature': 0.0, 'avg_logprob': -0.26857398805164157, 'compression_ratio': 1.6017699115044248, 'no_speech_prob': 0.0029796971939504147}, {'id': 560, 'seek': 458286, 'start': 4602.86, 'end': 4609.86, 'text': ' optimizations. We understood the desirable properties of optimizations and what is required', 'tokens': [51364, 5028, 14455, 13, 492, 7320, 264, 30533, 7221, 295, 5028, 14455, 293, 437, 307, 4739, 51714], 'temperature': 0.0, 'avg_logprob': -0.26857398805164157, 'compression_ratio': 1.6017699115044248, 'no_speech_prob': 0.0029796971939504147}, {'id': 561, 'seek': 460986, 'start': 4609.86, 'end': 4616.86, 'text': ' for them. We looked at flow sensitive, flow insensitive, context sensitive, context insensitive.', 'tokens': [50364, 337, 552, 13, 492, 2956, 412, 3095, 9477, 11, 3095, 1028, 34465, 11, 4319, 9477, 11, 4319, 1028, 34465, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.3243696946364183, 'compression_ratio': 1.6585365853658536, 'no_speech_prob': 0.002974629169330001}, {'id': 562, 'seek': 460986, 'start': 4617.98, 'end': 4624.98, 'text': ' What do these terms mean? We understood what is may information and must information. So,', 'tokens': [50770, 708, 360, 613, 2115, 914, 30, 492, 7320, 437, 307, 815, 1589, 293, 1633, 1589, 13, 407, 11, 51120], 'temperature': 0.0, 'avg_logprob': -0.3243696946364183, 'compression_ratio': 1.6585365853658536, 'no_speech_prob': 0.002974629169330001}, {'id': 563, 'seek': 460986, 'start': 4627.94, 'end': 4634.139999999999, 'text': ' let us keep this somewhere in our stack of our cache of things. We will come back and', 'tokens': [51268, 718, 505, 1066, 341, 4079, 294, 527, 8630, 295, 527, 19459, 295, 721, 13, 492, 486, 808, 646, 293, 51578], 'temperature': 0.0, 'avg_logprob': -0.3243696946364183, 'compression_ratio': 1.6585365853658536, 'no_speech_prob': 0.002974629169330001}, {'id': 564, 'seek': 463414, 'start': 4634.14, 'end': 4641.14, 'text': ' continue the discussion. This kind of brings to the introduction of the introduction to', 'tokens': [50364, 2354, 264, 5017, 13, 639, 733, 295, 5607, 281, 264, 9339, 295, 264, 9339, 281, 50714], 'temperature': 0.0, 'avg_logprob': -0.1707918604866403, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.002888324437662959}, {'id': 565, 'seek': 463414, 'start': 4641.54, 'end': 4648.54, 'text': ' optimization part. We will go into a very interesting example of what all optimizations', 'tokens': [50734, 19618, 644, 13, 492, 486, 352, 666, 257, 588, 1880, 1365, 295, 437, 439, 5028, 14455, 51084], 'temperature': 0.0, 'avg_logprob': -0.1707918604866403, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.002888324437662959}, {'id': 566, 'seek': 463414, 'start': 4648.860000000001, 'end': 4655.860000000001, 'text': ' can do. If you thought this example was exciting, wait for the next example. So, we will meet', 'tokens': [51100, 393, 360, 13, 759, 291, 1194, 341, 1365, 390, 4670, 11, 1699, 337, 264, 958, 1365, 13, 407, 11, 321, 486, 1677, 51450], 'temperature': 0.0, 'avg_logprob': -0.1707918604866403, 'compression_ratio': 1.6011904761904763, 'no_speech_prob': 0.002888324437662959}, {'id': 567, 'seek': 465586, 'start': 4656.82, 'end': 4663.82, 'text': ' after the lunch. Any questions so far? No? I thought you will ask when will you leave', 'tokens': [50412, 934, 264, 6349, 13, 2639, 1651, 370, 1400, 30, 883, 30, 286, 1194, 291, 486, 1029, 562, 486, 291, 1856, 50762], 'temperature': 0.0, 'avg_logprob': -0.33812842830534906, 'compression_ratio': 1.1195652173913044, 'no_speech_prob': 0.003271108027547598}, {'id': 568, 'seek': 465586, 'start': 4671.299999999999, 'end': 4673.82, 'text': ' us? See you soon.', 'tokens': [51136, 505, 30, 3008, 291, 2321, 13, 51262], 'temperature': 0.0, 'avg_logprob': -0.33812842830534906, 'compression_ratio': 1.1195652173913044, 'no_speech_prob': 0.003271108027547598}]