[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 10.84, 'text': ' Software Pipelining. Software Pipelining is essentially instruction scheduling for loops.', 'tokens': [50364, 27428, 35396, 338, 1760, 13, 27428, 35396, 338, 1760, 307, 4476, 10951, 29055, 337, 16121, 13, 50906], 'temperature': 0.0, 'avg_logprob': -0.22479114762271743, 'compression_ratio': 1.7989949748743719, 'no_speech_prob': 0.1402115672826767}, {'id': 1, 'seek': 0, 'start': 10.84, 'end': 16.6, 'text': ' So, we will talk about all of those topics in the current module, right. So, the current', 'tokens': [50906, 407, 11, 321, 486, 751, 466, 439, 295, 729, 8378, 294, 264, 2190, 10088, 11, 558, 13, 407, 11, 264, 2190, 51194], 'temperature': 0.0, 'avg_logprob': -0.22479114762271743, 'compression_ratio': 1.7989949748743719, 'no_speech_prob': 0.1402115672826767}, {'id': 2, 'seek': 0, 'start': 16.6, 'end': 21.6, 'text': ' module is titled Instruction Scheduling. And what you are going to see here as I mentioned', 'tokens': [51194, 10088, 307, 19841, 2730, 3826, 44926, 425, 278, 13, 400, 437, 291, 366, 516, 281, 536, 510, 382, 286, 2835, 51444], 'temperature': 0.0, 'avg_logprob': -0.22479114762271743, 'compression_ratio': 1.7989949748743719, 'no_speech_prob': 0.1402115672826767}, {'id': 3, 'seek': 0, 'start': 21.6, 'end': 26.8, 'text': ' earlier is that we will introduce the need for instruction scheduling. Then we will talk', 'tokens': [51444, 3071, 307, 300, 321, 486, 5366, 264, 643, 337, 10951, 29055, 13, 1396, 321, 486, 751, 51704], 'temperature': 0.0, 'avg_logprob': -0.22479114762271743, 'compression_ratio': 1.7989949748743719, 'no_speech_prob': 0.1402115672826767}, {'id': 4, 'seek': 2680, 'start': 26.8, 'end': 32.8, 'text': ' about how basic block scheduling is done. And subsequently we will extend this to global', 'tokens': [50364, 466, 577, 3875, 3461, 29055, 307, 1096, 13, 400, 26514, 321, 486, 10101, 341, 281, 4338, 50664], 'temperature': 0.0, 'avg_logprob': -0.16778367141197467, 'compression_ratio': 2.103286384976526, 'no_speech_prob': 0.3539592921733856}, {'id': 5, 'seek': 2680, 'start': 32.8, 'end': 38.120000000000005, 'text': ' instruction scheduling beyond basic blocks. And there are three different global instruction', 'tokens': [50664, 10951, 29055, 4399, 3875, 8474, 13, 400, 456, 366, 1045, 819, 4338, 10951, 50930], 'temperature': 0.0, 'avg_logprob': -0.16778367141197467, 'compression_ratio': 2.103286384976526, 'no_speech_prob': 0.3539592921733856}, {'id': 6, 'seek': 2680, 'start': 38.120000000000005, 'end': 44.0, 'text': ' scheduling that we talk about namely trace scheduling, super block scheduling and then', 'tokens': [50930, 29055, 300, 321, 751, 466, 20926, 13508, 29055, 11, 1687, 3461, 29055, 293, 550, 51224], 'temperature': 0.0, 'avg_logprob': -0.16778367141197467, 'compression_ratio': 2.103286384976526, 'no_speech_prob': 0.3539592921733856}, {'id': 7, 'seek': 2680, 'start': 44.0, 'end': 49.2, 'text': ' hyper block scheduling. Then subsequently we will talk about software pipelining which', 'tokens': [51224, 9848, 3461, 29055, 13, 1396, 26514, 321, 486, 751, 466, 4722, 8489, 338, 1760, 597, 51484], 'temperature': 0.0, 'avg_logprob': -0.16778367141197467, 'compression_ratio': 2.103286384976526, 'no_speech_prob': 0.3539592921733856}, {'id': 8, 'seek': 2680, 'start': 49.2, 'end': 55.22, 'text': ' is all about instruction scheduling for loops. And towards the end we will very briefly talk', 'tokens': [51484, 307, 439, 466, 10951, 29055, 337, 16121, 13, 400, 3030, 264, 917, 321, 486, 588, 10515, 751, 51785], 'temperature': 0.0, 'avg_logprob': -0.16778367141197467, 'compression_ratio': 2.103286384976526, 'no_speech_prob': 0.3539592921733856}, {'id': 9, 'seek': 5522, 'start': 55.26, 'end': 60.9, 'text': ' about the interaction between register allocation and instruction scheduling that is something', 'tokens': [50366, 466, 264, 9285, 1296, 7280, 27599, 293, 10951, 29055, 300, 307, 746, 50648], 'temperature': 0.0, 'avg_logprob': -0.23508514592676988, 'compression_ratio': 1.7962085308056872, 'no_speech_prob': 0.1195768192410469}, {'id': 10, 'seek': 5522, 'start': 60.9, 'end': 62.78, 'text': ' it is also used.', 'tokens': [50648, 309, 307, 611, 1143, 13, 50742], 'temperature': 0.0, 'avg_logprob': -0.23508514592676988, 'compression_ratio': 1.7962085308056872, 'no_speech_prob': 0.1195768192410469}, {'id': 11, 'seek': 5522, 'start': 62.78, 'end': 68.86, 'text': ' So, what is instruction scheduling? Instruction scheduling is essentially given an instruction', 'tokens': [50742, 407, 11, 437, 307, 10951, 29055, 30, 2730, 3826, 29055, 307, 4476, 2212, 364, 10951, 51046], 'temperature': 0.0, 'avg_logprob': -0.23508514592676988, 'compression_ratio': 1.7962085308056872, 'no_speech_prob': 0.1195768192410469}, {'id': 12, 'seek': 5522, 'start': 68.86, 'end': 75.98, 'text': ' sequence you reorder them in some other way such that it minimizes certain things. But', 'tokens': [51046, 8310, 291, 319, 4687, 552, 294, 512, 661, 636, 1270, 300, 309, 4464, 5660, 1629, 721, 13, 583, 51402], 'temperature': 0.0, 'avg_logprob': -0.23508514592676988, 'compression_ratio': 1.7962085308056872, 'no_speech_prob': 0.1195768192410469}, {'id': 13, 'seek': 5522, 'start': 75.98, 'end': 80.78, 'text': ' when you do the reordering you have to make sure that the dependences which are there', 'tokens': [51402, 562, 291, 360, 264, 319, 765, 1794, 291, 362, 281, 652, 988, 300, 264, 5672, 2667, 597, 366, 456, 51642], 'temperature': 0.0, 'avg_logprob': -0.23508514592676988, 'compression_ratio': 1.7962085308056872, 'no_speech_prob': 0.1195768192410469}, {'id': 14, 'seek': 8078, 'start': 80.78, 'end': 87.38, 'text': ' in the original program are always preserved, right. And what you try to minimize? You try', 'tokens': [50364, 294, 264, 3380, 1461, 366, 1009, 22242, 11, 558, 13, 400, 437, 291, 853, 281, 17522, 30, 509, 853, 50694], 'temperature': 0.0, 'avg_logprob': -0.1643117332458496, 'compression_ratio': 1.8008130081300813, 'no_speech_prob': 0.08566759526729584}, {'id': 15, 'seek': 8078, 'start': 87.38, 'end': 93.18, 'text': ' to minimize the execution time of the program that is of concern to you, right.', 'tokens': [50694, 281, 17522, 264, 15058, 565, 295, 264, 1461, 300, 307, 295, 3136, 281, 291, 11, 558, 13, 50984], 'temperature': 0.0, 'avg_logprob': -0.1643117332458496, 'compression_ratio': 1.8008130081300813, 'no_speech_prob': 0.08566759526729584}, {'id': 16, 'seek': 8078, 'start': 93.18, 'end': 98.7, 'text': ' So, instruction scheduling can be done to minimize the number of stalls that would be', 'tokens': [50984, 407, 11, 10951, 29055, 393, 312, 1096, 281, 17522, 264, 1230, 295, 50248, 300, 576, 312, 51260], 'temperature': 0.0, 'avg_logprob': -0.1643117332458496, 'compression_ratio': 1.8008130081300813, 'no_speech_prob': 0.08566759526729584}, {'id': 17, 'seek': 8078, 'start': 98.7, 'end': 105.02000000000001, 'text': ' incurred by the pipeline execution unit. Remember we talked about data hazards and control hazards.', 'tokens': [51260, 35774, 986, 538, 264, 15517, 15058, 4985, 13, 5459, 321, 2825, 466, 1412, 34516, 293, 1969, 34516, 13, 51576], 'temperature': 0.0, 'avg_logprob': -0.1643117332458496, 'compression_ratio': 1.8008130081300813, 'no_speech_prob': 0.08566759526729584}, {'id': 18, 'seek': 8078, 'start': 105.02000000000001, 'end': 110.02000000000001, 'text': ' And then when you have these hazards, right, normally stalls are incurred and to avoid', 'tokens': [51576, 400, 550, 562, 291, 362, 613, 34516, 11, 558, 11, 5646, 50248, 366, 35774, 986, 293, 281, 5042, 51826], 'temperature': 0.0, 'avg_logprob': -0.1643117332458496, 'compression_ratio': 1.8008130081300813, 'no_speech_prob': 0.08566759526729584}, {'id': 19, 'seek': 11002, 'start': 110.06, 'end': 116.06, 'text': ' these stalls you can again reorder instructions to avoid them. Some processors may exploit,', 'tokens': [50366, 613, 50248, 291, 393, 797, 319, 4687, 9415, 281, 5042, 552, 13, 2188, 27751, 815, 25924, 11, 50666], 'temperature': 0.0, 'avg_logprob': -0.1969812969828761, 'compression_ratio': 1.9051724137931034, 'no_speech_prob': 0.020228002220392227}, {'id': 20, 'seek': 11002, 'start': 116.06, 'end': 121.58, 'text': ' not some, today almost all processors exploit instruction level parallelism. That means', 'tokens': [50666, 406, 512, 11, 965, 1920, 439, 27751, 25924, 10951, 1496, 8952, 1434, 13, 663, 1355, 50942], 'temperature': 0.0, 'avg_logprob': -0.1969812969828761, 'compression_ratio': 1.9051724137931034, 'no_speech_prob': 0.020228002220392227}, {'id': 21, 'seek': 11002, 'start': 121.58, 'end': 127.94, 'text': ' that they are capable of executing multiple independent instructions in a single cycle.', 'tokens': [50942, 300, 436, 366, 8189, 295, 32368, 3866, 6695, 9415, 294, 257, 2167, 6586, 13, 51260], 'temperature': 0.0, 'avg_logprob': -0.1969812969828761, 'compression_ratio': 1.9051724137931034, 'no_speech_prob': 0.020228002220392227}, {'id': 22, 'seek': 11002, 'start': 127.94, 'end': 133.14, 'text': ' And when you have processors of that kind then instruction scheduling can expose these', 'tokens': [51260, 400, 562, 291, 362, 27751, 295, 300, 733, 550, 10951, 29055, 393, 19219, 613, 51520], 'temperature': 0.0, 'avg_logprob': -0.1969812969828761, 'compression_ratio': 1.9051724137931034, 'no_speech_prob': 0.020228002220392227}, {'id': 23, 'seek': 11002, 'start': 133.14, 'end': 138.78, 'text': ' independent instructions to these processors so that they can be executed together. And', 'tokens': [51520, 6695, 9415, 281, 613, 27751, 370, 300, 436, 393, 312, 17577, 1214, 13, 400, 51802], 'temperature': 0.0, 'avg_logprob': -0.1969812969828761, 'compression_ratio': 1.9051724137931034, 'no_speech_prob': 0.020228002220392227}, {'id': 24, 'seek': 13878, 'start': 138.78, 'end': 143.58, 'text': ' when you have instruction level parallelism and when you kind of expose this parallelism', 'tokens': [50364, 562, 291, 362, 10951, 1496, 8952, 1434, 293, 562, 291, 733, 295, 19219, 341, 8952, 1434, 50604], 'temperature': 0.0, 'avg_logprob': -0.2246570587158203, 'compression_ratio': 1.9779735682819384, 'no_speech_prob': 0.017115365713834763}, {'id': 25, 'seek': 13878, 'start': 143.58, 'end': 150.58, 'text': ' using instruction scheduling you have to make sure that the schedule that you generate,', 'tokens': [50604, 1228, 10951, 29055, 291, 362, 281, 652, 988, 300, 264, 7567, 300, 291, 8460, 11, 50954], 'temperature': 0.0, 'avg_logprob': -0.2246570587158203, 'compression_ratio': 1.9779735682819384, 'no_speech_prob': 0.017115365713834763}, {'id': 26, 'seek': 13878, 'start': 150.58, 'end': 156.02, 'text': ' right, the schedule will have multiple parallel instructions because they are able to, your', 'tokens': [50954, 558, 11, 264, 7567, 486, 362, 3866, 8952, 9415, 570, 436, 366, 1075, 281, 11, 428, 51226], 'temperature': 0.0, 'avg_logprob': -0.2246570587158203, 'compression_ratio': 1.9779735682819384, 'no_speech_prob': 0.017115365713834763}, {'id': 27, 'seek': 13878, 'start': 156.02, 'end': 160.78, 'text': ' architecture is able to exploit them. But these multiple parallel instructions should', 'tokens': [51226, 9482, 307, 1075, 281, 25924, 552, 13, 583, 613, 3866, 8952, 9415, 820, 51464], 'temperature': 0.0, 'avg_logprob': -0.2246570587158203, 'compression_ratio': 1.9779735682819384, 'no_speech_prob': 0.017115365713834763}, {'id': 28, 'seek': 13878, 'start': 160.78, 'end': 166.14, 'text': ' also obey resource constraints. By that what we mean? If you say that there are three multiply', 'tokens': [51464, 611, 19297, 7684, 18491, 13, 3146, 300, 437, 321, 914, 30, 759, 291, 584, 300, 456, 366, 1045, 12972, 51732], 'temperature': 0.0, 'avg_logprob': -0.2246570587158203, 'compression_ratio': 1.9779735682819384, 'no_speech_prob': 0.017115365713834763}, {'id': 29, 'seek': 16614, 'start': 166.26, 'end': 172.14, 'text': ' instructions, right, in your instruction schedule then there must be at least three multiply', 'tokens': [50370, 9415, 11, 558, 11, 294, 428, 10951, 7567, 550, 456, 1633, 312, 412, 1935, 1045, 12972, 50664], 'temperature': 0.0, 'avg_logprob': -0.15723678800794813, 'compression_ratio': 2.0, 'no_speech_prob': 0.066105417907238}, {'id': 30, 'seek': 16614, 'start': 172.14, 'end': 177.5, 'text': ' function units for you to execute them. If you have fewer than that then obviously this', 'tokens': [50664, 2445, 6815, 337, 291, 281, 14483, 552, 13, 759, 291, 362, 13366, 813, 300, 550, 2745, 341, 50932], 'temperature': 0.0, 'avg_logprob': -0.15723678800794813, 'compression_ratio': 2.0, 'no_speech_prob': 0.066105417907238}, {'id': 31, 'seek': 16614, 'start': 177.5, 'end': 183.29999999999998, 'text': ' schedule does not satisfy that resource constraint. So when you talk about instruction scheduling', 'tokens': [50932, 7567, 775, 406, 19319, 300, 7684, 25534, 13, 407, 562, 291, 751, 466, 10951, 29055, 51222], 'temperature': 0.0, 'avg_logprob': -0.15723678800794813, 'compression_ratio': 2.0, 'no_speech_prob': 0.066105417907238}, {'id': 32, 'seek': 16614, 'start': 183.29999999999998, 'end': 188.7, 'text': ' you always talk about satisfying dependence constraints which is data dependency and you', 'tokens': [51222, 291, 1009, 751, 466, 18348, 31704, 18491, 597, 307, 1412, 33621, 293, 291, 51492], 'temperature': 0.0, 'avg_logprob': -0.15723678800794813, 'compression_ratio': 2.0, 'no_speech_prob': 0.066105417907238}, {'id': 33, 'seek': 16614, 'start': 188.7, 'end': 194.29999999999998, 'text': ' always talk about satisfying resource constraints, right. These are the two things that you talk', 'tokens': [51492, 1009, 751, 466, 18348, 7684, 18491, 11, 558, 13, 1981, 366, 264, 732, 721, 300, 291, 751, 51772], 'temperature': 0.0, 'avg_logprob': -0.15723678800794813, 'compression_ratio': 2.0, 'no_speech_prob': 0.066105417907238}, {'id': 34, 'seek': 19430, 'start': 194.38000000000002, 'end': 199.38000000000002, 'text': ' about, okay. So instruction scheduling can improve the performance of a program by actually', 'tokens': [50368, 466, 11, 1392, 13, 407, 10951, 29055, 393, 3470, 264, 3389, 295, 257, 1461, 538, 767, 50618], 'temperature': 0.0, 'avg_logprob': -0.18690196673075357, 'compression_ratio': 1.8353413654618473, 'no_speech_prob': 0.0279845017939806}, {'id': 35, 'seek': 19430, 'start': 199.38000000000002, 'end': 205.26000000000002, 'text': ' moving these independent instructions around, okay, independent instructions in parallel', 'tokens': [50618, 2684, 613, 6695, 9415, 926, 11, 1392, 11, 6695, 9415, 294, 8952, 50912], 'temperature': 0.0, 'avg_logprob': -0.18690196673075357, 'compression_ratio': 1.8353413654618473, 'no_speech_prob': 0.0279845017939806}, {'id': 36, 'seek': 19430, 'start': 205.26000000000002, 'end': 210.26000000000002, 'text': ' or adjacent positions. Parallel because if you have a VLIW kind of an architecture you', 'tokens': [50912, 420, 24441, 8432, 13, 3457, 336, 338, 570, 498, 291, 362, 257, 691, 48718, 54, 733, 295, 364, 9482, 291, 51162], 'temperature': 0.0, 'avg_logprob': -0.18690196673075357, 'compression_ratio': 1.8353413654618473, 'no_speech_prob': 0.0279845017939806}, {'id': 37, 'seek': 19430, 'start': 210.26000000000002, 'end': 215.78, 'text': ' express them in parallel. If you have a superscalar architecture even, I mean each instruction', 'tokens': [51162, 5109, 552, 294, 8952, 13, 759, 291, 362, 257, 37906, 9895, 289, 9482, 754, 11, 286, 914, 1184, 10951, 51438], 'temperature': 0.0, 'avg_logprob': -0.18690196673075357, 'compression_ratio': 1.8353413654618473, 'no_speech_prob': 0.0279845017939806}, {'id': 38, 'seek': 19430, 'start': 215.78, 'end': 220.54000000000002, 'text': ' is going to hold only one operation. So successive independent operations are put next to each', 'tokens': [51438, 307, 516, 281, 1797, 787, 472, 6916, 13, 407, 48043, 6695, 7705, 366, 829, 958, 281, 1184, 51676], 'temperature': 0.0, 'avg_logprob': -0.18690196673075357, 'compression_ratio': 1.8353413654618473, 'no_speech_prob': 0.0279845017939806}, {'id': 39, 'seek': 22054, 'start': 220.57999999999998, 'end': 225.38, 'text': ' other so that the hardware when it decodes can actually look at these instructions and', 'tokens': [50366, 661, 370, 300, 264, 8837, 562, 309, 979, 4789, 393, 767, 574, 412, 613, 9415, 293, 50606], 'temperature': 0.0, 'avg_logprob': -0.20616819461186728, 'compression_ratio': 1.6468253968253967, 'no_speech_prob': 0.04294886812567711}, {'id': 40, 'seek': 22054, 'start': 225.38, 'end': 228.42, 'text': ' then say that yes they can be executed in parallel, right.', 'tokens': [50606, 550, 584, 300, 2086, 436, 393, 312, 17577, 294, 8952, 11, 558, 13, 50758], 'temperature': 0.0, 'avg_logprob': -0.20616819461186728, 'compression_ratio': 1.6468253968253967, 'no_speech_prob': 0.04294886812567711}, {'id': 41, 'seek': 22054, 'start': 228.42, 'end': 235.01999999999998, 'text': ' And of course in simple pipeline the processor you also use these things to stall data and', 'tokens': [50758, 400, 295, 1164, 294, 2199, 15517, 264, 15321, 291, 611, 764, 613, 721, 281, 19633, 1412, 293, 51088], 'temperature': 0.0, 'avg_logprob': -0.20616819461186728, 'compression_ratio': 1.6468253968253967, 'no_speech_prob': 0.04294886812567711}, {'id': 42, 'seek': 22054, 'start': 235.01999999999998, 'end': 240.57999999999998, 'text': ' control hazards, okay. Whereas for VLIW, EPIC and superscalar processor they are meant for', 'tokens': [51088, 1969, 34516, 11, 1392, 13, 13813, 337, 691, 48718, 54, 11, 25330, 2532, 293, 37906, 9895, 289, 15321, 436, 366, 4140, 337, 51366], 'temperature': 0.0, 'avg_logprob': -0.20616819461186728, 'compression_ratio': 1.6468253968253967, 'no_speech_prob': 0.04294886812567711}, {'id': 43, 'seek': 22054, 'start': 240.57999999999998, 'end': 245.01999999999998, 'text': ' exposing the parallelism, instruction level parallelism. We will give examples of these', 'tokens': [51366, 33178, 264, 8952, 1434, 11, 10951, 1496, 8952, 1434, 13, 492, 486, 976, 5110, 295, 613, 51588], 'temperature': 0.0, 'avg_logprob': -0.20616819461186728, 'compression_ratio': 1.6468253968253967, 'no_speech_prob': 0.04294886812567711}, {'id': 44, 'seek': 24502, 'start': 245.02, 'end': 250.58, 'text': ' things as we go by, right. Essentially the clue is important point here is that we need', 'tokens': [50364, 721, 382, 321, 352, 538, 11, 558, 13, 23596, 264, 13602, 307, 1021, 935, 510, 307, 300, 321, 643, 50642], 'temperature': 0.0, 'avg_logprob': -0.26067629168110507, 'compression_ratio': 1.670995670995671, 'no_speech_prob': 0.07762454450130463}, {'id': 45, 'seek': 24502, 'start': 250.58, 'end': 256.22, 'text': ' to make sure that these independent instructions, right, are exposed as parallelism. That is', 'tokens': [50642, 281, 652, 988, 300, 613, 6695, 9415, 11, 558, 11, 366, 9495, 382, 8952, 1434, 13, 663, 307, 50924], 'temperature': 0.0, 'avg_logprob': -0.26067629168110507, 'compression_ratio': 1.670995670995671, 'no_speech_prob': 0.07762454450130463}, {'id': 46, 'seek': 24502, 'start': 256.22, 'end': 258.38, 'text': ' really the key point, okay.', 'tokens': [50924, 534, 264, 2141, 935, 11, 1392, 13, 51032], 'temperature': 0.0, 'avg_logprob': -0.26067629168110507, 'compression_ratio': 1.670995670995671, 'no_speech_prob': 0.07762454450130463}, {'id': 47, 'seek': 24502, 'start': 258.38, 'end': 264.42, 'text': " In this example we saw in the in yesterday's class you have a sequence of instructions,", 'tokens': [51032, 682, 341, 1365, 321, 1866, 294, 264, 294, 5186, 311, 1508, 291, 362, 257, 8310, 295, 9415, 11, 51334], 'temperature': 0.0, 'avg_logprob': -0.26067629168110507, 'compression_ratio': 1.670995670995671, 'no_speech_prob': 0.07762454450130463}, {'id': 48, 'seek': 24502, 'start': 264.42, 'end': 271.42, 'text': ' right and here is there is a data dependency. The load instruction writes a value into R3', 'tokens': [51334, 558, 293, 510, 307, 456, 307, 257, 1412, 33621, 13, 440, 3677, 10951, 13657, 257, 2158, 666, 497, 18, 51684], 'temperature': 0.0, 'avg_logprob': -0.26067629168110507, 'compression_ratio': 1.670995670995671, 'no_speech_prob': 0.07762454450130463}, {'id': 49, 'seek': 27142, 'start': 271.42, 'end': 276.54, 'text': ' transistor which is being used by the add instruction. Typically load instructions have', 'tokens': [50364, 34750, 597, 307, 885, 1143, 538, 264, 909, 10951, 13, 23129, 3677, 9415, 362, 50620], 'temperature': 0.0, 'avg_logprob': -0.19195569079855215, 'compression_ratio': 1.8878923766816142, 'no_speech_prob': 0.07081853598356247}, {'id': 50, 'seek': 27142, 'start': 276.54, 'end': 283.06, 'text': ' a stall of one cycle that means that the load value is only available during the mem phase', 'tokens': [50620, 257, 19633, 295, 472, 6586, 300, 1355, 300, 264, 3677, 2158, 307, 787, 2435, 1830, 264, 1334, 5574, 50946], 'temperature': 0.0, 'avg_logprob': -0.19195569079855215, 'compression_ratio': 1.8878923766816142, 'no_speech_prob': 0.07081853598356247}, {'id': 51, 'seek': 27142, 'start': 283.06, 'end': 288.38, 'text': ' of the pipeline and the mem phase is always after the execute phase. Therefore if the', 'tokens': [50946, 295, 264, 15517, 293, 264, 1334, 5574, 307, 1009, 934, 264, 14483, 5574, 13, 7504, 498, 264, 51212], 'temperature': 0.0, 'avg_logprob': -0.19195569079855215, 'compression_ratio': 1.8878923766816142, 'no_speech_prob': 0.07081853598356247}, {'id': 52, 'seek': 27142, 'start': 288.38, 'end': 293.14, 'text': ' next instruction wants to execute this it has to at least wait till the mem phase of', 'tokens': [51212, 958, 10951, 2738, 281, 14483, 341, 309, 575, 281, 412, 1935, 1699, 4288, 264, 1334, 5574, 295, 51450], 'temperature': 0.0, 'avg_logprob': -0.19195569079855215, 'compression_ratio': 1.8878923766816142, 'no_speech_prob': 0.07081853598356247}, {'id': 53, 'seek': 27142, 'start': 293.14, 'end': 297.36, 'text': ' the next instruction and that is where the stall is kind of introduced.', 'tokens': [51450, 264, 958, 10951, 293, 300, 307, 689, 264, 19633, 307, 733, 295, 7268, 13, 51661], 'temperature': 0.0, 'avg_logprob': -0.19195569079855215, 'compression_ratio': 1.8878923766816142, 'no_speech_prob': 0.07081853598356247}, {'id': 54, 'seek': 29736, 'start': 297.36, 'end': 304.08000000000004, 'text': ' So both these instructions essentially generate one-one stall each, right and therefore you', 'tokens': [50364, 407, 1293, 613, 9415, 4476, 8460, 472, 12, 546, 19633, 1184, 11, 558, 293, 4412, 291, 50700], 'temperature': 0.0, 'avg_logprob': -0.1395257314046224, 'compression_ratio': 1.7512437810945274, 'no_speech_prob': 0.06065899506211281}, {'id': 55, 'seek': 29736, 'start': 304.08000000000004, 'end': 310.7, 'text': ' have two stalls following the two loads. But if you do instruction scheduling and then', 'tokens': [50700, 362, 732, 50248, 3480, 264, 732, 12668, 13, 583, 498, 291, 360, 10951, 29055, 293, 550, 51031], 'temperature': 0.0, 'avg_logprob': -0.1395257314046224, 'compression_ratio': 1.7512437810945274, 'no_speech_prob': 0.06065899506211281}, {'id': 56, 'seek': 29736, 'start': 310.7, 'end': 316.56, 'text': ' replace the loads around or move the loads around then you can avoid all of these stalls', 'tokens': [51031, 7406, 264, 12668, 926, 420, 1286, 264, 12668, 926, 550, 291, 393, 5042, 439, 295, 613, 50248, 51324], 'temperature': 0.0, 'avg_logprob': -0.1395257314046224, 'compression_ratio': 1.7512437810945274, 'no_speech_prob': 0.06065899506211281}, {'id': 57, 'seek': 29736, 'start': 316.56, 'end': 321.44, 'text': ' as you can see in this example. Here what you have done is that between the load and', 'tokens': [51324, 382, 291, 393, 536, 294, 341, 1365, 13, 1692, 437, 291, 362, 1096, 307, 300, 1296, 264, 3677, 293, 51568], 'temperature': 0.0, 'avg_logprob': -0.1395257314046224, 'compression_ratio': 1.7512437810945274, 'no_speech_prob': 0.06065899506211281}, {'id': 58, 'seek': 32144, 'start': 321.44, 'end': 327.4, 'text': ' the dependent add instruction you have another load instruction and that itself ensures that', 'tokens': [50364, 264, 12334, 909, 10951, 291, 362, 1071, 3677, 10951, 293, 300, 2564, 28111, 300, 50662], 'temperature': 0.0, 'avg_logprob': -0.19706363677978517, 'compression_ratio': 2.0223214285714284, 'no_speech_prob': 0.2871588170528412}, {'id': 59, 'seek': 32144, 'start': 327.4, 'end': 333.2, 'text': ' this load and the dependent add instruction are at least separated by one instruction,', 'tokens': [50662, 341, 3677, 293, 264, 12334, 909, 10951, 366, 412, 1935, 12005, 538, 472, 10951, 11, 50952], 'temperature': 0.0, 'avg_logprob': -0.19706363677978517, 'compression_ratio': 2.0223214285714284, 'no_speech_prob': 0.2871588170528412}, {'id': 60, 'seek': 32144, 'start': 333.2, 'end': 339.6, 'text': ' right. Therefore this schedule which you see on the right hand side essentially satisfies', 'tokens': [50952, 558, 13, 7504, 341, 7567, 597, 291, 536, 322, 264, 558, 1011, 1252, 4476, 44271, 51272], 'temperature': 0.0, 'avg_logprob': -0.19706363677978517, 'compression_ratio': 2.0223214285714284, 'no_speech_prob': 0.2871588170528412}, {'id': 61, 'seek': 32144, 'start': 339.6, 'end': 345.48, 'text': ' all the stalls and removes them. It satisfies all the dependencies and removes all the stalls.', 'tokens': [51272, 439, 264, 50248, 293, 30445, 552, 13, 467, 44271, 439, 264, 36606, 293, 30445, 439, 264, 50248, 13, 51566], 'temperature': 0.0, 'avg_logprob': -0.19706363677978517, 'compression_ratio': 2.0223214285714284, 'no_speech_prob': 0.2871588170528412}, {'id': 62, 'seek': 32144, 'start': 345.48, 'end': 350.15999999999997, 'text': ' Again you can see that the data dependencies that you see in the original source program', 'tokens': [51566, 3764, 291, 393, 536, 300, 264, 1412, 36606, 300, 291, 536, 294, 264, 3380, 4009, 1461, 51800], 'temperature': 0.0, 'avg_logprob': -0.19706363677978517, 'compression_ratio': 2.0223214285714284, 'no_speech_prob': 0.2871588170528412}, {'id': 63, 'seek': 35016, 'start': 350.16, 'end': 356.68, 'text': ' are always observed in the instruction in the scheduled program in the reordered program,', 'tokens': [50364, 366, 1009, 13095, 294, 264, 10951, 294, 264, 15678, 1461, 294, 264, 319, 765, 4073, 1461, 11, 50690], 'temperature': 0.0, 'avg_logprob': -0.2193801516578311, 'compression_ratio': 2.0318181818181817, 'no_speech_prob': 0.1382538378238678}, {'id': 64, 'seek': 35016, 'start': 356.68, 'end': 362.20000000000005, 'text': ' right. The essential dependencies that we talk about is from this R 3 to R 3 that dependency', 'tokens': [50690, 558, 13, 440, 7115, 36606, 300, 321, 751, 466, 307, 490, 341, 497, 805, 281, 497, 805, 300, 33621, 50966], 'temperature': 0.0, 'avg_logprob': -0.2193801516578311, 'compression_ratio': 2.0318181818181817, 'no_speech_prob': 0.1382538378238678}, {'id': 65, 'seek': 35016, 'start': 362.20000000000005, 'end': 367.68, 'text': ' is being preserved, right. Similarly this R 13 to R 13 that dependency is being preserved.', 'tokens': [50966, 307, 885, 22242, 11, 558, 13, 13157, 341, 497, 3705, 281, 497, 3705, 300, 33621, 307, 885, 22242, 13, 51240], 'temperature': 0.0, 'avg_logprob': -0.2193801516578311, 'compression_ratio': 2.0318181818181817, 'no_speech_prob': 0.1382538378238678}, {'id': 66, 'seek': 35016, 'start': 367.68, 'end': 373.8, 'text': ' There is a dependency from this R 3 to this R 3 that is also being preserved, correct.', 'tokens': [51240, 821, 307, 257, 33621, 490, 341, 497, 805, 281, 341, 497, 805, 300, 307, 611, 885, 22242, 11, 3006, 13, 51546], 'temperature': 0.0, 'avg_logprob': -0.2193801516578311, 'compression_ratio': 2.0318181818181817, 'no_speech_prob': 0.1382538378238678}, {'id': 67, 'seek': 35016, 'start': 373.8, 'end': 378.76000000000005, 'text': ' That is why we were unable to move either of these add instructions. Both of these add', 'tokens': [51546, 663, 307, 983, 321, 645, 11299, 281, 1286, 2139, 295, 613, 909, 9415, 13, 6767, 295, 613, 909, 51794], 'temperature': 0.0, 'avg_logprob': -0.2193801516578311, 'compression_ratio': 2.0318181818181817, 'no_speech_prob': 0.1382538378238678}, {'id': 68, 'seek': 37876, 'start': 378.76, 'end': 382.84, 'text': ' instructions are dependent, right. So, we could not have moved that thing. We cannot', 'tokens': [50364, 9415, 366, 12334, 11, 558, 13, 407, 11, 321, 727, 406, 362, 4259, 300, 551, 13, 492, 2644, 50568], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 69, 'seek': 37876, 'start': 382.84, 'end': 387.59999999999997, 'text': ' even move this instruction ahead here because this add is dependent on the load. So, you', 'tokens': [50568, 754, 1286, 341, 10951, 2286, 510, 570, 341, 909, 307, 12334, 322, 264, 3677, 13, 407, 11, 291, 50806], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 70, 'seek': 37876, 'start': 387.59999999999997, 'end': 392.24, 'text': ' cannot move this earlier than the load. When you talk about instruction scheduling essentially', 'tokens': [50806, 2644, 1286, 341, 3071, 813, 264, 3677, 13, 1133, 291, 751, 466, 10951, 29055, 4476, 51038], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 71, 'seek': 37876, 'start': 392.24, 'end': 398.24, 'text': ' to hide stalls it is still a serial schedule, serial but reordered schedule. Right there', 'tokens': [51038, 281, 6479, 50248, 309, 307, 920, 257, 17436, 7567, 11, 17436, 457, 319, 765, 4073, 7567, 13, 1779, 456, 51338], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 72, 'seek': 37876, 'start': 398.24, 'end': 403.92, 'text': ' you do not talk about resource constraints because every instruction means in every instruction', 'tokens': [51338, 291, 360, 406, 751, 466, 7684, 18491, 570, 633, 10951, 1355, 294, 633, 10951, 51622], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 73, 'seek': 37876, 'start': 403.92, 'end': 407.92, 'text': ' contains only one operation. So, there is no notion of a resource constraint that you', 'tokens': [51622, 8306, 787, 472, 6916, 13, 407, 11, 456, 307, 572, 10710, 295, 257, 7684, 25534, 300, 291, 51822], 'temperature': 0.0, 'avg_logprob': -0.20999876934549083, 'compression_ratio': 2.0111940298507465, 'no_speech_prob': 0.14084723591804504}, {'id': 74, 'seek': 40792, 'start': 407.92, 'end': 413.84000000000003, 'text': ' talk about. But of course, if you have non-pipelined units then there are certain other things', 'tokens': [50364, 751, 466, 13, 583, 295, 1164, 11, 498, 291, 362, 2107, 12, 79, 647, 338, 2001, 6815, 550, 456, 366, 1629, 661, 721, 50660], 'temperature': 0.0, 'avg_logprob': -0.19552957094632661, 'compression_ratio': 1.829875518672199, 'no_speech_prob': 0.1678539514541626}, {'id': 75, 'seek': 40792, 'start': 413.84000000000003, 'end': 417.76, 'text': ' that you need to do but we will not get into that right now.', 'tokens': [50660, 300, 291, 643, 281, 360, 457, 321, 486, 406, 483, 666, 300, 558, 586, 13, 50856], 'temperature': 0.0, 'avg_logprob': -0.19552957094632661, 'compression_ratio': 1.829875518672199, 'no_speech_prob': 0.1678539514541626}, {'id': 76, 'seek': 40792, 'start': 417.76, 'end': 425.16, 'text': ' Okay. So, if you have a superscalar architecture, right, which exploits instruction level parallelism', 'tokens': [50856, 1033, 13, 407, 11, 498, 291, 362, 257, 37906, 9895, 289, 9482, 11, 558, 11, 597, 12382, 1208, 10951, 1496, 8952, 1434, 51226], 'temperature': 0.0, 'avg_logprob': -0.19552957094632661, 'compression_ratio': 1.829875518672199, 'no_speech_prob': 0.1678539514541626}, {'id': 77, 'seek': 40792, 'start': 425.16, 'end': 431.40000000000003, 'text': ' then it may have multiple function units and during the instruction fetch and decode phase', 'tokens': [51226, 550, 309, 815, 362, 3866, 2445, 6815, 293, 1830, 264, 10951, 23673, 293, 979, 1429, 5574, 51538], 'temperature': 0.0, 'avg_logprob': -0.19552957094632661, 'compression_ratio': 1.829875518672199, 'no_speech_prob': 0.1678539514541626}, {'id': 78, 'seek': 40792, 'start': 431.40000000000003, 'end': 436.66, 'text': ' it can fetch and decode multiple instructions. These multiple instructions are put into this', 'tokens': [51538, 309, 393, 23673, 293, 979, 1429, 3866, 9415, 13, 1981, 3866, 9415, 366, 829, 666, 341, 51801], 'temperature': 0.0, 'avg_logprob': -0.19552957094632661, 'compression_ratio': 1.829875518672199, 'no_speech_prob': 0.1678539514541626}, {'id': 79, 'seek': 43666, 'start': 436.98, 'end': 443.62, 'text': ' issue queue or some kind of a buffer where they wait for the dependencies to be satisfied', 'tokens': [50380, 2734, 18639, 420, 512, 733, 295, 257, 21762, 689, 436, 1699, 337, 264, 36606, 281, 312, 11239, 50712], 'temperature': 0.0, 'avg_logprob': -0.187379150390625, 'compression_ratio': 1.825, 'no_speech_prob': 0.19515663385391235}, {'id': 80, 'seek': 43666, 'start': 443.62, 'end': 448.94000000000005, 'text': ' and after the dependencies are satisfied, right, whenever they are ready, data ready,', 'tokens': [50712, 293, 934, 264, 36606, 366, 11239, 11, 558, 11, 5699, 436, 366, 1919, 11, 1412, 1919, 11, 50978], 'temperature': 0.0, 'avg_logprob': -0.187379150390625, 'compression_ratio': 1.825, 'no_speech_prob': 0.19515663385391235}, {'id': 81, 'seek': 43666, 'start': 448.94000000000005, 'end': 453.98, 'text': ' they can go to the respective function units and can start execution, right.', 'tokens': [50978, 436, 393, 352, 281, 264, 23649, 2445, 6815, 293, 393, 722, 15058, 11, 558, 13, 51230], 'temperature': 0.0, 'avg_logprob': -0.187379150390625, 'compression_ratio': 1.825, 'no_speech_prob': 0.19515663385391235}, {'id': 82, 'seek': 43666, 'start': 453.98, 'end': 460.38, 'text': ' So, if an add instruction and a load instruction are independent of each other we can actually', 'tokens': [51230, 407, 11, 498, 364, 909, 10951, 293, 257, 3677, 10951, 366, 6695, 295, 1184, 661, 321, 393, 767, 51550], 'temperature': 0.0, 'avg_logprob': -0.187379150390625, 'compression_ratio': 1.825, 'no_speech_prob': 0.19515663385391235}, {'id': 83, 'seek': 43666, 'start': 460.38, 'end': 466.54, 'text': ' put them next to each other so that they could be fetched, decoded and then issued also in', 'tokens': [51550, 829, 552, 958, 281, 1184, 661, 370, 300, 436, 727, 312, 23673, 292, 11, 979, 12340, 293, 550, 14379, 611, 294, 51858], 'temperature': 0.0, 'avg_logprob': -0.187379150390625, 'compression_ratio': 1.825, 'no_speech_prob': 0.19515663385391235}, {'id': 84, 'seek': 46654, 'start': 466.54, 'end': 471.74, 'text': ' parallel, right. That is what you do in the superscalar processor. Instruction scheduling', 'tokens': [50364, 8952, 11, 558, 13, 663, 307, 437, 291, 360, 294, 264, 37906, 9895, 289, 15321, 13, 2730, 3826, 29055, 50624], 'temperature': 0.0, 'avg_logprob': -0.17598644892374674, 'compression_ratio': 1.9393939393939394, 'no_speech_prob': 0.004136608447879553}, {'id': 85, 'seek': 46654, 'start': 471.74, 'end': 478.58000000000004, 'text': ' helps in superscalar process but it is not mandatory, okay. Without even instruction', 'tokens': [50624, 3665, 294, 37906, 9895, 289, 1399, 457, 309, 307, 406, 22173, 11, 1392, 13, 9129, 754, 10951, 50966], 'temperature': 0.0, 'avg_logprob': -0.17598644892374674, 'compression_ratio': 1.9393939393939394, 'no_speech_prob': 0.004136608447879553}, {'id': 86, 'seek': 46654, 'start': 478.58000000000004, 'end': 483.90000000000003, 'text': ' scheduling also the superscalar processor can identify the parallelism and can export.', 'tokens': [50966, 29055, 611, 264, 37906, 9895, 289, 15321, 393, 5876, 264, 8952, 1434, 293, 393, 10725, 13, 51232], 'temperature': 0.0, 'avg_logprob': -0.17598644892374674, 'compression_ratio': 1.9393939393939394, 'no_speech_prob': 0.004136608447879553}, {'id': 87, 'seek': 46654, 'start': 483.90000000000003, 'end': 489.14000000000004, 'text': ' Maybe it can identify only lesser amount of parallelism and exploit that because independent', 'tokens': [51232, 2704, 309, 393, 5876, 787, 22043, 2372, 295, 8952, 1434, 293, 25924, 300, 570, 6695, 51494], 'temperature': 0.0, 'avg_logprob': -0.17598644892374674, 'compression_ratio': 1.9393939393939394, 'no_speech_prob': 0.004136608447879553}, {'id': 88, 'seek': 46654, 'start': 489.14000000000004, 'end': 494.38, 'text': ' instructions are far apart from each other. Typically what happens in a superscalar processor', 'tokens': [51494, 9415, 366, 1400, 4936, 490, 1184, 661, 13, 23129, 437, 2314, 294, 257, 37906, 9895, 289, 15321, 51756], 'temperature': 0.0, 'avg_logprob': -0.17598644892374674, 'compression_ratio': 1.9393939393939394, 'no_speech_prob': 0.004136608447879553}, {'id': 89, 'seek': 49438, 'start': 494.38, 'end': 498.94, 'text': ' there is something called a reorder buffer, right. The reorder buffer is the extent to', 'tokens': [50364, 456, 307, 746, 1219, 257, 319, 4687, 21762, 11, 558, 13, 440, 319, 4687, 21762, 307, 264, 8396, 281, 50592], 'temperature': 0.0, 'avg_logprob': -0.17629323147311068, 'compression_ratio': 1.905579399141631, 'no_speech_prob': 0.22329267859458923}, {'id': 90, 'seek': 49438, 'start': 498.94, 'end': 504.5, 'text': ' which it can actually see the instruction, reorder buffer or the issue queue is the extent', 'tokens': [50592, 597, 309, 393, 767, 536, 264, 10951, 11, 319, 4687, 21762, 420, 264, 2734, 18639, 307, 264, 8396, 50870], 'temperature': 0.0, 'avg_logprob': -0.17629323147311068, 'compression_ratio': 1.905579399141631, 'no_speech_prob': 0.22329267859458923}, {'id': 91, 'seek': 49438, 'start': 504.5, 'end': 510.7, 'text': ' to which it can really see, you know, independent instructions and expose parallelism, right.', 'tokens': [50870, 281, 597, 309, 393, 534, 536, 11, 291, 458, 11, 6695, 9415, 293, 19219, 8952, 1434, 11, 558, 13, 51180], 'temperature': 0.0, 'avg_logprob': -0.17629323147311068, 'compression_ratio': 1.905579399141631, 'no_speech_prob': 0.22329267859458923}, {'id': 92, 'seek': 49438, 'start': 510.7, 'end': 517.26, 'text': ' Whereas the compiler can see a much larger window of instructions and can possibly move', 'tokens': [51180, 13813, 264, 31958, 393, 536, 257, 709, 4833, 4910, 295, 9415, 293, 393, 6264, 1286, 51508], 'temperature': 0.0, 'avg_logprob': -0.17629323147311068, 'compression_ratio': 1.905579399141631, 'no_speech_prob': 0.22329267859458923}, {'id': 93, 'seek': 49438, 'start': 517.26, 'end': 522.42, 'text': ' that ahead and then allow this to exploit parallelism. So, remember that in the case', 'tokens': [51508, 300, 2286, 293, 550, 2089, 341, 281, 25924, 8952, 1434, 13, 407, 11, 1604, 300, 294, 264, 1389, 51766], 'temperature': 0.0, 'avg_logprob': -0.17629323147311068, 'compression_ratio': 1.905579399141631, 'no_speech_prob': 0.22329267859458923}, {'id': 94, 'seek': 52242, 'start': 522.42, 'end': 529.6999999999999, 'text': ' of superscalar processor instruction scheduling is preferable and it helps to expose the', 'tokens': [50364, 295, 37906, 9895, 289, 15321, 10951, 29055, 307, 4382, 712, 293, 309, 3665, 281, 19219, 264, 50728], 'temperature': 0.0, 'avg_logprob': -0.1551248872434938, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 0.20285053551197052}, {'id': 95, 'seek': 52242, 'start': 529.6999999999999, 'end': 535.3399999999999, 'text': ' parallelism but it is not mandatory, right, because the architecture is smart enough to', 'tokens': [50728, 8952, 1434, 457, 309, 307, 406, 22173, 11, 558, 11, 570, 264, 9482, 307, 4069, 1547, 281, 51010], 'temperature': 0.0, 'avg_logprob': -0.1551248872434938, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 0.20285053551197052}, {'id': 96, 'seek': 52242, 'start': 535.3399999999999, 'end': 542.42, 'text': ' identify whatever it can identify the parallelism. Whereas in the case of VLIW processor instruction', 'tokens': [51010, 5876, 2035, 309, 393, 5876, 264, 8952, 1434, 13, 13813, 294, 264, 1389, 295, 691, 48718, 54, 15321, 10951, 51364], 'temperature': 0.0, 'avg_logprob': -0.1551248872434938, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 0.20285053551197052}, {'id': 97, 'seek': 52242, 'start': 542.42, 'end': 548.86, 'text': ' scheduling is mandatory. If you do not identify independent instructions and put them together', 'tokens': [51364, 29055, 307, 22173, 13, 759, 291, 360, 406, 5876, 6695, 9415, 293, 829, 552, 1214, 51686], 'temperature': 0.0, 'avg_logprob': -0.1551248872434938, 'compression_ratio': 1.7714285714285714, 'no_speech_prob': 0.20285053551197052}, {'id': 98, 'seek': 54886, 'start': 548.94, 'end': 554.34, 'text': ' the processor cannot exploit. Whatever you specify as a parallel operation, right, in', 'tokens': [50368, 264, 15321, 2644, 25924, 13, 8541, 291, 16500, 382, 257, 8952, 6916, 11, 558, 11, 294, 50638], 'temperature': 0.0, 'avg_logprob': -0.1867755144491963, 'compression_ratio': 1.609865470852018, 'no_speech_prob': 0.27117934823036194}, {'id': 99, 'seek': 54886, 'start': 554.34, 'end': 562.3000000000001, 'text': ' a single VLIW word that is the only thing that it can execute, right. So, in that architecture', 'tokens': [50638, 257, 2167, 691, 48718, 54, 1349, 300, 307, 264, 787, 551, 300, 309, 393, 14483, 11, 558, 13, 407, 11, 294, 300, 9482, 51036], 'temperature': 0.0, 'avg_logprob': -0.1867755144491963, 'compression_ratio': 1.609865470852018, 'no_speech_prob': 0.27117934823036194}, {'id': 100, 'seek': 54886, 'start': 562.3000000000001, 'end': 567.66, 'text': " the compiler's role particularly, I mean, the compiler role in terms of doing instruction", 'tokens': [51036, 264, 31958, 311, 3090, 4098, 11, 286, 914, 11, 264, 31958, 3090, 294, 2115, 295, 884, 10951, 51304], 'temperature': 0.0, 'avg_logprob': -0.1867755144491963, 'compression_ratio': 1.609865470852018, 'no_speech_prob': 0.27117934823036194}, {'id': 101, 'seek': 54886, 'start': 567.66, 'end': 573.46, 'text': ' scheduling is very important, okay. So, the VLIW processor again we saw this in the last', 'tokens': [51304, 29055, 307, 588, 1021, 11, 1392, 13, 407, 11, 264, 691, 48718, 54, 15321, 797, 321, 1866, 341, 294, 264, 1036, 51594], 'temperature': 0.0, 'avg_logprob': -0.1867755144491963, 'compression_ratio': 1.609865470852018, 'no_speech_prob': 0.27117934823036194}, {'id': 102, 'seek': 57346, 'start': 574.02, 'end': 579.22, 'text': ' class consists of a simple instruction memory from where instructions are fetched but the', 'tokens': [50392, 1508, 14689, 295, 257, 2199, 10951, 4675, 490, 689, 9415, 366, 23673, 292, 457, 264, 50652], 'temperature': 0.0, 'avg_logprob': -0.2448444366455078, 'compression_ratio': 1.8029556650246306, 'no_speech_prob': 0.22284427285194397}, {'id': 103, 'seek': 57346, 'start': 579.22, 'end': 585.26, 'text': ' fetched instruction could be a long word meaning it could be 256 bit, 128 bits or 256 bits', 'tokens': [50652, 23673, 292, 10951, 727, 312, 257, 938, 1349, 3620, 309, 727, 312, 38882, 857, 11, 29810, 9239, 420, 38882, 9239, 50954], 'temperature': 0.0, 'avg_logprob': -0.2448444366455078, 'compression_ratio': 1.8029556650246306, 'no_speech_prob': 0.22284427285194397}, {'id': 104, 'seek': 57346, 'start': 585.26, 'end': 592.26, 'text': ' or 512 bits and it may contain multiple operations but these multiple operations that are there', 'tokens': [50954, 420, 1025, 4762, 9239, 293, 309, 815, 5304, 3866, 7705, 457, 613, 3866, 7705, 300, 366, 456, 51304], 'temperature': 0.0, 'avg_logprob': -0.2448444366455078, 'compression_ratio': 1.8029556650246306, 'no_speech_prob': 0.22284427285194397}, {'id': 105, 'seek': 57346, 'start': 592.26, 'end': 598.62, 'text': ' in a single word they are independent of each other and they can be executed in parallel.', 'tokens': [51304, 294, 257, 2167, 1349, 436, 366, 6695, 295, 1184, 661, 293, 436, 393, 312, 17577, 294, 8952, 13, 51622], 'temperature': 0.0, 'avg_logprob': -0.2448444366455078, 'compression_ratio': 1.8029556650246306, 'no_speech_prob': 0.22284427285194397}, {'id': 106, 'seek': 59862, 'start': 599.22, 'end': 604.94, 'text': ' So, the hardware in a VLIW processor essentially decodes that instruction and then moves those', 'tokens': [50394, 407, 11, 264, 8837, 294, 257, 691, 48718, 54, 15321, 4476, 979, 4789, 300, 10951, 293, 550, 6067, 729, 50680], 'temperature': 0.0, 'avg_logprob': -0.15440927092562018, 'compression_ratio': 1.825910931174089, 'no_speech_prob': 0.023470958694815636}, {'id': 107, 'seek': 59862, 'start': 604.94, 'end': 609.54, 'text': ' instruction to the respective functional unit and those functional units can actually start', 'tokens': [50680, 10951, 281, 264, 23649, 11745, 4985, 293, 729, 11745, 6815, 393, 767, 722, 50910], 'temperature': 0.0, 'avg_logprob': -0.15440927092562018, 'compression_ratio': 1.825910931174089, 'no_speech_prob': 0.023470958694815636}, {'id': 108, 'seek': 59862, 'start': 609.54, 'end': 614.94, 'text': ' executing them because when an instruction is issued it is assumed that it will have', 'tokens': [50910, 32368, 552, 570, 562, 364, 10951, 307, 14379, 309, 307, 15895, 300, 309, 486, 362, 51180], 'temperature': 0.0, 'avg_logprob': -0.15440927092562018, 'compression_ratio': 1.825910931174089, 'no_speech_prob': 0.023470958694815636}, {'id': 109, 'seek': 59862, 'start': 614.94, 'end': 619.94, 'text': ' its operands available. So, you do not need to necessarily check whether the instruction', 'tokens': [51180, 1080, 2208, 2967, 2435, 13, 407, 11, 291, 360, 406, 643, 281, 4725, 1520, 1968, 264, 10951, 51430], 'temperature': 0.0, 'avg_logprob': -0.15440927092562018, 'compression_ratio': 1.825910931174089, 'no_speech_prob': 0.023470958694815636}, {'id': 110, 'seek': 59862, 'start': 619.94, 'end': 626.0600000000001, 'text': ' is data ready to be executed. The operands would be anyway available. So, it can be issued', 'tokens': [51430, 307, 1412, 1919, 281, 312, 17577, 13, 440, 2208, 2967, 576, 312, 4033, 2435, 13, 407, 11, 309, 393, 312, 14379, 51736], 'temperature': 0.0, 'avg_logprob': -0.15440927092562018, 'compression_ratio': 1.825910931174089, 'no_speech_prob': 0.023470958694815636}, {'id': 111, 'seek': 62606, 'start': 626.0999999999999, 'end': 631.9399999999999, 'text': ' and then in the next cycle it can be executed, right. And after they finish executing they', 'tokens': [50366, 293, 550, 294, 264, 958, 6586, 309, 393, 312, 17577, 11, 558, 13, 400, 934, 436, 2413, 32368, 436, 50658], 'temperature': 0.0, 'avg_logprob': -0.16949786080254448, 'compression_ratio': 1.8284313725490196, 'no_speech_prob': 0.06040621176362038}, {'id': 112, 'seek': 62606, 'start': 631.9399999999999, 'end': 638.6999999999999, 'text': ' write the results either in the register file or in the memory and of course, this instruction', 'tokens': [50658, 2464, 264, 3542, 2139, 294, 264, 7280, 3991, 420, 294, 264, 4675, 293, 295, 1164, 11, 341, 10951, 50996], 'temperature': 0.0, 'avg_logprob': -0.16949786080254448, 'compression_ratio': 1.8284313725490196, 'no_speech_prob': 0.06040621176362038}, {'id': 113, 'seek': 62606, 'start': 638.6999999999999, 'end': 645.6999999999999, 'text': ' execution itself can be pipelined, VLIW instruction execution itself can be pipelined. So, what', 'tokens': [50996, 15058, 2564, 393, 312, 8489, 338, 2001, 11, 691, 48718, 54, 10951, 15058, 2564, 393, 312, 8489, 338, 2001, 13, 407, 11, 437, 51346], 'temperature': 0.0, 'avg_logprob': -0.16949786080254448, 'compression_ratio': 1.8284313725490196, 'no_speech_prob': 0.06040621176362038}, {'id': 114, 'seek': 62606, 'start': 645.9399999999999, 'end': 650.9799999999999, 'text': ' we will see next is that we will see one example program. So, this is again an architecture', 'tokens': [51358, 321, 486, 536, 958, 307, 300, 321, 486, 536, 472, 1365, 1461, 13, 407, 11, 341, 307, 797, 364, 9482, 51610], 'temperature': 0.0, 'avg_logprob': -0.16949786080254448, 'compression_ratio': 1.8284313725490196, 'no_speech_prob': 0.06040621176362038}, {'id': 115, 'seek': 65098, 'start': 650.98, 'end': 657.98, 'text': ' that we talked about which has 256 bit instruction word, 7 operations can be done in parallel,', 'tokens': [50364, 300, 321, 2825, 466, 597, 575, 38882, 857, 10951, 1349, 11, 1614, 7705, 393, 312, 1096, 294, 8952, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.255984580379793, 'compression_ratio': 1.5526315789473684, 'no_speech_prob': 0.026480717584490776}, {'id': 116, 'seek': 65098, 'start': 658.0600000000001, 'end': 662.94, 'text': ' it has one branch, two integer, two memory operation and two floating point operation', 'tokens': [50718, 309, 575, 472, 9819, 11, 732, 24922, 11, 732, 4675, 6916, 293, 732, 12607, 935, 6916, 50962], 'temperature': 0.0, 'avg_logprob': -0.255984580379793, 'compression_ratio': 1.5526315789473684, 'no_speech_prob': 0.026480717584490776}, {'id': 117, 'seek': 65098, 'start': 662.94, 'end': 669.94, 'text': ' in every cycle and so on, right. So, here is how the instruction schedule looks for', 'tokens': [50962, 294, 633, 6586, 293, 370, 322, 11, 558, 13, 407, 11, 510, 307, 577, 264, 10951, 7567, 1542, 337, 51312], 'temperature': 0.0, 'avg_logprob': -0.255984580379793, 'compression_ratio': 1.5526315789473684, 'no_speech_prob': 0.026480717584490776}, {'id': 118, 'seek': 65098, 'start': 670.02, 'end': 676.1, 'text': ' a VLIW processor, okay. Let us see if we can understand. Unfortunately, I did not put the', 'tokens': [51316, 257, 691, 48718, 54, 15321, 11, 1392, 13, 961, 505, 536, 498, 321, 393, 1223, 13, 8590, 11, 286, 630, 406, 829, 264, 51620], 'temperature': 0.0, 'avg_logprob': -0.255984580379793, 'compression_ratio': 1.5526315789473684, 'no_speech_prob': 0.026480717584490776}, {'id': 119, 'seek': 67610, 'start': 676.1, 'end': 681.34, 'text': ' initial part of this example here, but it does not matter. We will try to understand', 'tokens': [50364, 5883, 644, 295, 341, 1365, 510, 11, 457, 309, 775, 406, 1871, 13, 492, 486, 853, 281, 1223, 50626], 'temperature': 0.0, 'avg_logprob': -0.13932693435485105, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.007207767106592655}, {'id': 120, 'seek': 67610, 'start': 681.34, 'end': 688.34, 'text': ' what this code is trying to do, right. So, you can see that in this particular example', 'tokens': [50626, 437, 341, 3089, 307, 1382, 281, 360, 11, 558, 13, 407, 11, 291, 393, 536, 300, 294, 341, 1729, 1365, 50976], 'temperature': 0.0, 'avg_logprob': -0.13932693435485105, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.007207767106592655}, {'id': 121, 'seek': 67610, 'start': 691.98, 'end': 697.74, 'text': ' I have taken memory operation, floating point operation and integer or branch operation.', 'tokens': [51158, 286, 362, 2726, 4675, 6916, 11, 12607, 935, 6916, 293, 24922, 420, 9819, 6916, 13, 51446], 'temperature': 0.0, 'avg_logprob': -0.13932693435485105, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.007207767106592655}, {'id': 122, 'seek': 67610, 'start': 697.74, 'end': 704.74, 'text': ' So, I have taken an example of three operations in every VLIW word, okay, right.', 'tokens': [51446, 407, 11, 286, 362, 2726, 364, 1365, 295, 1045, 7705, 294, 633, 691, 48718, 54, 1349, 11, 1392, 11, 558, 13, 51796], 'temperature': 0.0, 'avg_logprob': -0.13932693435485105, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.007207767106592655}, {'id': 123, 'seek': 70610, 'start': 706.74, 'end': 710.66, 'text': ' And then you can see that in each one of this, it would have been nice if I have taken, okay.', 'tokens': [50396, 400, 550, 291, 393, 536, 300, 294, 1184, 472, 295, 341, 11, 309, 576, 362, 668, 1481, 498, 286, 362, 2726, 11, 1392, 13, 50592], 'temperature': 0.0, 'avg_logprob': -0.19833400151500963, 'compression_ratio': 1.567251461988304, 'no_speech_prob': 0.01850724220275879}, {'id': 124, 'seek': 70610, 'start': 710.66, 'end': 717.66, 'text': ' Let me try to do the following. Let me first try to, just give me a minute here. Let us', 'tokens': [50592, 961, 385, 853, 281, 360, 264, 3480, 13, 961, 385, 700, 853, 281, 11, 445, 976, 385, 257, 3456, 510, 13, 961, 505, 50942], 'temperature': 0.0, 'avg_logprob': -0.19833400151500963, 'compression_ratio': 1.567251461988304, 'no_speech_prob': 0.01850724220275879}, {'id': 125, 'seek': 70610, 'start': 724.22, 'end': 731.22, 'text': ' see what this code is because this is when you will appreciate what this is doing. So,', 'tokens': [51270, 536, 437, 341, 3089, 307, 570, 341, 307, 562, 291, 486, 4449, 437, 341, 307, 884, 13, 407, 11, 51620], 'temperature': 0.0, 'avg_logprob': -0.19833400151500963, 'compression_ratio': 1.567251461988304, 'no_speech_prob': 0.01850724220275879}, {'id': 126, 'seek': 73610, 'start': 736.1, 'end': 744.1, 'text': ' let me try to do this. Okay.', 'tokens': [50414, 718, 385, 853, 281, 360, 341, 13, 1033, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.992528518040975, 'compression_ratio': 0.7777777777777778, 'no_speech_prob': 0.5315311551094055}, {'id': 127, 'seek': 76610, 'start': 766.1, 'end': 773.1, 'text': ' So, let us say this is my original program, right. You are able to see that, correct.', 'tokens': [50364, 407, 11, 718, 505, 584, 341, 307, 452, 3380, 1461, 11, 558, 13, 509, 366, 1075, 281, 536, 300, 11, 3006, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.21366649784453928, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.048527978360652924}, {'id': 128, 'seek': 76610, 'start': 781.1, 'end': 788.1, 'text': ' So, can somebody look at it and then tell what it is trying to do? Let us say that R', 'tokens': [51114, 407, 11, 393, 2618, 574, 412, 309, 293, 550, 980, 437, 309, 307, 1382, 281, 360, 30, 961, 505, 584, 300, 497, 51464], 'temperature': 0.0, 'avg_logprob': -0.21366649784453928, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.048527978360652924}, {'id': 129, 'seek': 76610, 'start': 788.4200000000001, 'end': 795.4200000000001, 'text': ' 1 contains the address of an array A, right, contains the address of A of 0, let us say', 'tokens': [51480, 502, 8306, 264, 2985, 295, 364, 10225, 316, 11, 558, 11, 8306, 264, 2985, 295, 316, 295, 1958, 11, 718, 505, 584, 51830], 'temperature': 0.0, 'avg_logprob': -0.21366649784453928, 'compression_ratio': 1.5731707317073171, 'no_speech_prob': 0.048527978360652924}, {'id': 130, 'seek': 79610, 'start': 797.1, 'end': 803.1, 'text': ' then it loads that value into F 0 register, it loads that value into the F 0 register,', 'tokens': [50414, 550, 309, 12668, 300, 2158, 666, 479, 1958, 7280, 11, 309, 12668, 300, 2158, 666, 264, 479, 1958, 7280, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.2237780491511027, 'compression_ratio': 1.76, 'no_speech_prob': 0.005630488507449627}, {'id': 131, 'seek': 79610, 'start': 803.1, 'end': 810.1, 'text': ' it adds it with some scalar value, okay. F 2 is the other scalar with which it is adding,', 'tokens': [50714, 309, 10860, 309, 365, 512, 39684, 2158, 11, 1392, 13, 479, 568, 307, 264, 661, 39684, 365, 597, 309, 307, 5127, 11, 51064], 'temperature': 0.0, 'avg_logprob': -0.2237780491511027, 'compression_ratio': 1.76, 'no_speech_prob': 0.005630488507449627}, {'id': 132, 'seek': 79610, 'start': 810.34, 'end': 816.58, 'text': ' putting the result in F 4 and then storing the result back in the same memory location.', 'tokens': [51076, 3372, 264, 1874, 294, 479, 1017, 293, 550, 26085, 264, 1874, 646, 294, 264, 912, 4675, 4914, 13, 51388], 'temperature': 0.0, 'avg_logprob': -0.2237780491511027, 'compression_ratio': 1.76, 'no_speech_prob': 0.005630488507449627}, {'id': 133, 'seek': 79610, 'start': 816.58, 'end': 823.58, 'text': ' So, this is a code which says A of i is equal to A of i plus s, correct. And then it is', 'tokens': [51388, 407, 11, 341, 307, 257, 3089, 597, 1619, 316, 295, 741, 307, 2681, 281, 316, 295, 741, 1804, 262, 11, 3006, 13, 400, 550, 309, 307, 51738], 'temperature': 0.0, 'avg_logprob': -0.2237780491511027, 'compression_ratio': 1.76, 'no_speech_prob': 0.005630488507449627}, {'id': 134, 'seek': 82358, 'start': 824.58, 'end': 831.58, 'text': ' incrementing the pointer by 8 assuming that these are double precision floating point', 'tokens': [50414, 26200, 278, 264, 23918, 538, 1649, 11926, 300, 613, 366, 3834, 18356, 12607, 935, 50764], 'temperature': 0.0, 'avg_logprob': -0.23007654321604762, 'compression_ratio': 1.5723684210526316, 'no_speech_prob': 0.011163060553371906}, {'id': 135, 'seek': 82358, 'start': 832.0200000000001, 'end': 839.0200000000001, 'text': ' numbers, correct. And then what it does is it subtracts the loop count by 1 and when', 'tokens': [50786, 3547, 11, 3006, 13, 400, 550, 437, 309, 775, 307, 309, 16390, 82, 264, 6367, 1207, 538, 502, 293, 562, 51136], 'temperature': 0.0, 'avg_logprob': -0.23007654321604762, 'compression_ratio': 1.5723684210526316, 'no_speech_prob': 0.011163060553371906}, {'id': 136, 'seek': 82358, 'start': 840.6600000000001, 'end': 846.7, 'text': ' the loop count becomes 0, it comes out of the loop otherwise, right.', 'tokens': [51218, 264, 6367, 1207, 3643, 1958, 11, 309, 1487, 484, 295, 264, 6367, 5911, 11, 558, 13, 51520], 'temperature': 0.0, 'avg_logprob': -0.23007654321604762, 'compression_ratio': 1.5723684210526316, 'no_speech_prob': 0.011163060553371906}, {'id': 137, 'seek': 84670, 'start': 847.1400000000001, 'end': 854.1400000000001, 'text': ' Now assume that I have unrolled this loop, right, 6 times, right. That is why you see', 'tokens': [50386, 823, 6552, 300, 286, 362, 517, 28850, 341, 6367, 11, 558, 11, 1386, 1413, 11, 558, 13, 663, 307, 983, 291, 536, 50736], 'temperature': 0.0, 'avg_logprob': -0.21076923608779907, 'compression_ratio': 1.7313432835820894, 'no_speech_prob': 0.014712801203131676}, {'id': 138, 'seek': 84670, 'start': 854.5400000000001, 'end': 861.5400000000001, 'text': ' 6 of those loads, right. So, you have 5 loads here that corresponds to 5 times unrolling,', 'tokens': [50756, 1386, 295, 729, 12668, 11, 558, 13, 407, 11, 291, 362, 1025, 12668, 510, 300, 23249, 281, 1025, 1413, 517, 18688, 11, 51106], 'temperature': 0.0, 'avg_logprob': -0.21076923608779907, 'compression_ratio': 1.7313432835820894, 'no_speech_prob': 0.014712801203131676}, {'id': 139, 'seek': 84670, 'start': 861.7800000000001, 'end': 868.7800000000001, 'text': " isn't it, right. So, you have 5 loads, 5 floating point adds and 5 stores, correct.", 'tokens': [51118, 1943, 380, 309, 11, 558, 13, 407, 11, 291, 362, 1025, 12668, 11, 1025, 12607, 935, 10860, 293, 1025, 9512, 11, 3006, 13, 51468], 'temperature': 0.0, 'avg_logprob': -0.21076923608779907, 'compression_ratio': 1.7313432835820894, 'no_speech_prob': 0.014712801203131676}, {'id': 140, 'seek': 84670, 'start': 869.3000000000001, 'end': 876.0200000000001, 'text': ' So, those are the 3 instructions which are what are here. This of course is incrementing', 'tokens': [51494, 407, 11, 729, 366, 264, 805, 9415, 597, 366, 437, 366, 510, 13, 639, 295, 1164, 307, 26200, 278, 51830], 'temperature': 0.0, 'avg_logprob': -0.21076923608779907, 'compression_ratio': 1.7313432835820894, 'no_speech_prob': 0.014712801203131676}, {'id': 141, 'seek': 87602, 'start': 876.02, 'end': 883.02, 'text': ' the pointer, right. Now how am I loading A of 0? It is 0 of R 1. A of 1 is offset 8,', 'tokens': [50364, 264, 23918, 11, 558, 13, 823, 577, 669, 286, 15114, 316, 295, 1958, 30, 467, 307, 1958, 295, 497, 502, 13, 316, 295, 502, 307, 18687, 1649, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.1637621901252053, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.006199651397764683}, {'id': 142, 'seek': 87602, 'start': 888.22, 'end': 895.22, 'text': ' right, from A of 0. A of 2 is offset 16 and so on, right. So, each one of this load is', 'tokens': [50974, 558, 11, 490, 316, 295, 1958, 13, 316, 295, 568, 307, 18687, 3165, 293, 370, 322, 11, 558, 13, 407, 11, 1184, 472, 295, 341, 3677, 307, 51324], 'temperature': 0.0, 'avg_logprob': -0.1637621901252053, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.006199651397764683}, {'id': 143, 'seek': 87602, 'start': 898.42, 'end': 904.22, 'text': ' doing A of i, A of i plus 1 and so on. So, yesterday when you are unrolling the code,', 'tokens': [51484, 884, 316, 295, 741, 11, 316, 295, 741, 1804, 502, 293, 370, 322, 13, 407, 11, 5186, 562, 291, 366, 517, 18688, 264, 3089, 11, 51774], 'temperature': 0.0, 'avg_logprob': -0.1637621901252053, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.006199651397764683}, {'id': 144, 'seek': 90422, 'start': 904.22, 'end': 911.22, 'text': ' were you seeing something like this in the, yes or no? How many of you saw this? Okay,', 'tokens': [50364, 645, 291, 2577, 746, 411, 341, 294, 264, 11, 2086, 420, 572, 30, 1012, 867, 295, 291, 1866, 341, 30, 1033, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.2394691542083142, 'compression_ratio': 1.6990291262135921, 'no_speech_prob': 0.0053204623982310295}, {'id': 145, 'seek': 90422, 'start': 913.82, 'end': 919.02, 'text': " how many of you did not see this? Did you? Yeah, yeah, don't feel bad to say that you", 'tokens': [50844, 577, 867, 295, 291, 630, 406, 536, 341, 30, 2589, 291, 30, 865, 11, 1338, 11, 500, 380, 841, 1578, 281, 584, 300, 291, 51104], 'temperature': 0.0, 'avg_logprob': -0.2394691542083142, 'compression_ratio': 1.6990291262135921, 'no_speech_prob': 0.0053204623982310295}, {'id': 146, 'seek': 90422, 'start': 919.02, 'end': 924.02, 'text': ' did not see it. Maybe the compiler did not do it for you, right. It is not your problem.', 'tokens': [51104, 630, 406, 536, 309, 13, 2704, 264, 31958, 630, 406, 360, 309, 337, 291, 11, 558, 13, 467, 307, 406, 428, 1154, 13, 51354], 'temperature': 0.0, 'avg_logprob': -0.2394691542083142, 'compression_ratio': 1.6990291262135921, 'no_speech_prob': 0.0053204623982310295}, {'id': 147, 'seek': 90422, 'start': 924.02, 'end': 929.02, 'text': " It is a compiler's problem. So, the question is did you use the minus o 2 option? If you", 'tokens': [51354, 467, 307, 257, 31958, 311, 1154, 13, 407, 11, 264, 1168, 307, 630, 291, 764, 264, 3175, 277, 568, 3614, 30, 759, 291, 51604], 'temperature': 0.0, 'avg_logprob': -0.2394691542083142, 'compression_ratio': 1.6990291262135921, 'no_speech_prob': 0.0053204623982310295}, {'id': 148, 'seek': 92902, 'start': 929.42, 'end': 935.42, 'text': ' use the minus o 2 option, it would not try to add 8 to this and then try to do this,', 'tokens': [50384, 764, 264, 3175, 277, 568, 3614, 11, 309, 576, 406, 853, 281, 909, 1649, 281, 341, 293, 550, 853, 281, 360, 341, 11, 50684], 'temperature': 0.0, 'avg_logprob': -0.1877513783318656, 'compression_ratio': 2.0, 'no_speech_prob': 0.023032352328300476}, {'id': 149, 'seek': 92902, 'start': 935.42, 'end': 939.8199999999999, 'text': ' add 8 to this and then try to do this because when you add 8 and then try to do this, there', 'tokens': [50684, 909, 1649, 281, 341, 293, 550, 853, 281, 360, 341, 570, 562, 291, 909, 1649, 293, 550, 853, 281, 360, 341, 11, 456, 50904], 'temperature': 0.0, 'avg_logprob': -0.1877513783318656, 'compression_ratio': 2.0, 'no_speech_prob': 0.023032352328300476}, {'id': 150, 'seek': 92902, 'start': 939.8199999999999, 'end': 946.34, 'text': ' is a dependency chain that you are creating, correct. Whereas when you do like this, all', 'tokens': [50904, 307, 257, 33621, 5021, 300, 291, 366, 4084, 11, 3006, 13, 13813, 562, 291, 360, 411, 341, 11, 439, 51230], 'temperature': 0.0, 'avg_logprob': -0.1877513783318656, 'compression_ratio': 2.0, 'no_speech_prob': 0.023032352328300476}, {'id': 151, 'seek': 92902, 'start': 946.34, 'end': 950.62, 'text': ' these instructions are independent of each other. Any of these instructions could be', 'tokens': [51230, 613, 9415, 366, 6695, 295, 1184, 661, 13, 2639, 295, 613, 9415, 727, 312, 51444], 'temperature': 0.0, 'avg_logprob': -0.1877513783318656, 'compression_ratio': 2.0, 'no_speech_prob': 0.023032352328300476}, {'id': 152, 'seek': 92902, 'start': 950.62, 'end': 957.62, 'text': ' executed in any order, correct. If I have done this instruction, add 8 to R 1, then', 'tokens': [51444, 17577, 294, 604, 1668, 11, 3006, 13, 759, 286, 362, 1096, 341, 10951, 11, 909, 1649, 281, 497, 502, 11, 550, 51794], 'temperature': 0.0, 'avg_logprob': -0.1877513783318656, 'compression_ratio': 2.0, 'no_speech_prob': 0.023032352328300476}, {'id': 153, 'seek': 95762, 'start': 957.82, 'end': 964.82, 'text': ' 0 of R 1, then another add 8, 0 of R 1, another add 8, 0 of R 1, then it would have become', 'tokens': [50374, 1958, 295, 497, 502, 11, 550, 1071, 909, 1649, 11, 1958, 295, 497, 502, 11, 1071, 909, 1649, 11, 1958, 295, 497, 502, 11, 550, 309, 576, 362, 1813, 50724], 'temperature': 0.0, 'avg_logprob': -0.18261878791896777, 'compression_ratio': 1.8229166666666667, 'no_speech_prob': 0.007393839303404093}, {'id': 154, 'seek': 95762, 'start': 965.26, 'end': 971.42, 'text': ' sequential. But just by using these offsets appropriately, right, there is no dependency', 'tokens': [50746, 42881, 13, 583, 445, 538, 1228, 613, 39457, 1385, 23505, 11, 558, 11, 456, 307, 572, 33621, 51054], 'temperature': 0.0, 'avg_logprob': -0.18261878791896777, 'compression_ratio': 1.8229166666666667, 'no_speech_prob': 0.007393839303404093}, {'id': 155, 'seek': 95762, 'start': 971.42, 'end': 977.38, 'text': ' between these load instructions. But there is a dependency from this load instruction', 'tokens': [51054, 1296, 613, 3677, 9415, 13, 583, 456, 307, 257, 33621, 490, 341, 3677, 10951, 51352], 'temperature': 0.0, 'avg_logprob': -0.18261878791896777, 'compression_ratio': 1.8229166666666667, 'no_speech_prob': 0.007393839303404093}, {'id': 156, 'seek': 95762, 'start': 977.38, 'end': 983.26, 'text': ' to this add instruction because this loads the value into F naught, that F naught is', 'tokens': [51352, 281, 341, 909, 10951, 570, 341, 12668, 264, 2158, 666, 479, 13138, 11, 300, 479, 13138, 307, 51646], 'temperature': 0.0, 'avg_logprob': -0.18261878791896777, 'compression_ratio': 1.8229166666666667, 'no_speech_prob': 0.007393839303404093}, {'id': 157, 'seek': 98326, 'start': 983.3, 'end': 990.3, 'text': ' being used here. And then you compute some F 4 and that F 4 is being stored here. So,', 'tokens': [50366, 885, 1143, 510, 13, 400, 550, 291, 14722, 512, 479, 1017, 293, 300, 479, 1017, 307, 885, 12187, 510, 13, 407, 11, 50716], 'temperature': 0.0, 'avg_logprob': -0.1918183260185774, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.009152579121291637}, {'id': 158, 'seek': 98326, 'start': 991.1, 'end': 996.7, 'text': ' this dependency that you see here is a original dependency which was there in the code and', 'tokens': [50756, 341, 33621, 300, 291, 536, 510, 307, 257, 3380, 33621, 597, 390, 456, 294, 264, 3089, 293, 51036], 'temperature': 0.0, 'avg_logprob': -0.1918183260185774, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.009152579121291637}, {'id': 159, 'seek': 98326, 'start': 996.7, 'end': 1002.5, 'text': ' you want to retain the dependency, right. That is what we mean by saying that dependence', 'tokens': [51036, 291, 528, 281, 18340, 264, 33621, 11, 558, 13, 663, 307, 437, 321, 914, 538, 1566, 300, 31704, 51326], 'temperature': 0.0, 'avg_logprob': -0.1918183260185774, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.009152579121291637}, {'id': 160, 'seek': 98326, 'start': 1002.5, 'end': 1008.54, 'text': ' constraints have to be satisfied, right. We are not violating that. And look at this,', 'tokens': [51326, 18491, 362, 281, 312, 11239, 11, 558, 13, 492, 366, 406, 42201, 300, 13, 400, 574, 412, 341, 11, 51628], 'temperature': 0.0, 'avg_logprob': -0.1918183260185774, 'compression_ratio': 1.703883495145631, 'no_speech_prob': 0.009152579121291637}, {'id': 161, 'seek': 100854, 'start': 1008.54, 'end': 1014.3399999999999, 'text': ' this load and this add are separated by at least one cycle. That means that this one', 'tokens': [50364, 341, 3677, 293, 341, 909, 366, 12005, 538, 412, 1935, 472, 6586, 13, 663, 1355, 300, 341, 472, 50654], 'temperature': 0.0, 'avg_logprob': -0.12565327882766725, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.011064398102462292}, {'id': 162, 'seek': 100854, 'start': 1014.3399999999999, 'end': 1021.3399999999999, 'text': ' stall that we talked about has also been taken into account, correct, right.', 'tokens': [50654, 19633, 300, 321, 2825, 466, 575, 611, 668, 2726, 666, 2696, 11, 3006, 11, 558, 13, 51004], 'temperature': 0.0, 'avg_logprob': -0.12565327882766725, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.011064398102462292}, {'id': 163, 'seek': 100854, 'start': 1021.6999999999999, 'end': 1027.6599999999999, 'text': ' And then in cycles 3, 4 and 5, you have a load instruction and an add instruction executing', 'tokens': [51022, 400, 550, 294, 17796, 805, 11, 1017, 293, 1025, 11, 291, 362, 257, 3677, 10951, 293, 364, 909, 10951, 32368, 51320], 'temperature': 0.0, 'avg_logprob': -0.12565327882766725, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.011064398102462292}, {'id': 164, 'seek': 100854, 'start': 1027.6599999999999, 'end': 1033.6599999999999, 'text': ' together because these are independent of each other. They can be executed in parallel,', 'tokens': [51320, 1214, 570, 613, 366, 6695, 295, 1184, 661, 13, 814, 393, 312, 17577, 294, 8952, 11, 51620], 'temperature': 0.0, 'avg_logprob': -0.12565327882766725, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.011064398102462292}, {'id': 165, 'seek': 103366, 'start': 1034.3400000000001, 'end': 1040.1000000000001, 'text': ' right. And if you look at this particular cycle, right, you have a store instruction,', 'tokens': [50398, 558, 13, 400, 498, 291, 574, 412, 341, 1729, 6586, 11, 558, 11, 291, 362, 257, 3531, 10951, 11, 50686], 'temperature': 0.0, 'avg_logprob': -0.19397238890329996, 'compression_ratio': 1.8181818181818181, 'no_speech_prob': 0.005488768219947815}, {'id': 166, 'seek': 103366, 'start': 1040.1000000000001, 'end': 1045.9, 'text': ' an additional add instruction and a subtract instruction. So, one integer operation, one', 'tokens': [50686, 364, 4497, 909, 10951, 293, 257, 16390, 10951, 13, 407, 11, 472, 24922, 6916, 11, 472, 50976], 'temperature': 0.0, 'avg_logprob': -0.19397238890329996, 'compression_ratio': 1.8181818181818181, 'no_speech_prob': 0.005488768219947815}, {'id': 167, 'seek': 103366, 'start': 1045.9, 'end': 1052.14, 'text': ' floating point operation and one memory operation. All of this can be executed in parallel. If', 'tokens': [50976, 12607, 935, 6916, 293, 472, 4675, 6916, 13, 1057, 295, 341, 393, 312, 17577, 294, 8952, 13, 759, 51288], 'temperature': 0.0, 'avg_logprob': -0.19397238890329996, 'compression_ratio': 1.8181818181818181, 'no_speech_prob': 0.005488768219947815}, {'id': 168, 'seek': 103366, 'start': 1052.14, 'end': 1056.18, 'text': ' you have unrolled this loop more number of times, for example, 8 times or something like', 'tokens': [51288, 291, 362, 517, 28850, 341, 6367, 544, 1230, 295, 1413, 11, 337, 1365, 11, 1649, 1413, 420, 746, 411, 51490], 'temperature': 0.0, 'avg_logprob': -0.19397238890329996, 'compression_ratio': 1.8181818181818181, 'no_speech_prob': 0.005488768219947815}, {'id': 169, 'seek': 103366, 'start': 1056.18, 'end': 1059.5, 'text': ' that, more of these instructions could have been in parallel.', 'tokens': [51490, 300, 11, 544, 295, 613, 9415, 727, 362, 668, 294, 8952, 13, 51656], 'temperature': 0.0, 'avg_logprob': -0.19397238890329996, 'compression_ratio': 1.8181818181818181, 'no_speech_prob': 0.005488768219947815}, {'id': 170, 'seek': 105950, 'start': 1060.46, 'end': 1065.78, 'text': ' Now, let us look at the instructions which are integer instructions, right, and then', 'tokens': [50412, 823, 11, 718, 505, 574, 412, 264, 9415, 597, 366, 24922, 9415, 11, 558, 11, 293, 550, 50678], 'temperature': 0.0, 'avg_logprob': -0.1993220099087419, 'compression_ratio': 1.815, 'no_speech_prob': 0.05467136204242706}, {'id': 171, 'seek': 105950, 'start': 1065.78, 'end': 1072.78, 'text': ' see what is happening here. See this subtract instructions when we unroll, right, 5 iterations', 'tokens': [50678, 536, 437, 307, 2737, 510, 13, 3008, 341, 16390, 9415, 562, 321, 517, 3970, 11, 558, 11, 1025, 36540, 51028], 'temperature': 0.0, 'avg_logprob': -0.1993220099087419, 'compression_ratio': 1.815, 'no_speech_prob': 0.05467136204242706}, {'id': 172, 'seek': 105950, 'start': 1073.3, 'end': 1079.14, 'text': ' of the loops are executed in this one unrolled version. Therefore, the count has to be decremented', 'tokens': [51054, 295, 264, 16121, 366, 17577, 294, 341, 472, 517, 28850, 3037, 13, 7504, 11, 264, 1207, 575, 281, 312, 6853, 14684, 51346], 'temperature': 0.0, 'avg_logprob': -0.1993220099087419, 'compression_ratio': 1.815, 'no_speech_prob': 0.05467136204242706}, {'id': 173, 'seek': 105950, 'start': 1079.14, 'end': 1084.62, 'text': ' by it could have been decremented by 1, 5 times or it would have been decremented by', 'tokens': [51346, 538, 309, 727, 362, 668, 6853, 14684, 538, 502, 11, 1025, 1413, 420, 309, 576, 362, 668, 6853, 14684, 538, 51620], 'temperature': 0.0, 'avg_logprob': -0.1993220099087419, 'compression_ratio': 1.815, 'no_speech_prob': 0.05467136204242706}, {'id': 174, 'seek': 108462, 'start': 1084.7399999999998, 'end': 1091.7399999999998, 'text': ' 5 one time, right. That is right. So, this is 5, right. Similarly, this add instruction', 'tokens': [50370, 1025, 472, 565, 11, 558, 13, 663, 307, 558, 13, 407, 11, 341, 307, 1025, 11, 558, 13, 13157, 11, 341, 909, 10951, 50720], 'temperature': 0.0, 'avg_logprob': -0.19562004551743017, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.03181624785065651}, {'id': 175, 'seek': 108462, 'start': 1094.6599999999999, 'end': 1101.6599999999999, 'text': ' which was incrementing the R 1 pointer by 8 for each iteration can now be incremented', 'tokens': [50866, 597, 390, 26200, 278, 264, 497, 502, 23918, 538, 1649, 337, 1184, 24784, 393, 586, 312, 1946, 14684, 51216], 'temperature': 0.0, 'avg_logprob': -0.19562004551743017, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.03181624785065651}, {'id': 176, 'seek': 108462, 'start': 1101.9399999999998, 'end': 1108.9399999999998, 'text': ' by 40 because we are incrementing for every 5 iterations and these offsets are appropriately', 'tokens': [51230, 538, 3356, 570, 321, 366, 26200, 278, 337, 633, 1025, 36540, 293, 613, 39457, 1385, 366, 23505, 51580], 'temperature': 0.0, 'avg_logprob': -0.19562004551743017, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.03181624785065651}, {'id': 177, 'seek': 110894, 'start': 1109.42, 'end': 1116.42, 'text': ' taken into account, okay. Now, anything else that you see strange in this code or you are', 'tokens': [50388, 2726, 666, 2696, 11, 1392, 13, 823, 11, 1340, 1646, 300, 291, 536, 5861, 294, 341, 3089, 420, 291, 366, 50738], 'temperature': 0.0, 'avg_logprob': -0.16476384524641366, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.006941529922187328}, {'id': 178, 'seek': 110894, 'start': 1116.9, 'end': 1123.9, 'text': ' happy with it? So, this branch instruction is dependent on this R 2. There is no problem.', 'tokens': [50762, 2055, 365, 309, 30, 407, 11, 341, 9819, 10951, 307, 12334, 322, 341, 497, 568, 13, 821, 307, 572, 1154, 13, 51112], 'temperature': 0.0, 'avg_logprob': -0.16476384524641366, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.006941529922187328}, {'id': 179, 'seek': 110894, 'start': 1124.94, 'end': 1130.38, 'text': ' The dependency is being preserved. If you think of a branch delay slot, this is the', 'tokens': [51164, 440, 33621, 307, 885, 22242, 13, 759, 291, 519, 295, 257, 9819, 8577, 14747, 11, 341, 307, 264, 51436], 'temperature': 0.0, 'avg_logprob': -0.16476384524641366, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.006941529922187328}, {'id': 180, 'seek': 110894, 'start': 1130.38, 'end': 1135.02, 'text': ' branch delay slot in which a useful instruction is being put. That means the branch has been', 'tokens': [51436, 9819, 8577, 14747, 294, 597, 257, 4420, 10951, 307, 885, 829, 13, 663, 1355, 264, 9819, 575, 668, 51668], 'temperature': 0.0, 'avg_logprob': -0.16476384524641366, 'compression_ratio': 1.6872037914691944, 'no_speech_prob': 0.006941529922187328}, {'id': 181, 'seek': 113502, 'start': 1135.02, 'end': 1142.02, 'text': ' moved a little earlier, okay. That is fine and every one of these instructions satisfies', 'tokens': [50364, 4259, 257, 707, 3071, 11, 1392, 13, 663, 307, 2489, 293, 633, 472, 295, 613, 9415, 44271, 50714], 'temperature': 0.0, 'avg_logprob': -0.17712556688409103, 'compression_ratio': 1.6018099547511313, 'no_speech_prob': 0.04535480588674545}, {'id': 182, 'seek': 113502, 'start': 1142.62, 'end': 1147.18, 'text': ' the resource constraint because exactly there is one memory operation, one floating point', 'tokens': [50744, 264, 7684, 25534, 570, 2293, 456, 307, 472, 4675, 6916, 11, 472, 12607, 935, 50972], 'temperature': 0.0, 'avg_logprob': -0.17712556688409103, 'compression_ratio': 1.6018099547511313, 'no_speech_prob': 0.04535480588674545}, {'id': 183, 'seek': 113502, 'start': 1147.18, 'end': 1154.18, 'text': ' operation and one integer operation every cycle, right. What else do you see as something', 'tokens': [50972, 6916, 293, 472, 24922, 6916, 633, 6586, 11, 558, 13, 708, 1646, 360, 291, 536, 382, 746, 51322], 'temperature': 0.0, 'avg_logprob': -0.17712556688409103, 'compression_ratio': 1.6018099547511313, 'no_speech_prob': 0.04535480588674545}, {'id': 184, 'seek': 113502, 'start': 1155.78, 'end': 1162.78, 'text': ' different can be discussed about? The first two, first three stores are all right, 0,', 'tokens': [51402, 819, 393, 312, 7152, 466, 30, 440, 700, 732, 11, 700, 1045, 9512, 366, 439, 558, 11, 1958, 11, 51752], 'temperature': 0.0, 'avg_logprob': -0.17712556688409103, 'compression_ratio': 1.6018099547511313, 'no_speech_prob': 0.04535480588674545}, {'id': 185, 'seek': 116502, 'start': 1165.02, 'end': 1172.02, 'text': ' 8, 16. Then you should have seen 24 and 32, correct, but you are not seeing that. Why?', 'tokens': [50364, 1649, 11, 3165, 13, 1396, 291, 820, 362, 1612, 4022, 293, 8858, 11, 3006, 11, 457, 291, 366, 406, 2577, 300, 13, 1545, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.2571342416005592, 'compression_ratio': 1.4719101123595506, 'no_speech_prob': 0.015077921561896801}, {'id': 186, 'seek': 116502, 'start': 1174.3799999999999, 'end': 1181.3799999999999, 'text': ' Right. You see here what is happening to your R 1. R 1 in between has been incremented to', 'tokens': [50832, 1779, 13, 509, 536, 510, 437, 307, 2737, 281, 428, 497, 502, 13, 497, 502, 294, 1296, 575, 668, 1946, 14684, 281, 51182], 'temperature': 0.0, 'avg_logprob': -0.2571342416005592, 'compression_ratio': 1.4719101123595506, 'no_speech_prob': 0.015077921561896801}, {'id': 187, 'seek': 116502, 'start': 1181.98, 'end': 1188.98, 'text': ' incremented by 40, correct. That means that after this instruction R 1 is already R 1', 'tokens': [51212, 1946, 14684, 538, 3356, 11, 3006, 13, 663, 1355, 300, 934, 341, 10951, 497, 502, 307, 1217, 497, 502, 51562], 'temperature': 0.0, 'avg_logprob': -0.2571342416005592, 'compression_ratio': 1.4719101123595506, 'no_speech_prob': 0.015077921561896801}, {'id': 188, 'seek': 118898, 'start': 1189.98, 'end': 1196.98, 'text': ' plus 40. That means that the pointer has been moved to A 5. So, if you want A 4 and A 3,', 'tokens': [50414, 1804, 3356, 13, 663, 1355, 300, 264, 23918, 575, 668, 4259, 281, 316, 1025, 13, 407, 11, 498, 291, 528, 316, 1017, 293, 316, 805, 11, 50764], 'temperature': 0.0, 'avg_logprob': -0.09980813026428223, 'compression_ratio': 1.6883720930232557, 'no_speech_prob': 0.01724468544125557}, {'id': 189, 'seek': 118898, 'start': 1197.42, 'end': 1204.42, 'text': ' they are minus 8 and minus 16 from the A 5. So, that is why these have the offset values', 'tokens': [50786, 436, 366, 3175, 1649, 293, 3175, 3165, 490, 264, 316, 1025, 13, 407, 11, 300, 307, 983, 613, 362, 264, 18687, 4190, 51136], 'temperature': 0.0, 'avg_logprob': -0.09980813026428223, 'compression_ratio': 1.6883720930232557, 'no_speech_prob': 0.01724468544125557}, {'id': 190, 'seek': 118898, 'start': 1205.58, 'end': 1212.22, 'text': ' minus 16 and minus 8. In other words, other way of looking at it is that this add instruction', 'tokens': [51194, 3175, 3165, 293, 3175, 1649, 13, 682, 661, 2283, 11, 661, 636, 295, 1237, 412, 309, 307, 300, 341, 909, 10951, 51526], 'temperature': 0.0, 'avg_logprob': -0.09980813026428223, 'compression_ratio': 1.6883720930232557, 'no_speech_prob': 0.01724468544125557}, {'id': 191, 'seek': 118898, 'start': 1212.22, 'end': 1218.02, 'text': ' should not have been moved before the store, but if you want to move it, you have to adjust', 'tokens': [51526, 820, 406, 362, 668, 4259, 949, 264, 3531, 11, 457, 498, 291, 528, 281, 1286, 309, 11, 291, 362, 281, 4369, 51816], 'temperature': 0.0, 'avg_logprob': -0.09980813026428223, 'compression_ratio': 1.6883720930232557, 'no_speech_prob': 0.01724468544125557}, {'id': 192, 'seek': 121802, 'start': 1218.02, 'end': 1225.02, 'text': ' the offset values. Otherwise, you will be violating the dependence, correct, because', 'tokens': [50364, 264, 18687, 4190, 13, 10328, 11, 291, 486, 312, 42201, 264, 31704, 11, 3006, 11, 570, 50714], 'temperature': 0.0, 'avg_logprob': -0.17068696529307265, 'compression_ratio': 1.583710407239819, 'no_speech_prob': 0.008303032256662846}, {'id': 193, 'seek': 121802, 'start': 1225.22, 'end': 1232.22, 'text': ' if you have moved this by 40, incremented this by 40 and kept 24 and 32 here, then you', 'tokens': [50724, 498, 291, 362, 4259, 341, 538, 3356, 11, 1946, 14684, 341, 538, 3356, 293, 4305, 4022, 293, 8858, 510, 11, 550, 291, 51074], 'temperature': 0.0, 'avg_logprob': -0.17068696529307265, 'compression_ratio': 1.583710407239819, 'no_speech_prob': 0.008303032256662846}, {'id': 194, 'seek': 121802, 'start': 1232.98, 'end': 1239.98, 'text': ' will be writing some A 8 and A 9 instead of A 3 and A 4, correct. That is wrong. So, when', 'tokens': [51112, 486, 312, 3579, 512, 316, 1649, 293, 316, 1722, 2602, 295, 316, 805, 293, 316, 1017, 11, 3006, 13, 663, 307, 2085, 13, 407, 11, 562, 51462], 'temperature': 0.0, 'avg_logprob': -0.17068696529307265, 'compression_ratio': 1.583710407239819, 'no_speech_prob': 0.008303032256662846}, {'id': 195, 'seek': 121802, 'start': 1241.78, 'end': 1247.3799999999999, 'text': ' the scheduler does this, it can possibly do this also, right. It should possibly do this', 'tokens': [51552, 264, 12000, 260, 775, 341, 11, 309, 393, 6264, 360, 341, 611, 11, 558, 13, 467, 820, 6264, 360, 341, 51832], 'temperature': 0.0, 'avg_logprob': -0.17068696529307265, 'compression_ratio': 1.583710407239819, 'no_speech_prob': 0.008303032256662846}, {'id': 196, 'seek': 124738, 'start': 1247.38, 'end': 1254.38, 'text': ' also, not it can. It should do this, right. So, this schedule which is the schedule obtained', 'tokens': [50364, 611, 11, 406, 309, 393, 13, 467, 820, 360, 341, 11, 558, 13, 407, 11, 341, 7567, 597, 307, 264, 7567, 14879, 50714], 'temperature': 0.0, 'avg_logprob': -0.2619821375066584, 'compression_ratio': 1.569767441860465, 'no_speech_prob': 0.005203763954341412}, {'id': 197, 'seek': 124738, 'start': 1259.9, 'end': 1266.9, 'text': ' for this loop over here, right, which was unrolled five times and scheduled for a VLIW', 'tokens': [50990, 337, 341, 6367, 670, 510, 11, 558, 11, 597, 390, 517, 28850, 1732, 1413, 293, 15678, 337, 257, 691, 48718, 54, 51340], 'temperature': 0.0, 'avg_logprob': -0.2619821375066584, 'compression_ratio': 1.569767441860465, 'no_speech_prob': 0.005203763954341412}, {'id': 198, 'seek': 124738, 'start': 1269.5400000000002, 'end': 1274.6200000000001, 'text': ' machine with three parallel operations. Of course, I should have considered eight parallel', 'tokens': [51472, 3479, 365, 1045, 8952, 7705, 13, 2720, 1164, 11, 286, 820, 362, 4888, 3180, 8952, 51726], 'temperature': 0.0, 'avg_logprob': -0.2619821375066584, 'compression_ratio': 1.569767441860465, 'no_speech_prob': 0.005203763954341412}, {'id': 199, 'seek': 127462, 'start': 1274.62, 'end': 1279.06, 'text': ' operations, but then I could not have been able to fit it in the slide, could not have', 'tokens': [50364, 7705, 11, 457, 550, 286, 727, 406, 362, 668, 1075, 281, 3318, 309, 294, 264, 4137, 11, 727, 406, 362, 50586], 'temperature': 0.0, 'avg_logprob': -0.18758296966552734, 'compression_ratio': 1.7768240343347639, 'no_speech_prob': 0.03055819496512413}, {'id': 200, 'seek': 127462, 'start': 1279.06, 'end': 1283.1399999999999, 'text': ' been able to fit it in the slide. I have to unroll it maybe eight times or 16 times to', 'tokens': [50586, 668, 1075, 281, 3318, 309, 294, 264, 4137, 13, 286, 362, 281, 517, 3970, 309, 1310, 3180, 1413, 420, 3165, 1413, 281, 50790], 'temperature': 0.0, 'avg_logprob': -0.18758296966552734, 'compression_ratio': 1.7768240343347639, 'no_speech_prob': 0.03055819496512413}, {'id': 201, 'seek': 127462, 'start': 1283.1399999999999, 'end': 1287.9799999999998, 'text': ' get the parallelism. What else do you observe here? Very simple', 'tokens': [50790, 483, 264, 8952, 1434, 13, 708, 1646, 360, 291, 11441, 510, 30, 4372, 2199, 51032], 'temperature': 0.0, 'avg_logprob': -0.18758296966552734, 'compression_ratio': 1.7768240343347639, 'no_speech_prob': 0.03055819496512413}, {'id': 202, 'seek': 127462, 'start': 1287.9799999999998, 'end': 1294.9799999999998, 'text': ' observation is that in many places we have dashes and what does this dash means? It is', 'tokens': [51032, 14816, 307, 300, 294, 867, 3190, 321, 362, 8240, 279, 293, 437, 775, 341, 8240, 1355, 30, 467, 307, 51382], 'temperature': 0.0, 'avg_logprob': -0.18758296966552734, 'compression_ratio': 1.7768240343347639, 'no_speech_prob': 0.03055819496512413}, {'id': 203, 'seek': 127462, 'start': 1295.1799999999998, 'end': 1300.02, 'text': ' no instruction for that or no op for that. That means that these are wasted opportunities', 'tokens': [51392, 572, 10951, 337, 300, 420, 572, 999, 337, 300, 13, 663, 1355, 300, 613, 366, 19496, 4786, 51634], 'temperature': 0.0, 'avg_logprob': -0.18758296966552734, 'compression_ratio': 1.7768240343347639, 'no_speech_prob': 0.03055819496512413}, {'id': 204, 'seek': 130002, 'start': 1300.02, 'end': 1306.42, 'text': ' for parallelism. My code did not have enough parallelism. That is why I was not able to', 'tokens': [50364, 337, 8952, 1434, 13, 1222, 3089, 630, 406, 362, 1547, 8952, 1434, 13, 663, 307, 983, 286, 390, 406, 1075, 281, 50684], 'temperature': 0.0, 'avg_logprob': -0.23360263217579236, 'compression_ratio': 1.6081081081081081, 'no_speech_prob': 0.03259650990366936}, {'id': 205, 'seek': 130002, 'start': 1306.42, 'end': 1313.42, 'text': ' exploit it. If I have unrolled it maybe eight times, right, I would have had fewer of these', 'tokens': [50684, 25924, 309, 13, 759, 286, 362, 517, 28850, 309, 1310, 3180, 1413, 11, 558, 11, 286, 576, 362, 632, 13366, 295, 613, 51034], 'temperature': 0.0, 'avg_logprob': -0.23360263217579236, 'compression_ratio': 1.6081081081081081, 'no_speech_prob': 0.03259650990366936}, {'id': 206, 'seek': 130002, 'start': 1313.66, 'end': 1319.66, 'text': ' tools compared to the number of instructions that I have. Okay, what else do you observe', 'tokens': [51046, 3873, 5347, 281, 264, 1230, 295, 9415, 300, 286, 362, 13, 1033, 11, 437, 1646, 360, 291, 11441, 51346], 'temperature': 0.0, 'avg_logprob': -0.23360263217579236, 'compression_ratio': 1.6081081081081081, 'no_speech_prob': 0.03259650990366936}, {'id': 207, 'seek': 130002, 'start': 1319.66, 'end': 1326.66, 'text': ' since we have talked about the other point? Is there anything else that you observe with', 'tokens': [51346, 1670, 321, 362, 2825, 466, 264, 661, 935, 30, 1119, 456, 1340, 1646, 300, 291, 11441, 365, 51696], 'temperature': 0.0, 'avg_logprob': -0.23360263217579236, 'compression_ratio': 1.6081081081081081, 'no_speech_prob': 0.03259650990366936}, {'id': 208, 'seek': 132666, 'start': 1327.18, 'end': 1334.18, 'text': ' regard to let us say register allocation? Such an exercise that you will probably do', 'tokens': [50390, 3843, 281, 718, 505, 584, 7280, 27599, 30, 9653, 364, 5380, 300, 291, 486, 1391, 360, 50740], 'temperature': 0.0, 'avg_logprob': -0.2895848573143803, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.03404310345649719}, {'id': 209, 'seek': 132666, 'start': 1334.18, 'end': 1341.18, 'text': ' today, right. So, how many registers, how many floating point registers was the original', 'tokens': [50740, 965, 11, 558, 13, 407, 11, 577, 867, 38351, 11, 577, 867, 12607, 935, 38351, 390, 264, 3380, 51090], 'temperature': 0.0, 'avg_logprob': -0.2895848573143803, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.03404310345649719}, {'id': 210, 'seek': 132666, 'start': 1342.74, 'end': 1349.74, 'text': ' code using? F naught, F 2, F 4, correct, three registers, but it is actually three into two,', 'tokens': [51168, 3089, 1228, 30, 479, 13138, 11, 479, 568, 11, 479, 1017, 11, 3006, 11, 1045, 38351, 11, 457, 309, 307, 767, 1045, 666, 732, 11, 51518], 'temperature': 0.0, 'avg_logprob': -0.2895848573143803, 'compression_ratio': 1.5375722543352601, 'no_speech_prob': 0.03404310345649719}, {'id': 211, 'seek': 134974, 'start': 1349.74, 'end': 1356.74, 'text': ' six registers because each floating point register is actually here, two registers because', 'tokens': [50364, 2309, 38351, 570, 1184, 12607, 935, 7280, 307, 767, 510, 11, 732, 38351, 570, 50714], 'temperature': 0.0, 'avg_logprob': -0.23660341176119717, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 0.019082026556134224}, {'id': 212, 'seek': 134974, 'start': 1358.34, 'end': 1363.06, 'text': ' it is a double value, but again even if you take it as three, it is only three. What about', 'tokens': [50794, 309, 307, 257, 3834, 2158, 11, 457, 797, 754, 498, 291, 747, 309, 382, 1045, 11, 309, 307, 787, 1045, 13, 708, 466, 51030], 'temperature': 0.0, 'avg_logprob': -0.23660341176119717, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 0.019082026556134224}, {'id': 213, 'seek': 134974, 'start': 1363.06, 'end': 1370.06, 'text': ' here? Yeah, something like that, right. And if you have unrolled it eight times instead', 'tokens': [51030, 510, 30, 865, 11, 746, 411, 300, 11, 558, 13, 400, 498, 291, 362, 517, 28850, 309, 3180, 1413, 2602, 51380], 'temperature': 0.0, 'avg_logprob': -0.23660341176119717, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 0.019082026556134224}, {'id': 214, 'seek': 134974, 'start': 1371.9, 'end': 1378.9, 'text': ' of five times, it would have increased more. If I have unrolled it 16 times, it would have', 'tokens': [51472, 295, 1732, 1413, 11, 309, 576, 362, 6505, 544, 13, 759, 286, 362, 517, 28850, 309, 3165, 1413, 11, 309, 576, 362, 51822], 'temperature': 0.0, 'avg_logprob': -0.23660341176119717, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 0.019082026556134224}, {'id': 215, 'seek': 137974, 'start': 1380.5, 'end': 1385.72, 'text': ' increased more. What would have happened? I would require even more number of registers', 'tokens': [50402, 6505, 544, 13, 708, 576, 362, 2011, 30, 286, 576, 3651, 754, 544, 1230, 295, 38351, 50663], 'temperature': 0.0, 'avg_logprob': -0.20476678153064765, 'compression_ratio': 1.8907563025210083, 'no_speech_prob': 0.004256142303347588}, {'id': 216, 'seek': 137974, 'start': 1385.72, 'end': 1392.72, 'text': ' and when I do not have that registers, I would have to spill, right. So, you cannot be stretching', 'tokens': [50663, 293, 562, 286, 360, 406, 362, 300, 38351, 11, 286, 576, 362, 281, 22044, 11, 558, 13, 407, 11, 291, 2644, 312, 19632, 51013], 'temperature': 0.0, 'avg_logprob': -0.20476678153064765, 'compression_ratio': 1.8907563025210083, 'no_speech_prob': 0.004256142303347588}, {'id': 217, 'seek': 137974, 'start': 1393.7, 'end': 1398.16, 'text': ' this unroll, unroll, unroll and then you can put more instruction. Somewhere it is going', 'tokens': [51062, 341, 517, 3970, 11, 517, 3970, 11, 517, 3970, 293, 550, 291, 393, 829, 544, 10951, 13, 34500, 309, 307, 516, 51285], 'temperature': 0.0, 'avg_logprob': -0.20476678153064765, 'compression_ratio': 1.8907563025210083, 'no_speech_prob': 0.004256142303347588}, {'id': 218, 'seek': 137974, 'start': 1398.16, 'end': 1404.02, 'text': ' to come back and then tell you as you unroll, your register pressure is going to increase', 'tokens': [51285, 281, 808, 646, 293, 550, 980, 291, 382, 291, 517, 3970, 11, 428, 7280, 3321, 307, 516, 281, 3488, 51578], 'temperature': 0.0, 'avg_logprob': -0.20476678153064765, 'compression_ratio': 1.8907563025210083, 'no_speech_prob': 0.004256142303347588}, {'id': 219, 'seek': 137974, 'start': 1404.02, 'end': 1409.1, 'text': ' and if the register pressure increases, you will introduce spill code which is waste.', 'tokens': [51578, 293, 498, 264, 7280, 3321, 8637, 11, 291, 486, 5366, 22044, 3089, 597, 307, 5964, 13, 51832], 'temperature': 0.0, 'avg_logprob': -0.20476678153064765, 'compression_ratio': 1.8907563025210083, 'no_speech_prob': 0.004256142303347588}, {'id': 220, 'seek': 140910, 'start': 1409.6599999999999, 'end': 1416.6599999999999, 'text': ' So, there is some kind of, right, conflicting requirements happening. You can unroll and', 'tokens': [50392, 407, 11, 456, 307, 512, 733, 295, 11, 558, 11, 43784, 7728, 2737, 13, 509, 393, 517, 3970, 293, 50742], 'temperature': 0.0, 'avg_logprob': -0.18212648879650029, 'compression_ratio': 1.697674418604651, 'no_speech_prob': 0.001906115678139031}, {'id': 221, 'seek': 140910, 'start': 1416.6599999999999, 'end': 1421.9399999999998, 'text': ' then expose more parallelism, but as you unroll, one thing that happens is that the number', 'tokens': [50742, 550, 19219, 544, 8952, 1434, 11, 457, 382, 291, 517, 3970, 11, 472, 551, 300, 2314, 307, 300, 264, 1230, 51006], 'temperature': 0.0, 'avg_logprob': -0.18212648879650029, 'compression_ratio': 1.697674418604651, 'no_speech_prob': 0.001906115678139031}, {'id': 222, 'seek': 140910, 'start': 1421.9399999999998, 'end': 1427.98, 'text': ' of instructions increase. That is also true, right. Your code earlier had only six instructions.', 'tokens': [51006, 295, 9415, 3488, 13, 663, 307, 611, 2074, 11, 558, 13, 2260, 3089, 3071, 632, 787, 2309, 9415, 13, 51308], 'temperature': 0.0, 'avg_logprob': -0.18212648879650029, 'compression_ratio': 1.697674418604651, 'no_speech_prob': 0.001906115678139031}, {'id': 223, 'seek': 140910, 'start': 1427.98, 'end': 1434.62, 'text': ' Now you have this many instructions, right, ten instructions or something like that. So,', 'tokens': [51308, 823, 291, 362, 341, 867, 9415, 11, 558, 11, 2064, 9415, 420, 746, 411, 300, 13, 407, 11, 51640], 'temperature': 0.0, 'avg_logprob': -0.18212648879650029, 'compression_ratio': 1.697674418604651, 'no_speech_prob': 0.001906115678139031}, {'id': 224, 'seek': 143462, 'start': 1434.62, 'end': 1441.62, 'text': ' your code size increases. The code size increases, what happens? We do not know. The code will', 'tokens': [50364, 428, 3089, 2744, 8637, 13, 440, 3089, 2744, 8637, 11, 437, 2314, 30, 492, 360, 406, 458, 13, 440, 3089, 486, 50714], 'temperature': 0.0, 'avg_logprob': -0.23167428409352023, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.06933532655239105}, {'id': 225, 'seek': 143462, 'start': 1445.4599999999998, 'end': 1450.54, 'text': ' not fit in the instruction cache, ok. Whoever who suggests raise their hand, they could', 'tokens': [50906, 406, 3318, 294, 264, 10951, 19459, 11, 3133, 13, 24743, 567, 13409, 5300, 641, 1011, 11, 436, 727, 51160], 'temperature': 0.0, 'avg_logprob': -0.23167428409352023, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.06933532655239105}, {'id': 226, 'seek': 143462, 'start': 1450.54, 'end': 1454.1799999999998, 'text': ' get the appreciation. That is good. So, it will not fit into the instruction cache and', 'tokens': [51160, 483, 264, 18909, 13, 663, 307, 665, 13, 407, 11, 309, 486, 406, 3318, 666, 264, 10951, 19459, 293, 51342], 'temperature': 0.0, 'avg_logprob': -0.23167428409352023, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.06933532655239105}, {'id': 227, 'seek': 143462, 'start': 1454.1799999999998, 'end': 1460.82, 'text': ' therefore more instruction cache misses can happen, right. That is why you do not want', 'tokens': [51342, 4412, 544, 10951, 19459, 29394, 393, 1051, 11, 558, 13, 663, 307, 983, 291, 360, 406, 528, 51674], 'temperature': 0.0, 'avg_logprob': -0.23167428409352023, 'compression_ratio': 1.816326530612245, 'no_speech_prob': 0.06933532655239105}, {'id': 228, 'seek': 146082, 'start': 1460.82, 'end': 1467.1799999999998, 'text': ' to unroll the loop infinite number of times, right. If you unroll it eight or sixteen,', 'tokens': [50364, 281, 517, 3970, 264, 6367, 13785, 1230, 295, 1413, 11, 558, 13, 759, 291, 517, 3970, 309, 3180, 420, 27847, 11, 50682], 'temperature': 0.0, 'avg_logprob': -0.13918894473637375, 'compression_ratio': 1.8380566801619433, 'no_speech_prob': 0.06319687515497208}, {'id': 229, 'seek': 146082, 'start': 1467.1799999999998, 'end': 1472.58, 'text': ' you will increase the thing by a factor of nearly eight or sixteen. It increases the', 'tokens': [50682, 291, 486, 3488, 264, 551, 538, 257, 5952, 295, 6217, 3180, 420, 27847, 13, 467, 8637, 264, 50952], 'temperature': 0.0, 'avg_logprob': -0.13918894473637375, 'compression_ratio': 1.8380566801619433, 'no_speech_prob': 0.06319687515497208}, {'id': 230, 'seek': 146082, 'start': 1472.58, 'end': 1477.8999999999999, 'text': ' code size, so potentially there could be instruction cache misses that could happen. You will increase', 'tokens': [50952, 3089, 2744, 11, 370, 7263, 456, 727, 312, 10951, 19459, 29394, 300, 727, 1051, 13, 509, 486, 3488, 51218], 'temperature': 0.0, 'avg_logprob': -0.13918894473637375, 'compression_ratio': 1.8380566801619433, 'no_speech_prob': 0.06319687515497208}, {'id': 231, 'seek': 146082, 'start': 1477.8999999999999, 'end': 1483.98, 'text': ' the register pressure, potentially there could be spills. So, do this, but do it carefully', 'tokens': [51218, 264, 7280, 3321, 11, 7263, 456, 727, 312, 637, 2565, 13, 407, 11, 360, 341, 11, 457, 360, 309, 7500, 51522], 'temperature': 0.0, 'avg_logprob': -0.13918894473637375, 'compression_ratio': 1.8380566801619433, 'no_speech_prob': 0.06319687515497208}, {'id': 232, 'seek': 146082, 'start': 1483.98, 'end': 1490.46, 'text': ' is the advice, ok. Alright, so we have really not seen how instruction scheduling works,', 'tokens': [51522, 307, 264, 5192, 11, 3133, 13, 2798, 11, 370, 321, 362, 534, 406, 1612, 577, 10951, 29055, 1985, 11, 51846], 'temperature': 0.0, 'avg_logprob': -0.13918894473637375, 'compression_ratio': 1.8380566801619433, 'no_speech_prob': 0.06319687515497208}, {'id': 233, 'seek': 149046, 'start': 1490.46, 'end': 1496.78, 'text': ' but we saw an example of an instruction schedule and how that is helpful in terms of exploiting', 'tokens': [50364, 457, 321, 1866, 364, 1365, 295, 364, 10951, 7567, 293, 577, 300, 307, 4961, 294, 2115, 295, 12382, 1748, 50680], 'temperature': 0.0, 'avg_logprob': -0.18098562797613904, 'compression_ratio': 1.7857142857142858, 'no_speech_prob': 0.033486705273389816}, {'id': 234, 'seek': 149046, 'start': 1496.78, 'end': 1501.8600000000001, 'text': ' instruction level parallelism, ok. Now let us go to the nitty-gritty details of how to', 'tokens': [50680, 10951, 1496, 8952, 1434, 11, 3133, 13, 823, 718, 505, 352, 281, 264, 297, 10016, 12, 861, 10016, 4365, 295, 577, 281, 50934], 'temperature': 0.0, 'avg_logprob': -0.18098562797613904, 'compression_ratio': 1.7857142857142858, 'no_speech_prob': 0.033486705273389816}, {'id': 235, 'seek': 149046, 'start': 1501.8600000000001, 'end': 1505.98, 'text': ' do instruction scheduling. That is if you are given this loop or if you are given the', 'tokens': [50934, 360, 10951, 29055, 13, 663, 307, 498, 291, 366, 2212, 341, 6367, 420, 498, 291, 366, 2212, 264, 51140], 'temperature': 0.0, 'avg_logprob': -0.18098562797613904, 'compression_ratio': 1.7857142857142858, 'no_speech_prob': 0.033486705273389816}, {'id': 236, 'seek': 149046, 'start': 1505.98, 'end': 1512.58, 'text': ' unrolled version of this loop, but still a sequential code, how do I generate this code?', 'tokens': [51140, 517, 28850, 3037, 295, 341, 6367, 11, 457, 920, 257, 42881, 3089, 11, 577, 360, 286, 8460, 341, 3089, 30, 51470], 'temperature': 0.0, 'avg_logprob': -0.18098562797613904, 'compression_ratio': 1.7857142857142858, 'no_speech_prob': 0.033486705273389816}, {'id': 237, 'seek': 149046, 'start': 1512.58, 'end': 1517.42, 'text': ' How do we do this magic, right? That is the question. Because if I take the unrolled version', 'tokens': [51470, 1012, 360, 321, 360, 341, 5585, 11, 558, 30, 663, 307, 264, 1168, 13, 1436, 498, 286, 747, 264, 517, 28850, 3037, 51712], 'temperature': 0.0, 'avg_logprob': -0.18098562797613904, 'compression_ratio': 1.7857142857142858, 'no_speech_prob': 0.033486705273389816}, {'id': 238, 'seek': 151742, 'start': 1518.1000000000001, 'end': 1521.46, 'text': ' of the loop, what would I have seen? I would have seen three of these instructions, another', 'tokens': [50398, 295, 264, 6367, 11, 437, 576, 286, 362, 1612, 30, 286, 576, 362, 1612, 1045, 295, 613, 9415, 11, 1071, 50566], 'temperature': 0.8, 'avg_logprob': -0.23957443237304688, 'compression_ratio': 2.207729468599034, 'no_speech_prob': 0.30431634187698364}, {'id': 239, 'seek': 151742, 'start': 1521.46, 'end': 1524.94, 'text': ' three of these instructions, another three of those instructions, another three of those', 'tokens': [50566, 1045, 295, 613, 9415, 11, 1071, 1045, 295, 729, 9415, 11, 1071, 1045, 295, 729, 50740], 'temperature': 0.8, 'avg_logprob': -0.23957443237304688, 'compression_ratio': 2.207729468599034, 'no_speech_prob': 0.30431634187698364}, {'id': 240, 'seek': 151742, 'start': 1524.94, 'end': 1529.8200000000002, 'text': ' instructions like that and then maybe the control transfer instructions in the end.', 'tokens': [50740, 9415, 411, 300, 293, 550, 1310, 264, 1969, 5003, 9415, 294, 264, 917, 13, 50984], 'temperature': 0.8, 'avg_logprob': -0.23957443237304688, 'compression_ratio': 2.207729468599034, 'no_speech_prob': 0.30431634187698364}, {'id': 241, 'seek': 151742, 'start': 1529.8200000000002, 'end': 1536.22, 'text': ' But from that, how do I get this, this parallel version, right. I need to understand the dependencies', 'tokens': [50984, 583, 490, 300, 11, 577, 360, 286, 483, 341, 11, 341, 8952, 3037, 11, 558, 13, 286, 643, 281, 1223, 264, 36606, 51304], 'temperature': 0.8, 'avg_logprob': -0.23957443237304688, 'compression_ratio': 2.207729468599034, 'no_speech_prob': 0.30431634187698364}, {'id': 242, 'seek': 151742, 'start': 1536.22, 'end': 1541.2, 'text': ' between the instructions. I need to understand when this add instruction can be scheduled.', 'tokens': [51304, 1296, 264, 9415, 13, 286, 643, 281, 1223, 562, 341, 909, 10951, 393, 312, 15678, 13, 51553], 'temperature': 0.8, 'avg_logprob': -0.23957443237304688, 'compression_ratio': 2.207729468599034, 'no_speech_prob': 0.30431634187698364}, {'id': 243, 'seek': 154120, 'start': 1541.2, 'end': 1546.48, 'text': ' I need to understand when this store instruction can be scheduled and so on and so forth,', 'tokens': [50364, 286, 643, 281, 1223, 562, 341, 3531, 10951, 393, 312, 15678, 293, 370, 322, 293, 370, 5220, 11, 50628], 'temperature': 0.0, 'avg_logprob': -0.27106681566559865, 'compression_ratio': 1.658878504672897, 'no_speech_prob': 0.01568462885916233}, {'id': 244, 'seek': 154120, 'start': 1546.48, 'end': 1554.8400000000001, 'text': ' right. So, we need to talk about all of these things. Question? No? Okay, right. So, we', 'tokens': [50628, 558, 13, 407, 11, 321, 643, 281, 751, 466, 439, 295, 613, 721, 13, 14464, 30, 883, 30, 1033, 11, 558, 13, 407, 11, 321, 51046], 'temperature': 0.0, 'avg_logprob': -0.27106681566559865, 'compression_ratio': 1.658878504672897, 'no_speech_prob': 0.01568462885916233}, {'id': 245, 'seek': 154120, 'start': 1554.8400000000001, 'end': 1560.24, 'text': ' will we will get to that details now, okay. So, as I mentioned earlier we do instruction', 'tokens': [51046, 486, 321, 486, 483, 281, 300, 4365, 586, 11, 1392, 13, 407, 11, 382, 286, 2835, 3071, 321, 360, 10951, 51316], 'temperature': 0.0, 'avg_logprob': -0.27106681566559865, 'compression_ratio': 1.658878504672897, 'no_speech_prob': 0.01568462885916233}, {'id': 246, 'seek': 154120, 'start': 1560.24, 'end': 1566.32, 'text': ' scheduling to reduce stalls which is basically control hazard and data hazards, okay, to', 'tokens': [51316, 29055, 281, 5407, 50248, 597, 307, 1936, 1969, 20790, 293, 1412, 34516, 11, 1392, 11, 281, 51620], 'temperature': 0.0, 'avg_logprob': -0.27106681566559865, 'compression_ratio': 1.658878504672897, 'no_speech_prob': 0.01568462885916233}, {'id': 247, 'seek': 156632, 'start': 1566.32, 'end': 1574.6, 'text': ' exploit parallelism in super scalar processors and VLIW processors, okay. And the instruction', 'tokens': [50364, 25924, 8952, 1434, 294, 1687, 39684, 27751, 293, 691, 48718, 54, 27751, 11, 1392, 13, 400, 264, 10951, 50778], 'temperature': 0.0, 'avg_logprob': -0.22231157938639323, 'compression_ratio': 1.947089947089947, 'no_speech_prob': 0.4924657940864563}, {'id': 248, 'seek': 156632, 'start': 1574.6, 'end': 1582.84, 'text': ' scheduling that you do must necessarily obey data dependence and resource constraint, okay.', 'tokens': [50778, 29055, 300, 291, 360, 1633, 4725, 19297, 1412, 31704, 293, 7684, 25534, 11, 1392, 13, 51190], 'temperature': 0.0, 'avg_logprob': -0.22231157938639323, 'compression_ratio': 1.947089947089947, 'no_speech_prob': 0.4924657940864563}, {'id': 249, 'seek': 156632, 'start': 1582.84, 'end': 1587.9199999999998, 'text': ' When you talk about instruction scheduling within a basic block, it is basic block scheduling.', 'tokens': [51190, 1133, 291, 751, 466, 10951, 29055, 1951, 257, 3875, 3461, 11, 309, 307, 3875, 3461, 29055, 13, 51444], 'temperature': 0.0, 'avg_logprob': -0.22231157938639323, 'compression_ratio': 1.947089947089947, 'no_speech_prob': 0.4924657940864563}, {'id': 250, 'seek': 156632, 'start': 1587.9199999999998, 'end': 1593.12, 'text': ' When you talk about instruction scheduling beyond basic block, it is global scheduling,', 'tokens': [51444, 1133, 291, 751, 466, 10951, 29055, 4399, 3875, 3461, 11, 309, 307, 4338, 29055, 11, 51704], 'temperature': 0.0, 'avg_logprob': -0.22231157938639323, 'compression_ratio': 1.947089947089947, 'no_speech_prob': 0.4924657940864563}, {'id': 251, 'seek': 159312, 'start': 1594.12, 'end': 1598.6799999999998, 'text': ' So let us get into basic block instruction scheduling. First we will talk about instruction', 'tokens': [50414, 407, 718, 505, 483, 666, 3875, 3461, 10951, 29055, 13, 2386, 321, 486, 751, 466, 10951, 50642], 'temperature': 0.0, 'avg_logprob': -0.18213316406866517, 'compression_ratio': 1.9152542372881356, 'no_speech_prob': 0.06540771573781967}, {'id': 252, 'seek': 159312, 'start': 1598.6799999999998, 'end': 1603.2399999999998, 'text': ' scheduling on a processor which is a simple pipeline processor. That means that we are', 'tokens': [50642, 29055, 322, 257, 15321, 597, 307, 257, 2199, 15517, 15321, 13, 663, 1355, 300, 321, 366, 50870], 'temperature': 0.0, 'avg_logprob': -0.18213316406866517, 'compression_ratio': 1.9152542372881356, 'no_speech_prob': 0.06540771573781967}, {'id': 253, 'seek': 159312, 'start': 1603.2399999999998, 'end': 1608.76, 'text': ' not interested in exposing parallelism, right. Later we will also talk about parallelism,', 'tokens': [50870, 406, 3102, 294, 33178, 8952, 1434, 11, 558, 13, 11965, 321, 486, 611, 751, 466, 8952, 1434, 11, 51146], 'temperature': 0.0, 'avg_logprob': -0.18213316406866517, 'compression_ratio': 1.9152542372881356, 'no_speech_prob': 0.06540771573781967}, {'id': 254, 'seek': 159312, 'start': 1608.76, 'end': 1614.32, 'text': ' okay. So, basic block scheduling or instruction scheduling is essentially a reordering of', 'tokens': [51146, 1392, 13, 407, 11, 3875, 3461, 29055, 420, 10951, 29055, 307, 4476, 257, 319, 765, 1794, 295, 51424], 'temperature': 0.0, 'avg_logprob': -0.18213316406866517, 'compression_ratio': 1.9152542372881356, 'no_speech_prob': 0.06540771573781967}, {'id': 255, 'seek': 159312, 'start': 1614.32, 'end': 1620.8, 'text': ' instructions within the basic block, right. And what we try to do is that we want to minimize', 'tokens': [51424, 9415, 1951, 264, 3875, 3461, 11, 558, 13, 400, 437, 321, 853, 281, 360, 307, 300, 321, 528, 281, 17522, 51748], 'temperature': 0.0, 'avg_logprob': -0.18213316406866517, 'compression_ratio': 1.9152542372881356, 'no_speech_prob': 0.06540771573781967}, {'id': 256, 'seek': 162080, 'start': 1620.8, 'end': 1627.28, 'text': ' the execution time of this instruction schedule that essentially reducing the schedule length', 'tokens': [50364, 264, 15058, 565, 295, 341, 10951, 7567, 300, 4476, 12245, 264, 7567, 4641, 50688], 'temperature': 0.0, 'avg_logprob': -0.1994799084133572, 'compression_ratio': 2.050228310502283, 'no_speech_prob': 0.17394736409187317}, {'id': 257, 'seek': 162080, 'start': 1627.28, 'end': 1634.1599999999999, 'text': ' or schedule length is the total time it takes to execute this instruction, okay.', 'tokens': [50688, 420, 7567, 4641, 307, 264, 3217, 565, 309, 2516, 281, 14483, 341, 10951, 11, 1392, 13, 51032], 'temperature': 0.0, 'avg_logprob': -0.1994799084133572, 'compression_ratio': 2.050228310502283, 'no_speech_prob': 0.17394736409187317}, {'id': 258, 'seek': 162080, 'start': 1634.1599999999999, 'end': 1637.9199999999998, 'text': ' Again there are different instruction scheduling methods. Again instruction scheduling problem', 'tokens': [51032, 3764, 456, 366, 819, 10951, 29055, 7150, 13, 3764, 10951, 29055, 1154, 51220], 'temperature': 0.0, 'avg_logprob': -0.1994799084133572, 'compression_ratio': 2.050228310502283, 'no_speech_prob': 0.17394736409187317}, {'id': 259, 'seek': 162080, 'start': 1637.9199999999998, 'end': 1643.48, 'text': ' is an NP complete problem, okay. If you want to do optimal instruction scheduling that', 'tokens': [51220, 307, 364, 38611, 3566, 1154, 11, 1392, 13, 759, 291, 528, 281, 360, 16252, 10951, 29055, 300, 51498], 'temperature': 0.0, 'avg_logprob': -0.1994799084133572, 'compression_ratio': 2.050228310502283, 'no_speech_prob': 0.17394736409187317}, {'id': 260, 'seek': 162080, 'start': 1643.48, 'end': 1649.24, 'text': ' is an NP complete problem, right. And therefore, what you can say is that instead of getting', 'tokens': [51498, 307, 364, 38611, 3566, 1154, 11, 558, 13, 400, 4412, 11, 437, 291, 393, 584, 307, 300, 2602, 295, 1242, 51786], 'temperature': 0.0, 'avg_logprob': -0.1994799084133572, 'compression_ratio': 2.050228310502283, 'no_speech_prob': 0.17394736409187317}, {'id': 261, 'seek': 164924, 'start': 1649.32, 'end': 1655.0, 'text': ' the optimal schedule which is going to take a very large amount of time, one could actually', 'tokens': [50368, 264, 16252, 7567, 597, 307, 516, 281, 747, 257, 588, 2416, 2372, 295, 565, 11, 472, 727, 767, 50652], 'temperature': 0.0, 'avg_logprob': -0.17362022399902344, 'compression_ratio': 1.8207171314741035, 'no_speech_prob': 0.09092392772436142}, {'id': 262, 'seek': 164924, 'start': 1655.0, 'end': 1660.48, 'text': ' go for some heuristic methods which will give you close to that good solution but at a much', 'tokens': [50652, 352, 337, 512, 415, 374, 3142, 7150, 597, 486, 976, 291, 1998, 281, 300, 665, 3827, 457, 412, 257, 709, 50926], 'temperature': 0.0, 'avg_logprob': -0.17362022399902344, 'compression_ratio': 1.8207171314741035, 'no_speech_prob': 0.09092392772436142}, {'id': 263, 'seek': 164924, 'start': 1660.48, 'end': 1667.04, 'text': ' smaller computation time. So, this typically talk about heuristic scheduling methods and', 'tokens': [50926, 4356, 24903, 565, 13, 407, 11, 341, 5850, 751, 466, 415, 374, 3142, 29055, 7150, 293, 51254], 'temperature': 0.0, 'avg_logprob': -0.17362022399902344, 'compression_ratio': 1.8207171314741035, 'no_speech_prob': 0.09092392772436142}, {'id': 264, 'seek': 164924, 'start': 1667.04, 'end': 1672.04, 'text': ' they differ in terms of whether they do operation based scheduling or cycle based scheduling.', 'tokens': [51254, 436, 743, 294, 2115, 295, 1968, 436, 360, 6916, 2361, 29055, 420, 6586, 2361, 29055, 13, 51504], 'temperature': 0.0, 'avg_logprob': -0.17362022399902344, 'compression_ratio': 1.8207171314741035, 'no_speech_prob': 0.09092392772436142}, {'id': 265, 'seek': 164924, 'start': 1672.04, 'end': 1676.76, 'text': ' We will talk about examples of these two things or we will talk about these two algorithms', 'tokens': [51504, 492, 486, 751, 466, 5110, 295, 613, 732, 721, 420, 321, 486, 751, 466, 613, 732, 14642, 51740], 'temperature': 0.0, 'avg_logprob': -0.17362022399902344, 'compression_ratio': 1.8207171314741035, 'no_speech_prob': 0.09092392772436142}, {'id': 266, 'seek': 167676, 'start': 1676.84, 'end': 1681.96, 'text': ' in detail and also examples of these. You can also do an optimal instruction scheduling,', 'tokens': [50368, 294, 2607, 293, 611, 5110, 295, 613, 13, 509, 393, 611, 360, 364, 16252, 10951, 29055, 11, 50624], 'temperature': 0.0, 'avg_logprob': -0.1697944808792282, 'compression_ratio': 1.8204081632653062, 'no_speech_prob': 0.12205508351325989}, {'id': 267, 'seek': 167676, 'start': 1681.96, 'end': 1687.4, 'text': ' right. You can also do optimal instruction scheduling using integer linear programming', 'tokens': [50624, 558, 13, 509, 393, 611, 360, 16252, 10951, 29055, 1228, 24922, 8213, 9410, 50896], 'temperature': 0.0, 'avg_logprob': -0.1697944808792282, 'compression_ratio': 1.8204081632653062, 'no_speech_prob': 0.12205508351325989}, {'id': 268, 'seek': 167676, 'start': 1687.4, 'end': 1693.92, 'text': ' approach or using other approaches. But the time to compute the schedule could take very,', 'tokens': [50896, 3109, 420, 1228, 661, 11587, 13, 583, 264, 565, 281, 14722, 264, 7567, 727, 747, 588, 11, 51222], 'temperature': 0.0, 'avg_logprob': -0.1697944808792282, 'compression_ratio': 1.8204081632653062, 'no_speech_prob': 0.12205508351325989}, {'id': 269, 'seek': 167676, 'start': 1693.92, 'end': 1700.0, 'text': ' very long time because these are NP complete problems, okay. Or you could have used other', 'tokens': [51222, 588, 938, 565, 570, 613, 366, 38611, 3566, 2740, 11, 1392, 13, 1610, 291, 727, 362, 1143, 661, 51526], 'temperature': 0.0, 'avg_logprob': -0.1697944808792282, 'compression_ratio': 1.8204081632653062, 'no_speech_prob': 0.12205508351325989}, {'id': 270, 'seek': 167676, 'start': 1700.0, 'end': 1706.36, 'text': ' kinds of evolutionary algorithms like genetic algorithm, right or simulated annealing kind', 'tokens': [51526, 3685, 295, 27567, 14642, 411, 12462, 9284, 11, 558, 420, 41713, 22256, 4270, 733, 51844], 'temperature': 0.0, 'avg_logprob': -0.1697944808792282, 'compression_ratio': 1.8204081632653062, 'no_speech_prob': 0.12205508351325989}, {'id': 271, 'seek': 170636, 'start': 1706.36, 'end': 1712.24, 'text': ' of algorithms and so on, okay. Now, before we do instruction scheduling as I mentioned', 'tokens': [50364, 295, 14642, 293, 370, 322, 11, 1392, 13, 823, 11, 949, 321, 360, 10951, 29055, 382, 286, 2835, 50658], 'temperature': 0.0, 'avg_logprob': -0.1785612204640182, 'compression_ratio': 1.8504273504273505, 'no_speech_prob': 0.004776183981448412}, {'id': 272, 'seek': 170636, 'start': 1712.24, 'end': 1717.8, 'text': ' earlier instruction scheduling has to obey all the dependence constraints. So, how do', 'tokens': [50658, 3071, 10951, 29055, 575, 281, 19297, 439, 264, 31704, 18491, 13, 407, 11, 577, 360, 50936], 'temperature': 0.0, 'avg_logprob': -0.1785612204640182, 'compression_ratio': 1.8504273504273505, 'no_speech_prob': 0.004776183981448412}, {'id': 273, 'seek': 170636, 'start': 1717.8, 'end': 1723.1999999999998, 'text': ' we identify this dependence constraint and how do we ensure that they are satisfied?', 'tokens': [50936, 321, 5876, 341, 31704, 25534, 293, 577, 360, 321, 5586, 300, 436, 366, 11239, 30, 51206], 'temperature': 0.0, 'avg_logprob': -0.1785612204640182, 'compression_ratio': 1.8504273504273505, 'no_speech_prob': 0.004776183981448412}, {'id': 274, 'seek': 170636, 'start': 1723.1999999999998, 'end': 1728.1599999999999, 'text': ' Again to do this thing what we do is that we represent the basic block in terms of a', 'tokens': [51206, 3764, 281, 360, 341, 551, 437, 321, 360, 307, 300, 321, 2906, 264, 3875, 3461, 294, 2115, 295, 257, 51454], 'temperature': 0.0, 'avg_logprob': -0.1785612204640182, 'compression_ratio': 1.8504273504273505, 'no_speech_prob': 0.004776183981448412}, {'id': 275, 'seek': 170636, 'start': 1728.1599999999999, 'end': 1734.6, 'text': ' data dependence graph, okay. And in this data dependence graph each instruction is a node,', 'tokens': [51454, 1412, 31704, 4295, 11, 1392, 13, 400, 294, 341, 1412, 31704, 4295, 1184, 10951, 307, 257, 9984, 11, 51776], 'temperature': 0.0, 'avg_logprob': -0.1785612204640182, 'compression_ratio': 1.8504273504273505, 'no_speech_prob': 0.004776183981448412}, {'id': 276, 'seek': 173460, 'start': 1734.6, 'end': 1743.6399999999999, 'text': ' right. There is a directed arc from instruction i to instruction j if j is dependent on i,', 'tokens': [50364, 558, 13, 821, 307, 257, 12898, 10346, 490, 10951, 741, 281, 10951, 361, 498, 361, 307, 12334, 322, 741, 11, 50816], 'temperature': 0.0, 'avg_logprob': -0.18206450674268934, 'compression_ratio': 1.8013245033112584, 'no_speech_prob': 0.017459098249673843}, {'id': 277, 'seek': 173460, 'start': 1743.6399999999999, 'end': 1751.3999999999999, 'text': ' right. So, that is what it says there is an edge directed edge, okay from u to v, right.', 'tokens': [50816, 558, 13, 407, 11, 300, 307, 437, 309, 1619, 456, 307, 364, 4691, 12898, 4691, 11, 1392, 490, 344, 281, 371, 11, 558, 13, 51204], 'temperature': 0.0, 'avg_logprob': -0.18206450674268934, 'compression_ratio': 1.8013245033112584, 'no_speech_prob': 0.017459098249673843}, {'id': 278, 'seek': 173460, 'start': 1751.3999999999999, 'end': 1758.36, 'text': ' If there exists a dependence from instruction u to v. So, here I talk about true dependence,', 'tokens': [51204, 759, 456, 8198, 257, 31704, 490, 10951, 344, 281, 371, 13, 407, 11, 510, 286, 751, 466, 2074, 31704, 11, 51552], 'temperature': 0.0, 'avg_logprob': -0.18206450674268934, 'compression_ratio': 1.8013245033112584, 'no_speech_prob': 0.017459098249673843}, {'id': 279, 'seek': 175836, 'start': 1759.04, 'end': 1764.56, 'text': ' okay. So, let me just say how many of you know about true dependency, anti dependency', 'tokens': [50398, 1392, 13, 407, 11, 718, 385, 445, 584, 577, 867, 295, 291, 458, 466, 2074, 33621, 11, 6061, 33621, 50674], 'temperature': 0.0, 'avg_logprob': -0.21445508625196374, 'compression_ratio': 1.7614213197969544, 'no_speech_prob': 0.04357430711388588}, {'id': 280, 'seek': 175836, 'start': 1764.56, 'end': 1771.56, 'text': ' and output dependencies? One, only one. How many of you know raw dependency, war dependency', 'tokens': [50674, 293, 5598, 36606, 30, 1485, 11, 787, 472, 13, 1012, 867, 295, 291, 458, 8936, 33621, 11, 1516, 33621, 51024], 'temperature': 0.0, 'avg_logprob': -0.21445508625196374, 'compression_ratio': 1.7614213197969544, 'no_speech_prob': 0.04357430711388588}, {'id': 281, 'seek': 175836, 'start': 1773.76, 'end': 1779.6399999999999, 'text': ' and war dependency? They are the same, yes very good, right. So, those who know this', 'tokens': [51134, 293, 1516, 33621, 30, 814, 366, 264, 912, 11, 2086, 588, 665, 11, 558, 13, 407, 11, 729, 567, 458, 341, 51428], 'temperature': 0.0, 'avg_logprob': -0.21445508625196374, 'compression_ratio': 1.7614213197969544, 'no_speech_prob': 0.04357430711388588}, {'id': 282, 'seek': 175836, 'start': 1779.6399999999999, 'end': 1783.9599999999998, 'text': ' same thing, okay. Now, let us see what it is, okay. Let us first start off with this', 'tokens': [51428, 912, 551, 11, 1392, 13, 823, 11, 718, 505, 536, 437, 309, 307, 11, 1392, 13, 961, 505, 700, 722, 766, 365, 341, 51644], 'temperature': 0.0, 'avg_logprob': -0.21445508625196374, 'compression_ratio': 1.7614213197969544, 'no_speech_prob': 0.04357430711388588}, {'id': 283, 'seek': 178396, 'start': 1784.04, 'end': 1788.28, 'text': ' example and then come to the dependence graph. So, can you just tell me where there is a', 'tokens': [50368, 1365, 293, 550, 808, 281, 264, 31704, 4295, 13, 407, 11, 393, 291, 445, 980, 385, 689, 456, 307, 257, 50580], 'temperature': 0.0, 'avg_logprob': -0.24521874514493075, 'compression_ratio': 1.3358778625954197, 'no_speech_prob': 0.024242974817752838}, {'id': 284, 'seek': 178396, 'start': 1788.28, 'end': 1795.28, 'text': ' raw dependency in this? i 1 to i 2, correct, right. Where else? i 2, i 4, okay. i 1 to', 'tokens': [50580, 8936, 33621, 294, 341, 30, 741, 502, 281, 741, 568, 11, 3006, 11, 558, 13, 2305, 1646, 30, 741, 568, 11, 741, 1017, 11, 1392, 13, 741, 502, 281, 50930], 'temperature': 0.0, 'avg_logprob': -0.24521874514493075, 'compression_ratio': 1.3358778625954197, 'no_speech_prob': 0.024242974817752838}, {'id': 285, 'seek': 179528, 'start': 1795.28, 'end': 1802.28, 'text': ' itself, i 1, i 3, okay. I am sorry i 1, i 3, correct. i 3, i 4 should be there, right.', 'tokens': [50364, 2564, 11, 741, 502, 11, 741, 805, 11, 1392, 13, 286, 669, 2597, 741, 502, 11, 741, 805, 11, 3006, 13, 741, 805, 11, 741, 1017, 820, 312, 456, 11, 558, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.34679124014718193, 'compression_ratio': 1.1168831168831168, 'no_speech_prob': 0.398074746131897}, {'id': 286, 'seek': 182528, 'start': 1825.28, 'end': 1832.28, 'text': ' All of these dependencies are what are called raw dependency or true dependencies, right.', 'tokens': [50364, 1057, 295, 613, 36606, 366, 437, 366, 1219, 8936, 33621, 420, 2074, 36606, 11, 558, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.24993148602937398, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.02033417858183384}, {'id': 287, 'seek': 182528, 'start': 1839.3999999999999, 'end': 1846.3999999999999, 'text': ' Raw is read after write. These reads must happen after those writes have happened, right.', 'tokens': [51070, 23732, 307, 1401, 934, 2464, 13, 1981, 15700, 1633, 1051, 934, 729, 13657, 362, 2011, 11, 558, 13, 51420], 'temperature': 0.0, 'avg_logprob': -0.24993148602937398, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.02033417858183384}, {'id': 288, 'seek': 182528, 'start': 1848.32, 'end': 1853.76, 'text': ' And this dependency is a dependency which must necessarily be observed in the program,', 'tokens': [51516, 400, 341, 33621, 307, 257, 33621, 597, 1633, 4725, 312, 13095, 294, 264, 1461, 11, 51788], 'temperature': 0.0, 'avg_logprob': -0.24993148602937398, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.02033417858183384}, {'id': 289, 'seek': 185376, 'start': 1854.44, 'end': 1861.44, 'text': ' correct. Because you expect this add instruction to take the value produced by this load instruction.', 'tokens': [50398, 3006, 13, 1436, 291, 2066, 341, 909, 10951, 281, 747, 264, 2158, 7126, 538, 341, 3677, 10951, 13, 50748], 'temperature': 0.0, 'avg_logprob': -0.16505756075420078, 'compression_ratio': 1.9251700680272108, 'no_speech_prob': 0.0037060847971588373}, {'id': 290, 'seek': 185376, 'start': 1863.04, 'end': 1869.72, 'text': ' You expect this load instruction to take the value produced by this add instruction and', 'tokens': [50828, 509, 2066, 341, 3677, 10951, 281, 747, 264, 2158, 7126, 538, 341, 909, 10951, 293, 51162], 'temperature': 0.0, 'avg_logprob': -0.16505756075420078, 'compression_ratio': 1.9251700680272108, 'no_speech_prob': 0.0037060847971588373}, {'id': 291, 'seek': 185376, 'start': 1869.72, 'end': 1876.72, 'text': ' so on, correct. So, these are what we are going to call as raw dependency or true dependency.', 'tokens': [51162, 370, 322, 11, 3006, 13, 407, 11, 613, 366, 437, 321, 366, 516, 281, 818, 382, 8936, 33621, 420, 2074, 33621, 13, 51512], 'temperature': 0.0, 'avg_logprob': -0.16505756075420078, 'compression_ratio': 1.9251700680272108, 'no_speech_prob': 0.0037060847971588373}, {'id': 292, 'seek': 187672, 'start': 1877.72, 'end': 1884.72, 'text': ' So, what is a war dependency? Write after read. Can you give me an example here? Is', 'tokens': [50414, 407, 11, 437, 307, 257, 1516, 33621, 30, 23499, 934, 1401, 13, 1664, 291, 976, 385, 364, 1365, 510, 30, 1119, 50764], 'temperature': 0.0, 'avg_logprob': -0.2877021019275372, 'compression_ratio': 1.2335766423357664, 'no_speech_prob': 0.006672091782093048}, {'id': 293, 'seek': 187672, 'start': 1885.44, 'end': 1892.44, 'text': ' there one? No, right. There is none here, okay. Let us just try to change this to R3,', 'tokens': [50800, 456, 472, 30, 883, 11, 558, 13, 821, 307, 6022, 510, 11, 1392, 13, 961, 505, 445, 853, 281, 1319, 341, 281, 497, 18, 11, 51150], 'temperature': 0.0, 'avg_logprob': -0.2877021019275372, 'compression_ratio': 1.2335766423357664, 'no_speech_prob': 0.006672091782093048}, {'id': 294, 'seek': 189244, 'start': 1892.44, 'end': 1899.44, 'text': ' right. Then now what happens? In this case, this write of R3 should happen only after', 'tokens': [50364, 558, 13, 1396, 586, 437, 2314, 30, 682, 341, 1389, 11, 341, 2464, 295, 497, 18, 820, 1051, 787, 934, 50714], 'temperature': 0.0, 'avg_logprob': -0.14929439624150595, 'compression_ratio': 1.4065040650406504, 'no_speech_prob': 0.009072938933968544}, {'id': 295, 'seek': 189244, 'start': 1914.0800000000002, 'end': 1921.0800000000002, 'text': ' this read of R3 has happened, correct. So, this is what is called a war dependency. The', 'tokens': [51446, 341, 1401, 295, 497, 18, 575, 2011, 11, 3006, 13, 407, 11, 341, 307, 437, 307, 1219, 257, 1516, 33621, 13, 440, 51796], 'temperature': 0.0, 'avg_logprob': -0.14929439624150595, 'compression_ratio': 1.4065040650406504, 'no_speech_prob': 0.009072938933968544}, {'id': 296, 'seek': 192108, 'start': 1921.6399999999999, 'end': 1928.6399999999999, 'text': ' dependency between them let me, right. So, the dependency that you see from this instruction', 'tokens': [50392, 33621, 1296, 552, 718, 385, 11, 558, 13, 407, 11, 264, 33621, 300, 291, 536, 490, 341, 10951, 50742], 'temperature': 0.0, 'avg_logprob': -0.23056634267171225, 'compression_ratio': 1.7898089171974523, 'no_speech_prob': 0.006642794236540794}, {'id': 297, 'seek': 192108, 'start': 1928.72, 'end': 1935.72, 'text': ' to this one, okay. This is what you are going to call as the war dependency, right after', 'tokens': [50746, 281, 341, 472, 11, 1392, 13, 639, 307, 437, 291, 366, 516, 281, 818, 382, 264, 1516, 33621, 11, 558, 934, 51096], 'temperature': 0.0, 'avg_logprob': -0.23056634267171225, 'compression_ratio': 1.7898089171974523, 'no_speech_prob': 0.006642794236540794}, {'id': 298, 'seek': 192108, 'start': 1936.76, 'end': 1943.76, 'text': ' read dependency. This is also called the anti-dependency. Dependency, anti-dependency, correct. Why', 'tokens': [51148, 1401, 33621, 13, 639, 307, 611, 1219, 264, 6061, 12, 36763, 3020, 13, 4056, 521, 3020, 11, 6061, 12, 36763, 3020, 11, 3006, 13, 1545, 51498], 'temperature': 0.0, 'avg_logprob': -0.23056634267171225, 'compression_ratio': 1.7898089171974523, 'no_speech_prob': 0.006642794236540794}, {'id': 299, 'seek': 194376, 'start': 1943.84, 'end': 1950.84, 'text': ' does this anti-dependency happen? Now that you people have seen register allocation,', 'tokens': [50368, 775, 341, 6061, 12, 36763, 3020, 1051, 30, 823, 300, 291, 561, 362, 1612, 7280, 27599, 11, 50718], 'temperature': 0.0, 'avg_logprob': -0.2816770231568968, 'compression_ratio': 1.6111111111111112, 'no_speech_prob': 0.010654624551534653}, {'id': 300, 'seek': 194376, 'start': 1951.64, 'end': 1957.64, 'text': ' right. Let us say that this is the code generated by your register allocator, right. At that', 'tokens': [50758, 558, 13, 961, 505, 584, 300, 341, 307, 264, 3089, 10833, 538, 428, 7280, 12660, 1639, 11, 558, 13, 1711, 300, 51058], 'temperature': 0.0, 'avg_logprob': -0.2816770231568968, 'compression_ratio': 1.6111111111111112, 'no_speech_prob': 0.010654624551534653}, {'id': 301, 'seek': 194376, 'start': 1957.64, 'end': 1964.64, 'text': ' time you thought you did something very smart, right.', 'tokens': [51058, 565, 291, 1194, 291, 630, 746, 588, 4069, 11, 558, 13, 51408], 'temperature': 0.0, 'avg_logprob': -0.2816770231568968, 'compression_ratio': 1.6111111111111112, 'no_speech_prob': 0.010654624551534653}, {'id': 302, 'seek': 194376, 'start': 1967.56, 'end': 1972.8, 'text': ' Exactly. There was a variable which was live up to here and that was using the register', 'tokens': [51554, 7587, 13, 821, 390, 257, 7006, 597, 390, 1621, 493, 281, 510, 293, 300, 390, 1228, 264, 7280, 51816], 'temperature': 0.0, 'avg_logprob': -0.2816770231568968, 'compression_ratio': 1.6111111111111112, 'no_speech_prob': 0.010654624551534653}, {'id': 303, 'seek': 197280, 'start': 1973.0, 'end': 1980.0, 'text': ' R3. That liveness ended here. A new liveness started, new variable started here for which', 'tokens': [50374, 497, 18, 13, 663, 375, 553, 442, 4590, 510, 13, 316, 777, 375, 553, 442, 1409, 11, 777, 7006, 1409, 510, 337, 597, 50724], 'temperature': 0.0, 'avg_logprob': -0.2317743408546019, 'compression_ratio': 1.588235294117647, 'no_speech_prob': 0.00781403947621584}, {'id': 304, 'seek': 197280, 'start': 1980.0, 'end': 1984.8799999999999, 'text': ' you gave the same register which was okay because the live ranges were not conflicting.', 'tokens': [50724, 291, 2729, 264, 912, 7280, 597, 390, 1392, 570, 264, 1621, 22526, 645, 406, 43784, 13, 50968], 'temperature': 0.0, 'avg_logprob': -0.2317743408546019, 'compression_ratio': 1.588235294117647, 'no_speech_prob': 0.00781403947621584}, {'id': 305, 'seek': 197280, 'start': 1984.8799999999999, 'end': 1991.1399999999999, 'text': ' You did the smart thing by giving the same register, right. But now what have you done?', 'tokens': [50968, 509, 630, 264, 4069, 551, 538, 2902, 264, 912, 7280, 11, 558, 13, 583, 586, 437, 362, 291, 1096, 30, 51281], 'temperature': 0.0, 'avg_logprob': -0.2317743408546019, 'compression_ratio': 1.588235294117647, 'no_speech_prob': 0.00781403947621584}, {'id': 306, 'seek': 197280, 'start': 1991.1399999999999, 'end': 1998.1399999999999, 'text': " You have created an anti-dependence between these two instructions, isn't it? So, the", 'tokens': [51281, 509, 362, 2942, 364, 6061, 12, 36763, 655, 1296, 613, 732, 9415, 11, 1943, 380, 309, 30, 407, 11, 264, 51631], 'temperature': 0.0, 'avg_logprob': -0.2317743408546019, 'compression_ratio': 1.588235294117647, 'no_speech_prob': 0.00781403947621584}, {'id': 307, 'seek': 199814, 'start': 1998.14, 'end': 2004.9, 'text': ' anti-dependence happens because you are reusing the same register, okay. Let me give you one', 'tokens': [50364, 6061, 12, 36763, 655, 2314, 570, 291, 366, 319, 7981, 264, 912, 7280, 11, 1392, 13, 961, 385, 976, 291, 472, 50702], 'temperature': 0.0, 'avg_logprob': -0.17024021417322294, 'compression_ratio': 1.5248618784530388, 'no_speech_prob': 0.006902868859469891}, {'id': 308, 'seek': 199814, 'start': 2004.9, 'end': 2011.18, 'text': ' more example, right. Let us say that this instruction instead of using R5, let us say', 'tokens': [50702, 544, 1365, 11, 558, 13, 961, 505, 584, 300, 341, 10951, 2602, 295, 1228, 497, 20, 11, 718, 505, 584, 51016], 'temperature': 0.0, 'avg_logprob': -0.17024021417322294, 'compression_ratio': 1.5248618784530388, 'no_speech_prob': 0.006902868859469891}, {'id': 309, 'seek': 199814, 'start': 2011.18, 'end': 2018.18, 'text': ' was using R1. Then what happens? Then we introduce what is called the war dependency. So, between', 'tokens': [51016, 390, 1228, 497, 16, 13, 1396, 437, 2314, 30, 1396, 321, 5366, 437, 307, 1219, 264, 1516, 33621, 13, 407, 11, 1296, 51366], 'temperature': 0.0, 'avg_logprob': -0.17024021417322294, 'compression_ratio': 1.5248618784530388, 'no_speech_prob': 0.006902868859469891}, {'id': 310, 'seek': 201818, 'start': 2018.18, 'end': 2025.18, 'text': ' this instruction and this instruction there is a wow hazard or sorry wow dependency,', 'tokens': [50364, 341, 10951, 293, 341, 10951, 456, 307, 257, 6076, 20790, 420, 2597, 6076, 33621, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.417430744614712, 'compression_ratio': 1.4426229508196722, 'no_speech_prob': 0.05736732482910156}, {'id': 311, 'seek': 201818, 'start': 2034.5800000000002, 'end': 2041.5800000000002, 'text': ' W A W right after right. What do we say that? This right must happen only, sorry this right', 'tokens': [51184, 343, 316, 343, 558, 934, 558, 13, 708, 360, 321, 584, 300, 30, 639, 558, 1633, 1051, 787, 11, 2597, 341, 558, 51534], 'temperature': 0.0, 'avg_logprob': -0.417430744614712, 'compression_ratio': 1.4426229508196722, 'no_speech_prob': 0.05736732482910156}, {'id': 312, 'seek': 204158, 'start': 2042.26, 'end': 2047.6599999999999, 'text': ' must happen only after this right has happened or this right must happen before this right', 'tokens': [50398, 1633, 1051, 787, 934, 341, 558, 575, 2011, 420, 341, 558, 1633, 1051, 949, 341, 558, 50668], 'temperature': 0.0, 'avg_logprob': -0.23113887281302947, 'compression_ratio': 1.922279792746114, 'no_speech_prob': 0.003131027100607753}, {'id': 313, 'seek': 204158, 'start': 2047.6599999999999, 'end': 2054.66, 'text': ' happens. So, this is essentially called output dependency. Output meaning destination, correct.', 'tokens': [50668, 2314, 13, 407, 11, 341, 307, 4476, 1219, 5598, 33621, 13, 5925, 2582, 3620, 12236, 11, 3006, 13, 51018], 'temperature': 0.0, 'avg_logprob': -0.23113887281302947, 'compression_ratio': 1.922279792746114, 'no_speech_prob': 0.003131027100607753}, {'id': 314, 'seek': 204158, 'start': 2056.2599999999998, 'end': 2063.2599999999998, 'text': ' So, in this example what we have seen is that we have seen true dependency, anti-end, output', 'tokens': [51098, 407, 11, 294, 341, 1365, 437, 321, 362, 1612, 307, 300, 321, 362, 1612, 2074, 33621, 11, 6061, 12, 521, 11, 5598, 51448], 'temperature': 0.0, 'avg_logprob': -0.23113887281302947, 'compression_ratio': 1.922279792746114, 'no_speech_prob': 0.003131027100607753}, {'id': 315, 'seek': 204158, 'start': 2063.7, 'end': 2070.1, 'text': ' dependency. Among all these dependencies why do we only call this as the true dependencies?', 'tokens': [51470, 33621, 13, 16119, 439, 613, 36606, 983, 360, 321, 787, 818, 341, 382, 264, 2074, 36606, 30, 51790], 'temperature': 0.0, 'avg_logprob': -0.23113887281302947, 'compression_ratio': 1.922279792746114, 'no_speech_prob': 0.003131027100607753}, {'id': 316, 'seek': 207010, 'start': 2070.1, 'end': 2077.1, 'text': ' Because these two dependencies are false dependencies. Why is that they are false dependencies?', 'tokens': [50364, 1436, 613, 732, 36606, 366, 7908, 36606, 13, 1545, 307, 300, 436, 366, 7908, 36606, 30, 50714], 'temperature': 0.0, 'avg_logprob': -0.18134919150930937, 'compression_ratio': 1.608187134502924, 'no_speech_prob': 0.00987058412283659}, {'id': 317, 'seek': 207010, 'start': 2079.46, 'end': 2085.94, 'text': ' They happen essentially because you are reusing the same register, correct. If instead of', 'tokens': [50832, 814, 1051, 4476, 570, 291, 366, 319, 7981, 264, 912, 7280, 11, 3006, 13, 759, 2602, 295, 51156], 'temperature': 0.0, 'avg_logprob': -0.18134919150930937, 'compression_ratio': 1.608187134502924, 'no_speech_prob': 0.00987058412283659}, {'id': 318, 'seek': 207010, 'start': 2085.94, 'end': 2092.94, 'text': ' using R3 here, if you have used some R13 there would not have been any dependence between', 'tokens': [51156, 1228, 497, 18, 510, 11, 498, 291, 362, 1143, 512, 497, 7668, 456, 576, 406, 362, 668, 604, 31704, 1296, 51506], 'temperature': 0.0, 'avg_logprob': -0.18134919150930937, 'compression_ratio': 1.608187134502924, 'no_speech_prob': 0.00987058412283659}, {'id': 319, 'seek': 209294, 'start': 2092.94, 'end': 2099.94, 'text': ' these two instructions, correct. Similarly, instead of using R1 if you have used R21 there', 'tokens': [50364, 613, 732, 9415, 11, 3006, 13, 13157, 11, 2602, 295, 1228, 497, 16, 498, 291, 362, 1143, 497, 4436, 456, 50714], 'temperature': 0.0, 'avg_logprob': -0.2555139256619859, 'compression_ratio': 1.6666666666666667, 'no_speech_prob': 0.03773015737533569}, {'id': 320, 'seek': 209294, 'start': 2101.5, 'end': 2107.3, 'text': ' would not have been any dependence between I1 and I4, correct. So, the dependence has', 'tokens': [50792, 576, 406, 362, 668, 604, 31704, 1296, 286, 16, 293, 286, 19, 11, 3006, 13, 407, 11, 264, 31704, 575, 51082], 'temperature': 0.0, 'avg_logprob': -0.2555139256619859, 'compression_ratio': 1.6666666666666667, 'no_speech_prob': 0.03773015737533569}, {'id': 321, 'seek': 209294, 'start': 2107.3, 'end': 2112.82, 'text': ' happened because you are reusing the registers, not the true dependence which is dictated', 'tokens': [51082, 2011, 570, 291, 366, 319, 7981, 264, 38351, 11, 406, 264, 2074, 31704, 597, 307, 12569, 770, 51358], 'temperature': 0.0, 'avg_logprob': -0.2555139256619859, 'compression_ratio': 1.6666666666666667, 'no_speech_prob': 0.03773015737533569}, {'id': 322, 'seek': 209294, 'start': 2112.82, 'end': 2118.82, 'text': ' by the program. Whereas, this dependence that you talk about between this R3 and R3 that', 'tokens': [51358, 538, 264, 1461, 13, 13813, 11, 341, 31704, 300, 291, 751, 466, 1296, 341, 497, 18, 293, 497, 18, 300, 51658], 'temperature': 0.0, 'avg_logprob': -0.2555139256619859, 'compression_ratio': 1.6666666666666667, 'no_speech_prob': 0.03773015737533569}, {'id': 323, 'seek': 211882, 'start': 2119.2200000000003, 'end': 2124.94, 'text': ' a true dependent the program wants is if you rename this register to R13 this also has', 'tokens': [50384, 257, 2074, 12334, 264, 1461, 2738, 307, 498, 291, 36741, 341, 7280, 281, 497, 7668, 341, 611, 575, 50670], 'temperature': 0.0, 'avg_logprob': -0.20501160621643066, 'compression_ratio': 1.7777777777777777, 'no_speech_prob': 0.05340859666466713}, {'id': 324, 'seek': 211882, 'start': 2124.94, 'end': 2131.7000000000003, 'text': ' to be R13. If you rename this to R24 this also has to be R24 because here you want to', 'tokens': [50670, 281, 312, 497, 7668, 13, 759, 291, 36741, 341, 281, 497, 7911, 341, 611, 575, 281, 312, 497, 7911, 570, 510, 291, 528, 281, 51008], 'temperature': 0.0, 'avg_logprob': -0.20501160621643066, 'compression_ratio': 1.7777777777777777, 'no_speech_prob': 0.05340859666466713}, {'id': 325, 'seek': 211882, 'start': 2131.7000000000003, 'end': 2137.7000000000003, 'text': ' take the value produced by add and use it in this add instruction, right. So, this is', 'tokens': [51008, 747, 264, 2158, 7126, 538, 909, 293, 764, 309, 294, 341, 909, 10951, 11, 558, 13, 407, 11, 341, 307, 51308], 'temperature': 0.0, 'avg_logprob': -0.20501160621643066, 'compression_ratio': 1.7777777777777777, 'no_speech_prob': 0.05340859666466713}, {'id': 326, 'seek': 211882, 'start': 2137.7000000000003, 'end': 2144.7000000000003, 'text': ' a true dependence no matter how you do register allocation this dependence will always exist.', 'tokens': [51308, 257, 2074, 31704, 572, 1871, 577, 291, 360, 7280, 27599, 341, 31704, 486, 1009, 2514, 13, 51658], 'temperature': 0.0, 'avg_logprob': -0.20501160621643066, 'compression_ratio': 1.7777777777777777, 'no_speech_prob': 0.05340859666466713}, {'id': 327, 'seek': 214470, 'start': 2144.8199999999997, 'end': 2149.3399999999997, 'text': ' This dependence anti-dependence was introduced by your register allocator or introduced by', 'tokens': [50370, 639, 31704, 6061, 12, 36763, 655, 390, 7268, 538, 428, 7280, 12660, 1639, 420, 7268, 538, 50596], 'temperature': 0.0, 'avg_logprob': -0.2143276596069336, 'compression_ratio': 1.752895752895753, 'no_speech_prob': 0.008892068639397621}, {'id': 328, 'seek': 214470, 'start': 2149.3399999999997, 'end': 2154.3399999999997, 'text': ' something that you have done during code generation phase. It is not what is there in the original', 'tokens': [50596, 746, 300, 291, 362, 1096, 1830, 3089, 5125, 5574, 13, 467, 307, 406, 437, 307, 456, 294, 264, 3380, 50846], 'temperature': 0.0, 'avg_logprob': -0.2143276596069336, 'compression_ratio': 1.752895752895753, 'no_speech_prob': 0.008892068639397621}, {'id': 329, 'seek': 214470, 'start': 2154.3399999999997, 'end': 2160.3399999999997, 'text': ' program. Maybe you reuse the same temporary variable, right. In your program you always', 'tokens': [50846, 1461, 13, 2704, 291, 26225, 264, 912, 13413, 7006, 11, 558, 13, 682, 428, 1461, 291, 1009, 51146], 'temperature': 0.0, 'avg_logprob': -0.2143276596069336, 'compression_ratio': 1.752895752895753, 'no_speech_prob': 0.008892068639397621}, {'id': 330, 'seek': 214470, 'start': 2160.3399999999997, 'end': 2164.4199999999996, 'text': ' write temp is equal to something and after some point in time, okay let me reuse the', 'tokens': [51146, 2464, 18274, 307, 2681, 281, 746, 293, 934, 512, 935, 294, 565, 11, 1392, 718, 385, 26225, 264, 51350], 'temperature': 0.0, 'avg_logprob': -0.2143276596069336, 'compression_ratio': 1.752895752895753, 'no_speech_prob': 0.008892068639397621}, {'id': 331, 'seek': 214470, 'start': 2164.4199999999996, 'end': 2169.74, 'text': ' temp instead of declaring one more variable, right. That is exactly what has happened here,', 'tokens': [51350, 18274, 2602, 295, 40374, 472, 544, 7006, 11, 558, 13, 663, 307, 2293, 437, 575, 2011, 510, 11, 51616], 'temperature': 0.0, 'avg_logprob': -0.2143276596069336, 'compression_ratio': 1.752895752895753, 'no_speech_prob': 0.008892068639397621}, {'id': 332, 'seek': 216974, 'start': 2169.8199999999997, 'end': 2175.8199999999997, 'text': ' right. That is why you have this anti-dependency and that is why you have this output dependency.', 'tokens': [50368, 558, 13, 663, 307, 983, 291, 362, 341, 6061, 12, 36763, 3020, 293, 300, 307, 983, 291, 362, 341, 5598, 33621, 13, 50668], 'temperature': 0.0, 'avg_logprob': -0.18533846537272136, 'compression_ratio': 2.02262443438914, 'no_speech_prob': 0.019282540306448936}, {'id': 333, 'seek': 216974, 'start': 2175.8199999999997, 'end': 2181.3799999999997, 'text': ' That is why anti and output dependencies are together called false dependencies whereas,', 'tokens': [50668, 663, 307, 983, 6061, 293, 5598, 36606, 366, 1214, 1219, 7908, 36606, 9735, 11, 50946], 'temperature': 0.0, 'avg_logprob': -0.18533846537272136, 'compression_ratio': 2.02262443438914, 'no_speech_prob': 0.019282540306448936}, {'id': 334, 'seek': 216974, 'start': 2181.3799999999997, 'end': 2186.9399999999996, 'text': ' this one is called true dependence, okay. Alright, now I need to find a mechanism for', 'tokens': [50946, 341, 472, 307, 1219, 2074, 31704, 11, 1392, 13, 2798, 11, 586, 286, 643, 281, 915, 257, 7513, 337, 51224], 'temperature': 0.0, 'avg_logprob': -0.18533846537272136, 'compression_ratio': 2.02262443438914, 'no_speech_prob': 0.019282540306448936}, {'id': 335, 'seek': 216974, 'start': 2186.9399999999996, 'end': 2192.3399999999997, 'text': ' clearing this mess. So, we all understand all these dependencies, right. So, if somebody', 'tokens': [51224, 23937, 341, 2082, 13, 407, 11, 321, 439, 1223, 439, 613, 36606, 11, 558, 13, 407, 11, 498, 2618, 51494], 'temperature': 0.0, 'avg_logprob': -0.18533846537272136, 'compression_ratio': 2.02262443438914, 'no_speech_prob': 0.019282540306448936}, {'id': 336, 'seek': 216974, 'start': 2192.3399999999997, 'end': 2196.9399999999996, 'text': ' asks you now what is an output dependence or what is an anti-dependency you should be', 'tokens': [51494, 8962, 291, 586, 437, 307, 364, 5598, 31704, 420, 437, 307, 364, 6061, 12, 36763, 3020, 291, 820, 312, 51724], 'temperature': 0.0, 'avg_logprob': -0.18533846537272136, 'compression_ratio': 2.02262443438914, 'no_speech_prob': 0.019282540306448936}, {'id': 337, 'seek': 219694, 'start': 2196.94, 'end': 2203.94, 'text': ' able to. Okay, now let us get back to our data dependence graph, right. So, in this', 'tokens': [50364, 1075, 281, 13, 1033, 11, 586, 718, 505, 483, 646, 281, 527, 1412, 31704, 4295, 11, 558, 13, 407, 11, 294, 341, 50714], 'temperature': 0.0, 'avg_logprob': -0.20307242983863466, 'compression_ratio': 1.785425101214575, 'no_speech_prob': 0.020533910021185875}, {'id': 338, 'seek': 219694, 'start': 2203.94, 'end': 2209.1, 'text': ' data dependence graph you are going to say that each node represents an instruction and', 'tokens': [50714, 1412, 31704, 4295, 291, 366, 516, 281, 584, 300, 1184, 9984, 8855, 364, 10951, 293, 50972], 'temperature': 0.0, 'avg_logprob': -0.20307242983863466, 'compression_ratio': 1.785425101214575, 'no_speech_prob': 0.020533910021185875}, {'id': 339, 'seek': 219694, 'start': 2209.1, 'end': 2214.7400000000002, 'text': ' there is an edge from one node to the other if there is a true dependence. Now, you understand', 'tokens': [50972, 456, 307, 364, 4691, 490, 472, 9984, 281, 264, 661, 498, 456, 307, 257, 2074, 31704, 13, 823, 11, 291, 1223, 51254], 'temperature': 0.0, 'avg_logprob': -0.20307242983863466, 'compression_ratio': 1.785425101214575, 'no_speech_prob': 0.020533910021185875}, {'id': 340, 'seek': 219694, 'start': 2214.7400000000002, 'end': 2219.66, 'text': ' why we talk about true dependence, okay. Of course, we need to worry about anti and output', 'tokens': [51254, 983, 321, 751, 466, 2074, 31704, 11, 1392, 13, 2720, 1164, 11, 321, 643, 281, 3292, 466, 6061, 293, 5598, 51500], 'temperature': 0.0, 'avg_logprob': -0.20307242983863466, 'compression_ratio': 1.785425101214575, 'no_speech_prob': 0.020533910021185875}, {'id': 341, 'seek': 219694, 'start': 2219.66, 'end': 2223.7400000000002, 'text': ' dependencies as long as they use the same register names but then that is something', 'tokens': [51500, 36606, 382, 938, 382, 436, 764, 264, 912, 7280, 5288, 457, 550, 300, 307, 746, 51704], 'temperature': 0.0, 'avg_logprob': -0.20307242983863466, 'compression_ratio': 1.785425101214575, 'no_speech_prob': 0.020533910021185875}, {'id': 342, 'seek': 222374, 'start': 2223.8199999999997, 'end': 2228.3799999999997, 'text': ' that we can talk about it later. Remember I said that typically instruction scheduling', 'tokens': [50368, 300, 321, 393, 751, 466, 309, 1780, 13, 5459, 286, 848, 300, 5850, 10951, 29055, 50596], 'temperature': 0.0, 'avg_logprob': -0.20928075236658897, 'compression_ratio': 1.7644628099173554, 'no_speech_prob': 0.10399621725082397}, {'id': 343, 'seek': 222374, 'start': 2228.3799999999997, 'end': 2233.8599999999997, 'text': ' is done first in the compiler and then register allocation. If instruction scheduling is done', 'tokens': [50596, 307, 1096, 700, 294, 264, 31958, 293, 550, 7280, 27599, 13, 759, 10951, 29055, 307, 1096, 50870], 'temperature': 0.0, 'avg_logprob': -0.20928075236658897, 'compression_ratio': 1.7644628099173554, 'no_speech_prob': 0.10399621725082397}, {'id': 344, 'seek': 222374, 'start': 2233.8599999999997, 'end': 2239.12, 'text': ' first then it will be using only temporary variables. There the chances of seeing anti', 'tokens': [50870, 700, 550, 309, 486, 312, 1228, 787, 13413, 9102, 13, 821, 264, 10486, 295, 2577, 6061, 51133], 'temperature': 0.0, 'avg_logprob': -0.20928075236658897, 'compression_ratio': 1.7644628099173554, 'no_speech_prob': 0.10399621725082397}, {'id': 345, 'seek': 222374, 'start': 2239.12, 'end': 2244.9399999999996, 'text': ' and output dependencies are lower. So, you do not necessarily see them, right. Therefore,', 'tokens': [51133, 293, 5598, 36606, 366, 3126, 13, 407, 11, 291, 360, 406, 4725, 536, 552, 11, 558, 13, 7504, 11, 51424], 'temperature': 0.0, 'avg_logprob': -0.20928075236658897, 'compression_ratio': 1.7644628099173554, 'no_speech_prob': 0.10399621725082397}, {'id': 346, 'seek': 222374, 'start': 2244.9399999999996, 'end': 2249.3799999999997, 'text': ' it is okay to only talk about true dependencies in those cases, okay.', 'tokens': [51424, 309, 307, 1392, 281, 787, 751, 466, 2074, 36606, 294, 729, 3331, 11, 1392, 13, 51646], 'temperature': 0.0, 'avg_logprob': -0.20928075236658897, 'compression_ratio': 1.7644628099173554, 'no_speech_prob': 0.10399621725082397}, {'id': 347, 'seek': 224938, 'start': 2250.02, 'end': 2254.54, 'text': ' Now here is the sequence of instructions. We already analyzed all the true dependencies', 'tokens': [50396, 823, 510, 307, 264, 8310, 295, 9415, 13, 492, 1217, 28181, 439, 264, 2074, 36606, 50622], 'temperature': 0.0, 'avg_logprob': -0.2028413466465326, 'compression_ratio': 1.6745283018867925, 'no_speech_prob': 0.014053446240723133}, {'id': 348, 'seek': 224938, 'start': 2254.54, 'end': 2261.54, 'text': ' and those true dependencies are depicted by means of an edge. Now it is a directed edge,', 'tokens': [50622, 293, 729, 2074, 36606, 366, 30207, 538, 1355, 295, 364, 4691, 13, 823, 309, 307, 257, 12898, 4691, 11, 50972], 'temperature': 0.0, 'avg_logprob': -0.2028413466465326, 'compression_ratio': 1.6745283018867925, 'no_speech_prob': 0.014053446240723133}, {'id': 349, 'seek': 224938, 'start': 2262.58, 'end': 2267.58, 'text': ' remember, okay. In addition to this what we are going to say is that we will also allocate', 'tokens': [51024, 1604, 11, 1392, 13, 682, 4500, 281, 341, 437, 321, 366, 516, 281, 584, 307, 300, 321, 486, 611, 35713, 51274], 'temperature': 0.0, 'avg_logprob': -0.2028413466465326, 'compression_ratio': 1.6745283018867925, 'no_speech_prob': 0.014053446240723133}, {'id': 350, 'seek': 224938, 'start': 2267.58, 'end': 2273.2200000000003, 'text': ' or assign weights to each one of the nodes that will essentially tell how long it takes', 'tokens': [51274, 420, 6269, 17443, 281, 1184, 472, 295, 264, 13891, 300, 486, 4476, 980, 577, 938, 309, 2516, 51556], 'temperature': 0.0, 'avg_logprob': -0.2028413466465326, 'compression_ratio': 1.6745283018867925, 'no_speech_prob': 0.014053446240723133}, {'id': 351, 'seek': 227322, 'start': 2273.2999999999997, 'end': 2279.58, 'text': ' for that instruction to execute, right. When I say that this takes one cycle to execute', 'tokens': [50368, 337, 300, 10951, 281, 14483, 11, 558, 13, 1133, 286, 584, 300, 341, 2516, 472, 6586, 281, 14483, 50682], 'temperature': 0.0, 'avg_logprob': -0.13833643969367532, 'compression_ratio': 1.868421052631579, 'no_speech_prob': 0.03485443443059921}, {'id': 352, 'seek': 227322, 'start': 2279.58, 'end': 2285.4599999999996, 'text': ' that after one cycle this node will produce the value which can be consumed by this. When', 'tokens': [50682, 300, 934, 472, 6586, 341, 9984, 486, 5258, 264, 2158, 597, 393, 312, 21226, 538, 341, 13, 1133, 50976], 'temperature': 0.0, 'avg_logprob': -0.13833643969367532, 'compression_ratio': 1.868421052631579, 'no_speech_prob': 0.03485443443059921}, {'id': 353, 'seek': 227322, 'start': 2285.4599999999996, 'end': 2291.98, 'text': ' I say two cycles here after two cycles only this can produce the value. So, if this is', 'tokens': [50976, 286, 584, 732, 17796, 510, 934, 732, 17796, 787, 341, 393, 5258, 264, 2158, 13, 407, 11, 498, 341, 307, 51302], 'temperature': 0.0, 'avg_logprob': -0.13833643969367532, 'compression_ratio': 1.868421052631579, 'no_speech_prob': 0.03485443443059921}, {'id': 354, 'seek': 227322, 'start': 2291.98, 'end': 2298.98, 'text': ' scheduled at time t then this node can only be scheduled at time t plus 2 or later because', 'tokens': [51302, 15678, 412, 565, 256, 550, 341, 9984, 393, 787, 312, 15678, 412, 565, 256, 1804, 568, 420, 1780, 570, 51652], 'temperature': 0.0, 'avg_logprob': -0.13833643969367532, 'compression_ratio': 1.868421052631579, 'no_speech_prob': 0.03485443443059921}, {'id': 355, 'seek': 229898, 'start': 2299.06, 'end': 2302.9, 'text': ' this is not going to produce a result value until t plus 2, right.', 'tokens': [50368, 341, 307, 406, 516, 281, 5258, 257, 1874, 2158, 1826, 256, 1804, 568, 11, 558, 13, 50560], 'temperature': 0.0, 'avg_logprob': -0.18238163885669173, 'compression_ratio': 1.7923728813559323, 'no_speech_prob': 0.008865293115377426}, {'id': 356, 'seek': 229898, 'start': 2302.9, 'end': 2308.14, 'text': ' Similarly, if this is scheduled at time t 2 then this can also be scheduled only after', 'tokens': [50560, 13157, 11, 498, 341, 307, 15678, 412, 565, 256, 568, 550, 341, 393, 611, 312, 15678, 787, 934, 50822], 'temperature': 0.0, 'avg_logprob': -0.18238163885669173, 'compression_ratio': 1.7923728813559323, 'no_speech_prob': 0.008865293115377426}, {'id': 357, 'seek': 229898, 'start': 2308.14, 'end': 2314.7, 'text': ' t 2 plus 2, correct. That is really what we mean. So, each node has a weight assigned', 'tokens': [50822, 256, 568, 1804, 568, 11, 3006, 13, 663, 307, 534, 437, 321, 914, 13, 407, 11, 1184, 9984, 575, 257, 3364, 13279, 51150], 'temperature': 0.0, 'avg_logprob': -0.18238163885669173, 'compression_ratio': 1.7923728813559323, 'no_speech_prob': 0.008865293115377426}, {'id': 358, 'seek': 229898, 'start': 2314.7, 'end': 2320.78, 'text': ' to it or associated with it which tells you how much time it takes to execute this node.', 'tokens': [51150, 281, 309, 420, 6615, 365, 309, 597, 5112, 291, 577, 709, 565, 309, 2516, 281, 14483, 341, 9984, 13, 51454], 'temperature': 0.0, 'avg_logprob': -0.18238163885669173, 'compression_ratio': 1.7923728813559323, 'no_speech_prob': 0.008865293115377426}, {'id': 359, 'seek': 229898, 'start': 2320.78, 'end': 2326.06, 'text': ' Sometimes we will put the weights on the node, sometimes we will put the weights on the edges.', 'tokens': [51454, 4803, 321, 486, 829, 264, 17443, 322, 264, 9984, 11, 2171, 321, 486, 829, 264, 17443, 322, 264, 8819, 13, 51718], 'temperature': 0.0, 'avg_logprob': -0.18238163885669173, 'compression_ratio': 1.7923728813559323, 'no_speech_prob': 0.008865293115377426}, {'id': 360, 'seek': 232606, 'start': 2326.06, 'end': 2331.7799999999997, 'text': ' The kind of mean more or less the same thing. When you put the weights on the node it means', 'tokens': [50364, 440, 733, 295, 914, 544, 420, 1570, 264, 912, 551, 13, 1133, 291, 829, 264, 17443, 322, 264, 9984, 309, 1355, 50650], 'temperature': 0.0, 'avg_logprob': -0.15190355493388044, 'compression_ratio': 1.9694323144104804, 'no_speech_prob': 0.05166896432638168}, {'id': 361, 'seek': 232606, 'start': 2331.7799999999997, 'end': 2338.5, 'text': ' that all the outgoing edges have the same latency. When you put the weights on the edges', 'tokens': [50650, 300, 439, 264, 41565, 8819, 362, 264, 912, 27043, 13, 1133, 291, 829, 264, 17443, 322, 264, 8819, 50986], 'temperature': 0.0, 'avg_logprob': -0.15190355493388044, 'compression_ratio': 1.9694323144104804, 'no_speech_prob': 0.05166896432638168}, {'id': 362, 'seek': 232606, 'start': 2338.5, 'end': 2343.66, 'text': ' then you can individually specify this has one latency, this has two latency or this', 'tokens': [50986, 550, 291, 393, 16652, 16500, 341, 575, 472, 27043, 11, 341, 575, 732, 27043, 420, 341, 51244], 'temperature': 0.0, 'avg_logprob': -0.15190355493388044, 'compression_ratio': 1.9694323144104804, 'no_speech_prob': 0.05166896432638168}, {'id': 363, 'seek': 232606, 'start': 2343.66, 'end': 2349.54, 'text': ' has five latency and so on and so forth, right. You can do it either way but you only need', 'tokens': [51244, 575, 1732, 27043, 293, 370, 322, 293, 370, 5220, 11, 558, 13, 509, 393, 360, 309, 2139, 636, 457, 291, 787, 643, 51538], 'temperature': 0.0, 'avg_logprob': -0.15190355493388044, 'compression_ratio': 1.9694323144104804, 'no_speech_prob': 0.05166896432638168}, {'id': 364, 'seek': 232606, 'start': 2349.54, 'end': 2355.34, 'text': ' to do one of them not both, okay. Either associate the weights with the nodes or associate the', 'tokens': [51538, 281, 360, 472, 295, 552, 406, 1293, 11, 1392, 13, 13746, 14644, 264, 17443, 365, 264, 13891, 420, 14644, 264, 51828], 'temperature': 0.0, 'avg_logprob': -0.15190355493388044, 'compression_ratio': 1.9694323144104804, 'no_speech_prob': 0.05166896432638168}, {'id': 365, 'seek': 235534, 'start': 2355.34, 'end': 2362.34, 'text': ' weights with the edges, one of the two things that you do, right. And what do these weights', 'tokens': [50364, 17443, 365, 264, 8819, 11, 472, 295, 264, 732, 721, 300, 291, 360, 11, 558, 13, 400, 437, 360, 613, 17443, 50714], 'temperature': 0.0, 'avg_logprob': -0.285239749484592, 'compression_ratio': 1.5803571428571428, 'no_speech_prob': 0.005930422805249691}, {'id': 366, 'seek': 235534, 'start': 2362.34, 'end': 2368.86, 'text': ' represent? Number of cycles or amount of time it takes to execute that node, okay.', 'tokens': [50714, 2906, 30, 5118, 295, 17796, 420, 2372, 295, 565, 309, 2516, 281, 14483, 300, 9984, 11, 1392, 13, 51040], 'temperature': 0.0, 'avg_logprob': -0.285239749484592, 'compression_ratio': 1.5803571428571428, 'no_speech_prob': 0.005930422805249691}, {'id': 367, 'seek': 235534, 'start': 2368.86, 'end': 2373.5, 'text': ' So, when you talk about this schedule for pipeline to processors where you are only', 'tokens': [51040, 407, 11, 562, 291, 751, 466, 341, 7567, 337, 15517, 281, 27751, 689, 291, 366, 787, 51272], 'temperature': 0.0, 'avg_logprob': -0.285239749484592, 'compression_ratio': 1.5803571428571428, 'no_speech_prob': 0.005930422805249691}, {'id': 368, 'seek': 235534, 'start': 2373.5, 'end': 2380.94, 'text': ' talking about avoiding stalls, the schedule problem is essentially defined as below. Basically,', 'tokens': [51272, 1417, 466, 20220, 50248, 11, 264, 7567, 1154, 307, 4476, 7642, 382, 2507, 13, 8537, 11, 51644], 'temperature': 0.0, 'avg_logprob': -0.285239749484592, 'compression_ratio': 1.5803571428571428, 'no_speech_prob': 0.005930422805249691}, {'id': 369, 'seek': 238094, 'start': 2380.94, 'end': 2385.66, 'text': ' you have an instruction in the basic instruction sequence in the basic block which is I 1,', 'tokens': [50364, 291, 362, 364, 10951, 294, 264, 3875, 10951, 8310, 294, 264, 3875, 3461, 597, 307, 286, 502, 11, 50600], 'temperature': 0.0, 'avg_logprob': -0.20587759358542307, 'compression_ratio': 1.8936170212765957, 'no_speech_prob': 0.09569461643695831}, {'id': 370, 'seek': 238094, 'start': 2385.66, 'end': 2392.42, 'text': ' I 2, I 3, I m and you want to reorder them such that the number of stalls is minimized.', 'tokens': [50600, 286, 568, 11, 286, 805, 11, 286, 275, 293, 291, 528, 281, 319, 4687, 552, 1270, 300, 264, 1230, 295, 50248, 307, 4464, 1602, 13, 50938], 'temperature': 0.0, 'avg_logprob': -0.20587759358542307, 'compression_ratio': 1.8936170212765957, 'no_speech_prob': 0.09569461643695831}, {'id': 371, 'seek': 238094, 'start': 2392.42, 'end': 2397.2200000000003, 'text': ' That is really what you are trying to do and this reordering is going to be in such a way', 'tokens': [50938, 663, 307, 534, 437, 291, 366, 1382, 281, 360, 293, 341, 319, 765, 1794, 307, 516, 281, 312, 294, 1270, 257, 636, 51178], 'temperature': 0.0, 'avg_logprob': -0.20587759358542307, 'compression_ratio': 1.8936170212765957, 'no_speech_prob': 0.09569461643695831}, {'id': 372, 'seek': 238094, 'start': 2397.2200000000003, 'end': 2403.66, 'text': ' that these m instructions are going to be permuted in some form, right. Their positions', 'tokens': [51178, 300, 613, 275, 9415, 366, 516, 281, 312, 4784, 4866, 294, 512, 1254, 11, 558, 13, 6710, 8432, 51500], 'temperature': 0.0, 'avg_logprob': -0.20587759358542307, 'compression_ratio': 1.8936170212765957, 'no_speech_prob': 0.09569461643695831}, {'id': 373, 'seek': 238094, 'start': 2403.66, 'end': 2409.7400000000002, 'text': ' are being changed in some form but then in the change the form you essentially make sure', 'tokens': [51500, 366, 885, 3105, 294, 512, 1254, 457, 550, 294, 264, 1319, 264, 1254, 291, 4476, 652, 988, 51804], 'temperature': 0.0, 'avg_logprob': -0.20587759358542307, 'compression_ratio': 1.8936170212765957, 'no_speech_prob': 0.09569461643695831}, {'id': 374, 'seek': 240974, 'start': 2409.8199999999997, 'end': 2416.3399999999997, 'text': ' that the dependences are again satisfied, right. So, the instruction reordering in this', 'tokens': [50368, 300, 264, 5672, 2667, 366, 797, 11239, 11, 558, 13, 407, 11, 264, 10951, 319, 765, 1794, 294, 341, 50694], 'temperature': 0.0, 'avg_logprob': -0.14355283975601196, 'compression_ratio': 1.6727272727272726, 'no_speech_prob': 0.03601178899407387}, {'id': 375, 'seek': 240974, 'start': 2416.3399999999997, 'end': 2425.3399999999997, 'text': ' serial schedule is essentially a permutation function f on 1 to m such that f of j identifies', 'tokens': [50694, 17436, 7567, 307, 4476, 257, 4784, 11380, 2445, 283, 322, 502, 281, 275, 1270, 300, 283, 295, 361, 34597, 51144], 'temperature': 0.0, 'avg_logprob': -0.14355283975601196, 'compression_ratio': 1.6727272727272726, 'no_speech_prob': 0.03601178899407387}, {'id': 376, 'seek': 240974, 'start': 2425.3399999999997, 'end': 2432.14, 'text': ' the new position of instruction j, right. But then whatever is the new position of instruction', 'tokens': [51144, 264, 777, 2535, 295, 10951, 361, 11, 558, 13, 583, 550, 2035, 307, 264, 777, 2535, 295, 10951, 51484], 'temperature': 0.0, 'avg_logprob': -0.14355283975601196, 'compression_ratio': 1.6727272727272726, 'no_speech_prob': 0.03601178899407387}, {'id': 377, 'seek': 243214, 'start': 2432.14, 'end': 2440.66, 'text': ' j, if j is dependent on some k, sorry in this case, yeah, okay. If k is dependent on j,', 'tokens': [50364, 361, 11, 498, 361, 307, 12334, 322, 512, 350, 11, 2597, 294, 341, 1389, 11, 1338, 11, 1392, 13, 759, 350, 307, 12334, 322, 361, 11, 50790], 'temperature': 0.0, 'avg_logprob': -0.17229936314725328, 'compression_ratio': 1.778894472361809, 'no_speech_prob': 0.13599719107151031}, {'id': 378, 'seek': 243214, 'start': 2440.66, 'end': 2449.54, 'text': ' then f of j must necessarily happen before f of k, right. So, that is essentially saying', 'tokens': [50790, 550, 283, 295, 361, 1633, 4725, 1051, 949, 283, 295, 350, 11, 558, 13, 407, 11, 300, 307, 4476, 1566, 51234], 'temperature': 0.0, 'avg_logprob': -0.17229936314725328, 'compression_ratio': 1.778894472361809, 'no_speech_prob': 0.13599719107151031}, {'id': 379, 'seek': 243214, 'start': 2449.54, 'end': 2454.8599999999997, 'text': ' that all instructions on which an instruction is dependent must necessarily happen before,', 'tokens': [51234, 300, 439, 9415, 322, 597, 364, 10951, 307, 12334, 1633, 4725, 1051, 949, 11, 51500], 'temperature': 0.0, 'avg_logprob': -0.17229936314725328, 'compression_ratio': 1.778894472361809, 'no_speech_prob': 0.13599719107151031}, {'id': 380, 'seek': 243214, 'start': 2454.8599999999997, 'end': 2460.98, 'text': ' right. Here we are not worried so much about the delay cycles and other things because', 'tokens': [51500, 558, 13, 1692, 321, 366, 406, 5804, 370, 709, 466, 264, 8577, 17796, 293, 661, 721, 570, 51806], 'temperature': 0.0, 'avg_logprob': -0.17229936314725328, 'compression_ratio': 1.778894472361809, 'no_speech_prob': 0.13599719107151031}, {'id': 381, 'seek': 246098, 'start': 2460.98, 'end': 2465.9, 'text': ' it is a serial schedule and we are trying to put them and the delay cycles essentially tell', 'tokens': [50364, 309, 307, 257, 17436, 7567, 293, 321, 366, 1382, 281, 829, 552, 293, 264, 8577, 17796, 4476, 980, 50610], 'temperature': 0.0, 'avg_logprob': -0.12618473597935267, 'compression_ratio': 1.7195571955719557, 'no_speech_prob': 0.026853319257497787}, {'id': 382, 'seek': 246098, 'start': 2465.9, 'end': 2471.02, 'text': ' you that if you do not have enough stall cycles between them, they will be introduced as stall.', 'tokens': [50610, 291, 300, 498, 291, 360, 406, 362, 1547, 19633, 17796, 1296, 552, 11, 436, 486, 312, 7268, 382, 19633, 13, 50866], 'temperature': 0.0, 'avg_logprob': -0.12618473597935267, 'compression_ratio': 1.7195571955719557, 'no_speech_prob': 0.026853319257497787}, {'id': 383, 'seek': 246098, 'start': 2471.02, 'end': 2477.14, 'text': ' And your objective is to minimize the number of stalls, okay. That is really what it is, okay.', 'tokens': [50866, 400, 428, 10024, 307, 281, 17522, 264, 1230, 295, 50248, 11, 1392, 13, 663, 307, 534, 437, 309, 307, 11, 1392, 13, 51172], 'temperature': 0.0, 'avg_logprob': -0.12618473597935267, 'compression_ratio': 1.7195571955719557, 'no_speech_prob': 0.026853319257497787}, {'id': 384, 'seek': 246098, 'start': 2477.14, 'end': 2481.86, 'text': ' Now, let us define a few terms before we go into the details of instruction scheduling,', 'tokens': [51172, 823, 11, 718, 505, 6964, 257, 1326, 2115, 949, 321, 352, 666, 264, 4365, 295, 10951, 29055, 11, 51408], 'temperature': 0.0, 'avg_logprob': -0.12618473597935267, 'compression_ratio': 1.7195571955719557, 'no_speech_prob': 0.026853319257497787}, {'id': 385, 'seek': 246098, 'start': 2481.86, 'end': 2489.54, 'text': ' right. We define the start time of a node which is the time in which it starts executing, okay.', 'tokens': [51408, 558, 13, 492, 6964, 264, 722, 565, 295, 257, 9984, 597, 307, 264, 565, 294, 597, 309, 3719, 32368, 11, 1392, 13, 51792], 'temperature': 0.0, 'avg_logprob': -0.12618473597935267, 'compression_ratio': 1.7195571955719557, 'no_speech_prob': 0.026853319257497787}, {'id': 386, 'seek': 248954, 'start': 2489.54, 'end': 2497.58, 'text': ' Obviously, the start time of a node j has to be greater than or equal to 0, right. And two', 'tokens': [50364, 7580, 11, 264, 722, 565, 295, 257, 9984, 361, 575, 281, 312, 5044, 813, 420, 2681, 281, 1958, 11, 558, 13, 400, 732, 50766], 'temperature': 0.0, 'avg_logprob': -0.12583753564855554, 'compression_ratio': 1.6681818181818182, 'no_speech_prob': 0.05272797867655754}, {'id': 387, 'seek': 248954, 'start': 2497.58, 'end': 2502.42, 'text': ' instructions can have, okay. In this particular case, I am saying the two instructions cannot', 'tokens': [50766, 9415, 393, 362, 11, 1392, 13, 682, 341, 1729, 1389, 11, 286, 669, 1566, 264, 732, 9415, 2644, 51008], 'temperature': 0.0, 'avg_logprob': -0.12583753564855554, 'compression_ratio': 1.6681818181818182, 'no_speech_prob': 0.05272797867655754}, {'id': 388, 'seek': 248954, 'start': 2502.42, 'end': 2506.54, 'text': ' have the same start time. That means that I am putting one instruction in every cycle. So,', 'tokens': [51008, 362, 264, 912, 722, 565, 13, 663, 1355, 300, 286, 669, 3372, 472, 10951, 294, 633, 6586, 13, 407, 11, 51214], 'temperature': 0.0, 'avg_logprob': -0.12583753564855554, 'compression_ratio': 1.6681818181818182, 'no_speech_prob': 0.05272797867655754}, {'id': 389, 'seek': 248954, 'start': 2506.54, 'end': 2515.38, 'text': ' this is still the serial schedule that we are talking about, right. And if there is an edge', 'tokens': [51214, 341, 307, 920, 264, 17436, 7567, 300, 321, 366, 1417, 466, 11, 558, 13, 400, 498, 456, 307, 364, 4691, 51656], 'temperature': 0.0, 'avg_logprob': -0.12583753564855554, 'compression_ratio': 1.6681818181818182, 'no_speech_prob': 0.05272797867655754}, {'id': 390, 'seek': 251538, 'start': 2515.42, 'end': 2523.1800000000003, 'text': ' from j to k, that means that k is dependent on j, then the start time of k has to be greater', 'tokens': [50366, 490, 361, 281, 350, 11, 300, 1355, 300, 350, 307, 12334, 322, 361, 11, 550, 264, 722, 565, 295, 350, 575, 281, 312, 5044, 50754], 'temperature': 0.0, 'avg_logprob': -0.133004209269648, 'compression_ratio': 1.8556701030927836, 'no_speech_prob': 0.11258216202259064}, {'id': 391, 'seek': 251538, 'start': 2523.1800000000003, 'end': 2527.98, 'text': ' than the completion time of j. And what is the completion time of j? Which is basically', 'tokens': [50754, 813, 264, 19372, 565, 295, 361, 13, 400, 437, 307, 264, 19372, 565, 295, 361, 30, 3013, 307, 1936, 50994], 'temperature': 0.0, 'avg_logprob': -0.133004209269648, 'compression_ratio': 1.8556701030927836, 'no_speech_prob': 0.11258216202259064}, {'id': 392, 'seek': 251538, 'start': 2527.98, 'end': 2535.38, 'text': ' start time of j plus execution time of j, right. So, that is essentially what it is, okay.', 'tokens': [50994, 722, 565, 295, 361, 1804, 15058, 565, 295, 361, 11, 558, 13, 407, 11, 300, 307, 4476, 437, 309, 307, 11, 1392, 13, 51364], 'temperature': 0.0, 'avg_logprob': -0.133004209269648, 'compression_ratio': 1.8556701030927836, 'no_speech_prob': 0.11258216202259064}, {'id': 393, 'seek': 251538, 'start': 2535.38, 'end': 2544.3, 'text': ' Now, the schedule length is essentially the completion time of the last, not necessarily', 'tokens': [51364, 823, 11, 264, 7567, 4641, 307, 4476, 264, 19372, 565, 295, 264, 1036, 11, 406, 4725, 51810], 'temperature': 0.0, 'avg_logprob': -0.133004209269648, 'compression_ratio': 1.8556701030927836, 'no_speech_prob': 0.11258216202259064}, {'id': 394, 'seek': 254430, 'start': 2544.3, 'end': 2549.78, 'text': ' the last node in the schedule. The node that finishes last or finishes execution last. That', 'tokens': [50364, 264, 1036, 9984, 294, 264, 7567, 13, 440, 9984, 300, 23615, 1036, 420, 23615, 15058, 1036, 13, 663, 50638], 'temperature': 0.0, 'avg_logprob': -0.13846214218895034, 'compression_ratio': 1.8945147679324894, 'no_speech_prob': 0.0254550538957119}, {'id': 395, 'seek': 254430, 'start': 2549.78, 'end': 2555.46, 'text': ' means that for all the nodes, you find out what is the completion time, whichever one which ends', 'tokens': [50638, 1355, 300, 337, 439, 264, 13891, 11, 291, 915, 484, 437, 307, 264, 19372, 565, 11, 24123, 472, 597, 5314, 50922], 'temperature': 0.0, 'avg_logprob': -0.13846214218895034, 'compression_ratio': 1.8945147679324894, 'no_speech_prob': 0.0254550538957119}, {'id': 396, 'seek': 254430, 'start': 2555.46, 'end': 2561.7400000000002, 'text': ' last max, okay. That is the one that we are going to take as the completion time. So,', 'tokens': [50922, 1036, 11469, 11, 1392, 13, 663, 307, 264, 472, 300, 321, 366, 516, 281, 747, 382, 264, 19372, 565, 13, 407, 11, 51236], 'temperature': 0.0, 'avg_logprob': -0.13846214218895034, 'compression_ratio': 1.8945147679324894, 'no_speech_prob': 0.0254550538957119}, {'id': 397, 'seek': 254430, 'start': 2561.7400000000002, 'end': 2567.38, 'text': ' essentially if you are given an instruction sequence and you construct a schedule that', 'tokens': [51236, 4476, 498, 291, 366, 2212, 364, 10951, 8310, 293, 291, 7690, 257, 7567, 300, 51518], 'temperature': 0.0, 'avg_logprob': -0.13846214218895034, 'compression_ratio': 1.8945147679324894, 'no_speech_prob': 0.0254550538957119}, {'id': 398, 'seek': 254430, 'start': 2567.38, 'end': 2573.1800000000003, 'text': ' satisfies these properties, correct, which is basically the resource constraint, right,', 'tokens': [51518, 44271, 613, 7221, 11, 3006, 11, 597, 307, 1936, 264, 7684, 25534, 11, 558, 11, 51808], 'temperature': 0.0, 'avg_logprob': -0.13846214218895034, 'compression_ratio': 1.8945147679324894, 'no_speech_prob': 0.0254550538957119}, {'id': 399, 'seek': 257318, 'start': 2573.18, 'end': 2581.1, 'text': ' then the cost of that schedule is essentially the make span of that schedule, which essentially', 'tokens': [50364, 550, 264, 2063, 295, 300, 7567, 307, 4476, 264, 652, 16174, 295, 300, 7567, 11, 597, 4476, 50760], 'temperature': 0.0, 'avg_logprob': -0.14255853799673227, 'compression_ratio': 1.7567567567567568, 'no_speech_prob': 0.002840409753844142}, {'id': 400, 'seek': 257318, 'start': 2581.1, 'end': 2586.7, 'text': ' tells you how long it takes to complete execution of all the instructions in the schedule. And the', 'tokens': [50760, 5112, 291, 577, 938, 309, 2516, 281, 3566, 15058, 295, 439, 264, 9415, 294, 264, 7567, 13, 400, 264, 51040], 'temperature': 0.0, 'avg_logprob': -0.14255853799673227, 'compression_ratio': 1.7567567567567568, 'no_speech_prob': 0.002840409753844142}, {'id': 401, 'seek': 257318, 'start': 2586.7, 'end': 2592.7799999999997, 'text': ' idea is to minimize the schedule length, correct. That is really what we want to do. Again, we will', 'tokens': [51040, 1558, 307, 281, 17522, 264, 7567, 4641, 11, 3006, 13, 663, 307, 534, 437, 321, 528, 281, 360, 13, 3764, 11, 321, 486, 51344], 'temperature': 0.0, 'avg_logprob': -0.14255853799673227, 'compression_ratio': 1.7567567567567568, 'no_speech_prob': 0.002840409753844142}, {'id': 402, 'seek': 257318, 'start': 2592.7799999999997, 'end': 2597.74, 'text': ' see examples. That is how we understand things, right. So, again I have taken the same program,', 'tokens': [51344, 536, 5110, 13, 663, 307, 577, 321, 1223, 721, 11, 558, 13, 407, 11, 797, 286, 362, 2726, 264, 912, 1461, 11, 51592], 'temperature': 0.0, 'avg_logprob': -0.14255853799673227, 'compression_ratio': 1.7567567567567568, 'no_speech_prob': 0.002840409753844142}, {'id': 403, 'seek': 259774, 'start': 2597.74, 'end': 2606.62, 'text': ' okay, and I want to construct a serial schedule for this, okay. So, here is one schedule where I do', 'tokens': [50364, 1392, 11, 293, 286, 528, 281, 7690, 257, 17436, 7567, 337, 341, 11, 1392, 13, 407, 11, 510, 307, 472, 7567, 689, 286, 360, 50808], 'temperature': 0.0, 'avg_logprob': -0.1588991679502337, 'compression_ratio': 1.575268817204301, 'no_speech_prob': 0.08701211959123611}, {'id': 404, 'seek': 259774, 'start': 2606.62, 'end': 2615.02, 'text': ' I1, I2, I3, I4, which is the original schedule, right. Now, what happens? Okay, I may have made', 'tokens': [50808, 286, 16, 11, 286, 17, 11, 286, 18, 11, 286, 19, 11, 597, 307, 264, 3380, 7567, 11, 558, 13, 823, 11, 437, 2314, 30, 1033, 11, 286, 815, 362, 1027, 51228], 'temperature': 0.0, 'avg_logprob': -0.1588991679502337, 'compression_ratio': 1.575268817204301, 'no_speech_prob': 0.08701211959123611}, {'id': 405, 'seek': 259774, 'start': 2615.02, 'end': 2622.5, 'text': ' some mistake, but let us see. So, this takes five cycles, okay. So, this must not, this must have', 'tokens': [51228, 512, 6146, 11, 457, 718, 505, 536, 13, 407, 11, 341, 2516, 1732, 17796, 11, 1392, 13, 407, 11, 341, 1633, 406, 11, 341, 1633, 362, 51602], 'temperature': 0.0, 'avg_logprob': -0.1588991679502337, 'compression_ratio': 1.575268817204301, 'no_speech_prob': 0.08701211959123611}, {'id': 406, 'seek': 262250, 'start': 2622.5, 'end': 2632.1, 'text': ' been one instead of two, okay. So, let us do the correction, okay. So, for example, let us say that', 'tokens': [50364, 668, 472, 2602, 295, 732, 11, 1392, 13, 407, 11, 718, 505, 360, 264, 19984, 11, 1392, 13, 407, 11, 337, 1365, 11, 718, 505, 584, 300, 50844], 'temperature': 0.0, 'avg_logprob': -0.15591259002685548, 'compression_ratio': 1.650273224043716, 'no_speech_prob': 0.19062429666519165}, {'id': 407, 'seek': 262250, 'start': 2632.1, 'end': 2644.06, 'text': ' this is not two, but one, okay. Then this schedule, okay, should have checked this. Sorry about that,', 'tokens': [50844, 341, 307, 406, 732, 11, 457, 472, 11, 1392, 13, 1396, 341, 7567, 11, 1392, 11, 820, 362, 10033, 341, 13, 4919, 466, 300, 11, 51442], 'temperature': 0.0, 'avg_logprob': -0.15591259002685548, 'compression_ratio': 1.650273224043716, 'no_speech_prob': 0.19062429666519165}, {'id': 408, 'seek': 262250, 'start': 2644.06, 'end': 2651.26, 'text': ' okay. So, let us start off with this example again. Remember that I2 is an add instruction and I3 is', 'tokens': [51442, 1392, 13, 407, 11, 718, 505, 722, 766, 365, 341, 1365, 797, 13, 5459, 300, 286, 17, 307, 364, 909, 10951, 293, 286, 18, 307, 51802], 'temperature': 0.0, 'avg_logprob': -0.15591259002685548, 'compression_ratio': 1.650273224043716, 'no_speech_prob': 0.19062429666519165}, {'id': 409, 'seek': 265126, 'start': 2651.26, 'end': 2656.5400000000004, 'text': ' a load instruction. So, the load instruction is the one which takes two cycles. Add instruction takes', 'tokens': [50364, 257, 3677, 10951, 13, 407, 11, 264, 3677, 10951, 307, 264, 472, 597, 2516, 732, 17796, 13, 5349, 10951, 2516, 50628], 'temperature': 0.0, 'avg_logprob': -0.10665299757471625, 'compression_ratio': 1.8394495412844036, 'no_speech_prob': 0.03466782718896866}, {'id': 410, 'seek': 265126, 'start': 2656.5400000000004, 'end': 2663.5800000000004, 'text': ' only one cycle. By mistake, I put two here. So, ignore that for the time being, okay. So, if I have', 'tokens': [50628, 787, 472, 6586, 13, 3146, 6146, 11, 286, 829, 732, 510, 13, 407, 11, 11200, 300, 337, 264, 565, 885, 11, 1392, 13, 407, 11, 498, 286, 362, 50980], 'temperature': 0.0, 'avg_logprob': -0.10665299757471625, 'compression_ratio': 1.8394495412844036, 'no_speech_prob': 0.03466782718896866}, {'id': 411, 'seek': 265126, 'start': 2663.5800000000004, 'end': 2671.1400000000003, 'text': ' one here and if I do this schedule, because I3 takes two cycles, I3 will only complete at the end', 'tokens': [50980, 472, 510, 293, 498, 286, 360, 341, 7567, 11, 570, 286, 18, 2516, 732, 17796, 11, 286, 18, 486, 787, 3566, 412, 264, 917, 51358], 'temperature': 0.0, 'avg_logprob': -0.10665299757471625, 'compression_ratio': 1.8394495412844036, 'no_speech_prob': 0.03466782718896866}, {'id': 412, 'seek': 265126, 'start': 2671.1400000000003, 'end': 2679.6200000000003, 'text': ' of the cycle and I4 can only start here, right. Whereas, if I do this schedule where I first schedule', 'tokens': [51358, 295, 264, 6586, 293, 286, 19, 393, 787, 722, 510, 11, 558, 13, 13813, 11, 498, 286, 360, 341, 7567, 689, 286, 700, 7567, 51782], 'temperature': 0.0, 'avg_logprob': -0.10665299757471625, 'compression_ratio': 1.8394495412844036, 'no_speech_prob': 0.03466782718896866}, {'id': 413, 'seek': 267962, 'start': 2679.7799999999997, 'end': 2687.8599999999997, 'text': ' I3 and then come back and schedule I2, right, by the time I2 finishes, I3 would have also finished,', 'tokens': [50372, 286, 18, 293, 550, 808, 646, 293, 7567, 286, 17, 11, 558, 11, 538, 264, 565, 286, 17, 23615, 11, 286, 18, 576, 362, 611, 4335, 11, 50776], 'temperature': 0.0, 'avg_logprob': -0.12032293279965718, 'compression_ratio': 1.748878923766816, 'no_speech_prob': 0.09346727281808853}, {'id': 414, 'seek': 267962, 'start': 2687.8599999999997, 'end': 2695.38, 'text': ' because I3 takes two cycles and I2 takes only one cycle. Therefore, I can now start I4 in the next', 'tokens': [50776, 570, 286, 18, 2516, 732, 17796, 293, 286, 17, 2516, 787, 472, 6586, 13, 7504, 11, 286, 393, 586, 722, 286, 19, 294, 264, 958, 51152], 'temperature': 0.0, 'avg_logprob': -0.12032293279965718, 'compression_ratio': 1.748878923766816, 'no_speech_prob': 0.09346727281808853}, {'id': 415, 'seek': 267962, 'start': 2695.38, 'end': 2700.9, 'text': ' cycle and this schedule would have resulted me only four cycles, whereas this one would have', 'tokens': [51152, 6586, 293, 341, 7567, 576, 362, 18753, 385, 787, 1451, 17796, 11, 9735, 341, 472, 576, 362, 51428], 'temperature': 0.0, 'avg_logprob': -0.12032293279965718, 'compression_ratio': 1.748878923766816, 'no_speech_prob': 0.09346727281808853}, {'id': 416, 'seek': 267962, 'start': 2700.9, 'end': 2706.74, 'text': ' resulted five cycles. So, the instruction reordering problem essentially says that the instruction', 'tokens': [51428, 18753, 1732, 17796, 13, 407, 11, 264, 10951, 319, 765, 1794, 1154, 4476, 1619, 300, 264, 10951, 51720], 'temperature': 0.0, 'avg_logprob': -0.12032293279965718, 'compression_ratio': 1.748878923766816, 'no_speech_prob': 0.09346727281808853}, {'id': 417, 'seek': 270674, 'start': 2706.74, 'end': 2717.7799999999997, 'text': ' order should be I1, I3, I2 and I4, correct. Okay. So, with that understanding, let us just move', 'tokens': [50364, 1668, 820, 312, 286, 16, 11, 286, 18, 11, 286, 17, 293, 286, 19, 11, 3006, 13, 1033, 13, 407, 11, 365, 300, 3701, 11, 718, 505, 445, 1286, 50916], 'temperature': 0.0, 'avg_logprob': -0.14841764401166868, 'compression_ratio': 1.4615384615384615, 'no_speech_prob': 0.1380797177553177}, {'id': 418, 'seek': 270674, 'start': 2717.7799999999997, 'end': 2724.14, 'text': ' forward. Okay. Again, this is the same idea, but let us just try to explain this also, okay.', 'tokens': [50916, 2128, 13, 1033, 13, 3764, 11, 341, 307, 264, 912, 1558, 11, 457, 718, 505, 445, 853, 281, 2903, 341, 611, 11, 1392, 13, 51234], 'temperature': 0.0, 'avg_logprob': -0.14841764401166868, 'compression_ratio': 1.4615384615384615, 'no_speech_prob': 0.1380797177553177}, {'id': 419, 'seek': 270674, 'start': 2724.14, 'end': 2731.2999999999997, 'text': ' I have taken another data dependence graph and in this example, instead of attaching the weights', 'tokens': [51234, 286, 362, 2726, 1071, 1412, 31704, 4295, 293, 294, 341, 1365, 11, 2602, 295, 39074, 264, 17443, 51592], 'temperature': 0.0, 'avg_logprob': -0.14841764401166868, 'compression_ratio': 1.4615384615384615, 'no_speech_prob': 0.1380797177553177}, {'id': 420, 'seek': 273130, 'start': 2731.3, 'end': 2739.0600000000004, 'text': ' to the nodes, I have attached the weights to the arcs. As I mentioned earlier, this representation', 'tokens': [50364, 281, 264, 13891, 11, 286, 362, 8570, 264, 17443, 281, 264, 10346, 82, 13, 1018, 286, 2835, 3071, 11, 341, 10290, 50752], 'temperature': 0.0, 'avg_logprob': -0.10444441901312934, 'compression_ratio': 1.857843137254902, 'no_speech_prob': 0.3346235454082489}, {'id': 421, 'seek': 273130, 'start': 2739.0600000000004, 'end': 2745.54, 'text': ' is useful only if the different arcs from the same node have different weights. Otherwise,', 'tokens': [50752, 307, 4420, 787, 498, 264, 819, 10346, 82, 490, 264, 912, 9984, 362, 819, 17443, 13, 10328, 11, 51076], 'temperature': 0.0, 'avg_logprob': -0.10444441901312934, 'compression_ratio': 1.857843137254902, 'no_speech_prob': 0.3346235454082489}, {'id': 422, 'seek': 273130, 'start': 2745.54, 'end': 2751.6600000000003, 'text': ' I could have attached it to the nodes itself. So, for example, if this takes one cycle and', 'tokens': [51076, 286, 727, 362, 8570, 309, 281, 264, 13891, 2564, 13, 407, 11, 337, 1365, 11, 498, 341, 2516, 472, 6586, 293, 51382], 'temperature': 0.0, 'avg_logprob': -0.10444441901312934, 'compression_ratio': 1.857843137254902, 'no_speech_prob': 0.3346235454082489}, {'id': 423, 'seek': 273130, 'start': 2751.6600000000003, 'end': 2757.7400000000002, 'text': ' this takes two cycles, then this representation is useful. But if both of them take only one cycle', 'tokens': [51382, 341, 2516, 732, 17796, 11, 550, 341, 10290, 307, 4420, 13, 583, 498, 1293, 295, 552, 747, 787, 472, 6586, 51686], 'temperature': 0.0, 'avg_logprob': -0.10444441901312934, 'compression_ratio': 1.857843137254902, 'no_speech_prob': 0.3346235454082489}, {'id': 424, 'seek': 275774, 'start': 2757.74, 'end': 2761.7799999999997, 'text': ' because both of them take only two cycles, then attaching weights would have been the', 'tokens': [50364, 570, 1293, 295, 552, 747, 787, 732, 17796, 11, 550, 39074, 17443, 576, 362, 668, 264, 50566], 'temperature': 0.0, 'avg_logprob': -0.22404590918093312, 'compression_ratio': 1.7068273092369477, 'no_speech_prob': 0.10979525744915009}, {'id': 425, 'seek': 275774, 'start': 2761.7799999999997, 'end': 2768.14, 'text': ' same thing, right. So, essentially we have a data dependence graph and the arcs represent', 'tokens': [50566, 912, 551, 11, 558, 13, 407, 11, 4476, 321, 362, 257, 1412, 31704, 4295, 293, 264, 10346, 82, 2906, 50884], 'temperature': 0.0, 'avg_logprob': -0.22404590918093312, 'compression_ratio': 1.7068273092369477, 'no_speech_prob': 0.10979525744915009}, {'id': 426, 'seek': 275774, 'start': 2768.14, 'end': 2776.3399999999997, 'text': ' dependence, right, from node I to node J, okay. And the edge weight or arc weight essentially', 'tokens': [50884, 31704, 11, 558, 11, 490, 9984, 286, 281, 9984, 508, 11, 1392, 13, 400, 264, 4691, 3364, 420, 10346, 3364, 4476, 51294], 'temperature': 0.0, 'avg_logprob': -0.22404590918093312, 'compression_ratio': 1.7068273092369477, 'no_speech_prob': 0.10979525744915009}, {'id': 427, 'seek': 275774, 'start': 2776.3399999999997, 'end': 2781.3399999999997, 'text': ' tells you how much time it takes for the node to produce the result.', 'tokens': [51294, 5112, 291, 577, 709, 565, 309, 2516, 337, 264, 9984, 281, 5258, 264, 1874, 13, 51544], 'temperature': 0.0, 'avg_logprob': -0.22404590918093312, 'compression_ratio': 1.7068273092369477, 'no_speech_prob': 0.10979525744915009}, {'id': 428, 'seek': 275774, 'start': 2781.3399999999997, 'end': 2786.4199999999996, 'text': ' Now the goal of instruction scheduling is to construct a schedule such that the length', 'tokens': [51544, 823, 264, 3387, 295, 10951, 29055, 307, 281, 7690, 257, 7567, 1270, 300, 264, 4641, 51798], 'temperature': 0.0, 'avg_logprob': -0.22404590918093312, 'compression_ratio': 1.7068273092369477, 'no_speech_prob': 0.10979525744915009}, {'id': 429, 'seek': 278642, 'start': 2786.42, 'end': 2791.54, 'text': ' of the schedule is minimized. And the length of the schedule is typically defined by what', 'tokens': [50364, 295, 264, 7567, 307, 4464, 1602, 13, 400, 264, 4641, 295, 264, 7567, 307, 5850, 7642, 538, 437, 50620], 'temperature': 0.0, 'avg_logprob': -0.17052138010660808, 'compression_ratio': 1.6484848484848484, 'no_speech_prob': 0.134717658162117}, {'id': 430, 'seek': 278642, 'start': 2791.54, 'end': 2797.78, 'text': ' is called the critical path, right, the path which takes the maximum amount of time, right.', 'tokens': [50620, 307, 1219, 264, 4924, 3100, 11, 558, 11, 264, 3100, 597, 2516, 264, 6674, 2372, 295, 565, 11, 558, 13, 50932], 'temperature': 0.0, 'avg_logprob': -0.17052138010660808, 'compression_ratio': 1.6484848484848484, 'no_speech_prob': 0.134717658162117}, {'id': 431, 'seek': 278642, 'start': 2797.78, 'end': 2809.06, 'text': ' So, in this example, right, 1, 3, 4, 6 would be the critical path if d 1 3 plus d 3 4 plus', 'tokens': [50932, 407, 11, 294, 341, 1365, 11, 558, 11, 502, 11, 805, 11, 1017, 11, 1386, 576, 312, 264, 4924, 3100, 498, 274, 502, 805, 1804, 274, 805, 1017, 1804, 51496], 'temperature': 0.0, 'avg_logprob': -0.17052138010660808, 'compression_ratio': 1.6484848484848484, 'no_speech_prob': 0.134717658162117}, {'id': 432, 'seek': 280906, 'start': 2809.7, 'end': 2820.7, 'text': ' 6 has a value which is greater than d 1 3 plus d 3 5 plus d 5 6 or d 1 2 plus d 2 6', 'tokens': [50396, 1386, 575, 257, 2158, 597, 307, 5044, 813, 274, 502, 805, 1804, 274, 805, 1025, 1804, 274, 1025, 1386, 420, 274, 502, 568, 1804, 274, 568, 1386, 50946], 'temperature': 0.0, 'avg_logprob': -0.16312854261283416, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.19912521541118622}, {'id': 433, 'seek': 280906, 'start': 2820.7, 'end': 2827.7, 'text': ' or d 1 2 plus d 2 4 plus d 4, right. So, you call this a critical path only if that path', 'tokens': [50946, 420, 274, 502, 568, 1804, 274, 568, 1017, 1804, 274, 1017, 11, 558, 13, 407, 11, 291, 818, 341, 257, 4924, 3100, 787, 498, 300, 3100, 51296], 'temperature': 0.0, 'avg_logprob': -0.16312854261283416, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.19912521541118622}, {'id': 434, 'seek': 280906, 'start': 2827.7, 'end': 2834.7, 'text': ' takes more amount of time. What do we mean by this? By this we say that if node 1 is', 'tokens': [51296, 2516, 544, 2372, 295, 565, 13, 708, 360, 321, 914, 538, 341, 30, 3146, 341, 321, 584, 300, 498, 9984, 502, 307, 51646], 'temperature': 0.0, 'avg_logprob': -0.16312854261283416, 'compression_ratio': 1.5670731707317074, 'no_speech_prob': 0.19912521541118622}, {'id': 435, 'seek': 283470, 'start': 2834.8599999999997, 'end': 2840.8999999999996, 'text': ' scheduled, for example, let us take some examples, right, supposing let us say this is 1, this', 'tokens': [50372, 15678, 11, 337, 1365, 11, 718, 505, 747, 512, 5110, 11, 558, 11, 1003, 6110, 718, 505, 584, 341, 307, 502, 11, 341, 50674], 'temperature': 0.0, 'avg_logprob': -0.24843154809413812, 'compression_ratio': 1.680722891566265, 'no_speech_prob': 0.031077507883310318}, {'id': 436, 'seek': 283470, 'start': 2840.8999999999996, 'end': 2849.8999999999996, 'text': ' is 5 and this is 3, okay. And let us just take all of the others as 1 just to make things', 'tokens': [50674, 307, 1025, 293, 341, 307, 805, 11, 1392, 13, 400, 718, 505, 445, 747, 439, 295, 264, 2357, 382, 502, 445, 281, 652, 721, 51124], 'temperature': 0.0, 'avg_logprob': -0.24843154809413812, 'compression_ratio': 1.680722891566265, 'no_speech_prob': 0.031077507883310318}, {'id': 437, 'seek': 283470, 'start': 2849.8999999999996, 'end': 2858.8999999999996, 'text': ' easier, right. Now see what happens, right. If this node is scheduled, if node 1 is scheduled,', 'tokens': [51124, 3571, 11, 558, 13, 823, 536, 437, 2314, 11, 558, 13, 759, 341, 9984, 307, 15678, 11, 498, 9984, 502, 307, 15678, 11, 51574], 'temperature': 0.0, 'avg_logprob': -0.24843154809413812, 'compression_ratio': 1.680722891566265, 'no_speech_prob': 0.031077507883310318}, {'id': 438, 'seek': 285890, 'start': 2859.9, 'end': 2866.9, 'text': ' right, at time step 0, node 3 can be scheduled at time step 1 and node 4 can be scheduled', 'tokens': [50414, 558, 11, 412, 565, 1823, 1958, 11, 9984, 805, 393, 312, 15678, 412, 565, 1823, 502, 293, 9984, 1017, 393, 312, 15678, 50764], 'temperature': 0.0, 'avg_logprob': -0.18416172971007644, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.011753499507904053}, {'id': 439, 'seek': 285890, 'start': 2867.3, 'end': 2874.3, 'text': ' at time step, yes, it depends on this also, correct, but the earliest it can be scheduled', 'tokens': [50784, 412, 565, 1823, 11, 2086, 11, 309, 5946, 322, 341, 611, 11, 3006, 11, 457, 264, 20573, 309, 393, 312, 15678, 51134], 'temperature': 0.0, 'avg_logprob': -0.18416172971007644, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.011753499507904053}, {'id': 440, 'seek': 285890, 'start': 2874.62, 'end': 2881.62, 'text': ' is 6, right, because this result is going to come no earlier than time step 6, okay.', 'tokens': [51150, 307, 1386, 11, 558, 11, 570, 341, 1874, 307, 516, 281, 808, 572, 3071, 813, 565, 1823, 1386, 11, 1392, 13, 51500], 'temperature': 0.0, 'avg_logprob': -0.18416172971007644, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.011753499507904053}, {'id': 441, 'seek': 285890, 'start': 2882.38, 'end': 2888.1, 'text': ' Let us assume that the other nodes get completed before that. And then what about this? What', 'tokens': [51538, 961, 505, 6552, 300, 264, 661, 13891, 483, 7365, 949, 300, 13, 400, 550, 437, 466, 341, 30, 708, 51824], 'temperature': 0.0, 'avg_logprob': -0.18416172971007644, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.011753499507904053}, {'id': 442, 'seek': 288810, 'start': 2888.1, 'end': 2895.1, 'text': ' about node 6? The earliest it is going to get scheduled is time step 9, correct. So,', 'tokens': [50364, 466, 9984, 1386, 30, 440, 20573, 309, 307, 516, 281, 483, 15678, 307, 565, 1823, 1722, 11, 3006, 13, 407, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.12660244719622887, 'compression_ratio': 1.8287671232876712, 'no_speech_prob': 0.005172380246222019}, {'id': 443, 'seek': 288810, 'start': 2896.22, 'end': 2903.22, 'text': ' this path takes 9 units of time, whereas this path takes only 2 units of time, this path', 'tokens': [50770, 341, 3100, 2516, 1722, 6815, 295, 565, 11, 9735, 341, 3100, 2516, 787, 568, 6815, 295, 565, 11, 341, 3100, 51120], 'temperature': 0.0, 'avg_logprob': -0.12660244719622887, 'compression_ratio': 1.8287671232876712, 'no_speech_prob': 0.005172380246222019}, {'id': 444, 'seek': 288810, 'start': 2903.66, 'end': 2910.66, 'text': ' takes 5 units of time, this path takes 3 units of time. So, this is the critical path, right.', 'tokens': [51142, 2516, 1025, 6815, 295, 565, 11, 341, 3100, 2516, 805, 6815, 295, 565, 13, 407, 11, 341, 307, 264, 4924, 3100, 11, 558, 13, 51492], 'temperature': 0.0, 'avg_logprob': -0.12660244719622887, 'compression_ratio': 1.8287671232876712, 'no_speech_prob': 0.005172380246222019}, {'id': 445, 'seek': 291066, 'start': 2911.66, 'end': 2918.66, 'text': ' And what does the critical path tell you? Critical path tells you that these nodes are', 'tokens': [50414, 400, 437, 775, 264, 4924, 3100, 980, 291, 30, 39482, 3100, 5112, 291, 300, 613, 13891, 366, 50764], 'temperature': 0.0, 'avg_logprob': -0.11878508399514591, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.019260261207818985}, {'id': 446, 'seek': 291066, 'start': 2918.66, 'end': 2925.22, 'text': ' important nodes, do not delay scheduling them, correct. If you delay any of these nodes by', 'tokens': [50764, 1021, 13891, 11, 360, 406, 8577, 29055, 552, 11, 3006, 13, 759, 291, 8577, 604, 295, 613, 13891, 538, 51092], 'temperature': 0.0, 'avg_logprob': -0.11878508399514591, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.019260261207818985}, {'id': 447, 'seek': 291066, 'start': 2925.22, 'end': 2931.8599999999997, 'text': ' one cycle, what happens to your critical path length? It increases by 1, because this node', 'tokens': [51092, 472, 6586, 11, 437, 2314, 281, 428, 4924, 3100, 4641, 30, 467, 8637, 538, 502, 11, 570, 341, 9984, 51424], 'temperature': 0.0, 'avg_logprob': -0.11878508399514591, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.019260261207818985}, {'id': 448, 'seek': 291066, 'start': 2931.8599999999997, 'end': 2937.8599999999997, 'text': ' is going to finish later. Whereas if you delay this node or this node, it may not matter', 'tokens': [51424, 307, 516, 281, 2413, 1780, 13, 13813, 498, 291, 8577, 341, 9984, 420, 341, 9984, 11, 309, 815, 406, 1871, 51724], 'temperature': 0.0, 'avg_logprob': -0.11878508399514591, 'compression_ratio': 1.7586206896551724, 'no_speech_prob': 0.019260261207818985}, {'id': 449, 'seek': 293786, 'start': 2937.86, 'end': 2944.86, 'text': ' that much, correct, because you have some buffer amount of time, right. This is how', 'tokens': [50364, 300, 709, 11, 3006, 11, 570, 291, 362, 512, 21762, 2372, 295, 565, 11, 558, 13, 639, 307, 577, 50714], 'temperature': 0.0, 'avg_logprob': -0.1877546077821313, 'compression_ratio': 1.6778846153846154, 'no_speech_prob': 0.024360354989767075}, {'id': 450, 'seek': 293786, 'start': 2945.5, 'end': 2951.46, 'text': ' you schedule your work, right. So, that is essentially what is being done in this. So,', 'tokens': [50746, 291, 7567, 428, 589, 11, 558, 13, 407, 11, 300, 307, 4476, 437, 307, 885, 1096, 294, 341, 13, 407, 11, 51044], 'temperature': 0.0, 'avg_logprob': -0.1877546077821313, 'compression_ratio': 1.6778846153846154, 'no_speech_prob': 0.024360354989767075}, {'id': 451, 'seek': 293786, 'start': 2951.46, 'end': 2955.98, 'text': ' when we talk about instruction scheduling, we will always talk about this critical path', 'tokens': [51044, 562, 321, 751, 466, 10951, 29055, 11, 321, 486, 1009, 751, 466, 341, 4924, 3100, 51270], 'temperature': 0.0, 'avg_logprob': -0.1877546077821313, 'compression_ratio': 1.6778846153846154, 'no_speech_prob': 0.024360354989767075}, {'id': 452, 'seek': 293786, 'start': 2955.98, 'end': 2961.42, 'text': ' either directly or indirectly and try to make sure that the nodes on the critical path are', 'tokens': [51270, 2139, 3838, 420, 37779, 293, 853, 281, 652, 988, 300, 264, 13891, 322, 264, 4924, 3100, 366, 51542], 'temperature': 0.0, 'avg_logprob': -0.1877546077821313, 'compression_ratio': 1.6778846153846154, 'no_speech_prob': 0.024360354989767075}, {'id': 453, 'seek': 296142, 'start': 2962.06, 'end': 2966.42, 'text': ' scheduled as soon as possible without delaying them, right.', 'tokens': [50396, 15678, 382, 2321, 382, 1944, 1553, 8577, 278, 552, 11, 558, 13, 50614], 'temperature': 0.0, 'avg_logprob': -0.23316083980512015, 'compression_ratio': 1.62, 'no_speech_prob': 0.040613774210214615}, {'id': 454, 'seek': 296142, 'start': 2966.42, 'end': 2973.42, 'text': ' Okay, so the heuristic series scheduler is going to do the following things. You construct', 'tokens': [50614, 1033, 11, 370, 264, 415, 374, 3142, 2638, 12000, 260, 307, 516, 281, 360, 264, 3480, 721, 13, 509, 7690, 50964], 'temperature': 0.0, 'avg_logprob': -0.23316083980512015, 'compression_ratio': 1.62, 'no_speech_prob': 0.040613774210214615}, {'id': 455, 'seek': 296142, 'start': 2973.46, 'end': 2980.46, 'text': ' the data dependence graph and for all the nodes in the dependence graph, okay, you want', 'tokens': [50966, 264, 1412, 31704, 4295, 293, 337, 439, 264, 13891, 294, 264, 31704, 4295, 11, 1392, 11, 291, 528, 51316], 'temperature': 0.0, 'avg_logprob': -0.23316083980512015, 'compression_ratio': 1.62, 'no_speech_prob': 0.040613774210214615}, {'id': 456, 'seek': 296142, 'start': 2980.58, 'end': 2985.02, 'text': ' to schedule them. You can have some kind of a rank function. We will discuss what the', 'tokens': [51322, 281, 7567, 552, 13, 509, 393, 362, 512, 733, 295, 257, 6181, 2445, 13, 492, 486, 2248, 437, 264, 51544], 'temperature': 0.0, 'avg_logprob': -0.23316083980512015, 'compression_ratio': 1.62, 'no_speech_prob': 0.040613774210214615}, {'id': 457, 'seek': 298502, 'start': 2985.02, 'end': 2991.34, 'text': ' rank function is little later, okay, but right, but then you basically try to schedule', 'tokens': [50364, 6181, 2445, 307, 707, 1780, 11, 1392, 11, 457, 558, 11, 457, 550, 291, 1936, 853, 281, 7567, 50680], 'temperature': 0.0, 'avg_logprob': -0.15063173037308913, 'compression_ratio': 1.8583690987124464, 'no_speech_prob': 0.022090012207627296}, {'id': 458, 'seek': 298502, 'start': 2991.34, 'end': 2996.54, 'text': ' the nodes based on this rank function. The rank function could be either the node is', 'tokens': [50680, 264, 13891, 2361, 322, 341, 6181, 2445, 13, 440, 6181, 2445, 727, 312, 2139, 264, 9984, 307, 50940], 'temperature': 0.0, 'avg_logprob': -0.15063173037308913, 'compression_ratio': 1.8583690987124464, 'no_speech_prob': 0.022090012207627296}, {'id': 459, 'seek': 298502, 'start': 2996.54, 'end': 3001.7, 'text': ' critical or non-critical. Critical nodes are given more priority than the non-critical', 'tokens': [50940, 4924, 420, 2107, 12, 32255, 804, 13, 39482, 13891, 366, 2212, 544, 9365, 813, 264, 2107, 12, 32255, 804, 51198], 'temperature': 0.0, 'avg_logprob': -0.15063173037308913, 'compression_ratio': 1.8583690987124464, 'no_speech_prob': 0.022090012207627296}, {'id': 460, 'seek': 298502, 'start': 3001.7, 'end': 3008.06, 'text': ' nodes, right. Now, for each instruction j, what you do is that you make sure that how', 'tokens': [51198, 13891, 11, 558, 13, 823, 11, 337, 1184, 10951, 361, 11, 437, 291, 360, 307, 300, 291, 652, 988, 300, 577, 51516], 'temperature': 0.0, 'avg_logprob': -0.15063173037308913, 'compression_ratio': 1.8583690987124464, 'no_speech_prob': 0.022090012207627296}, {'id': 461, 'seek': 298502, 'start': 3008.06, 'end': 3012.58, 'text': ' many instructions on which it is dependent on. That is basically what we call the number', 'tokens': [51516, 867, 9415, 322, 597, 309, 307, 12334, 322, 13, 663, 307, 1936, 437, 321, 818, 264, 1230, 51742], 'temperature': 0.0, 'avg_logprob': -0.15063173037308913, 'compression_ratio': 1.8583690987124464, 'no_speech_prob': 0.022090012207627296}, {'id': 462, 'seek': 301258, 'start': 3012.58, 'end': 3019.58, 'text': ' of predecessors, right. Until all of those nodes finish, you cannot schedule j, right.', 'tokens': [50364, 295, 24874, 45700, 11, 558, 13, 9088, 439, 295, 729, 13891, 2413, 11, 291, 2644, 7567, 361, 11, 558, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.20700847270876863, 'compression_ratio': 1.7135922330097086, 'no_speech_prob': 0.028662459924817085}, {'id': 463, 'seek': 301258, 'start': 3019.98, 'end': 3025.74, 'text': ' So, you do all of this preparatory work and then you start your instruction scheduling.', 'tokens': [50734, 407, 11, 291, 360, 439, 295, 341, 8231, 4745, 589, 293, 550, 291, 722, 428, 10951, 29055, 13, 51022], 'temperature': 0.0, 'avg_logprob': -0.20700847270876863, 'compression_ratio': 1.7135922330097086, 'no_speech_prob': 0.028662459924817085}, {'id': 464, 'seek': 301258, 'start': 3025.74, 'end': 3031.9, 'text': ' First, you schedule all the nodes which has predecessor count equal to 0. That means that', 'tokens': [51022, 2386, 11, 291, 7567, 439, 264, 13891, 597, 575, 34991, 1207, 2681, 281, 1958, 13, 663, 1355, 300, 51330], 'temperature': 0.0, 'avg_logprob': -0.20700847270876863, 'compression_ratio': 1.7135922330097086, 'no_speech_prob': 0.028662459924817085}, {'id': 465, 'seek': 301258, 'start': 3031.9, 'end': 3037.9, 'text': ' these are the what we call as the root nodes or the start nodes in your program. They do', 'tokens': [51330, 613, 366, 264, 437, 321, 818, 382, 264, 5593, 13891, 420, 264, 722, 13891, 294, 428, 1461, 13, 814, 360, 51630], 'temperature': 0.0, 'avg_logprob': -0.20700847270876863, 'compression_ratio': 1.7135922330097086, 'no_speech_prob': 0.028662459924817085}, {'id': 466, 'seek': 303790, 'start': 3038.02, 'end': 3044.54, 'text': ' not have any dependencies. They can be scheduled in the initial cycle, right and as and when', 'tokens': [50370, 406, 362, 604, 36606, 13, 814, 393, 312, 15678, 294, 264, 5883, 6586, 11, 558, 293, 382, 293, 562, 50696], 'temperature': 0.0, 'avg_logprob': -0.17938492033216688, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.12280002236366272}, {'id': 467, 'seek': 303790, 'start': 3044.54, 'end': 3051.54, 'text': ' you schedule them, you make sure that their successors are decremented. The successor', 'tokens': [50696, 291, 7567, 552, 11, 291, 652, 988, 300, 641, 2245, 830, 366, 6853, 14684, 13, 440, 31864, 51046], 'temperature': 0.0, 'avg_logprob': -0.17938492033216688, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.12280002236366272}, {'id': 468, 'seek': 303790, 'start': 3051.54, 'end': 3055.86, 'text': ' predecessor counts are decremented which is being done by this. Of course, you need to', 'tokens': [51046, 34991, 14893, 366, 6853, 14684, 597, 307, 885, 1096, 538, 341, 13, 2720, 1164, 11, 291, 643, 281, 51262], 'temperature': 0.0, 'avg_logprob': -0.17938492033216688, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.12280002236366272}, {'id': 469, 'seek': 303790, 'start': 3055.86, 'end': 3061.2200000000003, 'text': ' do this only for the at the appropriate time, but in this example we will not really worry', 'tokens': [51262, 360, 341, 787, 337, 264, 412, 264, 6854, 565, 11, 457, 294, 341, 1365, 321, 486, 406, 534, 3292, 51530], 'temperature': 0.0, 'avg_logprob': -0.17938492033216688, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.12280002236366272}, {'id': 470, 'seek': 303790, 'start': 3061.2200000000003, 'end': 3065.42, 'text': ' about that too much. Let us assume that all of them have one cycle or so. So, it can be', 'tokens': [51530, 466, 300, 886, 709, 13, 961, 505, 6552, 300, 439, 295, 552, 362, 472, 6586, 420, 370, 13, 407, 11, 309, 393, 312, 51740], 'temperature': 0.0, 'avg_logprob': -0.17938492033216688, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.12280002236366272}, {'id': 471, 'seek': 306542, 'start': 3065.42, 'end': 3072.42, 'text': ' immediately decremented, okay. So, you schedule j and then you continue you kind of update', 'tokens': [50364, 4258, 6853, 14684, 11, 1392, 13, 407, 11, 291, 7567, 361, 293, 550, 291, 2354, 291, 733, 295, 5623, 50714], 'temperature': 0.0, 'avg_logprob': -0.19486676729642427, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.028645938262343407}, {'id': 472, 'seek': 306542, 'start': 3072.94, 'end': 3079.38, 'text': ' all its successors, their predecessor counts and as and when there are more instructions', 'tokens': [50740, 439, 1080, 2245, 830, 11, 641, 34991, 14893, 293, 382, 293, 562, 456, 366, 544, 9415, 51062], 'temperature': 0.0, 'avg_logprob': -0.19486676729642427, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.028645938262343407}, {'id': 473, 'seek': 306542, 'start': 3079.38, 'end': 3084.9, 'text': ' in your ready queue, you start doing this. And when you pick a ready instruction, you', 'tokens': [51062, 294, 428, 1919, 18639, 11, 291, 722, 884, 341, 13, 400, 562, 291, 1888, 257, 1919, 10951, 11, 291, 51338], 'temperature': 0.0, 'avg_logprob': -0.19486676729642427, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.028645938262343407}, {'id': 474, 'seek': 306542, 'start': 3084.9, 'end': 3090.66, 'text': ' always pick the ready instruction based on some priority which could be critical versus', 'tokens': [51338, 1009, 1888, 264, 1919, 10951, 2361, 322, 512, 9365, 597, 727, 312, 4924, 5717, 51626], 'temperature': 0.0, 'avg_logprob': -0.19486676729642427, 'compression_ratio': 1.6729857819905214, 'no_speech_prob': 0.028645938262343407}, {'id': 475, 'seek': 309066, 'start': 3090.66, 'end': 3097.42, 'text': ' non-critical, right. That is really what you do. These functions for doing update of predecessor', 'tokens': [50364, 2107, 12, 32255, 804, 11, 558, 13, 663, 307, 534, 437, 291, 360, 13, 1981, 6828, 337, 884, 5623, 295, 34991, 50702], 'temperature': 0.0, 'avg_logprob': -0.21728116458224267, 'compression_ratio': 1.8502202643171806, 'no_speech_prob': 0.15421918034553528}, {'id': 476, 'seek': 309066, 'start': 3097.42, 'end': 3103.06, 'text': ' count is that basically you look at all successor and for every successor, you decrement its', 'tokens': [50702, 1207, 307, 300, 1936, 291, 574, 412, 439, 31864, 293, 337, 633, 31864, 11, 291, 6853, 518, 1080, 50984], 'temperature': 0.0, 'avg_logprob': -0.21728116458224267, 'compression_ratio': 1.8502202643171806, 'no_speech_prob': 0.15421918034553528}, {'id': 477, 'seek': 309066, 'start': 3103.06, 'end': 3108.62, 'text': ' predecessor count by 1. That is really what it is and if the predecessor count of that', 'tokens': [50984, 34991, 1207, 538, 502, 13, 663, 307, 534, 437, 309, 307, 293, 498, 264, 34991, 1207, 295, 300, 51262], 'temperature': 0.0, 'avg_logprob': -0.21728116458224267, 'compression_ratio': 1.8502202643171806, 'no_speech_prob': 0.15421918034553528}, {'id': 478, 'seek': 309066, 'start': 3108.62, 'end': 3114.2599999999998, 'text': ' node becomes 0, you can put it into the ready list, okay.', 'tokens': [51262, 9984, 3643, 1958, 11, 291, 393, 829, 309, 666, 264, 1919, 1329, 11, 1392, 13, 51544], 'temperature': 0.0, 'avg_logprob': -0.21728116458224267, 'compression_ratio': 1.8502202643171806, 'no_speech_prob': 0.15421918034553528}, {'id': 479, 'seek': 309066, 'start': 3114.2599999999998, 'end': 3119.14, 'text': ' This simple scheduling essentially has an order m squared complexity because at every', 'tokens': [51544, 639, 2199, 29055, 4476, 575, 364, 1668, 275, 8889, 14024, 570, 412, 633, 51788], 'temperature': 0.0, 'avg_logprob': -0.21728116458224267, 'compression_ratio': 1.8502202643171806, 'no_speech_prob': 0.15421918034553528}, {'id': 480, 'seek': 311914, 'start': 3119.22, 'end': 3123.46, 'text': ' step you need to kind of look at this all other things. So, it is an n squared complexity', 'tokens': [50368, 1823, 291, 643, 281, 733, 295, 574, 412, 341, 439, 661, 721, 13, 407, 11, 309, 307, 364, 297, 8889, 14024, 50580], 'temperature': 0.0, 'avg_logprob': -0.19913774066501194, 'compression_ratio': 1.757936507936508, 'no_speech_prob': 0.021230509504675865}, {'id': 481, 'seek': 311914, 'start': 3123.46, 'end': 3130.46, 'text': ' algorithm, right. And even constructing the DDG where you try to find out sorry where', 'tokens': [50580, 9284, 11, 558, 13, 400, 754, 39969, 264, 30778, 38, 689, 291, 853, 281, 915, 484, 2597, 689, 50930], 'temperature': 0.0, 'avg_logprob': -0.19913774066501194, 'compression_ratio': 1.757936507936508, 'no_speech_prob': 0.021230509504675865}, {'id': 482, 'seek': 311914, 'start': 3131.3799999999997, 'end': 3135.8199999999997, 'text': ' you try to find out whether a node has a dependence to any other node, you essentially have to', 'tokens': [50976, 291, 853, 281, 915, 484, 1968, 257, 9984, 575, 257, 31704, 281, 604, 661, 9984, 11, 291, 4476, 362, 281, 51198], 'temperature': 0.0, 'avg_logprob': -0.19913774066501194, 'compression_ratio': 1.757936507936508, 'no_speech_prob': 0.021230509504675865}, {'id': 483, 'seek': 311914, 'start': 3135.8199999999997, 'end': 3142.58, 'text': ' consider all node to every other node in the graph. So, it has a complexity of order n', 'tokens': [51198, 1949, 439, 9984, 281, 633, 661, 9984, 294, 264, 4295, 13, 407, 11, 309, 575, 257, 14024, 295, 1668, 297, 51536], 'temperature': 0.0, 'avg_logprob': -0.19913774066501194, 'compression_ratio': 1.757936507936508, 'no_speech_prob': 0.021230509504675865}, {'id': 484, 'seek': 311914, 'start': 3142.58, 'end': 3148.2999999999997, 'text': ' squared in the worst case. An interesting result which was proved in 1987 is that the', 'tokens': [51536, 8889, 294, 264, 5855, 1389, 13, 1107, 1880, 1874, 597, 390, 14617, 294, 29008, 307, 300, 264, 51822], 'temperature': 0.0, 'avg_logprob': -0.19913774066501194, 'compression_ratio': 1.757936507936508, 'no_speech_prob': 0.021230509504675865}, {'id': 485, 'seek': 314830, 'start': 3148.3, 'end': 3153.98, 'text': ' heuristic scheduling that you try to do is always within a factor of 2 from the optimal', 'tokens': [50364, 415, 374, 3142, 29055, 300, 291, 853, 281, 360, 307, 1009, 1951, 257, 5952, 295, 568, 490, 264, 16252, 50648], 'temperature': 0.0, 'avg_logprob': -0.15614748430681658, 'compression_ratio': 1.7272727272727273, 'no_speech_prob': 0.008128376677632332}, {'id': 486, 'seek': 314830, 'start': 3153.98, 'end': 3158.98, 'text': ' schedule. That means that you will never ever do worse than the 2 times the best schedule.', 'tokens': [50648, 7567, 13, 663, 1355, 300, 291, 486, 1128, 1562, 360, 5324, 813, 264, 568, 1413, 264, 1151, 7567, 13, 50898], 'temperature': 0.0, 'avg_logprob': -0.15614748430681658, 'compression_ratio': 1.7272727272727273, 'no_speech_prob': 0.008128376677632332}, {'id': 487, 'seek': 314830, 'start': 3158.98, 'end': 3164.98, 'text': ' But let us not worry about it. We want to do as good as the best schedule, okay.', 'tokens': [50898, 583, 718, 505, 406, 3292, 466, 309, 13, 492, 528, 281, 360, 382, 665, 382, 264, 1151, 7567, 11, 1392, 13, 51198], 'temperature': 0.0, 'avg_logprob': -0.15614748430681658, 'compression_ratio': 1.7272727272727273, 'no_speech_prob': 0.008128376677632332}, {'id': 488, 'seek': 314830, 'start': 3164.98, 'end': 3171.98, 'text': ' Now, let us talk about one kind of a rank function for nodes. We said that one possibility', 'tokens': [51198, 823, 11, 718, 505, 751, 466, 472, 733, 295, 257, 6181, 2445, 337, 13891, 13, 492, 848, 300, 472, 7959, 51548], 'temperature': 0.0, 'avg_logprob': -0.15614748430681658, 'compression_ratio': 1.7272727272727273, 'no_speech_prob': 0.008128376677632332}, {'id': 489, 'seek': 314830, 'start': 3172.82, 'end': 3178.02, 'text': ' is critical node versus non-critical node. That is more like a binary decision, right.', 'tokens': [51590, 307, 4924, 9984, 5717, 2107, 12, 32255, 804, 9984, 13, 663, 307, 544, 411, 257, 17434, 3537, 11, 558, 13, 51850], 'temperature': 0.0, 'avg_logprob': -0.15614748430681658, 'compression_ratio': 1.7272727272727273, 'no_speech_prob': 0.008128376677632332}, {'id': 490, 'seek': 317802, 'start': 3178.02, 'end': 3181.94, 'text': ' But we can do something better than that and that is typically decided by what is', 'tokens': [50364, 583, 321, 393, 360, 746, 1101, 813, 300, 293, 300, 307, 5850, 3047, 538, 437, 307, 50560], 'temperature': 0.0, 'avg_logprob': -0.16199664842514766, 'compression_ratio': 1.8688524590163935, 'no_speech_prob': 0.005010041408240795}, {'id': 491, 'seek': 317802, 'start': 3181.94, 'end': 3188.94, 'text': ' called the earliest start time and the latest start time, right. So, let us define these', 'tokens': [50560, 1219, 264, 20573, 722, 565, 293, 264, 6792, 722, 565, 11, 558, 13, 407, 11, 718, 505, 6964, 613, 50910], 'temperature': 0.0, 'avg_logprob': -0.16199664842514766, 'compression_ratio': 1.8688524590163935, 'no_speech_prob': 0.005010041408240795}, {'id': 492, 'seek': 317802, 'start': 3189.62, 'end': 3196.62, 'text': ' two functions, one called EST and the other called LST, latest start time, right. Let', 'tokens': [50944, 732, 6828, 11, 472, 1219, 47140, 293, 264, 661, 1219, 441, 6840, 11, 6792, 722, 565, 11, 558, 13, 961, 51294], 'temperature': 0.0, 'avg_logprob': -0.16199664842514766, 'compression_ratio': 1.8688524590163935, 'no_speech_prob': 0.005010041408240795}, {'id': 493, 'seek': 317802, 'start': 3197.18, 'end': 3203.74, 'text': ' us see what it is. The earliest start time, okay, is essentially the earliest time in', 'tokens': [51322, 505, 536, 437, 309, 307, 13, 440, 20573, 722, 565, 11, 1392, 11, 307, 4476, 264, 20573, 565, 294, 51650], 'temperature': 0.0, 'avg_logprob': -0.16199664842514766, 'compression_ratio': 1.8688524590163935, 'no_speech_prob': 0.005010041408240795}, {'id': 494, 'seek': 320374, 'start': 3203.74, 'end': 3210.74, 'text': ' which a node can be executed. That means that for the start node, it is 0 because all', 'tokens': [50364, 597, 257, 9984, 393, 312, 17577, 13, 663, 1355, 300, 337, 264, 722, 9984, 11, 309, 307, 1958, 570, 439, 50714], 'temperature': 0.0, 'avg_logprob': -0.15081204924472544, 'compression_ratio': 1.763819095477387, 'no_speech_prob': 0.013202894479036331}, {'id': 495, 'seek': 320374, 'start': 3211.02, 'end': 3218.02, 'text': ' the root nodes can be started to start with. But then for any other node, it is the start', 'tokens': [50728, 264, 5593, 13891, 393, 312, 1409, 281, 722, 365, 13, 583, 550, 337, 604, 661, 9984, 11, 309, 307, 264, 722, 51078], 'temperature': 0.0, 'avg_logprob': -0.15081204924472544, 'compression_ratio': 1.763819095477387, 'no_speech_prob': 0.013202894479036331}, {'id': 496, 'seek': 320374, 'start': 3218.02, 'end': 3225.02, 'text': ' time, earliest start time of its predecessor plus that node weight. But then among all', 'tokens': [51078, 565, 11, 20573, 722, 565, 295, 1080, 34991, 1804, 300, 9984, 3364, 13, 583, 550, 3654, 439, 51428], 'temperature': 0.0, 'avg_logprob': -0.15081204924472544, 'compression_ratio': 1.763819095477387, 'no_speech_prob': 0.013202894479036331}, {'id': 497, 'seek': 320374, 'start': 3225.2999999999997, 'end': 3229.3399999999997, 'text': ' these nodes, you should take the one which is giving you the maximum because it can have', 'tokens': [51442, 613, 13891, 11, 291, 820, 747, 264, 472, 597, 307, 2902, 291, 264, 6674, 570, 309, 393, 362, 51644], 'temperature': 0.0, 'avg_logprob': -0.15081204924472544, 'compression_ratio': 1.763819095477387, 'no_speech_prob': 0.013202894479036331}, {'id': 498, 'seek': 322934, 'start': 3229.34, 'end': 3236.34, 'text': ' multiple predecessors. Whichever predecessor which gets executed last, that completion', 'tokens': [50364, 3866, 24874, 45700, 13, 3013, 1054, 34991, 597, 2170, 17577, 1036, 11, 300, 19372, 50714], 'temperature': 0.0, 'avg_logprob': -0.20084473638251277, 'compression_ratio': 1.8798283261802575, 'no_speech_prob': 0.015456411987543106}, {'id': 499, 'seek': 322934, 'start': 3236.78, 'end': 3241.9, 'text': ' plus its completion time, not necessarily scheduled last, but scheduled plus its completion', 'tokens': [50736, 1804, 1080, 19372, 565, 11, 406, 4725, 15678, 1036, 11, 457, 15678, 1804, 1080, 19372, 50992], 'temperature': 0.0, 'avg_logprob': -0.20084473638251277, 'compression_ratio': 1.8798283261802575, 'no_speech_prob': 0.015456411987543106}, {'id': 500, 'seek': 322934, 'start': 3241.9, 'end': 3246.26, 'text': ' time, whichever one which has the greater value, that is the one which dictates how', 'tokens': [50992, 565, 11, 24123, 472, 597, 575, 264, 5044, 2158, 11, 300, 307, 264, 472, 597, 12569, 1024, 577, 51210], 'temperature': 0.0, 'avg_logprob': -0.20084473638251277, 'compression_ratio': 1.8798283261802575, 'no_speech_prob': 0.015456411987543106}, {'id': 501, 'seek': 322934, 'start': 3246.26, 'end': 3251.06, 'text': ' soon this node can be started, right. So, that is the earliest start time. I will give', 'tokens': [51210, 2321, 341, 9984, 393, 312, 1409, 11, 558, 13, 407, 11, 300, 307, 264, 20573, 722, 565, 13, 286, 486, 976, 51450], 'temperature': 0.0, 'avg_logprob': -0.20084473638251277, 'compression_ratio': 1.8798283261802575, 'no_speech_prob': 0.015456411987543106}, {'id': 502, 'seek': 322934, 'start': 3251.06, 'end': 3255.46, 'text': ' you an example in the next slide. So, do not worry. You will understand that better. The', 'tokens': [51450, 291, 364, 1365, 294, 264, 958, 4137, 13, 407, 11, 360, 406, 3292, 13, 509, 486, 1223, 300, 1101, 13, 440, 51670], 'temperature': 0.0, 'avg_logprob': -0.20084473638251277, 'compression_ratio': 1.8798283261802575, 'no_speech_prob': 0.015456411987543106}, {'id': 503, 'seek': 325546, 'start': 3255.46, 'end': 3260.42, 'text': ' latest start time is actually the reverse of that, right. If I am, if I want to schedule', 'tokens': [50364, 6792, 722, 565, 307, 767, 264, 9943, 295, 300, 11, 558, 13, 759, 286, 669, 11, 498, 286, 528, 281, 7567, 50612], 'temperature': 0.0, 'avg_logprob': -0.1334570839291527, 'compression_ratio': 1.9217391304347826, 'no_speech_prob': 0.016464823856949806}, {'id': 504, 'seek': 325546, 'start': 3260.42, 'end': 3266.14, 'text': ' this node as late as possible, but still meet the overall critical path length, how late', 'tokens': [50612, 341, 9984, 382, 3469, 382, 1944, 11, 457, 920, 1677, 264, 4787, 4924, 3100, 4641, 11, 577, 3469, 50898], 'temperature': 0.0, 'avg_logprob': -0.1334570839291527, 'compression_ratio': 1.9217391304347826, 'no_speech_prob': 0.016464823856949806}, {'id': 505, 'seek': 325546, 'start': 3266.14, 'end': 3271.54, 'text': ' can I schedule? That is really what is the latest start time. And to compute the latest', 'tokens': [50898, 393, 286, 7567, 30, 663, 307, 534, 437, 307, 264, 6792, 722, 565, 13, 400, 281, 14722, 264, 6792, 51168], 'temperature': 0.0, 'avg_logprob': -0.1334570839291527, 'compression_ratio': 1.9217391304347826, 'no_speech_prob': 0.016464823856949806}, {'id': 506, 'seek': 325546, 'start': 3271.54, 'end': 3275.98, 'text': ' start time, what you do is that you first compute the critical path length. Critical', 'tokens': [51168, 722, 565, 11, 437, 291, 360, 307, 300, 291, 700, 14722, 264, 4924, 3100, 4641, 13, 39482, 51390], 'temperature': 0.0, 'avg_logprob': -0.1334570839291527, 'compression_ratio': 1.9217391304347826, 'no_speech_prob': 0.016464823856949806}, {'id': 507, 'seek': 325546, 'start': 3275.98, 'end': 3282.98, 'text': ' path length is essentially the earliest start time of a node, okay, plus its execution time', 'tokens': [51390, 3100, 4641, 307, 4476, 264, 20573, 722, 565, 295, 257, 9984, 11, 1392, 11, 1804, 1080, 15058, 565, 51740], 'temperature': 0.0, 'avg_logprob': -0.1334570839291527, 'compression_ratio': 1.9217391304347826, 'no_speech_prob': 0.016464823856949806}, {'id': 508, 'seek': 328298, 'start': 3283.9, 'end': 3290.9, 'text': ' across all nodes. That is the completion time. And that completion time is same as the start', 'tokens': [50410, 2108, 439, 13891, 13, 663, 307, 264, 19372, 565, 13, 400, 300, 19372, 565, 307, 912, 382, 264, 722, 50760], 'temperature': 0.0, 'avg_logprob': -0.1579041009420877, 'compression_ratio': 1.8883248730964468, 'no_speech_prob': 0.012983403168618679}, {'id': 509, 'seek': 328298, 'start': 3290.9, 'end': 3296.54, 'text': ' time of the end node, which is our fictitious end node. But let us call this as the completion', 'tokens': [50760, 565, 295, 264, 917, 9984, 11, 597, 307, 527, 283, 985, 16401, 917, 9984, 13, 583, 718, 505, 818, 341, 382, 264, 19372, 51042], 'temperature': 0.0, 'avg_logprob': -0.1579041009420877, 'compression_ratio': 1.8883248730964468, 'no_speech_prob': 0.012983403168618679}, {'id': 510, 'seek': 328298, 'start': 3296.54, 'end': 3303.54, 'text': ' time. Then what you do is that for every node, you say that the latest start time is basically', 'tokens': [51042, 565, 13, 1396, 437, 291, 360, 307, 300, 337, 633, 9984, 11, 291, 584, 300, 264, 6792, 722, 565, 307, 1936, 51392], 'temperature': 0.0, 'avg_logprob': -0.1579041009420877, 'compression_ratio': 1.8883248730964468, 'no_speech_prob': 0.012983403168618679}, {'id': 511, 'seek': 328298, 'start': 3303.82, 'end': 3310.82, 'text': ' the minimum of the latest start time of its successor minus the weight of this node. That', 'tokens': [51406, 264, 7285, 295, 264, 6792, 722, 565, 295, 1080, 31864, 3175, 264, 3364, 295, 341, 9984, 13, 663, 51756], 'temperature': 0.0, 'avg_logprob': -0.1579041009420877, 'compression_ratio': 1.8883248730964468, 'no_speech_prob': 0.012983403168618679}, {'id': 512, 'seek': 331082, 'start': 3311.82, 'end': 3318.82, 'text': ' is, if that node has to start at time t, I have a weight of 2, then I must at least start', 'tokens': [50414, 307, 11, 498, 300, 9984, 575, 281, 722, 412, 565, 256, 11, 286, 362, 257, 3364, 295, 568, 11, 550, 286, 1633, 412, 1935, 722, 50764], 'temperature': 0.0, 'avg_logprob': -0.1274394502445143, 'compression_ratio': 1.672811059907834, 'no_speech_prob': 0.006905173882842064}, {'id': 513, 'seek': 331082, 'start': 3320.5, 'end': 3327.2200000000003, 'text': ' t minus 2 cycles before. That is really what you do. And if you, if that node has, sorry,', 'tokens': [50848, 256, 3175, 568, 17796, 949, 13, 663, 307, 534, 437, 291, 360, 13, 400, 498, 291, 11, 498, 300, 9984, 575, 11, 2597, 11, 51184], 'temperature': 0.0, 'avg_logprob': -0.1274394502445143, 'compression_ratio': 1.672811059907834, 'no_speech_prob': 0.006905173882842064}, {'id': 514, 'seek': 331082, 'start': 3327.2200000000003, 'end': 3333.1000000000004, 'text': ' if you have multiple such successors, then among all of them, whichever one is the minimum,', 'tokens': [51184, 498, 291, 362, 3866, 1270, 2245, 830, 11, 550, 3654, 439, 295, 552, 11, 24123, 472, 307, 264, 7285, 11, 51478], 'temperature': 0.0, 'avg_logprob': -0.1274394502445143, 'compression_ratio': 1.672811059907834, 'no_speech_prob': 0.006905173882842064}, {'id': 515, 'seek': 331082, 'start': 3333.1000000000004, 'end': 3337.54, 'text': ' that is the latest start you can do. Because if you delay it further, potentially you might', 'tokens': [51478, 300, 307, 264, 6792, 722, 291, 393, 360, 13, 1436, 498, 291, 8577, 309, 3052, 11, 7263, 291, 1062, 51700], 'temperature': 0.0, 'avg_logprob': -0.1274394502445143, 'compression_ratio': 1.672811059907834, 'no_speech_prob': 0.006905173882842064}, {'id': 516, 'seek': 333754, 'start': 3337.54, 'end': 3341.46, 'text': ' be affecting the critical path. That is really what it is.', 'tokens': [50364, 312, 17476, 264, 4924, 3100, 13, 663, 307, 534, 437, 309, 307, 13, 50560], 'temperature': 0.0, 'avg_logprob': -0.20782055457433066, 'compression_ratio': 1.8141592920353982, 'no_speech_prob': 0.010276238434016705}, {'id': 517, 'seek': 333754, 'start': 3341.46, 'end': 3346.86, 'text': ' So, we will give you examples of this. Rank is essentially the difference between the', 'tokens': [50560, 407, 11, 321, 486, 976, 291, 5110, 295, 341, 13, 35921, 307, 4476, 264, 2649, 1296, 264, 50830], 'temperature': 0.0, 'avg_logprob': -0.20782055457433066, 'compression_ratio': 1.8141592920353982, 'no_speech_prob': 0.010276238434016705}, {'id': 518, 'seek': 333754, 'start': 3346.86, 'end': 3352.7799999999997, 'text': ' latest start time and the earliest start time. If the rank is 0, that means it should be', 'tokens': [50830, 6792, 722, 565, 293, 264, 20573, 722, 565, 13, 759, 264, 6181, 307, 1958, 11, 300, 1355, 309, 820, 312, 51126], 'temperature': 0.0, 'avg_logprob': -0.20782055457433066, 'compression_ratio': 1.8141592920353982, 'no_speech_prob': 0.010276238434016705}, {'id': 519, 'seek': 333754, 'start': 3352.7799999999997, 'end': 3359.7799999999997, 'text': ' given very high priority because there is no slack between its earliest start time and', 'tokens': [51126, 2212, 588, 1090, 9365, 570, 456, 307, 572, 29767, 1296, 1080, 20573, 722, 565, 293, 51476], 'temperature': 0.0, 'avg_logprob': -0.20782055457433066, 'compression_ratio': 1.8141592920353982, 'no_speech_prob': 0.010276238434016705}, {'id': 520, 'seek': 333754, 'start': 3359.7799999999997, 'end': 3365.7799999999997, 'text': ' its latest start time. Only critical nodes in the critical path will have slack 0, right.', 'tokens': [51476, 1080, 6792, 722, 565, 13, 5686, 4924, 13891, 294, 264, 4924, 3100, 486, 362, 29767, 1958, 11, 558, 13, 51776], 'temperature': 0.0, 'avg_logprob': -0.20782055457433066, 'compression_ratio': 1.8141592920353982, 'no_speech_prob': 0.010276238434016705}, {'id': 521, 'seek': 336578, 'start': 3366.38, 'end': 3370.9, 'text': ' And when you have slack 0 for the nodes on the critical path, you essentially say that', 'tokens': [50394, 400, 562, 291, 362, 29767, 1958, 337, 264, 13891, 322, 264, 4924, 3100, 11, 291, 4476, 584, 300, 50620], 'temperature': 0.0, 'avg_logprob': -0.17637162459524056, 'compression_ratio': 1.7370517928286853, 'no_speech_prob': 0.004883813671767712}, {'id': 522, 'seek': 336578, 'start': 3370.9, 'end': 3375.9, 'text': ' they have to be scheduled as soon as possible, right, and they have no slack. And that is', 'tokens': [50620, 436, 362, 281, 312, 15678, 382, 2321, 382, 1944, 11, 558, 11, 293, 436, 362, 572, 29767, 13, 400, 300, 307, 50870], 'temperature': 0.0, 'avg_logprob': -0.17637162459524056, 'compression_ratio': 1.7370517928286853, 'no_speech_prob': 0.004883813671767712}, {'id': 523, 'seek': 336578, 'start': 3375.9, 'end': 3380.9, 'text': ' why they have higher priority. So, let us, let us see the same example. I have taken', 'tokens': [50870, 983, 436, 362, 2946, 9365, 13, 407, 11, 718, 505, 11, 718, 505, 536, 264, 912, 1365, 13, 286, 362, 2726, 51120], 'temperature': 0.0, 'avg_logprob': -0.17637162459524056, 'compression_ratio': 1.7370517928286853, 'no_speech_prob': 0.004883813671767712}, {'id': 524, 'seek': 336578, 'start': 3380.9, 'end': 3387.9, 'text': ' the same graph, okay, and here correctly I have put the weight as 1, thankfully, right.', 'tokens': [51120, 264, 912, 4295, 11, 1392, 11, 293, 510, 8944, 286, 362, 829, 264, 3364, 382, 502, 11, 27352, 11, 558, 13, 51470], 'temperature': 0.0, 'avg_logprob': -0.17637162459524056, 'compression_ratio': 1.7370517928286853, 'no_speech_prob': 0.004883813671767712}, {'id': 525, 'seek': 336578, 'start': 3388.02, 'end': 3393.6200000000003, 'text': ' And then I have introduced two fictitious nodes, start and end, right. There is an arc', 'tokens': [51476, 400, 550, 286, 362, 7268, 732, 283, 985, 16401, 13891, 11, 722, 293, 917, 11, 558, 13, 821, 307, 364, 10346, 51756], 'temperature': 0.0, 'avg_logprob': -0.17637162459524056, 'compression_ratio': 1.7370517928286853, 'no_speech_prob': 0.004883813671767712}, {'id': 526, 'seek': 339362, 'start': 3393.62, 'end': 3398.42, 'text': ' from the start node to every node, but here I have only shown it to the first node, right,', 'tokens': [50364, 490, 264, 722, 9984, 281, 633, 9984, 11, 457, 510, 286, 362, 787, 4898, 309, 281, 264, 700, 9984, 11, 558, 11, 50604], 'temperature': 0.0, 'avg_logprob': -0.1589694341023763, 'compression_ratio': 1.838174273858921, 'no_speech_prob': 0.0485699437558651}, {'id': 527, 'seek': 339362, 'start': 3398.42, 'end': 3403.62, 'text': ' but you can actually put it. Similarly, there is an arc from every node to the end node,', 'tokens': [50604, 457, 291, 393, 767, 829, 309, 13, 13157, 11, 456, 307, 364, 10346, 490, 633, 9984, 281, 264, 917, 9984, 11, 50864], 'temperature': 0.0, 'avg_logprob': -0.1589694341023763, 'compression_ratio': 1.838174273858921, 'no_speech_prob': 0.0485699437558651}, {'id': 528, 'seek': 339362, 'start': 3403.62, 'end': 3407.98, 'text': ' but I have only shown it for this just for the sake of clarity. You will see how that', 'tokens': [50864, 457, 286, 362, 787, 4898, 309, 337, 341, 445, 337, 264, 9717, 295, 16992, 13, 509, 486, 536, 577, 300, 51082], 'temperature': 0.0, 'avg_logprob': -0.1589694341023763, 'compression_ratio': 1.838174273858921, 'no_speech_prob': 0.0485699437558651}, {'id': 529, 'seek': 339362, 'start': 3407.98, 'end': 3414.98, 'text': " doesn't really matter. Now, this node can start at time t 0, right. Its earliest start", 'tokens': [51082, 1177, 380, 534, 1871, 13, 823, 11, 341, 9984, 393, 722, 412, 565, 256, 1958, 11, 558, 13, 6953, 20573, 722, 51432], 'temperature': 0.0, 'avg_logprob': -0.1589694341023763, 'compression_ratio': 1.838174273858921, 'no_speech_prob': 0.0485699437558651}, {'id': 530, 'seek': 339362, 'start': 3415.54, 'end': 3421.94, 'text': ' time is 0, okay, right. Because this is the first node, it can start at time 0. What about', 'tokens': [51460, 565, 307, 1958, 11, 1392, 11, 558, 13, 1436, 341, 307, 264, 700, 9984, 11, 309, 393, 722, 412, 565, 1958, 13, 708, 466, 51780], 'temperature': 0.0, 'avg_logprob': -0.1589694341023763, 'compression_ratio': 1.838174273858921, 'no_speech_prob': 0.0485699437558651}, {'id': 531, 'seek': 342194, 'start': 3421.98, 'end': 3428.06, 'text': ' this one? What would be its earliest start time? If this starts at 0, this can start', 'tokens': [50366, 341, 472, 30, 708, 576, 312, 1080, 20573, 722, 565, 30, 759, 341, 3719, 412, 1958, 11, 341, 393, 722, 50670], 'temperature': 0.0, 'avg_logprob': -0.17066426026193718, 'compression_ratio': 1.6883116883116882, 'no_speech_prob': 0.011811433359980583}, {'id': 532, 'seek': 342194, 'start': 3428.06, 'end': 3435.06, 'text': ' at 1, right. What about this one? That can also start at 1, right. What about this one?', 'tokens': [50670, 412, 502, 11, 558, 13, 708, 466, 341, 472, 30, 663, 393, 611, 722, 412, 502, 11, 558, 13, 708, 466, 341, 472, 30, 51020], 'temperature': 0.0, 'avg_logprob': -0.17066426026193718, 'compression_ratio': 1.6883116883116882, 'no_speech_prob': 0.011811433359980583}, {'id': 533, 'seek': 342194, 'start': 3440.02, 'end': 3447.02, 'text': ' 3, because 1 plus 1 is 2, whereas 1 plus 2 is 3 and I have to take the maximum of these', 'tokens': [51268, 805, 11, 570, 502, 1804, 502, 307, 568, 11, 9735, 502, 1804, 568, 307, 805, 293, 286, 362, 281, 747, 264, 6674, 295, 613, 51618], 'temperature': 0.0, 'avg_logprob': -0.17066426026193718, 'compression_ratio': 1.6883116883116882, 'no_speech_prob': 0.011811433359980583}, {'id': 534, 'seek': 344702, 'start': 3448.02, 'end': 3455.02, 'text': ' two things. So, let us see whether it calculates these things correctly, right. It does, right.', 'tokens': [50414, 732, 721, 13, 407, 11, 718, 505, 536, 1968, 309, 4322, 1024, 613, 721, 8944, 11, 558, 13, 467, 775, 11, 558, 13, 50764], 'temperature': 0.0, 'avg_logprob': -0.15349549362339923, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.012686047703027725}, {'id': 535, 'seek': 344702, 'start': 3455.54, 'end': 3460.46, 'text': ' And then I say that the earliest start time of end, which is same as the maximum of all', 'tokens': [50790, 400, 550, 286, 584, 300, 264, 20573, 722, 565, 295, 917, 11, 597, 307, 912, 382, 264, 6674, 295, 439, 51036], 'temperature': 0.0, 'avg_logprob': -0.15349549362339923, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.012686047703027725}, {'id': 536, 'seek': 344702, 'start': 3460.46, 'end': 3467.46, 'text': ' of these things, well, this completes at 4. So, this is 4, right. Now, from here I am', 'tokens': [51036, 295, 613, 721, 11, 731, 11, 341, 36362, 412, 1017, 13, 407, 11, 341, 307, 1017, 11, 558, 13, 823, 11, 490, 510, 286, 669, 51386], 'temperature': 0.0, 'avg_logprob': -0.15349549362339923, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.012686047703027725}, {'id': 537, 'seek': 344702, 'start': 3467.54, 'end': 3474.34, 'text': ' going to work backward to compute the latest start time. If this has to complete at 4,', 'tokens': [51390, 516, 281, 589, 23897, 281, 14722, 264, 6792, 722, 565, 13, 759, 341, 575, 281, 3566, 412, 1017, 11, 51730], 'temperature': 0.0, 'avg_logprob': -0.15349549362339923, 'compression_ratio': 1.6713615023474178, 'no_speech_prob': 0.012686047703027725}, {'id': 538, 'seek': 347434, 'start': 3474.34, 'end': 3481.34, 'text': " this must start at 3, otherwise it won't complete at 4. If this has to start at 3,", 'tokens': [50364, 341, 1633, 722, 412, 805, 11, 5911, 309, 1582, 380, 3566, 412, 1017, 13, 759, 341, 575, 281, 722, 412, 805, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.10454140981038411, 'compression_ratio': 1.72, 'no_speech_prob': 0.014340567402541637}, {'id': 539, 'seek': 347434, 'start': 3483.1400000000003, 'end': 3490.1400000000003, 'text': ' what about this one? This has to start at least at 2, because this has only one latency.', 'tokens': [50804, 437, 466, 341, 472, 30, 639, 575, 281, 722, 412, 1935, 412, 568, 11, 570, 341, 575, 787, 472, 27043, 13, 51154], 'temperature': 0.0, 'avg_logprob': -0.10454140981038411, 'compression_ratio': 1.72, 'no_speech_prob': 0.014340567402541637}, {'id': 540, 'seek': 347434, 'start': 3490.1800000000003, 'end': 3497.1800000000003, 'text': ' What about this one? It has to be 1, right. So, its latest start time is 1. What about', 'tokens': [51156, 708, 466, 341, 472, 30, 467, 575, 281, 312, 502, 11, 558, 13, 407, 11, 1080, 6792, 722, 565, 307, 502, 13, 708, 466, 51506], 'temperature': 0.0, 'avg_logprob': -0.10454140981038411, 'compression_ratio': 1.72, 'no_speech_prob': 0.014340567402541637}, {'id': 541, 'seek': 349718, 'start': 3498.18, 'end': 3504.66, 'text': ' this node? This latest start time is 1, this latest start time is 2. Let us start from', 'tokens': [50414, 341, 9984, 30, 639, 6792, 722, 565, 307, 502, 11, 341, 6792, 722, 565, 307, 568, 13, 961, 505, 722, 490, 50738], 'temperature': 0.0, 'avg_logprob': -0.14555404663085938, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.018306922167539597}, {'id': 542, 'seek': 349718, 'start': 3504.66, 'end': 3511.66, 'text': ' here. This 2 minus 1, this says that the latest start time is 1, right. Whereas, if I take', 'tokens': [50738, 510, 13, 639, 568, 3175, 502, 11, 341, 1619, 300, 264, 6792, 722, 565, 307, 502, 11, 558, 13, 13813, 11, 498, 286, 747, 51088], 'temperature': 0.0, 'avg_logprob': -0.14555404663085938, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.018306922167539597}, {'id': 543, 'seek': 349718, 'start': 3513.22, 'end': 3518.46, 'text': ' this 1 minus 1, what does it say about its latest start time? 0. Since for the latest', 'tokens': [51166, 341, 502, 3175, 502, 11, 437, 775, 309, 584, 466, 1080, 6792, 722, 565, 30, 1958, 13, 4162, 337, 264, 6792, 51428], 'temperature': 0.0, 'avg_logprob': -0.14555404663085938, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.018306922167539597}, {'id': 544, 'seek': 349718, 'start': 3518.46, 'end': 3523.46, 'text': ' start time I have to take the minimum of the two, I will take this as 0. So, let us see', 'tokens': [51428, 722, 565, 286, 362, 281, 747, 264, 7285, 295, 264, 732, 11, 286, 486, 747, 341, 382, 1958, 13, 407, 11, 718, 505, 536, 51678], 'temperature': 0.0, 'avg_logprob': -0.14555404663085938, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.018306922167539597}, {'id': 545, 'seek': 352346, 'start': 3523.46, 'end': 3530.46, 'text': ' what happens. CPL is 4, LST is 0. So, these are the values that we have calculated, right.', 'tokens': [50364, 437, 2314, 13, 383, 21593, 307, 1017, 11, 441, 6840, 307, 1958, 13, 407, 11, 613, 366, 264, 4190, 300, 321, 362, 15598, 11, 558, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.19469517546814757, 'compression_ratio': 1.8027210884353742, 'no_speech_prob': 0.012931997887790203}, {'id': 546, 'seek': 352346, 'start': 3534.18, 'end': 3541.18, 'text': ' So, let us say for node 1, the earliest start time and the latest start time are both 0.', 'tokens': [50900, 407, 11, 718, 505, 584, 337, 9984, 502, 11, 264, 20573, 722, 565, 293, 264, 6792, 722, 565, 366, 1293, 1958, 13, 51250], 'temperature': 0.0, 'avg_logprob': -0.19469517546814757, 'compression_ratio': 1.8027210884353742, 'no_speech_prob': 0.012931997887790203}, {'id': 547, 'seek': 352346, 'start': 3544.38, 'end': 3551.38, 'text': ' For node 3, the earliest start time and the latest start time are both 1. For node 4,', 'tokens': [51410, 1171, 9984, 805, 11, 264, 20573, 722, 565, 293, 264, 6792, 722, 565, 366, 1293, 502, 13, 1171, 9984, 1017, 11, 51760], 'temperature': 0.0, 'avg_logprob': -0.19469517546814757, 'compression_ratio': 1.8027210884353742, 'no_speech_prob': 0.012931997887790203}, {'id': 548, 'seek': 355138, 'start': 3552.38, 'end': 3559.38, 'text': ' the earliest start time and the latest start time is 3. Which is the critical path here?', 'tokens': [50414, 264, 20573, 722, 565, 293, 264, 6792, 722, 565, 307, 805, 13, 3013, 307, 264, 4924, 3100, 510, 30, 50764], 'temperature': 0.0, 'avg_logprob': -0.16414702733357747, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.007413561921566725}, {'id': 549, 'seek': 355138, 'start': 3559.7400000000002, 'end': 3565.46, 'text': ' This is the critical path, right, because that is the one which takes maximum amount', 'tokens': [50782, 639, 307, 264, 4924, 3100, 11, 558, 11, 570, 300, 307, 264, 472, 597, 2516, 6674, 2372, 51068], 'temperature': 0.0, 'avg_logprob': -0.16414702733357747, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.007413561921566725}, {'id': 550, 'seek': 355138, 'start': 3565.46, 'end': 3571.9, 'text': ' of time. This is not the critical path, because on this path if I add the weights of all the', 'tokens': [51068, 295, 565, 13, 639, 307, 406, 264, 4924, 3100, 11, 570, 322, 341, 3100, 498, 286, 909, 264, 17443, 295, 439, 264, 51390], 'temperature': 0.0, 'avg_logprob': -0.16414702733357747, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.007413561921566725}, {'id': 551, 'seek': 355138, 'start': 3571.9, 'end': 3577.02, 'text': ' nodes, it is only 3. Whereas, if I add the weights of all the nodes here, the weight', 'tokens': [51390, 13891, 11, 309, 307, 787, 805, 13, 13813, 11, 498, 286, 909, 264, 17443, 295, 439, 264, 13891, 510, 11, 264, 3364, 51646], 'temperature': 0.0, 'avg_logprob': -0.16414702733357747, 'compression_ratio': 1.9943181818181819, 'no_speech_prob': 0.007413561921566725}, {'id': 552, 'seek': 357702, 'start': 3577.02, 'end': 3583.86, 'text': ' is 4, correct. So, for the nodes which are on the critical path, the earliest start time', 'tokens': [50364, 307, 1017, 11, 3006, 13, 407, 11, 337, 264, 13891, 597, 366, 322, 264, 4924, 3100, 11, 264, 20573, 722, 565, 50706], 'temperature': 0.0, 'avg_logprob': -0.13179452078683035, 'compression_ratio': 1.6635071090047393, 'no_speech_prob': 0.012715104036033154}, {'id': 553, 'seek': 357702, 'start': 3583.86, 'end': 3590.38, 'text': ' and the latest start time would be same. And because they are the same, the rank value', 'tokens': [50706, 293, 264, 6792, 722, 565, 576, 312, 912, 13, 400, 570, 436, 366, 264, 912, 11, 264, 6181, 2158, 51032], 'temperature': 0.0, 'avg_logprob': -0.13179452078683035, 'compression_ratio': 1.6635071090047393, 'no_speech_prob': 0.012715104036033154}, {'id': 554, 'seek': 357702, 'start': 3590.38, 'end': 3597.38, 'text': ' for them are 0. Whereas, for all the other nodes, the rank will be greater than 0. Now,', 'tokens': [51032, 337, 552, 366, 1958, 13, 13813, 11, 337, 439, 264, 661, 13891, 11, 264, 6181, 486, 312, 5044, 813, 1958, 13, 823, 11, 51382], 'temperature': 0.0, 'avg_logprob': -0.13179452078683035, 'compression_ratio': 1.6635071090047393, 'no_speech_prob': 0.012715104036033154}, {'id': 555, 'seek': 357702, 'start': 3598.66, 'end': 3603.22, 'text': ' at any point in time when you have multiple ready nodes, you can choose the nodes based', 'tokens': [51446, 412, 604, 935, 294, 565, 562, 291, 362, 3866, 1919, 13891, 11, 291, 393, 2826, 264, 13891, 2361, 51674], 'temperature': 0.0, 'avg_logprob': -0.13179452078683035, 'compression_ratio': 1.6635071090047393, 'no_speech_prob': 0.012715104036033154}, {'id': 556, 'seek': 360322, 'start': 3603.22, 'end': 3609.18, 'text': ' on the rank. The ones which have the lowest rank can be chosen first. If you have multiple', 'tokens': [50364, 322, 264, 6181, 13, 440, 2306, 597, 362, 264, 12437, 6181, 393, 312, 8614, 700, 13, 759, 291, 362, 3866, 50662], 'temperature': 0.0, 'avg_logprob': -0.18384555705542704, 'compression_ratio': 1.7020408163265306, 'no_speech_prob': 0.016521262004971504}, {'id': 557, 'seek': 360322, 'start': 3609.18, 'end': 3614.62, 'text': ' nodes and you can only schedule one of them, the ones with higher priority will get scheduled,', 'tokens': [50662, 13891, 293, 291, 393, 787, 7567, 472, 295, 552, 11, 264, 2306, 365, 2946, 9365, 486, 483, 15678, 11, 50934], 'temperature': 0.0, 'avg_logprob': -0.18384555705542704, 'compression_ratio': 1.7020408163265306, 'no_speech_prob': 0.016521262004971504}, {'id': 558, 'seek': 360322, 'start': 3614.62, 'end': 3619.62, 'text': ' the others will be delayed. That is really how it goes.', 'tokens': [50934, 264, 2357, 486, 312, 20268, 13, 663, 307, 534, 577, 309, 1709, 13, 51184], 'temperature': 0.0, 'avg_logprob': -0.18384555705542704, 'compression_ratio': 1.7020408163265306, 'no_speech_prob': 0.016521262004971504}, {'id': 559, 'seek': 360322, 'start': 3619.62, 'end': 3625.3799999999997, 'text': ' So, that is as far as the serial schedule is concerned. We will now move on to more', 'tokens': [51184, 407, 11, 300, 307, 382, 1400, 382, 264, 17436, 7567, 307, 5922, 13, 492, 486, 586, 1286, 322, 281, 544, 51472], 'temperature': 0.0, 'avg_logprob': -0.18384555705542704, 'compression_ratio': 1.7020408163265306, 'no_speech_prob': 0.016521262004971504}, {'id': 560, 'seek': 360322, 'start': 3625.3799999999997, 'end': 3632.3799999999997, 'text': ' interesting things like the parallel schedule, multiple ALUs, VLIW architectures and so on,', 'tokens': [51472, 1880, 721, 411, 264, 8952, 7567, 11, 3866, 7056, 29211, 11, 691, 48718, 54, 6331, 1303, 293, 370, 322, 11, 51822], 'temperature': 0.0, 'avg_logprob': -0.18384555705542704, 'compression_ratio': 1.7020408163265306, 'no_speech_prob': 0.016521262004971504}, {'id': 561, 'seek': 363322, 'start': 3633.54, 'end': 3640.54, 'text': ' so here this problem essentially becomes an important problem because you now have M resources,', 'tokens': [50380, 370, 510, 341, 1154, 4476, 3643, 364, 1021, 1154, 570, 291, 586, 362, 376, 3593, 11, 50730], 'temperature': 0.0, 'avg_logprob': -0.18930795192718505, 'compression_ratio': 1.736842105263158, 'no_speech_prob': 0.005094381049275398}, {'id': 562, 'seek': 363322, 'start': 3640.54, 'end': 3645.5, 'text': ' a machine with M identical. Let us say to start off with identical resources, then we', 'tokens': [50730, 257, 3479, 365, 376, 14800, 13, 961, 505, 584, 281, 722, 766, 365, 14800, 3593, 11, 550, 321, 50978], 'temperature': 0.0, 'avg_logprob': -0.18930795192718505, 'compression_ratio': 1.736842105263158, 'no_speech_prob': 0.005094381049275398}, {'id': 563, 'seek': 363322, 'start': 3645.5, 'end': 3652.5, 'text': ' will talk about different types of resources and so on, right. If I have M identical resources', 'tokens': [50978, 486, 751, 466, 819, 3467, 295, 3593, 293, 370, 322, 11, 558, 13, 759, 286, 362, 376, 14800, 3593, 51328], 'temperature': 0.0, 'avg_logprob': -0.18930795192718505, 'compression_ratio': 1.736842105263158, 'no_speech_prob': 0.005094381049275398}, {'id': 564, 'seek': 363322, 'start': 3652.58, 'end': 3658.62, 'text': ' and I want to schedule these things, right, then that particular problem for M greater', 'tokens': [51332, 293, 286, 528, 281, 7567, 613, 721, 11, 558, 11, 550, 300, 1729, 1154, 337, 376, 5044, 51634], 'temperature': 0.0, 'avg_logprob': -0.18930795192718505, 'compression_ratio': 1.736842105263158, 'no_speech_prob': 0.005094381049275398}, {'id': 565, 'seek': 365862, 'start': 3658.62, 'end': 3663.9, 'text': ' than or equal to 3 is NP complete. This is again what is called the job stop scheduling', 'tokens': [50364, 813, 420, 2681, 281, 805, 307, 38611, 3566, 13, 639, 307, 797, 437, 307, 1219, 264, 1691, 1590, 29055, 50628], 'temperature': 0.0, 'avg_logprob': -0.20488051005772182, 'compression_ratio': 1.6227272727272728, 'no_speech_prob': 0.08234056085348129}, {'id': 566, 'seek': 365862, 'start': 3663.9, 'end': 3670.9, 'text': ' problem, okay. I will try to explain some notions here before we move further.', 'tokens': [50628, 1154, 11, 1392, 13, 286, 486, 853, 281, 2903, 512, 35799, 510, 949, 321, 1286, 3052, 13, 50978], 'temperature': 0.0, 'avg_logprob': -0.20488051005772182, 'compression_ratio': 1.6227272727272728, 'no_speech_prob': 0.08234056085348129}, {'id': 567, 'seek': 365862, 'start': 3671.14, 'end': 3677.7, 'text': ' So let us try to write down something, right. This notion of what are called identical function', 'tokens': [50990, 407, 718, 505, 853, 281, 2464, 760, 746, 11, 558, 13, 639, 10710, 295, 437, 366, 1219, 14800, 2445, 51318], 'temperature': 0.0, 'avg_logprob': -0.20488051005772182, 'compression_ratio': 1.6227272727272728, 'no_speech_prob': 0.08234056085348129}, {'id': 568, 'seek': 365862, 'start': 3677.7, 'end': 3684.7, 'text': ' units and clean pipeline, right. So, two things that we talked about, identical function units', 'tokens': [51318, 6815, 293, 2541, 15517, 11, 558, 13, 407, 11, 732, 721, 300, 321, 2825, 466, 11, 14800, 2445, 6815, 51668], 'temperature': 0.0, 'avg_logprob': -0.20488051005772182, 'compression_ratio': 1.6227272727272728, 'no_speech_prob': 0.08234056085348129}, {'id': 569, 'seek': 368470, 'start': 3685.2599999999998, 'end': 3692.2599999999998, 'text': ' and clean pipeline, okay. First of all, let us just talk about pipeline function unit.', 'tokens': [50392, 293, 2541, 15517, 11, 1392, 13, 2386, 295, 439, 11, 718, 505, 445, 751, 466, 15517, 2445, 4985, 13, 50742], 'temperature': 0.0, 'avg_logprob': -0.20128486156463624, 'compression_ratio': 1.898936170212766, 'no_speech_prob': 0.020849863067269325}, {'id': 570, 'seek': 368470, 'start': 3692.2599999999998, 'end': 3699.2599999999998, 'text': ' We say a function unit is pipeline, okay. If every cycle you can put an operation into', 'tokens': [50742, 492, 584, 257, 2445, 4985, 307, 15517, 11, 1392, 13, 759, 633, 6586, 291, 393, 829, 364, 6916, 666, 51092], 'temperature': 0.0, 'avg_logprob': -0.20128486156463624, 'compression_ratio': 1.898936170212766, 'no_speech_prob': 0.020849863067269325}, {'id': 571, 'seek': 368470, 'start': 3700.06, 'end': 3707.06, 'text': ' it and now we are talking about function units, not just the instruction execution pipeline.', 'tokens': [51132, 309, 293, 586, 321, 366, 1417, 466, 2445, 6815, 11, 406, 445, 264, 10951, 15058, 15517, 13, 51482], 'temperature': 0.0, 'avg_logprob': -0.20128486156463624, 'compression_ratio': 1.898936170212766, 'no_speech_prob': 0.020849863067269325}, {'id': 572, 'seek': 368470, 'start': 3707.54, 'end': 3711.7, 'text': ' Remember that in the instruction execution pipeline, you have the instruction fetch phase,', 'tokens': [51506, 5459, 300, 294, 264, 10951, 15058, 15517, 11, 291, 362, 264, 10951, 23673, 5574, 11, 51714], 'temperature': 0.0, 'avg_logprob': -0.20128486156463624, 'compression_ratio': 1.898936170212766, 'no_speech_prob': 0.020849863067269325}, {'id': 573, 'seek': 371170, 'start': 3711.7, 'end': 3717.54, 'text': ' the decode phase and then the execute phase. The execute phase is essentially what corresponds', 'tokens': [50364, 264, 979, 1429, 5574, 293, 550, 264, 14483, 5574, 13, 440, 14483, 5574, 307, 4476, 437, 23249, 50656], 'temperature': 0.0, 'avg_logprob': -0.17869335750363907, 'compression_ratio': 2.022421524663677, 'no_speech_prob': 0.002814275911077857}, {'id': 574, 'seek': 371170, 'start': 3717.54, 'end': 3722.7, 'text': ' to the function unit. If you have an add instruction, maybe there is a simple add function unit.', 'tokens': [50656, 281, 264, 2445, 4985, 13, 759, 291, 362, 364, 909, 10951, 11, 1310, 456, 307, 257, 2199, 909, 2445, 4985, 13, 50914], 'temperature': 0.0, 'avg_logprob': -0.17869335750363907, 'compression_ratio': 2.022421524663677, 'no_speech_prob': 0.002814275911077857}, {'id': 575, 'seek': 371170, 'start': 3722.7, 'end': 3728.4199999999996, 'text': ' If you have a multiply, then you have a integer multiply function unit. If you have, let us', 'tokens': [50914, 759, 291, 362, 257, 12972, 11, 550, 291, 362, 257, 24922, 12972, 2445, 4985, 13, 759, 291, 362, 11, 718, 505, 51200], 'temperature': 0.0, 'avg_logprob': -0.17869335750363907, 'compression_ratio': 2.022421524663677, 'no_speech_prob': 0.002814275911077857}, {'id': 576, 'seek': 371170, 'start': 3728.4199999999996, 'end': 3733.06, 'text': ' say a floating point add, you have a floating point function unit and so on. In the superscalar', 'tokens': [51200, 584, 257, 12607, 935, 909, 11, 291, 362, 257, 12607, 935, 2445, 4985, 293, 370, 322, 13, 682, 264, 37906, 9895, 289, 51432], 'temperature': 0.0, 'avg_logprob': -0.17869335750363907, 'compression_ratio': 2.022421524663677, 'no_speech_prob': 0.002814275911077857}, {'id': 577, 'seek': 371170, 'start': 3733.06, 'end': 3737.1, 'text': ' architecture, we saw these things as different functional units, right.', 'tokens': [51432, 9482, 11, 321, 1866, 613, 721, 382, 819, 11745, 6815, 11, 558, 13, 51634], 'temperature': 0.0, 'avg_logprob': -0.17869335750363907, 'compression_ratio': 2.022421524663677, 'no_speech_prob': 0.002814275911077857}, {'id': 578, 'seek': 373710, 'start': 3737.1, 'end': 3742.18, 'text': ' So these functional units again depending on what they perform may take one or more', 'tokens': [50364, 407, 613, 11745, 6815, 797, 5413, 322, 437, 436, 2042, 815, 747, 472, 420, 544, 50618], 'temperature': 0.0, 'avg_logprob': -0.15931233395351452, 'compression_ratio': 1.662037037037037, 'no_speech_prob': 0.026813779026269913}, {'id': 579, 'seek': 373710, 'start': 3742.18, 'end': 3747.8199999999997, 'text': ' cycles. If you want, I can quickly show you. So, each one of these function units depending', 'tokens': [50618, 17796, 13, 759, 291, 528, 11, 286, 393, 2661, 855, 291, 13, 407, 11, 1184, 472, 295, 613, 2445, 6815, 5413, 50900], 'temperature': 0.0, 'avg_logprob': -0.15931233395351452, 'compression_ratio': 1.662037037037037, 'no_speech_prob': 0.026813779026269913}, {'id': 580, 'seek': 373710, 'start': 3747.8199999999997, 'end': 3754.8199999999997, 'text': ' on, okay. So, they may take multiple time steps to complete, but if it is fully pipelined,', 'tokens': [50900, 322, 11, 1392, 13, 407, 11, 436, 815, 747, 3866, 565, 4439, 281, 3566, 11, 457, 498, 309, 307, 4498, 8489, 338, 2001, 11, 51250], 'temperature': 0.0, 'avg_logprob': -0.15931233395351452, 'compression_ratio': 1.662037037037037, 'no_speech_prob': 0.026813779026269913}, {'id': 581, 'seek': 373710, 'start': 3755.06, 'end': 3760.2999999999997, 'text': ' then you can actually start issuing an operation every cycle. Let me take an example. Let us', 'tokens': [51262, 550, 291, 393, 767, 722, 43214, 364, 6916, 633, 6586, 13, 961, 385, 747, 364, 1365, 13, 961, 505, 51524], 'temperature': 0.0, 'avg_logprob': -0.15931233395351452, 'compression_ratio': 1.662037037037037, 'no_speech_prob': 0.026813779026269913}, {'id': 582, 'seek': 376030, 'start': 3760.6200000000003, 'end': 3767.6200000000003, 'text': ' say that I have an integer, okay. So, let us say that I have this integer multiply function', 'tokens': [50380, 584, 300, 286, 362, 364, 24922, 11, 1392, 13, 407, 11, 718, 505, 584, 300, 286, 362, 341, 24922, 12972, 2445, 50730], 'temperature': 0.0, 'avg_logprob': -0.2341451644897461, 'compression_ratio': 1.7198067632850242, 'no_speech_prob': 0.012444295920431614}, {'id': 583, 'seek': 376030, 'start': 3768.02, 'end': 3775.02, 'text': ' unit, which takes four latencies, four cycles time, right, latency of four cycles. That', 'tokens': [50750, 4985, 11, 597, 2516, 1451, 4465, 6464, 11, 1451, 17796, 565, 11, 558, 11, 27043, 295, 1451, 17796, 13, 663, 51100], 'temperature': 0.0, 'avg_logprob': -0.2341451644897461, 'compression_ratio': 1.7198067632850242, 'no_speech_prob': 0.012444295920431614}, {'id': 584, 'seek': 376030, 'start': 3775.7400000000002, 'end': 3782.7400000000002, 'text': ' is essentially a pipeline with four stages, correct. I do not even know what this is,', 'tokens': [51136, 307, 4476, 257, 15517, 365, 1451, 10232, 11, 3006, 13, 286, 360, 406, 754, 458, 437, 341, 307, 11, 51486], 'temperature': 0.0, 'avg_logprob': -0.2341451644897461, 'compression_ratio': 1.7198067632850242, 'no_speech_prob': 0.012444295920431614}, {'id': 585, 'seek': 376030, 'start': 3783.1000000000004, 'end': 3787.78, 'text': ' okay. Let us just call them stage one, stage two, stage three and stage four. This is only', 'tokens': [51504, 1392, 13, 961, 505, 445, 818, 552, 3233, 472, 11, 3233, 732, 11, 3233, 1045, 293, 3233, 1451, 13, 639, 307, 787, 51738], 'temperature': 0.0, 'avg_logprob': -0.2341451644897461, 'compression_ratio': 1.7198067632850242, 'no_speech_prob': 0.012444295920431614}, {'id': 586, 'seek': 378778, 'start': 3787.78, 'end': 3794.78, 'text': ' for, let us say, floating point multiply, right. And if I say that this is pipeline,', 'tokens': [50364, 337, 11, 718, 505, 584, 11, 12607, 935, 12972, 11, 558, 13, 400, 498, 286, 584, 300, 341, 307, 15517, 11, 50714], 'temperature': 0.0, 'avg_logprob': -0.20090082579968022, 'compression_ratio': 1.8263157894736841, 'no_speech_prob': 0.007736337371170521}, {'id': 587, 'seek': 378778, 'start': 3796.1000000000004, 'end': 3803.1000000000004, 'text': ' then what it means is that every cycle I can initiate a new operation in this, right. That', 'tokens': [50780, 550, 437, 309, 1355, 307, 300, 633, 6586, 286, 393, 31574, 257, 777, 6916, 294, 341, 11, 558, 13, 663, 51130], 'temperature': 0.0, 'avg_logprob': -0.20090082579968022, 'compression_ratio': 1.8263157894736841, 'no_speech_prob': 0.007736337371170521}, {'id': 588, 'seek': 378778, 'start': 3803.1400000000003, 'end': 3809.6600000000003, 'text': ' means that at time t equal to one, that could be instruction i one, right, going through', 'tokens': [51132, 1355, 300, 412, 565, 256, 2681, 281, 472, 11, 300, 727, 312, 10951, 741, 472, 11, 558, 11, 516, 807, 51458], 'temperature': 0.0, 'avg_logprob': -0.20090082579968022, 'compression_ratio': 1.8263157894736841, 'no_speech_prob': 0.007736337371170521}, {'id': 589, 'seek': 378778, 'start': 3809.6600000000003, 'end': 3816.6600000000003, 'text': ' this i one, i one, i one, i one. So, this is time one, i one, i one, i one, i one.', 'tokens': [51458, 341, 741, 472, 11, 741, 472, 11, 741, 472, 11, 741, 472, 13, 407, 11, 341, 307, 565, 472, 11, 741, 472, 11, 741, 472, 11, 741, 472, 11, 741, 472, 13, 51808], 'temperature': 0.0, 'avg_logprob': -0.20090082579968022, 'compression_ratio': 1.8263157894736841, 'no_speech_prob': 0.007736337371170521}, {'id': 590, 'seek': 381778, 'start': 3817.78, 'end': 3824.78, 'text': ' So, this is time two, three, four, right. In the next cycle, I can start the next operation', 'tokens': [50364, 407, 11, 341, 307, 565, 732, 11, 1045, 11, 1451, 11, 558, 13, 682, 264, 958, 6586, 11, 286, 393, 722, 264, 958, 6916, 50714], 'temperature': 0.0, 'avg_logprob': -0.24448418617248535, 'compression_ratio': 1.894736842105263, 'no_speech_prob': 0.018604548647999763}, {'id': 591, 'seek': 381778, 'start': 3824.78, 'end': 3830.26, 'text': ' and in the next cycle, I can start the next operation and so on. And they will go through', 'tokens': [50714, 293, 294, 264, 958, 6586, 11, 286, 393, 722, 264, 958, 6916, 293, 370, 322, 13, 400, 436, 486, 352, 807, 50988], 'temperature': 0.0, 'avg_logprob': -0.24448418617248535, 'compression_ratio': 1.894736842105263, 'no_speech_prob': 0.018604548647999763}, {'id': 592, 'seek': 381778, 'start': 3830.26, 'end': 3837.26, 'text': ' the pipeline completing it one cycle through. Correct. But the instruction still takes,', 'tokens': [50988, 264, 15517, 19472, 309, 472, 6586, 807, 13, 12753, 13, 583, 264, 10951, 920, 2516, 11, 51338], 'temperature': 0.0, 'avg_logprob': -0.24448418617248535, 'compression_ratio': 1.894736842105263, 'no_speech_prob': 0.018604548647999763}, {'id': 593, 'seek': 381778, 'start': 3837.9, 'end': 3843.98, 'text': ' the floating point multiplication still takes four cycles. So, the latency is four cycles,', 'tokens': [51370, 264, 12607, 935, 27290, 920, 2516, 1451, 17796, 13, 407, 11, 264, 27043, 307, 1451, 17796, 11, 51674], 'temperature': 0.0, 'avg_logprob': -0.24448418617248535, 'compression_ratio': 1.894736842105263, 'no_speech_prob': 0.018604548647999763}, {'id': 594, 'seek': 384398, 'start': 3843.98, 'end': 3850.98, 'text': ' but it is pipeline. And when we say it is pipeline, you can issue one operation every', 'tokens': [50364, 457, 309, 307, 15517, 13, 400, 562, 321, 584, 309, 307, 15517, 11, 291, 393, 2734, 472, 6916, 633, 50714], 'temperature': 0.0, 'avg_logprob': -0.17607641808780622, 'compression_ratio': 1.8770053475935828, 'no_speech_prob': 0.012275862507522106}, {'id': 595, 'seek': 384398, 'start': 3851.14, 'end': 3857.1, 'text': ' cycle. How is this important from a scheduling perspective? From a scheduling perspective,', 'tokens': [50722, 6586, 13, 1012, 307, 341, 1021, 490, 257, 29055, 4585, 30, 3358, 257, 29055, 4585, 11, 51020], 'temperature': 0.0, 'avg_logprob': -0.17607641808780622, 'compression_ratio': 1.8770053475935828, 'no_speech_prob': 0.012275862507522106}, {'id': 596, 'seek': 384398, 'start': 3857.1, 'end': 3863.18, 'text': ' if I schedule, let us say, a floating point multiply operation in time t, I can schedule', 'tokens': [51020, 498, 286, 7567, 11, 718, 505, 584, 11, 257, 12607, 935, 12972, 6916, 294, 565, 256, 11, 286, 393, 7567, 51324], 'temperature': 0.0, 'avg_logprob': -0.17607641808780622, 'compression_ratio': 1.8770053475935828, 'no_speech_prob': 0.012275862507522106}, {'id': 597, 'seek': 384398, 'start': 3863.18, 'end': 3870.18, 'text': ' another floating point multiply operation on the same pipeline at time t plus one. If', 'tokens': [51324, 1071, 12607, 935, 12972, 6916, 322, 264, 912, 15517, 412, 565, 256, 1804, 472, 13, 759, 51674], 'temperature': 0.0, 'avg_logprob': -0.17607641808780622, 'compression_ratio': 1.8770053475935828, 'no_speech_prob': 0.012275862507522106}, {'id': 598, 'seek': 387018, 'start': 3870.7799999999997, 'end': 3877.7799999999997, 'text': ' it is not pipeline, what does it mean? The one can only be issued at time t plus four,', 'tokens': [50394, 309, 307, 406, 15517, 11, 437, 775, 309, 914, 30, 440, 472, 393, 787, 312, 14379, 412, 565, 256, 1804, 1451, 11, 50744], 'temperature': 0.0, 'avg_logprob': -0.19690900099904915, 'compression_ratio': 1.7490196078431373, 'no_speech_prob': 0.00873542483896017}, {'id': 599, 'seek': 387018, 'start': 3879.22, 'end': 3884.8999999999996, 'text': ' exactly. Correct. So, that is why this may not be possible and you can only do that.', 'tokens': [50816, 2293, 13, 12753, 13, 407, 11, 300, 307, 983, 341, 815, 406, 312, 1944, 293, 291, 393, 787, 360, 300, 13, 51100], 'temperature': 0.0, 'avg_logprob': -0.19690900099904915, 'compression_ratio': 1.7490196078431373, 'no_speech_prob': 0.00873542483896017}, {'id': 600, 'seek': 387018, 'start': 3884.8999999999996, 'end': 3889.54, 'text': ' Okay. So, that is what we mean by pipeline versus non-pipeline functional unit.', 'tokens': [51100, 1033, 13, 407, 11, 300, 307, 437, 321, 914, 538, 15517, 5717, 2107, 12, 79, 647, 5440, 11745, 4985, 13, 51332], 'temperature': 0.0, 'avg_logprob': -0.19690900099904915, 'compression_ratio': 1.7490196078431373, 'no_speech_prob': 0.00873542483896017}, {'id': 601, 'seek': 387018, 'start': 3889.54, 'end': 3895.46, 'text': ' When I talk about identical, when I say identical, it is actually a simplification. In practice,', 'tokens': [51332, 1133, 286, 751, 466, 14800, 11, 562, 286, 584, 14800, 11, 309, 307, 767, 257, 6883, 3774, 13, 682, 3124, 11, 51628], 'temperature': 0.0, 'avg_logprob': -0.19690900099904915, 'compression_ratio': 1.7490196078431373, 'no_speech_prob': 0.00873542483896017}, {'id': 602, 'seek': 387018, 'start': 3895.46, 'end': 3899.4199999999996, 'text': ' what happens is that you have a separate function unit for integer operation, you have a separate', 'tokens': [51628, 437, 2314, 307, 300, 291, 362, 257, 4994, 2445, 4985, 337, 24922, 6916, 11, 291, 362, 257, 4994, 51826], 'temperature': 0.0, 'avg_logprob': -0.19690900099904915, 'compression_ratio': 1.7490196078431373, 'no_speech_prob': 0.00873542483896017}, {'id': 603, 'seek': 389942, 'start': 3899.42, 'end': 3903.46, 'text': ' function unit for floating point, you have a separate function unit for load store, you', 'tokens': [50364, 2445, 4985, 337, 12607, 935, 11, 291, 362, 257, 4994, 2445, 4985, 337, 3677, 3531, 11, 291, 50566], 'temperature': 0.0, 'avg_logprob': -0.16619458565345177, 'compression_ratio': 1.9264069264069263, 'no_speech_prob': 0.005581820383667946}, {'id': 604, 'seek': 389942, 'start': 3903.46, 'end': 3908.1, 'text': ' have a separate function unit for let us say integer divide or floating point divide and', 'tokens': [50566, 362, 257, 4994, 2445, 4985, 337, 718, 505, 584, 24922, 9845, 420, 12607, 935, 9845, 293, 50798], 'temperature': 0.0, 'avg_logprob': -0.16619458565345177, 'compression_ratio': 1.9264069264069263, 'no_speech_prob': 0.005581820383667946}, {'id': 605, 'seek': 389942, 'start': 3908.1, 'end': 3913.5, 'text': ' so on and so forth. They are all different. Okay. But to do the instruction scheduling,', 'tokens': [50798, 370, 322, 293, 370, 5220, 13, 814, 366, 439, 819, 13, 1033, 13, 583, 281, 360, 264, 10951, 29055, 11, 51068], 'temperature': 0.0, 'avg_logprob': -0.16619458565345177, 'compression_ratio': 1.9264069264069263, 'no_speech_prob': 0.005581820383667946}, {'id': 606, 'seek': 389942, 'start': 3913.5, 'end': 3919.02, 'text': ' sometimes we will assume that let us say I have n pipelines and all of them are identical.', 'tokens': [51068, 2171, 321, 486, 6552, 300, 718, 505, 584, 286, 362, 297, 40168, 293, 439, 295, 552, 366, 14800, 13, 51344], 'temperature': 0.0, 'avg_logprob': -0.16619458565345177, 'compression_ratio': 1.9264069264069263, 'no_speech_prob': 0.005581820383667946}, {'id': 607, 'seek': 389942, 'start': 3919.02, 'end': 3924.34, 'text': ' But in practice, this does not happen. Okay. In practice, it is always each function unit', 'tokens': [51344, 583, 294, 3124, 11, 341, 775, 406, 1051, 13, 1033, 13, 682, 3124, 11, 309, 307, 1009, 1184, 2445, 4985, 51610], 'temperature': 0.0, 'avg_logprob': -0.16619458565345177, 'compression_ratio': 1.9264069264069263, 'no_speech_prob': 0.005581820383667946}, {'id': 608, 'seek': 392434, 'start': 3924.34, 'end': 3929.54, 'text': ' is unique or different. Right. So, but for simplification, we will consider it to be', 'tokens': [50364, 307, 3845, 420, 819, 13, 1779, 13, 407, 11, 457, 337, 6883, 3774, 11, 321, 486, 1949, 309, 281, 312, 50624], 'temperature': 0.0, 'avg_logprob': -0.18009983409534802, 'compression_ratio': 1.6384976525821595, 'no_speech_prob': 0.1037682369351387}, {'id': 609, 'seek': 392434, 'start': 3929.54, 'end': 3934.6200000000003, 'text': ' that way. Oftentimes, we will either use this word called homogeneous, which means that', 'tokens': [50624, 300, 636, 13, 46636, 11, 321, 486, 2139, 764, 341, 1349, 1219, 42632, 11, 597, 1355, 300, 50878], 'temperature': 0.0, 'avg_logprob': -0.18009983409534802, 'compression_ratio': 1.6384976525821595, 'no_speech_prob': 0.1037682369351387}, {'id': 610, 'seek': 392434, 'start': 3934.6200000000003, 'end': 3941.6200000000003, 'text': ' all of them are same or heterogeneous. Okay. In practice, it is always heterogeneous, but', 'tokens': [50878, 439, 295, 552, 366, 912, 420, 20789, 31112, 13, 1033, 13, 682, 3124, 11, 309, 307, 1009, 20789, 31112, 11, 457, 51228], 'temperature': 0.0, 'avg_logprob': -0.18009983409534802, 'compression_ratio': 1.6384976525821595, 'no_speech_prob': 0.1037682369351387}, {'id': 611, 'seek': 392434, 'start': 3944.58, 'end': 3949.46, 'text': ' to make the problem simple, we can look at it as homogeneous. Even when you look at it', 'tokens': [51376, 281, 652, 264, 1154, 2199, 11, 321, 393, 574, 412, 309, 382, 42632, 13, 2754, 562, 291, 574, 412, 309, 51620], 'temperature': 0.0, 'avg_logprob': -0.18009983409534802, 'compression_ratio': 1.6384976525821595, 'no_speech_prob': 0.1037682369351387}, {'id': 612, 'seek': 394946, 'start': 3949.46, 'end': 3955.98, 'text': ' as homogeneous, when you have more than three functional units, right, the instruction scheduling', 'tokens': [50364, 382, 42632, 11, 562, 291, 362, 544, 813, 1045, 11745, 6815, 11, 558, 11, 264, 10951, 29055, 50690], 'temperature': 0.0, 'avg_logprob': -0.18412141572861446, 'compression_ratio': 1.6818181818181819, 'no_speech_prob': 0.026003267616033554}, {'id': 613, 'seek': 394946, 'start': 3955.98, 'end': 3962.42, 'text': ' problem, optimal instruction scheduling problem is NP complete. So, if it is heterogeneous,', 'tokens': [50690, 1154, 11, 16252, 10951, 29055, 1154, 307, 38611, 3566, 13, 407, 11, 498, 309, 307, 20789, 31112, 11, 51012], 'temperature': 0.0, 'avg_logprob': -0.18412141572861446, 'compression_ratio': 1.6818181818181819, 'no_speech_prob': 0.026003267616033554}, {'id': 614, 'seek': 394946, 'start': 3962.42, 'end': 3969.42, 'text': ' it is going to be equally or more hard. Right. That is the reason. Okay. So, as I mentioned', 'tokens': [51012, 309, 307, 516, 281, 312, 12309, 420, 544, 1152, 13, 1779, 13, 663, 307, 264, 1778, 13, 1033, 13, 407, 11, 382, 286, 2835, 51362], 'temperature': 0.0, 'avg_logprob': -0.18412141572861446, 'compression_ratio': 1.6818181818181819, 'no_speech_prob': 0.026003267616033554}, {'id': 615, 'seek': 394946, 'start': 3970.78, 'end': 3974.78, 'text': ' earlier, different resources, for example, integer operation, memory operation, floating', 'tokens': [51430, 3071, 11, 819, 3593, 11, 337, 1365, 11, 24922, 6916, 11, 4675, 6916, 11, 12607, 51630], 'temperature': 0.0, 'avg_logprob': -0.18412141572861446, 'compression_ratio': 1.6818181818181819, 'no_speech_prob': 0.026003267616033554}, {'id': 616, 'seek': 397478, 'start': 3975.1000000000004, 'end': 3979.7400000000002, 'text': ' point operation, etcetera, they all go through different pipelines. And each one of these', 'tokens': [50380, 935, 6916, 11, 22066, 11, 436, 439, 352, 807, 819, 40168, 13, 400, 1184, 472, 295, 613, 50612], 'temperature': 0.0, 'avg_logprob': -0.18179283142089844, 'compression_ratio': 1.7956521739130435, 'no_speech_prob': 0.024397581815719604}, {'id': 617, 'seek': 397478, 'start': 3979.7400000000002, 'end': 3984.94, 'text': ' pipelines could either be fully pipelined or non-pipelined. If they are pipelined, then', 'tokens': [50612, 40168, 727, 2139, 312, 4498, 8489, 338, 2001, 420, 2107, 12, 79, 647, 338, 2001, 13, 759, 436, 366, 8489, 338, 2001, 11, 550, 50872], 'temperature': 0.0, 'avg_logprob': -0.18179283142089844, 'compression_ratio': 1.7956521739130435, 'no_speech_prob': 0.024397581815719604}, {'id': 618, 'seek': 397478, 'start': 3984.94, 'end': 3989.38, 'text': ' every successive cycle, you can actually initiate a new operation, even though the latency', 'tokens': [50872, 633, 48043, 6586, 11, 291, 393, 767, 31574, 257, 777, 6916, 11, 754, 1673, 264, 27043, 51094], 'temperature': 0.0, 'avg_logprob': -0.18179283142089844, 'compression_ratio': 1.7956521739130435, 'no_speech_prob': 0.024397581815719604}, {'id': 619, 'seek': 397478, 'start': 3989.38, 'end': 3995.42, 'text': ' may be greater than one. Whereas, if it is non-pipelined, you can only initiate after', 'tokens': [51094, 815, 312, 5044, 813, 472, 13, 13813, 11, 498, 309, 307, 2107, 12, 79, 647, 338, 2001, 11, 291, 393, 787, 31574, 934, 51396], 'temperature': 0.0, 'avg_logprob': -0.18179283142089844, 'compression_ratio': 1.7956521739130435, 'no_speech_prob': 0.024397581815719604}, {'id': 620, 'seek': 397478, 'start': 3995.42, 'end': 4002.42, 'text': ' that operation completes. That is really what it is. Okay.', 'tokens': [51396, 300, 6916, 36362, 13, 663, 307, 534, 437, 309, 307, 13, 1033, 13, 51746], 'temperature': 0.0, 'avg_logprob': -0.18179283142089844, 'compression_ratio': 1.7956521739130435, 'no_speech_prob': 0.024397581815719604}, {'id': 621, 'seek': 400242, 'start': 4002.98, 'end': 4008.06, 'text': ' Alright. So, we will see some instruction scheduling methods, essentially what you are', 'tokens': [50392, 2798, 13, 407, 11, 321, 486, 536, 512, 10951, 29055, 7150, 11, 4476, 437, 291, 366, 50646], 'temperature': 0.0, 'avg_logprob': -0.21770961014265866, 'compression_ratio': 2.0355555555555553, 'no_speech_prob': 0.026744311675429344}, {'id': 622, 'seek': 400242, 'start': 4008.06, 'end': 4014.02, 'text': ' going to call as the list scheduling methods. They differ, there are many list scheduling', 'tokens': [50646, 516, 281, 818, 382, 264, 1329, 29055, 7150, 13, 814, 743, 11, 456, 366, 867, 1329, 29055, 50944], 'temperature': 0.0, 'avg_logprob': -0.21770961014265866, 'compression_ratio': 2.0355555555555553, 'no_speech_prob': 0.026744311675429344}, {'id': 623, 'seek': 400242, 'start': 4014.02, 'end': 4019.2200000000003, 'text': ' methods that have been published in the literature. And they differ in terms of whether these', 'tokens': [50944, 7150, 300, 362, 668, 6572, 294, 264, 10394, 13, 400, 436, 743, 294, 2115, 295, 1968, 613, 51204], 'temperature': 0.0, 'avg_logprob': -0.21770961014265866, 'compression_ratio': 2.0355555555555553, 'no_speech_prob': 0.026744311675429344}, {'id': 624, 'seek': 400242, 'start': 4019.2200000000003, 'end': 4024.3, 'text': ' are, so what happens is that there are several list scheduling methods. And these list scheduling', 'tokens': [51204, 366, 11, 370, 437, 2314, 307, 300, 456, 366, 2940, 1329, 29055, 7150, 13, 400, 613, 1329, 29055, 51458], 'temperature': 0.0, 'avg_logprob': -0.21770961014265866, 'compression_ratio': 2.0355555555555553, 'no_speech_prob': 0.026744311675429344}, {'id': 625, 'seek': 400242, 'start': 4024.3, 'end': 4030.02, 'text': ' methods depends, you know, varies in terms of the following aspects. Some list scheduling', 'tokens': [51458, 7150, 5946, 11, 291, 458, 11, 21716, 294, 2115, 295, 264, 3480, 7270, 13, 2188, 1329, 29055, 51744], 'temperature': 0.0, 'avg_logprob': -0.21770961014265866, 'compression_ratio': 2.0355555555555553, 'no_speech_prob': 0.026744311675429344}, {'id': 626, 'seek': 403002, 'start': 4030.02, 'end': 4034.58, 'text': ' methods are operation based and some are cycle based. I will give you examples of these', 'tokens': [50364, 7150, 366, 6916, 2361, 293, 512, 366, 6586, 2361, 13, 286, 486, 976, 291, 5110, 295, 613, 50592], 'temperature': 0.0, 'avg_logprob': -0.16315155403286802, 'compression_ratio': 1.8114754098360655, 'no_speech_prob': 0.013658667914569378}, {'id': 627, 'seek': 403002, 'start': 4034.58, 'end': 4041.58, 'text': ' two things as we go by. Some are forward and some are backward or some are what we call', 'tokens': [50592, 732, 721, 382, 321, 352, 538, 13, 2188, 366, 2128, 293, 512, 366, 23897, 420, 512, 366, 437, 321, 818, 50942], 'temperature': 0.0, 'avg_logprob': -0.16315155403286802, 'compression_ratio': 1.8114754098360655, 'no_speech_prob': 0.013658667914569378}, {'id': 628, 'seek': 403002, 'start': 4041.82, 'end': 4048.58, 'text': ' as greedy and some are lazy. And then they use some extent of backtracking, which essentially', 'tokens': [50954, 382, 28228, 293, 512, 366, 14847, 13, 400, 550, 436, 764, 512, 8396, 295, 646, 6903, 14134, 11, 597, 4476, 51292], 'temperature': 0.0, 'avg_logprob': -0.16315155403286802, 'compression_ratio': 1.8114754098360655, 'no_speech_prob': 0.013658667914569378}, {'id': 629, 'seek': 403002, 'start': 4048.58, 'end': 4054.86, 'text': ' means that after I have done scheduling of an instruction, I try to go forward and as', 'tokens': [51292, 1355, 300, 934, 286, 362, 1096, 29055, 295, 364, 10951, 11, 286, 853, 281, 352, 2128, 293, 382, 51606], 'temperature': 0.0, 'avg_logprob': -0.16315155403286802, 'compression_ratio': 1.8114754098360655, 'no_speech_prob': 0.013658667914569378}, {'id': 630, 'seek': 403002, 'start': 4054.86, 'end': 4059.3, 'text': ' I keep scheduling more instruction, suddenly I decide that one of the instruction that', 'tokens': [51606, 286, 1066, 29055, 544, 10951, 11, 5800, 286, 4536, 300, 472, 295, 264, 10951, 300, 51828], 'temperature': 0.0, 'avg_logprob': -0.16315155403286802, 'compression_ratio': 1.8114754098360655, 'no_speech_prob': 0.013658667914569378}, {'id': 631, 'seek': 405930, 'start': 4059.3, 'end': 4065.1800000000003, 'text': ' I have scheduled earlier is possibly a wrong choice. I try to undo that instruction and', 'tokens': [50364, 286, 362, 15678, 3071, 307, 6264, 257, 2085, 3922, 13, 286, 853, 281, 23779, 300, 10951, 293, 50658], 'temperature': 0.0, 'avg_logprob': -0.1469097137451172, 'compression_ratio': 1.8097165991902835, 'no_speech_prob': 0.005842207930982113}, {'id': 632, 'seek': 405930, 'start': 4065.1800000000003, 'end': 4070.26, 'text': ' then try to schedule more instructions. So, that is backtracking. And if you do backtracking,', 'tokens': [50658, 550, 853, 281, 7567, 544, 9415, 13, 407, 11, 300, 307, 646, 6903, 14134, 13, 400, 498, 291, 360, 646, 6903, 14134, 11, 50912], 'temperature': 0.0, 'avg_logprob': -0.1469097137451172, 'compression_ratio': 1.8097165991902835, 'no_speech_prob': 0.005842207930982113}, {'id': 633, 'seek': 405930, 'start': 4070.26, 'end': 4075.7000000000003, 'text': ' like in any backtracking things, you actually spend more time, but you are likely to produce', 'tokens': [50912, 411, 294, 604, 646, 6903, 14134, 721, 11, 291, 767, 3496, 544, 565, 11, 457, 291, 366, 3700, 281, 5258, 51184], 'temperature': 0.0, 'avg_logprob': -0.1469097137451172, 'compression_ratio': 1.8097165991902835, 'no_speech_prob': 0.005842207930982113}, {'id': 634, 'seek': 405930, 'start': 4075.7000000000003, 'end': 4082.1400000000003, 'text': ' better schedules. Then they use different kinds of priorities and some of them update', 'tokens': [51184, 1101, 28078, 13, 1396, 436, 764, 819, 3685, 295, 15503, 293, 512, 295, 552, 5623, 51506], 'temperature': 0.0, 'avg_logprob': -0.1469097137451172, 'compression_ratio': 1.8097165991902835, 'no_speech_prob': 0.005842207930982113}, {'id': 635, 'seek': 405930, 'start': 4082.1400000000003, 'end': 4087.5, 'text': ' this priority only once at the beginning of scheduling. Some of them keep updating the', 'tokens': [51506, 341, 9365, 787, 1564, 412, 264, 2863, 295, 29055, 13, 2188, 295, 552, 1066, 25113, 264, 51774], 'temperature': 0.0, 'avg_logprob': -0.1469097137451172, 'compression_ratio': 1.8097165991902835, 'no_speech_prob': 0.005842207930982113}, {'id': 636, 'seek': 408750, 'start': 4087.5, 'end': 4094.5, 'text': ' priority as time goes by. So, they differ in that as well. They also differ in terms', 'tokens': [50364, 9365, 382, 565, 1709, 538, 13, 407, 11, 436, 743, 294, 300, 382, 731, 13, 814, 611, 743, 294, 2115, 50714], 'temperature': 0.0, 'avg_logprob': -0.2237346319504726, 'compression_ratio': 1.9411764705882353, 'no_speech_prob': 0.08469186723232269}, {'id': 637, 'seek': 408750, 'start': 4095.62, 'end': 4099.46, 'text': ' of how they consider these functional units, whether they consider these functional units', 'tokens': [50770, 295, 577, 436, 1949, 613, 11745, 6815, 11, 1968, 436, 1949, 613, 11745, 6815, 50962], 'temperature': 0.0, 'avg_logprob': -0.2237346319504726, 'compression_ratio': 1.9411764705882353, 'no_speech_prob': 0.08469186723232269}, {'id': 638, 'seek': 408750, 'start': 4099.46, 'end': 4106.46, 'text': ' as uniform, that means homogeneous or heterogeneous and whether they consider how many units are', 'tokens': [50962, 382, 9452, 11, 300, 1355, 42632, 420, 20789, 31112, 293, 1968, 436, 1949, 577, 867, 6815, 366, 51312], 'temperature': 0.0, 'avg_logprob': -0.2237346319504726, 'compression_ratio': 1.9411764705882353, 'no_speech_prob': 0.08469186723232269}, {'id': 639, 'seek': 408750, 'start': 4106.46, 'end': 4112.26, 'text': ' there, etcetera, depending on that they differ. So, here is the algorithm for doing what we', 'tokens': [51312, 456, 11, 22066, 11, 5413, 322, 300, 436, 743, 13, 407, 11, 510, 307, 264, 9284, 337, 884, 437, 321, 51602], 'temperature': 0.0, 'avg_logprob': -0.2237346319504726, 'compression_ratio': 1.9411764705882353, 'no_speech_prob': 0.08469186723232269}, {'id': 640, 'seek': 411226, 'start': 4112.26, 'end': 4118.3, 'text': ' call as cycle based scheduling. So, what you do is that you have the instructions', 'tokens': [50364, 818, 382, 6586, 2361, 29055, 13, 407, 11, 437, 291, 360, 307, 300, 291, 362, 264, 9415, 50666], 'temperature': 0.0, 'avg_logprob': -0.2016589732109746, 'compression_ratio': 1.8272251308900525, 'no_speech_prob': 0.03340610861778259}, {'id': 641, 'seek': 411226, 'start': 4118.3, 'end': 4123.7, 'text': ' from the basic block from which you construct the data dependence graph. The data dependence', 'tokens': [50666, 490, 264, 3875, 3461, 490, 597, 291, 7690, 264, 1412, 31704, 4295, 13, 440, 1412, 31704, 50936], 'temperature': 0.0, 'avg_logprob': -0.2016589732109746, 'compression_ratio': 1.8272251308900525, 'no_speech_prob': 0.03340610861778259}, {'id': 642, 'seek': 411226, 'start': 4123.7, 'end': 4130.7, 'text': ' graph is represented by means of the edges and sorry vertices and edges. Now, what you', 'tokens': [50936, 4295, 307, 10379, 538, 1355, 295, 264, 8819, 293, 2597, 32053, 293, 8819, 13, 823, 11, 437, 291, 51286], 'temperature': 0.0, 'avg_logprob': -0.2016589732109746, 'compression_ratio': 1.8272251308900525, 'no_speech_prob': 0.03340610861778259}, {'id': 643, 'seek': 411226, 'start': 4131.5, 'end': 4137.02, 'text': ' do in a cycle based scheduling is that you start with time step 0 and you keep visiting', 'tokens': [51326, 360, 294, 257, 6586, 2361, 29055, 307, 300, 291, 722, 365, 565, 1823, 1958, 293, 291, 1066, 11700, 51602], 'temperature': 0.0, 'avg_logprob': -0.2016589732109746, 'compression_ratio': 1.8272251308900525, 'no_speech_prob': 0.03340610861778259}, {'id': 644, 'seek': 413702, 'start': 4137.02, 'end': 4142.38, 'text': ' every cycle. And as you keep visiting each cycle, you will see whether there are any', 'tokens': [50364, 633, 6586, 13, 400, 382, 291, 1066, 11700, 1184, 6586, 11, 291, 486, 536, 1968, 456, 366, 604, 50632], 'temperature': 0.0, 'avg_logprob': -0.15811950028544725, 'compression_ratio': 2.0044642857142856, 'no_speech_prob': 0.025418544188141823}, {'id': 645, 'seek': 413702, 'start': 4142.38, 'end': 4147.900000000001, 'text': ' ready operations to be scheduled. And among all the ready operations, you choose the ones', 'tokens': [50632, 1919, 7705, 281, 312, 15678, 13, 400, 3654, 439, 264, 1919, 7705, 11, 291, 2826, 264, 2306, 50908], 'temperature': 0.0, 'avg_logprob': -0.15811950028544725, 'compression_ratio': 2.0044642857142856, 'no_speech_prob': 0.025418544188141823}, {'id': 646, 'seek': 413702, 'start': 4147.900000000001, 'end': 4153.620000000001, 'text': ' which have higher priority and you start scheduling them in the decreasing order of priority.', 'tokens': [50908, 597, 362, 2946, 9365, 293, 291, 722, 29055, 552, 294, 264, 23223, 1668, 295, 9365, 13, 51194], 'temperature': 0.0, 'avg_logprob': -0.15811950028544725, 'compression_ratio': 2.0044642857142856, 'no_speech_prob': 0.025418544188141823}, {'id': 647, 'seek': 413702, 'start': 4153.620000000001, 'end': 4160.620000000001, 'text': ' If you cannot schedule any more operations, you increase your time step to the next cycle.', 'tokens': [51194, 759, 291, 2644, 7567, 604, 544, 7705, 11, 291, 3488, 428, 565, 1823, 281, 264, 958, 6586, 13, 51544], 'temperature': 0.0, 'avg_logprob': -0.15811950028544725, 'compression_ratio': 2.0044642857142856, 'no_speech_prob': 0.025418544188141823}, {'id': 648, 'seek': 413702, 'start': 4160.860000000001, 'end': 4164.9800000000005, 'text': ' And before you increase our time step to the next cycle, you also make sure whether there', 'tokens': [51556, 400, 949, 291, 3488, 527, 565, 1823, 281, 264, 958, 6586, 11, 291, 611, 652, 988, 1968, 456, 51762], 'temperature': 0.0, 'avg_logprob': -0.15811950028544725, 'compression_ratio': 2.0044642857142856, 'no_speech_prob': 0.025418544188141823}, {'id': 649, 'seek': 416498, 'start': 4164.98, 'end': 4170.54, 'text': ' are any new ready operations that have become available. Then in the next cycle again, you', 'tokens': [50364, 366, 604, 777, 1919, 7705, 300, 362, 1813, 2435, 13, 1396, 294, 264, 958, 6586, 797, 11, 291, 50642], 'temperature': 0.0, 'avg_logprob': -0.1568325344878848, 'compression_ratio': 1.7387755102040816, 'no_speech_prob': 0.009389244951307774}, {'id': 650, 'seek': 416498, 'start': 4170.54, 'end': 4175.82, 'text': ' try to schedule the operations based on the priority and you keep doing this. So, that', 'tokens': [50642, 853, 281, 7567, 264, 7705, 2361, 322, 264, 9365, 293, 291, 1066, 884, 341, 13, 407, 11, 300, 50906], 'temperature': 0.0, 'avg_logprob': -0.1568325344878848, 'compression_ratio': 1.7387755102040816, 'no_speech_prob': 0.009389244951307774}, {'id': 651, 'seek': 416498, 'start': 4175.82, 'end': 4179.66, 'text': ' is essentially what this algorithm is. Let us go through the detail.', 'tokens': [50906, 307, 4476, 437, 341, 9284, 307, 13, 961, 505, 352, 807, 264, 2607, 13, 51098], 'temperature': 0.0, 'avg_logprob': -0.1568325344878848, 'compression_ratio': 1.7387755102040816, 'no_speech_prob': 0.009389244951307774}, {'id': 652, 'seek': 416498, 'start': 4179.66, 'end': 4186.66, 'text': ' To start with your schedule is initially empty and you start off at cycle t equal to 0. Now,', 'tokens': [51098, 1407, 722, 365, 428, 7567, 307, 9105, 6707, 293, 291, 722, 766, 412, 6586, 256, 2681, 281, 1958, 13, 823, 11, 51448], 'temperature': 0.0, 'avg_logprob': -0.1568325344878848, 'compression_ratio': 1.7387755102040816, 'no_speech_prob': 0.009389244951307774}, {'id': 653, 'seek': 416498, 'start': 4186.78, 'end': 4192.259999999999, 'text': ' you start saying that ready list is the list of all nodes which are the source node in', 'tokens': [51454, 291, 722, 1566, 300, 1919, 1329, 307, 264, 1329, 295, 439, 13891, 597, 366, 264, 4009, 9984, 294, 51728], 'temperature': 0.0, 'avg_logprob': -0.1568325344878848, 'compression_ratio': 1.7387755102040816, 'no_speech_prob': 0.009389244951307774}, {'id': 654, 'seek': 419226, 'start': 4192.26, 'end': 4196.5, 'text': ' the graph. That means that they do not have any predecessors. They are always ready. They', 'tokens': [50364, 264, 4295, 13, 663, 1355, 300, 436, 360, 406, 362, 604, 24874, 45700, 13, 814, 366, 1009, 1919, 13, 814, 50576], 'temperature': 0.0, 'avg_logprob': -0.20723751613071986, 'compression_ratio': 1.8140495867768596, 'no_speech_prob': 0.22508086264133453}, {'id': 655, 'seek': 419226, 'start': 4196.5, 'end': 4202.66, 'text': ' can be executed. So, now prioritize this ready queue because you do not, there may be five', 'tokens': [50576, 393, 312, 17577, 13, 407, 11, 586, 25164, 341, 1919, 18639, 570, 291, 360, 406, 11, 456, 815, 312, 1732, 50884], 'temperature': 0.0, 'avg_logprob': -0.20723751613071986, 'compression_ratio': 1.8140495867768596, 'no_speech_prob': 0.22508086264133453}, {'id': 656, 'seek': 419226, 'start': 4202.66, 'end': 4207.7, 'text': ' nodes that are ready in the initial list. There may be five source nodes and you may', 'tokens': [50884, 13891, 300, 366, 1919, 294, 264, 5883, 1329, 13, 821, 815, 312, 1732, 4009, 13891, 293, 291, 815, 51136], 'temperature': 0.0, 'avg_logprob': -0.20723751613071986, 'compression_ratio': 1.8140495867768596, 'no_speech_prob': 0.22508086264133453}, {'id': 657, 'seek': 419226, 'start': 4207.7, 'end': 4212.46, 'text': ' have only slot for scheduling two of them or you can only do two integer instruction', 'tokens': [51136, 362, 787, 14747, 337, 29055, 732, 295, 552, 420, 291, 393, 787, 360, 732, 24922, 10951, 51374], 'temperature': 0.0, 'avg_logprob': -0.20723751613071986, 'compression_ratio': 1.8140495867768596, 'no_speech_prob': 0.22508086264133453}, {'id': 658, 'seek': 419226, 'start': 4212.46, 'end': 4216.9400000000005, 'text': ' and one floating point instruction. So, you have to now see which ones can be scheduled.', 'tokens': [51374, 293, 472, 12607, 935, 10951, 13, 407, 11, 291, 362, 281, 586, 536, 597, 2306, 393, 312, 15678, 13, 51598], 'temperature': 0.0, 'avg_logprob': -0.20723751613071986, 'compression_ratio': 1.8140495867768596, 'no_speech_prob': 0.22508086264133453}, {'id': 659, 'seek': 421694, 'start': 4217.259999999999, 'end': 4224.179999999999, 'text': ' So, what you do is that you prioritize them. Then, right, while schedule is not complete,', 'tokens': [50380, 407, 11, 437, 291, 360, 307, 300, 291, 25164, 552, 13, 1396, 11, 558, 11, 1339, 7567, 307, 406, 3566, 11, 50726], 'temperature': 0.0, 'avg_logprob': -0.18720746040344238, 'compression_ratio': 1.9864864864864864, 'no_speech_prob': 0.18764394521713257}, {'id': 660, 'seek': 421694, 'start': 4224.179999999999, 'end': 4227.82, 'text': ' that means that while you have not scheduled all the nodes in the graph, keep doing the', 'tokens': [50726, 300, 1355, 300, 1339, 291, 362, 406, 15678, 439, 264, 13891, 294, 264, 4295, 11, 1066, 884, 264, 50908], 'temperature': 0.0, 'avg_logprob': -0.18720746040344238, 'compression_ratio': 1.9864864864864864, 'no_speech_prob': 0.18764394521713257}, {'id': 661, 'seek': 421694, 'start': 4227.82, 'end': 4234.82, 'text': ' following, right. What you do is that you first take a node from V, from the ready list', 'tokens': [50908, 3480, 11, 558, 13, 708, 291, 360, 307, 300, 291, 700, 747, 257, 9984, 490, 691, 11, 490, 264, 1919, 1329, 51258], 'temperature': 0.0, 'avg_logprob': -0.18720746040344238, 'compression_ratio': 1.9864864864864864, 'no_speech_prob': 0.18764394521713257}, {'id': 662, 'seek': 421694, 'start': 4235.339999999999, 'end': 4241.139999999999, 'text': ' in the priority order, okay. In the prioritize order, you take a node and then you try to', 'tokens': [51284, 294, 264, 9365, 1668, 11, 1392, 13, 682, 264, 25164, 1668, 11, 291, 747, 257, 9984, 293, 550, 291, 853, 281, 51574], 'temperature': 0.0, 'avg_logprob': -0.18720746040344238, 'compression_ratio': 1.9864864864864864, 'no_speech_prob': 0.18764394521713257}, {'id': 663, 'seek': 421694, 'start': 4241.139999999999, 'end': 4245.98, 'text': ' schedule the node in the current time step, okay. And when you schedule the node, you', 'tokens': [51574, 7567, 264, 9984, 294, 264, 2190, 565, 1823, 11, 1392, 13, 400, 562, 291, 7567, 264, 9984, 11, 291, 51816], 'temperature': 0.0, 'avg_logprob': -0.18720746040344238, 'compression_ratio': 1.9864864864864864, 'no_speech_prob': 0.18764394521713257}, {'id': 664, 'seek': 424598, 'start': 4245.98, 'end': 4252.5, 'text': ' have to essentially ensure that there is no resource conflict. That means that if in', 'tokens': [50364, 362, 281, 4476, 5586, 300, 456, 307, 572, 7684, 6596, 13, 663, 1355, 300, 498, 294, 50690], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 665, 'seek': 424598, 'start': 4252.5, 'end': 4257.0599999999995, 'text': ' the current schedule, let us say you have already scheduled two integer add operations', 'tokens': [50690, 264, 2190, 7567, 11, 718, 505, 584, 291, 362, 1217, 15678, 732, 24922, 909, 7705, 50918], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 666, 'seek': 424598, 'start': 4257.0599999999995, 'end': 4262.0199999999995, 'text': ' and there are only two integer function unit, then the third odd operation cannot be scheduled', 'tokens': [50918, 293, 456, 366, 787, 732, 24922, 2445, 4985, 11, 550, 264, 2636, 7401, 6916, 2644, 312, 15678, 51166], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 667, 'seek': 424598, 'start': 4262.0199999999995, 'end': 4267.219999999999, 'text': ' in the current cycle no matter how high its priority is. Because the other two nodes must', 'tokens': [51166, 294, 264, 2190, 6586, 572, 1871, 577, 1090, 1080, 9365, 307, 13, 1436, 264, 661, 732, 13891, 1633, 51426], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 668, 'seek': 424598, 'start': 4267.219999999999, 'end': 4271.62, 'text': ' have had higher priorities. That is why they have got scheduled. This node has a higher', 'tokens': [51426, 362, 632, 2946, 15503, 13, 663, 307, 983, 436, 362, 658, 15678, 13, 639, 9984, 575, 257, 2946, 51646], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 669, 'seek': 424598, 'start': 4271.62, 'end': 4275.9, 'text': ' priority than some of the other operations, but still it cannot be scheduled in the current', 'tokens': [51646, 9365, 813, 512, 295, 264, 661, 7705, 11, 457, 920, 309, 2644, 312, 15678, 294, 264, 2190, 51860], 'temperature': 0.0, 'avg_logprob': -0.1931063942287279, 'compression_ratio': 2.00749063670412, 'no_speech_prob': 0.014743736013770103}, {'id': 670, 'seek': 427590, 'start': 4276.299999999999, 'end': 4281.139999999999, 'text': ' cycle. So, you have to skip this operation and go to the next operation in the priority', 'tokens': [50384, 6586, 13, 407, 11, 291, 362, 281, 10023, 341, 6916, 293, 352, 281, 264, 958, 6916, 294, 264, 9365, 50626], 'temperature': 0.0, 'avg_logprob': -0.13651905926791105, 'compression_ratio': 1.8875, 'no_speech_prob': 0.0019223338458687067}, {'id': 671, 'seek': 427590, 'start': 4281.139999999999, 'end': 4286.379999999999, 'text': ' queue and then see whether any of them can be scheduled, right. So, that is really what', 'tokens': [50626, 18639, 293, 550, 536, 1968, 604, 295, 552, 393, 312, 15678, 11, 558, 13, 407, 11, 300, 307, 534, 437, 50888], 'temperature': 0.0, 'avg_logprob': -0.13651905926791105, 'compression_ratio': 1.8875, 'no_speech_prob': 0.0019223338458687067}, {'id': 672, 'seek': 427590, 'start': 4286.379999999999, 'end': 4292.82, 'text': ' you try to see. If there is no resource conflict, then you add this node to what is called the', 'tokens': [50888, 291, 853, 281, 536, 13, 759, 456, 307, 572, 7684, 6596, 11, 550, 291, 909, 341, 9984, 281, 437, 307, 1219, 264, 51210], 'temperature': 0.0, 'avg_logprob': -0.13651905926791105, 'compression_ratio': 1.8875, 'no_speech_prob': 0.0019223338458687067}, {'id': 673, 'seek': 427590, 'start': 4292.82, 'end': 4299.139999999999, 'text': ' schedule, right. And then you mark the resources that are being used for this schedule. That', 'tokens': [51210, 7567, 11, 558, 13, 400, 550, 291, 1491, 264, 3593, 300, 366, 885, 1143, 337, 341, 7567, 13, 663, 51526], 'temperature': 0.0, 'avg_logprob': -0.13651905926791105, 'compression_ratio': 1.8875, 'no_speech_prob': 0.0019223338458687067}, {'id': 674, 'seek': 427590, 'start': 4299.139999999999, 'end': 4304.0599999999995, 'text': ' is essentially what this add function is doing. You add the node to the schedule and then', 'tokens': [51526, 307, 4476, 437, 341, 909, 2445, 307, 884, 13, 509, 909, 264, 9984, 281, 264, 7567, 293, 550, 51772], 'temperature': 0.0, 'avg_logprob': -0.13651905926791105, 'compression_ratio': 1.8875, 'no_speech_prob': 0.0019223338458687067}, {'id': 675, 'seek': 430406, 'start': 4304.06, 'end': 4309.780000000001, 'text': ' mark all the resources which are used by the schedule. And you keep doing this. If', 'tokens': [50364, 1491, 439, 264, 3593, 597, 366, 1143, 538, 264, 7567, 13, 400, 291, 1066, 884, 341, 13, 759, 50650], 'temperature': 0.0, 'avg_logprob': -0.13037451789492652, 'compression_ratio': 1.9504504504504505, 'no_speech_prob': 0.02722771279513836}, {'id': 676, 'seek': 430406, 'start': 4309.780000000001, 'end': 4315.42, 'text': ' the node has a resource conflict, you skip that, go to the next node in the priority', 'tokens': [50650, 264, 9984, 575, 257, 7684, 6596, 11, 291, 10023, 300, 11, 352, 281, 264, 958, 9984, 294, 264, 9365, 50932], 'temperature': 0.0, 'avg_logprob': -0.13037451789492652, 'compression_ratio': 1.9504504504504505, 'no_speech_prob': 0.02722771279513836}, {'id': 677, 'seek': 430406, 'start': 4315.42, 'end': 4322.820000000001, 'text': ' list until you exhaust all the nodes in the ready list. After you have exhausted all the', 'tokens': [50932, 1329, 1826, 291, 14687, 439, 264, 13891, 294, 264, 1919, 1329, 13, 2381, 291, 362, 17992, 439, 264, 51302], 'temperature': 0.0, 'avg_logprob': -0.13037451789492652, 'compression_ratio': 1.9504504504504505, 'no_speech_prob': 0.02722771279513836}, {'id': 678, 'seek': 430406, 'start': 4322.820000000001, 'end': 4328.5, 'text': ' nodes in the ready list, you know that no more nodes can be scheduled. Then you increment', 'tokens': [51302, 13891, 294, 264, 1919, 1329, 11, 291, 458, 300, 572, 544, 13891, 393, 312, 15678, 13, 1396, 291, 26200, 51586], 'temperature': 0.0, 'avg_logprob': -0.13037451789492652, 'compression_ratio': 1.9504504504504505, 'no_speech_prob': 0.02722771279513836}, {'id': 679, 'seek': 430406, 'start': 4328.5, 'end': 4333.9800000000005, 'text': ' your time step. After you have incremented your time step, you try to find out whether', 'tokens': [51586, 428, 565, 1823, 13, 2381, 291, 362, 1946, 14684, 428, 565, 1823, 11, 291, 853, 281, 915, 484, 1968, 51860], 'temperature': 0.0, 'avg_logprob': -0.13037451789492652, 'compression_ratio': 1.9504504504504505, 'no_speech_prob': 0.02722771279513836}, {'id': 680, 'seek': 433398, 'start': 4333.98, 'end': 4340.7, 'text': ' any node v has now become ready. When would you know a node is ready? Know a node is ready', 'tokens': [50364, 604, 9984, 371, 575, 586, 1813, 1919, 13, 1133, 576, 291, 458, 257, 9984, 307, 1919, 30, 10265, 257, 9984, 307, 1919, 50700], 'temperature': 0.0, 'avg_logprob': -0.1767528382214633, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.0063615115359425545}, {'id': 681, 'seek': 433398, 'start': 4340.7, 'end': 4345.7, 'text': ' if its predecessor has completed its execution. If all its predecessors have completed its', 'tokens': [50700, 498, 1080, 34991, 575, 7365, 1080, 15058, 13, 759, 439, 1080, 24874, 45700, 362, 7365, 1080, 50950], 'temperature': 0.0, 'avg_logprob': -0.1767528382214633, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.0063615115359425545}, {'id': 682, 'seek': 433398, 'start': 4345.7, 'end': 4352.7, 'text': ' execution. Therefore, whenever you schedule a node, you have to make sure that its successors', 'tokens': [50950, 15058, 13, 7504, 11, 5699, 291, 7567, 257, 9984, 11, 291, 362, 281, 652, 988, 300, 1080, 2245, 830, 51300], 'temperature': 0.0, 'avg_logprob': -0.1767528382214633, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.0063615115359425545}, {'id': 683, 'seek': 433398, 'start': 4354.139999999999, 'end': 4361.139999999999, 'text': ' will be intimated after a time which is equal to the execution time of this. So, if node', 'tokens': [51372, 486, 312, 13148, 770, 934, 257, 565, 597, 307, 2681, 281, 264, 15058, 565, 295, 341, 13, 407, 11, 498, 9984, 51722], 'temperature': 0.0, 'avg_logprob': -0.1767528382214633, 'compression_ratio': 1.793103448275862, 'no_speech_prob': 0.0063615115359425545}, {'id': 684, 'seek': 436114, 'start': 4361.54, 'end': 4368.54, 'text': ' v is scheduled at time step t, this is v and v has a successor u and let us say u has only', 'tokens': [50384, 371, 307, 15678, 412, 565, 1823, 256, 11, 341, 307, 371, 293, 371, 575, 257, 31864, 344, 293, 718, 505, 584, 344, 575, 787, 50734], 'temperature': 0.0, 'avg_logprob': -0.26754253932407923, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.040383338928222656}, {'id': 685, 'seek': 436114, 'start': 4374.3, 'end': 4381.3, 'text': ' v as the predecessor. If this is scheduled at time step t and this takes let us say two', 'tokens': [51022, 371, 382, 264, 34991, 13, 759, 341, 307, 15678, 412, 565, 1823, 256, 293, 341, 2516, 718, 505, 584, 732, 51372], 'temperature': 0.0, 'avg_logprob': -0.26754253932407923, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.040383338928222656}, {'id': 686, 'seek': 436114, 'start': 4381.3, 'end': 4388.3, 'text': ' cycles to execute, then obviously this will become ready in t plus 2. If u has multiple', 'tokens': [51372, 17796, 281, 14483, 11, 550, 2745, 341, 486, 1813, 1919, 294, 256, 1804, 568, 13, 759, 344, 575, 3866, 51722], 'temperature': 0.0, 'avg_logprob': -0.26754253932407923, 'compression_ratio': 1.6729559748427674, 'no_speech_prob': 0.040383338928222656}, {'id': 687, 'seek': 439114, 'start': 4391.700000000001, 'end': 4398.700000000001, 'text': ' predecessors, then it will be ready at t plus 2 or later depending on whichever ones that', 'tokens': [50392, 24874, 45700, 11, 550, 309, 486, 312, 1919, 412, 256, 1804, 568, 420, 1780, 5413, 322, 24123, 2306, 300, 50742], 'temperature': 0.0, 'avg_logprob': -0.2317210365744198, 'compression_ratio': 1.7960526315789473, 'no_speech_prob': 0.01919768936932087}, {'id': 688, 'seek': 439114, 'start': 4402.26, 'end': 4409.26, 'text': ' happen. So, you can say that one of its predecessors have become ready at t plus 2 and then you', 'tokens': [50920, 1051, 13, 407, 11, 291, 393, 584, 300, 472, 295, 1080, 24874, 45700, 362, 1813, 1919, 412, 256, 1804, 568, 293, 550, 291, 51270], 'temperature': 0.0, 'avg_logprob': -0.2317210365744198, 'compression_ratio': 1.7960526315789473, 'no_speech_prob': 0.01919768936932087}, {'id': 689, 'seek': 439114, 'start': 4409.26, 'end': 4414.46, 'text': ' can decrement the predecessor count. So, that when the predecessor count becomes 0, you', 'tokens': [51270, 393, 6853, 518, 264, 34991, 1207, 13, 407, 11, 300, 562, 264, 34991, 1207, 3643, 1958, 11, 291, 51530], 'temperature': 0.0, 'avg_logprob': -0.2317210365744198, 'compression_ratio': 1.7960526315789473, 'no_speech_prob': 0.01919768936932087}, {'id': 690, 'seek': 441446, 'start': 4414.46, 'end': 4421.46, 'text': ' know that all the inputs are available and then at that point in time node u can be added', 'tokens': [50364, 458, 300, 439, 264, 15743, 366, 2435, 293, 550, 412, 300, 935, 294, 565, 9984, 344, 393, 312, 3869, 50714], 'temperature': 0.0, 'avg_logprob': -0.27424356307106457, 'compression_ratio': 1.7184466019417475, 'no_speech_prob': 0.012169791385531425}, {'id': 691, 'seek': 441446, 'start': 4421.62, 'end': 4428.62, 'text': ' to the ready list. So, you do that for all the successor nodes of v, not only the v,', 'tokens': [50722, 281, 264, 1919, 1329, 13, 407, 11, 291, 360, 300, 337, 439, 264, 31864, 13891, 295, 371, 11, 406, 787, 264, 371, 11, 51072], 'temperature': 0.0, 'avg_logprob': -0.27424356307106457, 'compression_ratio': 1.7184466019417475, 'no_speech_prob': 0.012169791385531425}, {'id': 692, 'seek': 441446, 'start': 4430.3, 'end': 4437.3, 'text': ' I mean for every v that is scheduled in the current cycle. So, that essentially increases', 'tokens': [51156, 286, 914, 337, 633, 371, 300, 307, 15678, 294, 264, 2190, 6586, 13, 407, 11, 300, 4476, 8637, 51506], 'temperature': 0.0, 'avg_logprob': -0.27424356307106457, 'compression_ratio': 1.7184466019417475, 'no_speech_prob': 0.012169791385531425}, {'id': 693, 'seek': 441446, 'start': 4437.3, 'end': 4443.14, 'text': ' your ready list, then again you prioritize your ready list and then keep doing this again', 'tokens': [51506, 428, 1919, 1329, 11, 550, 797, 291, 25164, 428, 1919, 1329, 293, 550, 1066, 884, 341, 797, 51798], 'temperature': 0.0, 'avg_logprob': -0.27424356307106457, 'compression_ratio': 1.7184466019417475, 'no_speech_prob': 0.012169791385531425}, {'id': 694, 'seek': 444314, 'start': 4443.14, 'end': 4450.14, 'text': ' and again until you schedule all the nodes. Now, let us see what this schedule is, how', 'tokens': [50364, 293, 797, 1826, 291, 7567, 439, 264, 13891, 13, 823, 11, 718, 505, 536, 437, 341, 7567, 307, 11, 577, 50714], 'temperature': 0.0, 'avg_logprob': -0.17522280715232671, 'compression_ratio': 1.736318407960199, 'no_speech_prob': 0.010661505162715912}, {'id': 695, 'seek': 444314, 'start': 4450.34, 'end': 4455.34, 'text': ' do you represent this schedule and how do you kind of keep track of your resources.', 'tokens': [50724, 360, 291, 2906, 341, 7567, 293, 577, 360, 291, 733, 295, 1066, 2837, 295, 428, 3593, 13, 50974], 'temperature': 0.0, 'avg_logprob': -0.17522280715232671, 'compression_ratio': 1.736318407960199, 'no_speech_prob': 0.010661505162715912}, {'id': 696, 'seek': 444314, 'start': 4455.34, 'end': 4462.34, 'text': ' So, let me try to do this example. So, let us consider the simple case that I have that', 'tokens': [50974, 407, 11, 718, 385, 853, 281, 360, 341, 1365, 13, 407, 11, 718, 505, 1949, 264, 2199, 1389, 300, 286, 362, 300, 51324], 'temperature': 0.0, 'avg_logprob': -0.17522280715232671, 'compression_ratio': 1.736318407960199, 'no_speech_prob': 0.010661505162715912}, {'id': 697, 'seek': 444314, 'start': 4464.34, 'end': 4471.34, 'text': ' I am trying to schedule for an architecture which has one integer unit, one floating point', 'tokens': [51424, 286, 669, 1382, 281, 7567, 337, 364, 9482, 597, 575, 472, 24922, 4985, 11, 472, 12607, 935, 51774], 'temperature': 0.0, 'avg_logprob': -0.17522280715232671, 'compression_ratio': 1.736318407960199, 'no_speech_prob': 0.010661505162715912}, {'id': 698, 'seek': 447134, 'start': 4471.900000000001, 'end': 4478.900000000001, 'text': ' unit and one load store unit. So, this schedule is essentially a table, the number of columns', 'tokens': [50392, 4985, 293, 472, 3677, 3531, 4985, 13, 407, 11, 341, 7567, 307, 4476, 257, 3199, 11, 264, 1230, 295, 13766, 50742], 'temperature': 0.0, 'avg_logprob': -0.2500293788625233, 'compression_ratio': 1.735483870967742, 'no_speech_prob': 0.006983638741075993}, {'id': 699, 'seek': 447134, 'start': 4486.22, 'end': 4493.22, 'text': ' is equal to the number of resources that you have and the number of rows is equal to the', 'tokens': [51108, 307, 2681, 281, 264, 1230, 295, 3593, 300, 291, 362, 293, 264, 1230, 295, 13241, 307, 2681, 281, 264, 51458], 'temperature': 0.0, 'avg_logprob': -0.2500293788625233, 'compression_ratio': 1.735483870967742, 'no_speech_prob': 0.006983638741075993}, {'id': 700, 'seek': 447134, 'start': 4493.38, 'end': 4500.38, 'text': ' schedule length. So, if when I schedule let us say an operation v at time step t, then', 'tokens': [51466, 7567, 4641, 13, 407, 11, 498, 562, 286, 7567, 718, 505, 584, 364, 6916, 371, 412, 565, 1823, 256, 11, 550, 51816], 'temperature': 0.0, 'avg_logprob': -0.2500293788625233, 'compression_ratio': 1.735483870967742, 'no_speech_prob': 0.006983638741075993}, {'id': 701, 'seek': 450134, 'start': 4502.02, 'end': 4507.66, 'text': ' what do I do? If it is a load store operation, then I say that that particular operation', 'tokens': [50398, 437, 360, 286, 360, 30, 759, 309, 307, 257, 3677, 3531, 6916, 11, 550, 286, 584, 300, 300, 1729, 6916, 50680], 'temperature': 0.0, 'avg_logprob': -0.1800466557984711, 'compression_ratio': 1.9153439153439153, 'no_speech_prob': 0.00497342087328434}, {'id': 702, 'seek': 450134, 'start': 4507.66, 'end': 4514.66, 'text': ' is scheduled. If I am at time step t and I find one more load store operation, I go and', 'tokens': [50680, 307, 15678, 13, 759, 286, 669, 412, 565, 1823, 256, 293, 286, 915, 472, 544, 3677, 3531, 6916, 11, 286, 352, 293, 51030], 'temperature': 0.0, 'avg_logprob': -0.1800466557984711, 'compression_ratio': 1.9153439153439153, 'no_speech_prob': 0.00497342087328434}, {'id': 703, 'seek': 450134, 'start': 4515.46, 'end': 4521.46, 'text': ' look in this table, I find that there is already an entry that therefore, I cannot schedule', 'tokens': [51070, 574, 294, 341, 3199, 11, 286, 915, 300, 456, 307, 1217, 364, 8729, 300, 4412, 11, 286, 2644, 7567, 51370], 'temperature': 0.0, 'avg_logprob': -0.1800466557984711, 'compression_ratio': 1.9153439153439153, 'no_speech_prob': 0.00497342087328434}, {'id': 704, 'seek': 450134, 'start': 4521.46, 'end': 4527.860000000001, 'text': ' any more operation, any more load store operation. So, similarly I see at time step t plus 1,', 'tokens': [51370, 604, 544, 6916, 11, 604, 544, 3677, 3531, 6916, 13, 407, 11, 14138, 286, 536, 412, 565, 1823, 256, 1804, 502, 11, 51690], 'temperature': 0.0, 'avg_logprob': -0.1800466557984711, 'compression_ratio': 1.9153439153439153, 'no_speech_prob': 0.00497342087328434}, {'id': 705, 'seek': 452786, 'start': 4527.86, 'end': 4534.86, 'text': ' what happens? Correct? May be a node u was scheduled in the floating point unit. If I', 'tokens': [50364, 437, 2314, 30, 12753, 30, 1891, 312, 257, 9984, 344, 390, 15678, 294, 264, 12607, 935, 4985, 13, 759, 286, 50714], 'temperature': 0.0, 'avg_logprob': -0.24195192076943137, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.011900798417627811}, {'id': 706, 'seek': 452786, 'start': 4534.94, 'end': 4539.86, 'text': ' have an integer operation, I can schedule this. If I have a load store operation, I', 'tokens': [50718, 362, 364, 24922, 6916, 11, 286, 393, 7567, 341, 13, 759, 286, 362, 257, 3677, 3531, 6916, 11, 286, 50964], 'temperature': 0.0, 'avg_logprob': -0.24195192076943137, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.011900798417627811}, {'id': 707, 'seek': 452786, 'start': 4539.86, 'end': 4544.66, 'text': ' can schedule this in time plus 1, but not a floating point up. So, you keep kind of', 'tokens': [50964, 393, 7567, 341, 294, 565, 1804, 502, 11, 457, 406, 257, 12607, 935, 493, 13, 407, 11, 291, 1066, 733, 295, 51204], 'temperature': 0.0, 'avg_logprob': -0.24195192076943137, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.011900798417627811}, {'id': 708, 'seek': 452786, 'start': 4544.66, 'end': 4551.66, 'text': ' updating this table and that tells you how your resources are being used. As far as the', 'tokens': [51204, 25113, 341, 3199, 293, 300, 5112, 291, 577, 428, 3593, 366, 885, 1143, 13, 1018, 1400, 382, 264, 51554], 'temperature': 0.0, 'avg_logprob': -0.24195192076943137, 'compression_ratio': 1.6634146341463414, 'no_speech_prob': 0.011900798417627811}, {'id': 709, 'seek': 455166, 'start': 4552.66, 'end': 4559.66, 'text': ' cycle based scheduler is concerned, it basically goes from t equal to 0 to some t equal to', 'tokens': [50414, 6586, 2361, 12000, 260, 307, 5922, 11, 309, 1936, 1709, 490, 256, 2681, 281, 1958, 281, 512, 256, 2681, 281, 50764], 'temperature': 0.0, 'avg_logprob': -0.1941380994073276, 'compression_ratio': 1.651376146788991, 'no_speech_prob': 0.02129749394953251}, {'id': 710, 'seek': 455166, 'start': 4560.42, 'end': 4566.74, 'text': ' k in the increasing order, keep scheduling the nodes. Let us later on see what is called', 'tokens': [50802, 350, 294, 264, 5662, 1668, 11, 1066, 29055, 264, 13891, 13, 961, 505, 1780, 322, 536, 437, 307, 1219, 51118], 'temperature': 0.0, 'avg_logprob': -0.1941380994073276, 'compression_ratio': 1.651376146788991, 'no_speech_prob': 0.02129749394953251}, {'id': 711, 'seek': 455166, 'start': 4566.74, 'end': 4571.74, 'text': ' an operation based scheduler, which will actually do things in a slightly different way.', 'tokens': [51118, 364, 6916, 2361, 12000, 260, 11, 597, 486, 767, 360, 721, 294, 257, 4748, 819, 636, 13, 51368], 'temperature': 0.0, 'avg_logprob': -0.1941380994073276, 'compression_ratio': 1.651376146788991, 'no_speech_prob': 0.02129749394953251}, {'id': 712, 'seek': 455166, 'start': 4571.74, 'end': 4578.74, 'text': ' That is the next slide. Any questions on this cycle based scheduler? No, right? Easy enough', 'tokens': [51368, 663, 307, 264, 958, 4137, 13, 2639, 1651, 322, 341, 6586, 2361, 12000, 260, 30, 883, 11, 558, 30, 16002, 1547, 51718], 'temperature': 0.0, 'avg_logprob': -0.1941380994073276, 'compression_ratio': 1.651376146788991, 'no_speech_prob': 0.02129749394953251}, {'id': 713, 'seek': 457874, 'start': 4579.74, 'end': 4585.74, 'text': ' to understand? Okay. So, the operation based scheduler works in a different way. It does', 'tokens': [50414, 281, 1223, 30, 1033, 13, 407, 11, 264, 6916, 2361, 12000, 260, 1985, 294, 257, 819, 636, 13, 467, 775, 50714], 'temperature': 0.0, 'avg_logprob': -0.2300262036530868, 'compression_ratio': 1.6118721461187215, 'no_speech_prob': 0.007927081547677517}, {'id': 714, 'seek': 457874, 'start': 4585.74, 'end': 4592.74, 'text': ' not have the notion of cycle time. Instead what it does is that you have the d d g and', 'tokens': [50714, 406, 362, 264, 10710, 295, 6586, 565, 13, 7156, 437, 309, 775, 307, 300, 291, 362, 264, 274, 274, 290, 293, 51064], 'temperature': 0.0, 'avg_logprob': -0.2300262036530868, 'compression_ratio': 1.6118721461187215, 'no_speech_prob': 0.007927081547677517}, {'id': 715, 'seek': 457874, 'start': 4592.98, 'end': 4599.98, 'text': ' then you have the for all the nodes, there is a priority function just like the LST minus', 'tokens': [51076, 550, 291, 362, 264, 337, 439, 264, 13891, 11, 456, 307, 257, 9365, 2445, 445, 411, 264, 441, 6840, 3175, 51426], 'temperature': 0.0, 'avg_logprob': -0.2300262036530868, 'compression_ratio': 1.6118721461187215, 'no_speech_prob': 0.007927081547677517}, {'id': 716, 'seek': 457874, 'start': 4600.86, 'end': 4607.34, 'text': ' EST kind of a priority function. Correct? So, every node has an assigned priority. Now,', 'tokens': [51470, 462, 6840, 733, 295, 257, 9365, 2445, 13, 12753, 30, 407, 11, 633, 9984, 575, 364, 13279, 9365, 13, 823, 11, 51794], 'temperature': 0.0, 'avg_logprob': -0.2300262036530868, 'compression_ratio': 1.6118721461187215, 'no_speech_prob': 0.007927081547677517}, {'id': 717, 'seek': 460734, 'start': 4607.34, 'end': 4613.9400000000005, 'text': ' what you do is that among all the nodes you find, this is what you try to do, right? You', 'tokens': [50364, 437, 291, 360, 307, 300, 3654, 439, 264, 13891, 291, 915, 11, 341, 307, 437, 291, 853, 281, 360, 11, 558, 30, 509, 50694], 'temperature': 0.0, 'avg_logprob': -0.21422433233880378, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.012519163079559803}, {'id': 718, 'seek': 460734, 'start': 4613.9400000000005, 'end': 4620.9400000000005, 'text': ' find, okay, so let us assume that for every node we have this notion of EST and LST, okay,', 'tokens': [50694, 915, 11, 1392, 11, 370, 718, 505, 6552, 300, 337, 633, 9984, 321, 362, 341, 10710, 295, 462, 6840, 293, 441, 6840, 11, 1392, 11, 51044], 'temperature': 0.0, 'avg_logprob': -0.21422433233880378, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.012519163079559803}, {'id': 719, 'seek': 460734, 'start': 4627.02, 'end': 4634.02, 'text': ' to start with. Now, what I do is that ready node is the set of source nodes in the set', 'tokens': [51348, 281, 722, 365, 13, 823, 11, 437, 286, 360, 307, 300, 1919, 9984, 307, 264, 992, 295, 4009, 13891, 294, 264, 992, 51698], 'temperature': 0.0, 'avg_logprob': -0.21422433233880378, 'compression_ratio': 1.5833333333333333, 'no_speech_prob': 0.012519163079559803}, {'id': 720, 'seek': 463734, 'start': 4637.54, 'end': 4643.78, 'text': ' of nodes. So, initially I have all the source nodes in the ready list and then I start off', 'tokens': [50374, 295, 13891, 13, 407, 11, 9105, 286, 362, 439, 264, 4009, 13891, 294, 264, 1919, 1329, 293, 550, 286, 722, 766, 50686], 'temperature': 0.0, 'avg_logprob': -0.2044581528548356, 'compression_ratio': 1.6875, 'no_speech_prob': 0.011275777593255043}, {'id': 721, 'seek': 463734, 'start': 4643.78, 'end': 4649.14, 'text': ' with an empty schedule, okay, and I continue to do this until I construct the schedule', 'tokens': [50686, 365, 364, 6707, 7567, 11, 1392, 11, 293, 286, 2354, 281, 360, 341, 1826, 286, 7690, 264, 7567, 50954], 'temperature': 0.0, 'avg_logprob': -0.2044581528548356, 'compression_ratio': 1.6875, 'no_speech_prob': 0.011275777593255043}, {'id': 722, 'seek': 463734, 'start': 4649.14, 'end': 4655.54, 'text': ' for all the nodes. Then what I do is that I do select the node with the highest priority', 'tokens': [50954, 337, 439, 264, 13891, 13, 1396, 437, 286, 360, 307, 300, 286, 360, 3048, 264, 9984, 365, 264, 6343, 9365, 51274], 'temperature': 0.0, 'avg_logprob': -0.2044581528548356, 'compression_ratio': 1.6875, 'no_speech_prob': 0.011275777593255043}, {'id': 723, 'seek': 463734, 'start': 4655.54, 'end': 4662.54, 'text': ' from the ready queue, right? Okay. So, now given this operation, what I try to do is', 'tokens': [51274, 490, 264, 1919, 18639, 11, 558, 30, 1033, 13, 407, 11, 586, 2212, 341, 6916, 11, 437, 286, 853, 281, 360, 307, 51624], 'temperature': 0.0, 'avg_logprob': -0.2044581528548356, 'compression_ratio': 1.6875, 'no_speech_prob': 0.011275777593255043}, {'id': 724, 'seek': 466254, 'start': 4663.42, 'end': 4670.42, 'text': ' that I now try to schedule this not in the current time step, but from its earliest time', 'tokens': [50408, 300, 286, 586, 853, 281, 7567, 341, 406, 294, 264, 2190, 565, 1823, 11, 457, 490, 1080, 20573, 565, 50758], 'temperature': 0.0, 'avg_logprob': -0.15806624163752017, 'compression_ratio': 1.9329896907216495, 'no_speech_prob': 0.005752517841756344}, {'id': 725, 'seek': 466254, 'start': 4670.86, 'end': 4677.86, 'text': ' step to its latest time step I try to schedule it or the maximum time I try to schedule this.', 'tokens': [50780, 1823, 281, 1080, 6792, 565, 1823, 286, 853, 281, 7567, 309, 420, 264, 6674, 565, 286, 853, 281, 7567, 341, 13, 51130], 'temperature': 0.0, 'avg_logprob': -0.15806624163752017, 'compression_ratio': 1.9329896907216495, 'no_speech_prob': 0.005752517841756344}, {'id': 726, 'seek': 466254, 'start': 4678.42, 'end': 4683.42, 'text': ' In other words, what happens is that you remember the resource graph that we talked about, sorry,', 'tokens': [51158, 682, 661, 2283, 11, 437, 2314, 307, 300, 291, 1604, 264, 7684, 4295, 300, 321, 2825, 466, 11, 2597, 11, 51408], 'temperature': 0.0, 'avg_logprob': -0.15806624163752017, 'compression_ratio': 1.9329896907216495, 'no_speech_prob': 0.005752517841756344}, {'id': 727, 'seek': 466254, 'start': 4683.42, 'end': 4690.26, 'text': ' right, the resource graph that we talked about, the table. So, if you are scheduling for that,', 'tokens': [51408, 558, 11, 264, 7684, 4295, 300, 321, 2825, 466, 11, 264, 3199, 13, 407, 11, 498, 291, 366, 29055, 337, 300, 11, 51750], 'temperature': 0.0, 'avg_logprob': -0.15806624163752017, 'compression_ratio': 1.9329896907216495, 'no_speech_prob': 0.005752517841756344}, {'id': 728, 'seek': 469026, 'start': 4690.26, 'end': 4697.26, 'text': ' then what I do is that, so this table has all these rows and columns. So, I take an', 'tokens': [50364, 550, 437, 286, 360, 307, 300, 11, 370, 341, 3199, 575, 439, 613, 13241, 293, 13766, 13, 407, 11, 286, 747, 364, 50714], 'temperature': 0.0, 'avg_logprob': -0.1780990182536922, 'compression_ratio': 1.6125, 'no_speech_prob': 0.04263529181480408}, {'id': 729, 'seek': 469026, 'start': 4705.02, 'end': 4711.02, 'text': ' operation V, I find out when is the earliest that it can get scheduled, correct? So, let', 'tokens': [51102, 6916, 691, 11, 286, 915, 484, 562, 307, 264, 20573, 300, 309, 393, 483, 15678, 11, 3006, 30, 407, 11, 718, 51402], 'temperature': 0.0, 'avg_logprob': -0.1780990182536922, 'compression_ratio': 1.6125, 'no_speech_prob': 0.04263529181480408}, {'id': 730, 'seek': 469026, 'start': 4711.02, 'end': 4717.42, 'text': ' us say if it can get scheduled at time step 0, I try to schedule this in time step 0,', 'tokens': [51402, 505, 584, 498, 309, 393, 483, 15678, 412, 565, 1823, 1958, 11, 286, 853, 281, 7567, 341, 294, 565, 1823, 1958, 11, 51722], 'temperature': 0.0, 'avg_logprob': -0.1780990182536922, 'compression_ratio': 1.6125, 'no_speech_prob': 0.04263529181480408}, {'id': 731, 'seek': 471742, 'start': 4717.62, 'end': 4724.62, 'text': ' correct? But let us say this operation V has an earliest start time of 0 and blah, blah,', 'tokens': [50374, 3006, 30, 583, 718, 505, 584, 341, 6916, 691, 575, 364, 20573, 722, 565, 295, 1958, 293, 12288, 11, 12288, 11, 50724], 'temperature': 0.0, 'avg_logprob': -0.16257909138997395, 'compression_ratio': 1.9227467811158798, 'no_speech_prob': 0.005910312291234732}, {'id': 732, 'seek': 471742, 'start': 4725.06, 'end': 4730.58, 'text': ' blah. I do not even worry about its latest start time for the time being, okay, right?', 'tokens': [50746, 12288, 13, 286, 360, 406, 754, 3292, 466, 1080, 6792, 722, 565, 337, 264, 565, 885, 11, 1392, 11, 558, 30, 51022], 'temperature': 0.0, 'avg_logprob': -0.16257909138997395, 'compression_ratio': 1.9227467811158798, 'no_speech_prob': 0.005910312291234732}, {'id': 733, 'seek': 471742, 'start': 4730.58, 'end': 4735.38, 'text': ' Now what I try to do is that I take this operation, I try to see if I can schedule this in time', 'tokens': [51022, 823, 437, 286, 853, 281, 360, 307, 300, 286, 747, 341, 6916, 11, 286, 853, 281, 536, 498, 286, 393, 7567, 341, 294, 565, 51262], 'temperature': 0.0, 'avg_logprob': -0.16257909138997395, 'compression_ratio': 1.9227467811158798, 'no_speech_prob': 0.005910312291234732}, {'id': 734, 'seek': 471742, 'start': 4735.38, 'end': 4740.14, 'text': ' step 0. Maybe this is a floating point operation and I see that there is already a floating', 'tokens': [51262, 1823, 1958, 13, 2704, 341, 307, 257, 12607, 935, 6916, 293, 286, 536, 300, 456, 307, 1217, 257, 12607, 51500], 'temperature': 0.0, 'avg_logprob': -0.16257909138997395, 'compression_ratio': 1.9227467811158798, 'no_speech_prob': 0.005910312291234732}, {'id': 735, 'seek': 471742, 'start': 4740.14, 'end': 4746.54, 'text': ' point operation in time step 0. Then I go to time step 1 or I go to time step 2 or I', 'tokens': [51500, 935, 6916, 294, 565, 1823, 1958, 13, 1396, 286, 352, 281, 565, 1823, 502, 420, 286, 352, 281, 565, 1823, 568, 420, 286, 51820], 'temperature': 0.0, 'avg_logprob': -0.16257909138997395, 'compression_ratio': 1.9227467811158798, 'no_speech_prob': 0.005910312291234732}, {'id': 736, 'seek': 474654, 'start': 4746.54, 'end': 4752.26, 'text': ' go to time step 3 and then try to schedule this wherever it is possible to schedule this.', 'tokens': [50364, 352, 281, 565, 1823, 805, 293, 550, 853, 281, 7567, 341, 8660, 309, 307, 1944, 281, 7567, 341, 13, 50650], 'temperature': 0.0, 'avg_logprob': -0.13212531872009964, 'compression_ratio': 1.8223350253807107, 'no_speech_prob': 0.0036908837500959635}, {'id': 737, 'seek': 474654, 'start': 4752.26, 'end': 4757.42, 'text': ' Let us say finally I find a place to schedule, I schedule it. Then I go and take the next', 'tokens': [50650, 961, 505, 584, 2721, 286, 915, 257, 1081, 281, 7567, 11, 286, 7567, 309, 13, 1396, 286, 352, 293, 747, 264, 958, 50908], 'temperature': 0.0, 'avg_logprob': -0.13212531872009964, 'compression_ratio': 1.8223350253807107, 'no_speech_prob': 0.0036908837500959635}, {'id': 738, 'seek': 474654, 'start': 4757.42, 'end': 4763.86, 'text': ' operation and then try to schedule. So, for each operation I try to find a time slot from', 'tokens': [50908, 6916, 293, 550, 853, 281, 7567, 13, 407, 11, 337, 1184, 6916, 286, 853, 281, 915, 257, 565, 14747, 490, 51230], 'temperature': 0.0, 'avg_logprob': -0.13212531872009964, 'compression_ratio': 1.8223350253807107, 'no_speech_prob': 0.0036908837500959635}, {'id': 739, 'seek': 474654, 'start': 4763.86, 'end': 4770.86, 'text': ' its earliest time step to the maximum possible time step where it can be scheduled, okay?', 'tokens': [51230, 1080, 20573, 565, 1823, 281, 264, 6674, 1944, 565, 1823, 689, 309, 393, 312, 15678, 11, 1392, 30, 51580], 'temperature': 0.0, 'avg_logprob': -0.13212531872009964, 'compression_ratio': 1.8223350253807107, 'no_speech_prob': 0.0036908837500959635}, {'id': 740, 'seek': 477086, 'start': 4771.0199999999995, 'end': 4778.0199999999995, 'text': ' Now let us see how do we update the ready list here, right? So, we now start adding', 'tokens': [50372, 823, 718, 505, 536, 577, 360, 321, 5623, 264, 1919, 1329, 510, 11, 558, 30, 407, 11, 321, 586, 722, 5127, 50722], 'temperature': 0.0, 'avg_logprob': -0.13293622129706925, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.03715476021170616}, {'id': 741, 'seek': 477086, 'start': 4779.86, 'end': 4786.86, 'text': ' all the nodes V such that, okay, there is an edge from U to V, right? V is the node', 'tokens': [50814, 439, 264, 13891, 691, 1270, 300, 11, 1392, 11, 456, 307, 364, 4691, 490, 624, 281, 691, 11, 558, 30, 691, 307, 264, 9984, 51164], 'temperature': 0.0, 'avg_logprob': -0.13293622129706925, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.03715476021170616}, {'id': 742, 'seek': 477086, 'start': 4787.78, 'end': 4793.38, 'text': ' that we have just completed execution. So, let us look at it in the following way. U', 'tokens': [51210, 300, 321, 362, 445, 7365, 15058, 13, 407, 11, 718, 505, 574, 412, 309, 294, 264, 3480, 636, 13, 624, 51490], 'temperature': 0.0, 'avg_logprob': -0.13293622129706925, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.03715476021170616}, {'id': 743, 'seek': 477086, 'start': 4793.38, 'end': 4800.38, 'text': ' is already scheduled and the scheduled time of U plus the delay of U is greater than the', 'tokens': [51490, 307, 1217, 15678, 293, 264, 15678, 565, 295, 624, 1804, 264, 8577, 295, 624, 307, 5044, 813, 264, 51840], 'temperature': 0.0, 'avg_logprob': -0.13293622129706925, 'compression_ratio': 1.6238095238095238, 'no_speech_prob': 0.03715476021170616}, {'id': 744, 'seek': 480038, 'start': 4800.78, 'end': 4805.14, 'text': ' cycle time. Well, this actually should not be cycle time, okay? Let us do one thing.', 'tokens': [50384, 6586, 565, 13, 1042, 11, 341, 767, 820, 406, 312, 6586, 565, 11, 1392, 30, 961, 505, 360, 472, 551, 13, 50602], 'temperature': 0.0, 'avg_logprob': -0.17230561200310202, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.005409943871200085}, {'id': 745, 'seek': 480038, 'start': 4805.14, 'end': 4809.1, 'text': ' I think there is something wrong here. We will probably stop here and then complete', 'tokens': [50602, 286, 519, 456, 307, 746, 2085, 510, 13, 492, 486, 1391, 1590, 510, 293, 550, 3566, 50800], 'temperature': 0.0, 'avg_logprob': -0.17230561200310202, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.005409943871200085}, {'id': 746, 'seek': 480038, 'start': 4809.1, 'end': 4814.1, 'text': ' because this does not work this way. This essentially tries to take each node and try', 'tokens': [50800, 570, 341, 775, 406, 589, 341, 636, 13, 639, 4476, 9898, 281, 747, 1184, 9984, 293, 853, 51050], 'temperature': 0.0, 'avg_logprob': -0.17230561200310202, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.005409943871200085}, {'id': 747, 'seek': 480038, 'start': 4814.1, 'end': 4819.900000000001, 'text': ' to schedule it between its earliest time and end wherever it is possible and then try to', 'tokens': [51050, 281, 7567, 309, 1296, 1080, 20573, 565, 293, 917, 8660, 309, 307, 1944, 293, 550, 853, 281, 51340], 'temperature': 0.0, 'avg_logprob': -0.17230561200310202, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.005409943871200085}, {'id': 748, 'seek': 480038, 'start': 4819.900000000001, 'end': 4824.42, 'text': ' adjust things. So, I will come back and then correct this tomorrow and then maybe we can', 'tokens': [51340, 4369, 721, 13, 407, 11, 286, 486, 808, 646, 293, 550, 3006, 341, 4153, 293, 550, 1310, 321, 393, 51566], 'temperature': 0.0, 'avg_logprob': -0.17230561200310202, 'compression_ratio': 1.7142857142857142, 'no_speech_prob': 0.005409943871200085}, {'id': 749, 'seek': 482442, 'start': 4824.42, 'end': 4830.34, 'text': ' discuss it, okay? We will probably stop here because this is more or less what I wanted', 'tokens': [50364, 2248, 309, 11, 1392, 30, 492, 486, 1391, 1590, 510, 570, 341, 307, 544, 420, 1570, 437, 286, 1415, 50660], 'temperature': 0.0, 'avg_logprob': -0.21472619455071945, 'compression_ratio': 1.5125628140703518, 'no_speech_prob': 0.07231106609106064}, {'id': 750, 'seek': 482442, 'start': 4830.34, 'end': 4835.7, 'text': ' to cover for the day. After this we have an example, but that example is not very specific', 'tokens': [50660, 281, 2060, 337, 264, 786, 13, 2381, 341, 321, 362, 364, 1365, 11, 457, 300, 1365, 307, 406, 588, 2685, 50928], 'temperature': 0.0, 'avg_logprob': -0.21472619455071945, 'compression_ratio': 1.5125628140703518, 'no_speech_prob': 0.07231106609106064}, {'id': 751, 'seek': 482442, 'start': 4835.7, 'end': 4840.78, 'text': ' to the earliest, I mean to the operation base or other things. Then we will go to global', 'tokens': [50928, 281, 264, 20573, 11, 286, 914, 281, 264, 6916, 3096, 420, 661, 721, 13, 1396, 321, 486, 352, 281, 4338, 51182], 'temperature': 0.0, 'avg_logprob': -0.21472619455071945, 'compression_ratio': 1.5125628140703518, 'no_speech_prob': 0.07231106609106064}, {'id': 752, 'seek': 482442, 'start': 4840.78, 'end': 4841.3, 'text': ' scheduling.', 'tokens': [51182, 29055, 13, 51208], 'temperature': 0.0, 'avg_logprob': -0.21472619455071945, 'compression_ratio': 1.5125628140703518, 'no_speech_prob': 0.07231106609106064}, {'id': 753, 'seek': 482442, 'start': 4841.3, 'end': 4842.46, 'text': ' So, let us stop here.', 'tokens': [51208, 407, 11, 718, 505, 1590, 510, 13, 51266], 'temperature': 0.0, 'avg_logprob': -0.21472619455071945, 'compression_ratio': 1.5125628140703518, 'no_speech_prob': 0.07231106609106064}]